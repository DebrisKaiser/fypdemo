"Authors","Author full names","Author(s) ID","Title","Year","Source title","Volume","Issue","Art. No.","Page start","Page end","Page count","Cited by","DOI","Link","Affiliations","Authors with affiliations","Abstract","Author Keywords","Index Keywords","Molecular Sequence Numbers","Chemicals/CAS","Tradenames","Manufacturers","Funding Details","Funding Texts","References","Correspondence Address","Editors","Publisher","Sponsors","Conference name","Conference date","Conference location","Conference code","ISSN","ISBN","CODEN","PubMed ID","Language of Original Document","Abbreviated Source Title","Document Type","Publication Stage","Open Access","Source","EID"
"San-Segundo R.; Echeverry-Correa J.D.; Salamea-Palacios C.; Lebai Lutfi S.; Pardo J.M.","San-Segundo, Rubén (8333266700); Echeverry-Correa, Julián David (26322401600); Salamea-Palacios, Cristian (56304388200); Lebai Lutfi, Syaheerah (27567802400); Pardo, José M. (57193752834)","8333266700; 26322401600; 56304388200; 27567802400; 57193752834","I-vector analysis for Gait-based Person Identification using smartphone inertial signals","2017","Pervasive and Mobile Computing","38","","","140","153","13","22","10.1016/j.pmcj.2016.09.007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994475509&doi=10.1016%2fj.pmcj.2016.09.007&partnerID=40&md5=77199d3596893808ae64ca7e6dd6184d","Speech Technology Group, E.T.S.I. Telecomunicación, UPM, Spain; Department of Electrical Engineering at Universidad Tecnológica de Pereira, Colombia; School of Computer Sciences, University Science of Malaysia, Penang, Malaysia","San-Segundo R., Speech Technology Group, E.T.S.I. Telecomunicación, UPM, Spain; Echeverry-Correa J.D., Department of Electrical Engineering at Universidad Tecnológica de Pereira, Colombia; Salamea-Palacios C., Speech Technology Group, E.T.S.I. Telecomunicación, UPM, Spain; Lebai Lutfi S., School of Computer Sciences, University Science of Malaysia, Penang, Malaysia; Pardo J.M., Speech Technology Group, E.T.S.I. Telecomunicación, UPM, Spain","This paper describes and evaluates an i-vector based approach for Gait-based Person Identification (GPI) using inertial signals from a smartphone. This approach includes two variability compensation strategies (Linear Discrimination Analysis (LDA) and Probabilistic LDA) for dealing with the gait variability due to different recording sessions or different activities carried out by the user. This study uses a public available dataset that includes recordings from 30 users performing three different activities: walking, walking-upstairs and walking-downstairs. The i-vector approach is compared to a Gaussian Mixture Model-Universal Background Model (GMM-UBM) system, providing significant performance improvements when incorporating the PLDA compensation strategy: the best result reports a User Recognition Error Rate (URER) of 17.7%, an Equal Error Rate (EER) of 6.1% and an F1-score of 82.7% with 30 enrolled users. For less than six enrolled users, the URER error decreases to 5%. © 2016 Elsevier B.V.","Gait recognition; I-vector analysis; Person identification; PLDA compensation; Smartphone inertial signals","Gaussian distribution; Object recognition; Smartphones; Speech recognition; Vectors; Compensation strategy; Gait recognition; Gaussian mixture model-universal background models; I vectors; Linear discrimination analysis; Performance improvements; Person identification; Variability compensation; Error compensation","","","","","ASLP-MULÁN, (TIN2014-54288-C4-1-R); NAVEGABLE; Ministerio de Ciencia e Innovación, MICINN, (DPI2014-53525-C3-2-R)","The work leading to these results has been supported by ASLP-MULÁN ( TIN2014-54288-C4-1-R ) and NAVEGABLE (MICINN, DPI2014-53525-C3-2-R ) projects. ","Johansson G., Visual perception of biological motion and a model for its analysis, Attention Percept. Psychophys., 1973, 14, pp. 201-211, (1973); Qinghan X., Technology review - Biometrics-Technology, Application, Challenge, and Computational Intelligence Solutions, IEEE Comput. Intell. Mag., 2, 2, pp. 5-25, (2007); Mjaaland B.B., Bours P., Gligoroski D., Walk the walk: attacking gait biometrics by imitation., in: Proceedings of the 13th International Conference on Information Security 2011, pp. 361-80, (2011); Matsumoto T., Matsumoto H., Yamada K., Hoshino S., Impact of artificial ”gummy” fingers on fingerprint systems., pp. 275-89, (2002); Anguita D., Ghio A., Oneto L., Parra X., Reyes-Ortiz J.L., A public domain dataset for human activity recognition using smartphones, 21th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning, (2013); San-Segundo R., Cordoba R., Ferreiros J., D'Haro L.F., Frequency Features and GMM-UBM approach for Gait-based Person Identification using Smartphone Inertial Signals, Pattern Recognit. Lett., 73, pp. 60-67, (2016); Lee T.K., Belkhatir M., Sanei S., A comprehensive review of past and present vision-based techniques for gait recognition, Multimedia Tools Appl., 72, 3, pp. 1-37, (2014); Yang S.X., Larsen P.K., Alkjaer T., Simonsen E.B., Lynnerup N., Variability and similarity of gait as evaluated by joint angles: implications for forensic gait analysis, J. For. Sci., 59, 2, pp. 494-504, (2014); Ariyanto G., Nixon M.S., Marionette mass–spring model for 3D gait biometrics., in: 5th IAPR International Conference on Biometrics (ICB)IEEE 2012, pp. 354-359, (2012); Shotton J., Sharp T., Kipman A., Fitzgibbon A., Finocchio M., Blake A., Cook M., Moore R., Real-time human pose recognition in parts from single depth images, IEEE Conference on Computer Vision and Pattern Recognition, 2011, pp. 1297-1304, (2011); Milovanovic M., Minovic M., Starcevic D., Walking in colors: human gait recognition using kinect and CBIR, IEEE Multimedia, 20, 4, pp. 28-36, (2013); Chattopadhyay P., Sural S., Mukherjee J., Frontal gait recognition from occluded scenes, Pattern Recognit. Lett., 63, pp. 9-15, (2015); Ng H., Tong H., Tan W.H., Tzen-Vun T., Chon P., Abdullah J., Human identification based on extracted gait features, Int. J. New Comput. Archit. Appl. (IJNCAA), 1, 2, pp. 358-370, (2011); Liu J., Zheng N., Xiong L., Silhouette quality quantification for gait sequence analysis and recognition, Signal Process., 89, 7, pp. 1417-1427, (2009); Arora P., Srivastava S., Gait recognition using gait Gaussian image, 2nd International Conference on Signal Processing and Integrated Networks, 2015, SPIN 2015, pp. 915-918, (2015); Das Choudhury S., Tjahjad, Silhouette-based gait recognition using Procrustes shape analysis and elliptic Fourier descriptors, Pattern Recognit., 45, 9, pp. 3414-3426, (2012); Zeng W., Wang C., Yang F., Silhouette-based gait recognition via deterministic learning, Pattern Recognit., 47, 11, pp. 3568-3584, (2014); Martin-Felez R., Xiang T., Uncooperative gait recognition by learning to rank, Pattern Recognit., 47, 12, pp. 3793-3806, (2014); Zhang L., Zhang L., Tao D., Du B., A sparse and discriminative tensor to vector projection for human gait feature representation, Signal Process., 106, pp. 245-252, (2015); Ailisto H.J., Lindholm M., Mantyjarvi J., Vildjiounaite E., Makela S.M., Identifying people from gait pattern with accelerometers., in: Proceedings of SPIE, 5779, pp. 7-14, (2005); Gafurov D., Helkala K., Soendrol T., Gait recognition using acceleration from mems., in: The first International Conference on Availability, Reliability and Security 2006, (2006); Ngo T.T., Makihara Y., Nagahara H., Mukaigawa Y., Yagi Y., Similar gait action recognition using an inertial sensor, Pattern Recognit., 48, 4, pp. 1289-1301, (2015); Derawi M., Bours P., Holien K., Improved cycle detection for accelerometer based gait authentication., in: Sixth International Conference on Intelligent Information Hiding and Multimedia Signal Processing 2010, pp. 312-7, (2010); Derawi M., Nickel C., Bours P., Busch C., Unobtrusive user-authentication on mobile phones using biometric gait recognition., in: Sixth International Conference on Intelligent Information Hiding and Multimedia Signal Processing 2010, pp. 306-11, (2010); Frank J., Mannor S., Precup D., Activity and gait recognition with time-delay embeddings., in: Proceedings of the Twenty-Fourth AAAI Conference on Artificial Intelligence 2010, (2010); Kwapisz J., Weiss G., Moore S., Cell phone-based biometric identification., in: Fourth IEEE International Conference on Biometrics: Theory Applications and Systems 2010, pp. 1-7, (2010); Mannini A., Sabatini A.M., Machine learning methods for classifying human physical activity from on-body accelerometers, Sensors, 10, 2, pp. 1154-1175, (2010); Vinh L.T., Lee S., Le H.X., Ngo H.Q., Kim H.I., Han M., Lee Y.-K., Semi-markov conditional random fields for accelerometer-based activity recognition, Appl. Intell., 35, 2, pp. 226-241, (2011); Holien K., Gait recognition under non-standard circumstances, (2008); Nickel C., Derawi M., Bours P., Busch C., Scenario test for accelerometer-based biometric gait recognition., in: 3rd International Workshop on Security and Communication Networks 2011, (2011); Bours P., Shrestha R., Eigensteps: a giant leap for gait recognition., in: 2nd International Workshop on Security and Communication Networks 2010, pp. 1-6, (2010); Gafurov D., Performance and security analysis of gait-based user authentication, (2008); Derawi M., Bours P., Gait and activity recognition using commercial phones, Comput. Secur., 39, pp. 137-144, (2013); Kenny P., Boulianne G., Ouellet P., Dumouchel P., Joint factor analysis versus Eigenchannels in speaker recognition, IEEE Trans. Audio Speech Lang. Process., 15, 4, pp. 1435-1447, (2007); Solomonoff A., Campbell W., Boardman I., Advances in channel compensation for SVM speaker recognition, Proc. ICASSP, vol. 1, 2005, pp. 629-632, (2005); Dehak N., Kenny P., Dehak R., Dumouchel P., Ouellet P., Frontend factor analysis for speaker verification, IEEE Trans. Audio Speech Lang. Process., 19, 99, pp. 788-798, (2010); Senoussaoui M., Kenny P., Dehak N., Dumouchel P., An i-vector Extractor Suitable for Speaker Recognition with both Microphone and Telephone Speech, Proc Odyssey Speaker and Language Recognition Workshop, Brno, Czech Republic, June 2010, (2010); Garcia-Romero G., Espy-Wilson C.Y., Analysis of i-vector length normalization in speaker recognition systems, Proc. INTERSPEECH, Florence, pp. 249-252, (2011); San-Segundo R., Montero J.M., Barra-Chicote R., Fernandez F., Pardo J.M., Feature extraction from smartphone inertial signals for human activity segmentation, Signal Process., 120, pp. 359-372, (2016); Sadjadi S.O., Slaney M., Heck L., MSR Identity Toolbox: A MATLAB Toolbox for Speaker Recognition Research. Version 1.0. Technical Report, (2013); Kenny P., Ouellet P., Dehak N., Gupta V., Dumouchel P., A study of interspeaker variability in speaker verification, IEEE Trans. Audio Speech Lang. Process., 16, 5, pp. 980-988, (2008); Kenny P., Boulianne G., Dumouchel P., Eigenvoice modeling with sparse training data, IEEE Trans. Speech Audio Process., 13, 3, pp. 345-354, (2005); Dehak N., Dehak R., Kenny P., Brummer N., Ouellet P., Dumouchel P., pp. 1559-1562, (2009); Prince S.J.D., Elder J.H., Probabilistic linear discriminant analysis for inferences about identity., Computer Vision, 2007. ICCV 2007. IEEE 11th International Conference on, pp. 1-8, (2007); Fawcett T., An introduction to ROC analysis, Pattern Recognit. Lett., 27, pp. 861-874, (2006); Martin A.F., Et al., The det curve in assessment of detection task performance, in: Proc. Eurospeech ’97, Rhodes, Greece, September 1997, 4, pp. 1899-1903","R. San-Segundo; E.T.S.I. Telecomunicación, Ciudad Universitaria SN, Madrid, 28040, Spain; email: ruben.sansegundo@upm.es","","Elsevier B.V.","","","","","","15741192","","","","English","Pervasive Mob. Comput.","Article","Final","","Scopus","2-s2.0-84994475509"
"Ahmad Z.; Lutfi S.L.; Kushan A.L.; Khairuddin M.H.; Zolkeplay A.F.; Rahmat M.H.; Mishan M.T.","Ahmad, Zaaba (35172590500); Lutfi, Syaheerah Lebai (27567802400); Kushan, Albin Lemuel (57196192361); Khairuddin, Mohamad Hafiz (56104924500); Zolkeplay, Anwar Farhan (57196191913); Rahmat, Mohammad Hafidz (55837692600); Mishan, Mohd Taufik (57196186572)","35172590500; 27567802400; 57196192361; 56104924500; 57196191913; 55837692600; 57196186572","Construction of the Malay language psychometric properties using LIWC from facebook statuses","2017","Advanced Science Letters","23","8","","7911","7914","3","2","10.1166/asl.2017.9607","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032213347&doi=10.1166%2fasl.2017.9607&partnerID=40&md5=e3111c537e37b555460cd5778addb456","Faculty of Computer Science and Mathematics, Universiti Teknologi MARA (UiTM) Melaka Kampus Jasin, Merlimau, 77300, Melaka, Malaysia; School of Computer Sciences, Universiti Sains Malaysia, Minden, 11800, Penang, Malaysia","Ahmad Z., Faculty of Computer Science and Mathematics, Universiti Teknologi MARA (UiTM) Melaka Kampus Jasin, Merlimau, 77300, Melaka, Malaysia; Lutfi S.L., School of Computer Sciences, Universiti Sains Malaysia, Minden, 11800, Penang, Malaysia; Kushan A.L., Faculty of Computer Science and Mathematics, Universiti Teknologi MARA (UiTM) Melaka Kampus Jasin, Merlimau, 77300, Melaka, Malaysia; Khairuddin M.H., Faculty of Computer Science and Mathematics, Universiti Teknologi MARA (UiTM) Melaka Kampus Jasin, Merlimau, 77300, Melaka, Malaysia; Zolkeplay A.F., Faculty of Computer Science and Mathematics, Universiti Teknologi MARA (UiTM) Melaka Kampus Jasin, Merlimau, 77300, Melaka, Malaysia; Rahmat M.H., Faculty of Computer Science and Mathematics, Universiti Teknologi MARA (UiTM) Melaka Kampus Jasin, Merlimau, 77300, Melaka, Malaysia; Mishan M.T., Faculty of Computer Science and Mathematics, Universiti Teknologi MARA (UiTM) Melaka Kampus Jasin, Merlimau, 77300, Melaka, Malaysia","This work aims at constructing a Malay language psychometric dictionary from Facebook statuses for LIWC by using the direct translation approach. The linguistic were obtained from 160 Malaysian Facebook users with an extracted textual data derived from 12573 wall-posted statuses. The jury method is used to assign each word to its correct category by comparing the direct translation of the word in Malay versus the English word in the English psychometric dictionary. LIWC classifies words by categories thus assigning the correct ones to the most precise translations and usage are essential. The work successfully categorized 2820 Malay words from the Malaysian Facebook statuses. This methodological note declares the creation of the Malay language version of the LIWC and the exemplary application of the dictionary in classifying personality of extraversion of the Malaysian Facebook users. The constructed Malay LIWC dictionary can be applied to any natural language processing framework or machine learning area that focuses on mining the Malay text language. © 2017 American Scientific Publishers. All rights reserved.","Facebook; Machine learning; Malay language; Malay LIWC; Natural language processing; Psychometric properties; Sentiment analysis; Text classification","","","","","","","","Connolly T., C. Begg Database Systems: A Practical Approach to Design, Implementation, and Management, pp. 1280-1281, (2010); Tausczik Y.R., Pennebaker J.W., Journal of Language and Social Psychology, 29, 24, (2010); Ahmad Z., Prediction Model of Extraversion and Neuroticism of Malaysian Facebook Users, (2015); Pennebaker J.W., Francis M.E., Booth R.J., Linguistic Inquiry and Word Count: LIWC 2001, 71, (2001); Gill A.J., Nowson S., Oberlander J., What Are They Blogging About? Personality, Topic and Motivation in Blogs, ICWSM, (2009); Golbeck J., Robles C., Turner K., Predicting personality with social media, Proceedings of the 2011 Annual Conference Extended Abstracts on Human Factors in Computing Systems - CHI EA ’11, (2011); Golbeck J., Robles C., Edmondson M., Turner K., Predicting personality from twitter, 2011 IEEE Third International Conference on Privacy, Security, Risk and Trust (PASSAT) and 2011 IEEE Third Inernational Conference on Social Computing (Socialcom), pp. 149-156, (2011); Mairesse F., Walker M.A., Mehl M.R., Moore R.K., Journal of Artificial Intelligence Research, (2007); Pennebaker J.W., Chung C.K., Ireland M., Gonzales A., Booth R.J., The Development and Psychometric Properties of LIWC2007, (2007); Ramirez-Esparza N., Pennebaker J.W., Andrea Garcia F., Suria R., Revista Mexicana De Psicologia, 24, (2007); Wolf M., Horn A.B., Mehl M.R., Haug S., Pennebaker J.W., Kordy H., Diagnostica, 54, (2008); Laney M.O., The Introvert Advantage: How to Thrive in an Extrovert World, (2002); Olakitan O.O., International Business and Management, 3, (2011); Rothmann S., Coetzer E.P., SA Journal of Industrial Psychology, 29, (2003); Beukeboom C.J., Tanis M., Vermeulen I.E., Journal of Language and Social Psychology, 32, (2013); Guidelines U., Birkbeck ePrints: An open access repository of the research output of Birkbeck College Dewaele, The Effects of Trait Emotional Intelligence and Sociobiographical Variables on Communicative An, (2008); Heylighen F., Dewaele J.-M., Foundations of Science, 7, (2002); Gill A.J., Oberlander J., Austin E., Personality and Individual Differences, 40, (2006); Yarkoni T., Journal of Research in Personality, 44, (2010); Carr C.T., Walther J.B., Journal of Computer-Mediated Communication, 19, (2014); Sheldon P., Cyberpsychology: Journal of Psychosocial Research on Cyberspace, 3, (2009)","","","American Scientific Publishers","","","","","","19366612","","","","English","Adv. Sci. Lett.","Article","Final","","Scopus","2-s2.0-85032213347"
"Lutfi S.L.; Fernández-Martínez F.; Lorenzo-Trueba J.; Barra-Chicote R.; Montero J.M.","Lutfi, Syaheerah Lebai (27567802400); Fernández-Martínez, Fernando (6602973640); Lorenzo-Trueba, Jaime (36986671800); Barra-Chicote, Roberto (27567444800); Montero, Juan Manuel (55960772400)","27567802400; 6602973640; 36986671800; 27567444800; 55960772400","I Feel You: The design and evaluation of a domotic affect-sensitive spoken conversational agent","2013","Sensors (Switzerland)","13","8","","10519","10538","19","11","10.3390/s130810519","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84923002780&doi=10.3390%2fs130810519&partnerID=40&md5=102ae58e35bc033a1be9514d0295b841","School of Computer Sciences, University Science of Malaysia, Penang, 11800, Malaysia; Departamento de Teoría de la Señal y Comunicaciones, Universidad Carlos III de Madrid, Madrid, 28911, Spain; Grupo de Tecnología del Habla, Universidad Politécnica de Madrid, Madrid, 28040, Spain","Lutfi S.L., School of Computer Sciences, University Science of Malaysia, Penang, 11800, Malaysia; Fernández-Martínez F., Departamento de Teoría de la Señal y Comunicaciones, Universidad Carlos III de Madrid, Madrid, 28911, Spain; Lorenzo-Trueba J., Grupo de Tecnología del Habla, Universidad Politécnica de Madrid, Madrid, 28040, Spain; Barra-Chicote R., Grupo de Tecnología del Habla, Universidad Politécnica de Madrid, Madrid, 28040, Spain; Montero J.M., Grupo de Tecnología del Habla, Universidad Politécnica de Madrid, Madrid, 28040, Spain","We describe the work on infusion of emotion into a limited-task autonomous spoken conversational agent situated in the domestic environment, using a need-inspired task-independent emotion model (NEMO). In order to demonstrate the generation of affect through the use of the model, we describe the work of integrating it with a natural-language mixed-initiative HiFi-control spoken conversational agent (SCA). NEMO and the host system communicate externally, removing the need for the Dialog Manager to be modified, as is done in most existing dialog systems, in order to be adaptive. The first part of the paper concerns the integration between NEMO and the host agent. The second part summarizes the work on automatic affect prediction, namely, frustration and contentment, from dialog features, a non-conventional source, in the attempt of moving towards a more user-centric approach. The final part reports the evaluation results obtained from a user study, in which both versions of the agent (non-adaptive and emotionally-adaptive) were compared. The results provide substantial evidences with respect to the benefits of adding emotion in a spoken conversational agent, especially in mitigating users’ frustrations and, ultimately, improving their satisfaction. © 2013 by the authors; licensee MDPI, Basel, Switzerland.","Affect prediction; Affective agents; Contentment; Conversational features; Domotic applications; Emotion design and evaluation; Emotion model; Frustration; Spoken conversational agents; User satisfaction","Contentment; Conversational agents; Conversational features; Design and evaluations; Emotion modeling; Frustration; User satisfaction; Autonomous agents","","","","","Seventh Framework Programme, FP7, (248765, 287678)","","Lutfi S., Barra-Chicote R., Lucas-Cuesta J., Montero J., NEMO: Need-Inspired Emotional Expressions within a Task-Independent Framework, Proceedings of Brain Inspired Cognitive Systems (BICS), (2010); Lucas-Cuesta J., Ferreiros J., Fernandez-Martinez F., Echeverry J., Lutfi S.L., On the dynamic adaptation of language models based on dialogue information, Expect Syst. Appl, 40, pp. 1069-1085, (2012); Hervas R., Bravo J., Fontecha J.A., Context model based on ontological languages: A proposal for information visualization, J. Univ. Comput. Sci, 16, pp. 1539-1555, (2010); Garcia-Vazquez J.P., Rodriguez M.D., Tentori M.E., Saldana D., Andrade A.G., Espinoza A.N., An agent-based architecture for developing activity-aware systems for assisting elderly, J. Univ. Comput. Sci, 16, pp. 1500-1520, (2010); Miori V., Russo D., Concordia C., Meeting people’s needs in a fully interoperable domotic environment, Sensors, 12, pp. 6802-6824, (2012); Fernandez-Martinez F., Zablotskaya K., Minker W., Text categorization methods for automatic estimation of verbal intelligence, Expect Syst. Appl, 39, pp. 9807-9820, (2012); D'Mello S.K., Craig S.D., Witherspoon A., McDaniel B., Graesser A., Automatic detection of learner’s affect from conversational cues, User Model User Adap. Interact, 18, pp. 45-80, (2008); Forbes-Riley K., Litman D., Designing and evaluating a wizarded uncertainty-adaptive spoken dialogue tutoring system, Comput. Speech Lang, 25, pp. 105-126, (2011); Forbes-Riley K., Litman D., Benefits and challenges of real-time uncertainty detection and adaptation in a spoken dialogue computer tutor, Speech Commun, 53, pp. 1115-1136, (2011); McQuiggan S.W., Robison J.L., Lester J.C., Affective transitions in narrative-centered learning environments, Lect. Note. Comput. Sci, 5091, pp. 490-499, (2008); Robison J., Rowe J., McQuiggan S., Lester J., Predicting user psychological characteristics from interactions with empathetic virtual agents, Lect. Note. Comput. Sci, 5773, pp. 330-336, (2009); Bianchi-Berthouze N., Kim W.W., Patel D., Does body movement engage you more in digital game play? And why, Lect. Note. Comput. Sci, 4738, pp. 102-113, (2007); Yildirim S., Narayanan S., Potamianos A., Detecting emotional state of a child in a conversational computer game. Comput, Speech Lang, 25, pp. 29-44, (2011); Rani P., Sarkar N., Adams J., Anxiety-based affective communication for implicit human-machine interaction, Adv. Eng. Inform, 21, pp. 323-334, (2007); Klein J., Moon Y., Picard R., This computer responds to user frustration: Theory, design and results, Interact. Comput, 14, pp. 119-140, (2002); Laukka P., Neiberg D., Forsell M., Karlsson I., Elenius K., Expression of affect in spontaneous speech: Acoustic correlates and automatic detection of irritation and resignation, Comput. Speech Lang, 25, pp. 84-104, (2011); Callejas Z., Lopez-Cozar R., Influence of contextual information in emotion annotation for spoken dialogue systems, Speech Commun, 50, pp. 416-433, (2008); Lopez-Cozar R., Silovsky J., Griol D., New Technique for Recognition of User Emotional States in Spoken Dialog Systems, Proceedings of the 11Th Anual Meeting of the Special Interest Group on Discourse and Dialog (SIGDIAL), pp. 281-288, (2010); Dautenhahn K., Socially Intelligent Agents in Human Primate Culture, Agent Culture: Human-Agent Interaction in a Multicultural World, pp. 45-71, (2004); Sung J.Y., Guo L., Grinter R.E., Christensen H.I., My roomba is rambo: Intimate home appliances, Lect. Note. Comput. Sci, 4717, pp. 145-162, (2007); Edlund J., Gustafson J., Heldner M., Hjalmarsson A., Towards human-like spoken dialogue systems, Speech Commun, 50, pp. 630-645, (2008); Reeves B., Nass C., The Media Equation: How People Treat Computers, Television and New Media like Real People and Places, (1996); Fernandez-Martinez F., Ferreiros J., Lucas-Cuesta J.M., Echeverry J.D., San-Segundo R., Cordoba R., Flexible, Robust and Dynamic Dialogue Modeling with a Speech Dialogue Interface for Controlling a Hi-Fi Audio System, Proceedings of the IEEE Workshop on Database and Expert Systems Applications, (2010); Sanz-Moreno C., Lutfi S., Barra-Chicote R., Lucas-Cuesta J., Montero J., Desarrollo de un asistente domótico emocional inteligente, Proceedings of XIX Jornadas Telecom I+D, (2009); Lorenzo-Trueba J., Watts O., Barra-Chicote R., Yamagishi J., King S., Montero J.M., Simple4All proposals for the Albayzin Evaluations in Speech Synthesis, Proceedings of VII Jornadas De Tecnología Del Habla (Iberspeech2012), (2012); Ekman P., Friesen W., The Facial Action Coding System: A Technique for the Measurement of Facial Movement, (1978); Lutfi S.L., Fernandez-Martinez F., Lopez-Lebonjuan L., A satisfaction-based model for affect recognition from conversational features in spoken dialog systems, Speech Commun, 55, pp. 825-840, (2013); Bailey J.E., Pearson S.W., Development of a tool for measuring and analyzing computer user satisfaction, Manag. Sci, 24, pp. 530-545, (1983); Doll W.J., Torkzadeh G., The measurement of end-user computing satisfaction, MIS Q, 12, pp. 259-274, (1988); Locke E.A., The Nature and Causes of Job Satisfaction, (1976); Gelbrich K., Beyond just being dissatisfied: How angry and helpless customers react to failures when using self-service technologies, Schmalenbach Bus. Rev, 61, pp. 40-59, (2009); Kernbach S., Schutte N.S., The impact of service provider emotional intelligence on customer satisfaction, J. Serv. Market, 19, 7, pp. 438-444, (2005); Fernandez-Martinez F., Blazquez J., Ferreiros J., Barra-Chicote R., Macias-Guarasa J., Lucas-Cuesta J.M., Evaluation of a Spoken Dialog System for controlling a HiFi Audio System, Proceedings of the IEEE Workshop on Spoken Language Technology, (2008); Fernandez-Martinez F., Lucas-Cuesta J.M., Chicote R.B., Ferreiros J., Macias-Guarasa J., HIFI-AV: An Audio-Visual Corpus for Spoken Language Human-Machine Dialogue Research in Spanish, Proceedings of the Seventh Conference on International Language Resources and Evaluation, (2010); Witten I.H., Frank E., Data Mining: Practical Machine Learning Tools and Techniques, (2005); Callejas Z., Lopez-Cozar R., On the use of aappa coefficients to measure the reliability of the annotation of non-acted emotions, Lect. Note. Comput. Sci, 5078, pp. 221-232, (2008); Field A., Discovering Statistics Using SPSS, (2005); Acosta J.C., Ward N.G., Achieving rapport with turn-by-turn, user-responsive emotional colouring, Speech Commun, 53, pp. 1137-1148, (2011)","S.L. Lutfi; School of Computer Sciences, University Science of Malaysia, Penang, 11800, Malaysia; email: syaheerah@cs.usm.my","","MDPI AG","","","","","","14248220","","","23945740","English","Sensors","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-84923002780"
"Al Qudah M.; Mohamed A.; Lutfi S.","Al Qudah, Mustafa (57222567501); Mohamed, Ahmad (57190968285); Lutfi, Syaheerah (27567802400)","57222567501; 57190968285; 27567802400","Analysis of Facial Occlusion Challenge in Thermal Images for Human Affective State Recognition","2023","Sensors","23","7","3513","","","","1","10.3390/s23073513","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152352283&doi=10.3390%2fs23073513&partnerID=40&md5=51425677df6c40edb11a0b9b97668eb3","School of Computer Sciences, Universiti Sains Malaysia, Penang, Gelugor, 11800, Malaysia; Department of Computer Science, College of Science and Humanities in Al-Sulail, Prince Sattam bin Abdulaziz University, Kharj, 16278, Saudi Arabia","Al Qudah M., School of Computer Sciences, Universiti Sains Malaysia, Penang, Gelugor, 11800, Malaysia, Department of Computer Science, College of Science and Humanities in Al-Sulail, Prince Sattam bin Abdulaziz University, Kharj, 16278, Saudi Arabia; Mohamed A., School of Computer Sciences, Universiti Sains Malaysia, Penang, Gelugor, 11800, Malaysia; Lutfi S., School of Computer Sciences, Universiti Sains Malaysia, Penang, Gelugor, 11800, Malaysia","Several studies have been conducted using both visual and thermal facial images to identify human affective states. Despite the advantages of thermal facial images in recognizing spontaneous human affects, few studies have focused on facial occlusion challenges in thermal images, particularly eyeglasses and facial hair occlusion. As a result, three classification models are proposed in this paper to address the problem of thermal occlusion in facial images, with six basic spontaneous emotions being classified. The first proposed model in this paper is based on six main facial regions, including the forehead, tip of the nose, cheeks, mouth, and chin. The second model deconstructs the six main facial regions into multiple subregions to investigate the efficacy of subregions in recognizing the human affective state. The third proposed model in this paper uses selected facial subregions, free of eyeglasses and facial hair (beard, mustaches). Nine statistical features on apex and onset thermal images are implemented. Furthermore, four feature selection techniques with two classification algorithms are proposed for a further investigation. According to the comparative analysis presented in this paper, the results obtained from the three proposed modalities were promising and comparable to those of other studies. © 2023 by the authors.","affects; emotion; eyeglass; occlusion; recognition; thermal","Algorithms; Emotions; Face; Facial Expression; Humans; Mouth; Eyeglasses; Face recognition; Thermoanalysis; Affect; Affective state; Emotion; Facial images; Facial occlusions; Facial regions; Occlusion; Recognition; Thermal; Thermal images; algorithm; diagnostic imaging; emotion; face; facial expression; human; mouth; Emotion Recognition","","","","","Ministry of Higher Education, Malaysia, MOHE, (FRGS/1/2020/STG07/USM/02/12)","This work was supported by the Ministry of Higher Education Malaysia for Fundamental Research Grant Scheme with project code: FRGS/1/2020/STG07/USM/02/12.","Shouse E., Feeling, Emotion, Affect, M/C J, 8, (2005); Nayak S., Panda S.K., Uttarkabat S., A Non-contact Framework based on Thermal and Visual Imaging for Classification of Affective States during HCI, Proceedings of the 2020 4th International Conference on Trends in Electronics and Informatics (ICOEI), pp. 653-660; Desideri L., Ottaviani C., Malavasi M., di Marzio R., Bonifacci P., Emotional processes in human-robot interaction during brief cognitive testing, Comput. Human Behav, 90, pp. 331-342, (2019); Lee M.S., Cho Y.R., Lee Y.K., Pae D.S., Lim M.T., Kang T.K., PPG and EMG based emotion recognition using convolutional neural network, Proceedings of the 16th International Conference on Informatics in Control, Automation and Robotics, Prague, Czech Republic, 29 July 2019, pp. 595-600, (2019); Nancarrow A.F., Gilpin A.T., Thibodeau R.B., Farrell C.B., Knowing what others know: Linking deception detection, emotion knowledge, and Theory of Mind in preschool, Infant Child Dev, 27, (2018); Rooj S., Antesh U., Bhattacharya S., Routray A., Mandal M.K., Emotion Classification of Facial Thermal Images using Sparse Coded Filters, Proceedings of the IECON 2020 The 46th Annual Conference of the IEEE Industrial Electronics Society, pp. 453-458; Chen C.-H., Lee I.J., Lin L.-Y., Augmented reality-based self-facial modeling to promote the emotional expression and social skills of adolescents with autism spectrum disorders, Res. Dev. Disabil, 36, pp. 396-403, (2015); Usman M., Evans R., Saatchi R., Kingshott R., Elphick H., Non-invasive respiration monitoring by thermal imaging to detect sleep apnoea, Proceedings of the 32nd International Congress and Exhibition on Condition Monitoring and Diagnostic Engineering Management; Huang Y., Chen F., Lv S., Wang X., Facial expression recognition: A survey, Symmetry, 11, (2019); Mohd M.N.H., Kashima M., Sato K., Watanabe M., Mental stress recognition based on non-invasive and non-contact measurement from stereo thermal and visible sensors, Int. J. Affect. Eng, 14, pp. 9-17, (2015); Nguyen T., Tran K., Nguyen H., Towards thermal region of interest for human emotion estimation, Proceedings of the 2018 10th International Conference on Knowledge and Systems Engineering (KSE), pp. 152-157; Wang S., Pan B., Chen H., Ji Q., Thermal Augmented Expression Recognition, IEEE Trans Cybern, 48, pp. 2203-2214, (2018); Wang S., He M., Gao Z., He S., Ji Q., Emotion recognition from thermal infrared images using deep Boltzmann machine, Front. Comput. Sci, 8, pp. 609-618, (2014); Yan X., Andrews T.J., Jenkins R., Young A.W., Cross-cultural differences and similarities underlying other-race effects for facial identity and expression, Q. J. Exp. Psychol, 62, (2016); Wang S., Liu Z., Wang Z., Wu G., Shen P., He S., Wang X., Analyses of a Multimodal Spontaneous Facial Expression Database, IEEE Trans. Affect. Comput, 4, pp. 34-46, (2013); Bhowmik M.K., Saha P., Singha A., Bhattacharjee D., Dutta P., Enhancement of robustness of face recognition system through reduced gaussianity in Log-ICA, Expert Syst. Appl, 116, pp. 96-107, (2019); Zhang X., Yin L., Cohn J.F., Canavan S., Reale M., Horowitz A., Liu P., Girard J.M., Bp4d-spontaneous: A high-resolution spontaneous 3d dynamic facial expression database, Image Vis. Comput, 32, pp. 692-706, (2014); Al Qudah M.M., Mohamed A.S., Lutfi S.L., Affective State Recognition Using Thermal-Based Imaging: A Survey, Comput. Syst. Sci. Eng, 37, pp. 47-62, (2021); Wang Y., Jiang X., Yang M., Zhang D., Yi X., Nguyen H., Kotani K., Chen F., Le B., Estimation of human emotions using thermal facial information, Proceedings of the 5th International Conference on Graphic and Image Processing (ICGIP 2013); Nguyen H., Chen F., Kotani K., Le B., Fusion of visible images and thermal image sequences for automated facial emotion estimation, J. Mobile Multimed, 10, pp. 294-308, (2014); Abd Latif M., Yusof H.M., Sidek S., Rusli N., Thermal imaging based affective state recognition, Proceedings of the 2015 IEEE International Symposium on Robotics and Intelligent Sensors (IRIS), pp. 214-219; Saha P., Bhattacharjee D., De B.K., Nasipuri M., A Thermal Blended Facial Expression Analysis and Recognition System Using Deformed Thermal Facial Areas, Int. J. Image Graph, 22, (2022); Basu A., Routray A., Shit S., Deb A.K., Human emotion recognition from facial thermal image based on fused statistical feature and multi-class SVM, Proceedings of the 2015 Annual IEEE India Conference (INDICON), pp. 1-5; Goulart C., Valadao C., Delisle-Rodriguez D., Caldeira E., Bastos T., Emotion analysis in children through facial emissivity of infrared thermal imaging, PLoS ONE, 14, (2019); Khan M.M., Ward R.D., Ingleby M., Classifying pretended and evoked facial expressions of positive and negative affective states using infrared measurement of skin temperature, ACM Trans. Appl. Percept, 6, pp. 1-22, (2009); Cross C., Skipper J., Petkie D., Thermal imaging to detect physiological indicators of stress in humans, Proceedings of the SPIE Defense, Security, and Sensing; Wang S., Liu Z., Lv S., Lv Y., Wu G., Peng P., Chen F., Wang X., A Natural Visible and Infrared Facial Expression Database for Expression Recognition and Emotion Inference, IEEE Trans. Multimed, 12, pp. 682-691, (2010); Kopaczka M., Kolk R., Merhof D., A fully annotated thermal face database and its application for thermal facial expression recognition, Proceedings of the 2018 IEEE International Instrumentation and Measurement Technology Conference (I2MTC), pp. 1-6; Haamer R.E., Rusadze E., Lsi I., Ahmed T., Escalera S., Anbarjafari G., Review on emotion recognition databases, Hum. Robot Interact. Theor. Appl, 3, pp. 39-63, (2017); Pantic M., Valstar M., Rademaker R., Maat L., Web-based database for facial expression analysis, Proceedings of the 2005 IEEE International Conference on Multimedia and Expo; Liu P., Yin L., Spontaneous facial expression analysis based on temperature changes and head motions, Proceedings of the 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), pp. 1-6; Zhu X., Ramanan D., Face detection, pose estimation, and landmark localization in the wild, Proceedings of the 2012 IEEE Conference on Computer Vision and Pattern Recognition, pp. 2879-2886; Latif M., Yusof M.H., Sidek S., Rusli N., Texture descriptors based affective states recognition-frontal face thermal image, Proceedings of the 2016 IEEE EMBS Conference on Biomedical Engineering and Sciences (IECBES), pp. 80-85; Carrapico R., Mourao A., Magalhaes J., Cavaco S., A comparison of thermal image descriptors for face analysis, Proceedings of the 2015 23rd European Signal Processing Conference (EUSIPCO), pp. 829-833; Cruz-Albarran I.A., Benitez-Rangel J.P., Osornio-Rios R.A., Morales-Hernandez L.A., Human emotions detection based on a smart-thermal system of thermographic images, Infrared Phys. Technol, 81, pp. 250-261, (2017); Ioannou S., Gallese V., Merla A., Thermal infrared imaging in psychophysiology: Potentialities and limits, Psychophysiology, 51, pp. 951-963, (2014); Jian B.-L., Chen C.-L., Huang M.-W., Yau H.-T., Emotion-Specific Facial Activation Maps Based on Infrared Thermal Image Sequences, IEEE Access, 7, pp. 48046-48052, (2019); Kyal C.K., Poddar H., Reza M., Human Emotion Recognition from Spontaneous Thermal Image Sequence Using GPU Accelerated Emotion Landmark Localization and Parallel Deep Emotion Net, Proceedings of the International Conference on Innovative Computing and Communications: Proceedings of ICICC 2020, pp. 931-943; Perez-Rosas V., Narvaez A., Burzo M., Mihalcea R., Thermal imaging for affect detection, Proceedings of the 6th International Conference on PErvasive Technologies Related to Assistive Environments—PETRA ‘13, pp. 1-4; Latif M., Sidek S., Rusli N., Fatai S., Emotion detection from thermal facial imprint based on GLCM features, ARPN J. Eng. Appl. Sci, 11, pp. 345-350, (2016); Shaees S., Naeem H., Arslan M., Naeem M.R., Ali S.H., Aldabbas H., Facial emotion recognition using transfer learning, Proceedings of the 2020 International Conference on Computing and Information Technology (ICCIT-1441), pp. 1-5; Boccanfuso L., Wang Q., Leite I., Li B., Torres C., Chen L., Salomons N., Foster C., Barney E., Ahn Y.A., A thermal emotion classifier for improved human-robot interaction, Proceedings of the 2016 25th IEEE International Symposium on Robot and Human Interactive Communication (RO-MAN), pp. 718-723; Liu Y., Chen X., Wang Z., Wang Z.J., Ward R.K., Wang X., Deep learning for pixel-level image fusion: Recent advances and future prospects, Inf. Fusion, 42, pp. 158-173, (2018); Nayak S., Nagesh B., Routray A., Sarma M., A Human–Computer Interaction framework for emotion recognition through time-series thermal video sequences, Comput. Electr. Eng, 93, (2021); Kopaczka M., Schock J., Nestler J., Kielholz K., Merhof D., A combined modular system for face detection, head pose estimation, face tracking and emotion recognition in thermal infrared images, Proceedings of the 2018 IEEE International Conference on Imaging Systems and Techniques (IST), pp. 1-6; Sharma N., Dhall A., Gedeon T., Goecke R., Modeling Stress Using Thermal Facial Patterns: A Spatio-temporal Approach, Proceedings of the 2013 Humaine Association Conference on Affective Computing and Intelligent Interaction, pp. 387-392; Bian C., Zhang Y., Yang F., Bi W., Lu W., Spontaneous facial expression database for academic emotion inference in online learning, IET Comput. Vis, 13, pp. 329-337, (2019); Murtaza M., Sharif M., AbdullahYasmin M., Ahmad T., Facial expression detection using six facial expressions hexagon (SFEH) model, Proceedings of the 2019 IEEE 9th Annual Computing and Communication Workshop and Conference (CCWC), pp. 0190-0195; Saha P., Bhattacharjee D., De B.K., Nasipuri M., Characterization and recognition of mixed emotional expressions in thermal face image, Proceedings of the Infrared Imaging Systems: Design, Analysis, Modeling, and Testing xxvii, pp. 184-193; Ng E., Yee G.C., Hua T.J., Kagathi M., Analysis of normal human eye with different age groups using infrared images, J. Med. Syst, 33, pp. 207-213, (2009); Shi X., Wang S., Zhu Y., Expression recognition from visible images with the help of thermal images, Proceedings of the 5th ACM on International Conference on Multimedia Retrieval, pp. 563-566; Liew C.F., Yairi T., Facial expression recognition and analysis: A comparison study of feature descriptors, IPSJ Trans. Comput. Vis. Appl, 7, pp. 104-120, (2015); Alshamsi H., Meng H., Li M., Real time facial expression recognition app development on mobile phones, Proceedings of the 2016 12th International Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD), pp. 1750-1755; Zhao X., Shi X., Zhang S., Facial expression recognition via deep learning, IETE Tech. Rev, 32, pp. 347-355, (2015); Akhand M.A.H., Roy S., Siddique N., Kamal M.A.S., Shimamura T., Facial Emotion Recognition Using Transfer Learning in the Deep CNN, Electronics, 10, (2021)","M. Al Qudah; School of Computer Sciences, Universiti Sains Malaysia, Penang, Gelugor 11800, Malaysia; email: m.alqudah@psau.edu.sa; A. Mohamed; School of Computer Sciences, Universiti Sains Malaysia, Gelugor, Penang, 11800, Malaysia; email: sufril@usm.my","","MDPI","","","","","","14248220","","","37050571","English","Sensors","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85152352283"
"Gil-Martin M.; San-Segundo R.; Lutfi S.L.; Coucheiro-Limeres A.","Gil-Martin, Manuel (57201032781); San-Segundo, Ruben (8333266700); Lutfi, Syaheerah Lebai (27567802400); Coucheiro-Limeres, Alejandro (56337879600)","57201032781; 8333266700; 27567802400; 56337879600","Estimating gravity component from accelerometers","2019","IEEE Instrumentation and Measurement Magazine","22","1","8633352","48","53","5","4","10.1109/MIM.2019.8633352","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061077787&doi=10.1109%2fMIM.2019.8633352&partnerID=40&md5=fd88d49e2fea1c4ca4f7ad7695ec3998","","","[No abstract available]","","","","","","","AMIC; CAVIAR, (TEC2017-84593-C2-1-R); Nvidia; Ministerio de Economía y Competitividad, MINECO, (TIN2017-85854-C4-4-R)","Funding text 1: We gratefully acknowledge the support of NVIDIA Corporation with the donation of the Titan X Pascal GPU used for this research.; Funding text 2: The work leading to these results has been supported by AMIC (MINECO, TIN2017-85854-C4-4-R) and CAVIAR (MINECO, TEC2017-84593-C2-1-R) projects.","Dias Pereira J.M., Viegas V., Pedro L., Silva P., Oliveira R., Postolache G., Smart walker solutions for physical rehabilitation, IEEE Instrum. Meas. Mag., 18, 5, pp. 21-30, (2015); San-Segundo R., Echeverry-Correa J.D., Salamea C., Pardo J.M., Human activity monitoring based on hidden Markov models using a smartphone, IEEE Instrum. Meas. Mag., 19, 6, pp. 27-31, (2016); Jachimczyk B., Dziak D., Czapla J., Damps P., Kulesza W.J., IoT on-board system for driving style assessment, Sensors, 18, 4, (2018); Redmond D.P., Hegge F.W., Observations on the design and specification of a wrist-worn human activity monitoring system, Behavior Research Methods, Instruments and Computers, 17, 6, pp. 659-669, (1985); Van Someren E.J., Lazeron R.H., Vonk B.F., Mirmiran M., Swaab D.F., Gravitational artefact in frequency spectra of movement acceleration: Implications for actigraphy in young and elderly subjects, J. Neuroscience Methods, 65, pp. 55-62, (1996); Van Hees V.T., Gorzelniak L., Separating movement and gravity components in an acceleration signal and implications for the assessment of human daily physical activity, PLOS One Open Access Journal, 8, 4, (2013); Sabatini A.M., Quaternion-based extended Kalman filter for determining orientation by inertial and magnetic sensing, IEEE Trans. Biomedical Eng., 53, 7, pp. 1346-1356, (2006); Yun X., Lizarraga M., Bachmann E.R., McGhee R.B., An improved quaternion-based Kalman filter for real-time tracking of rigid body oOrientation, Proc. 2003 IEEE/RSJ, Int. Conf. Intelligent Robots and Systems (IROS 2003), pp. 1074-1079, (2003); Reiss A., Stricker D., Creating and benchmarking a new dataset for physical activity monitoring, Proc. 5th Workshop on Affect and Behaviour Related Assistance (ABRA), (2012); Datasheet: Slam Stick Shock & Vibration Data Loggers, (2017)","","","Institute of Electrical and Electronics Engineers Inc.","","","","","","10946969","","IIMMF","","English","IEEE Instrum Meas Mag","Article","Final","","Scopus","2-s2.0-85061077787"
"López-Ludeña V.; Barra-Chicote R.; Lutfi S.; Montero J.M.; San-Segundo R.","López-Ludeña, Verónica (48761413700); Barra-Chicote, Roberto (27567444800); Lutfi, Syaheerah (27567802400); Montero, Juan Manuel (55960772400); San-Segundo, Rubén (8333266700)","48761413700; 27567444800; 27567802400; 55960772400; 8333266700","LSESpeak: A spoken language generator for Deaf people","2013","Expert Systems with Applications","40","4","","1283","1295","12","11","10.1016/j.eswa.2012.08.062","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870239195&doi=10.1016%2fj.eswa.2012.08.062&partnerID=40&md5=1a8b9a2a0d5d96db98ff2893979d87a3","Departamento de Ingeniería Electrónica, ETSI Telecomunicación, Universidad Politécnica de Madrid, Spain","López-Ludeña V., Departamento de Ingeniería Electrónica, ETSI Telecomunicación, Universidad Politécnica de Madrid, Spain; Barra-Chicote R., Departamento de Ingeniería Electrónica, ETSI Telecomunicación, Universidad Politécnica de Madrid, Spain; Lutfi S., Departamento de Ingeniería Electrónica, ETSI Telecomunicación, Universidad Politécnica de Madrid, Spain; Montero J.M., Departamento de Ingeniería Electrónica, ETSI Telecomunicación, Universidad Politécnica de Madrid, Spain; San-Segundo R., Departamento de Ingeniería Electrónica, ETSI Telecomunicación, Universidad Politécnica de Madrid, Spain","This paper describes the development of LSESpeak, a spoken Spanish generator for Deaf people. This system integrates two main tools: a sign language into speech translation system and an SMS (Short Message Service) into speech translation system. The first tool is made up of three modules: an advanced visual interface (where a deaf person can specify a sequence of signs), a language translator (for generating the sequence of words in Spanish), and finally, an emotional text to speech (TTS) converter to generate spoken Spanish. The visual interface allows a sign sequence to be defined using several utilities. The emotional TTS converter is based on Hidden Semi-Markov Models (HSMMs) permitting voice gender, type of emotion, and emotional strength to be controlled. The second tool is made up of an SMS message editor, a language translator and the same emotional text to speech converter. Both translation tools use a phrase-based translation strategy where translation and target language models are trained from parallel corpora. In the experiments carried out to evaluate the translation performance, the sign language-speech translation system reported a 96.45 BLEU and the SMS-speech system a 44.36 BLEU in a specific domain: the renewal of the Identity Document and Driving License. In the evaluation of the emotional TTS, it is important to highlight the improvement in the naturalness thanks to the morpho-syntactic features, and the high flexibility provided by HSMMs when generating different emotional strengths. © 2012 Elsevier Ltd. All rights reserved.","Emotional speech synthesis; LSE: Lengua de Signos Española; SMS to Spanish translation; Spanish sign language; Speech generation from LSE","Computational linguistics; Speech synthesis; Visual languages; Driving license; Emotional speech synthesis; Emotional TTS; Hidden semi-Markov models; High flexibility; Identity documents; Language translators; Parallel corpora; Sign language; SMS (short message service); SMS messages; Speech generation; Speech translation systems; Spoken languages; Target language; Text to speech; Translation strategies; Translation systems; Translation tools; Visual Interface; Translation (languages)","","","","","CAM-UPM; INAPRA; ITALIHA; TIMPANO, (TIN2011-28169-C05-03); Seventh Framework Programme, FP7, (287678); Comunidad de Madrid, (S2009/TIC-1542); European Commission, EC; Ministerio de Economía y Competitividad, MINECO, (MA2VICMR, TIN2008-06856-C05-03); Ministerio de Ciencia e Innovación, MICINN, (DPI2010-21247-C02-02)","The work leading to these results has received funding from the European Union under grant agreement n 287678. It has also been supported by TIMPANO (TIN2011-28169-C05-03), ITALIHA (CAM-UPM), INAPRA (MICINN, DPI2010-21247-C02-02), SD-TEAM (MEC, TIN2008-06856-C05-03) and MA2VICMR (Comunidad Autónoma de Madrid, S2009/TIC-1542) projects. Authors also thank Mark Hallett for the English revision of this paper and all the other members of the Speech Technology Group for the continuous and fruitful discussion on these topics.","Barra-Chicote B., Montero J.M., MacIas-Guarasa J., Lufti S., Lucas J.M., Fernandez F., D'Haro L.F., San-Segundo R., Ferreiros J., Cordoba R., Pardo J.M., Spanish expressive voices: Corpus for emotion research in Spanish, Proceedings of 6th International Conference On, Language Resources and Evaluation, (2008); Barra-Chicote R., Yamagishi J., Montero J.M., King S., Lufti S., MacIas-Guarasa J., Generacion de una voz sintetica en Castellano basada en HSMM para la Evaluacion Albayzin 2008: conversion texto a voz, Proceedings of V. Jornadas en Tecnologia Del Habla, (2008); Barra-Chicote R., Yamagishi J., King S., Montero J.M., MacIas-Guarasa J., Analysis of statistical parametric and unit selection speech synthesis systems applied to emotional speech, Speech Communication, 52, 5, pp. 394-404, (2010); Deana L., Pennell, Yang L., A character-level machine translation approach for normalization of SMS abbreviations, IJCNLP, (2011); Dreuw P., Visual modeling and tracking adaptation for automatic sign language recognition, Proceedings of International Computer Vision Summer School (ICVSS), (2008); Dreuw P., Forster J., Deselaers T., Ney H., Efficient approximations to model-based joint tracking and recognition of continuous sign language, Proceedings of IEEE International Conference Automatic Face and Gesture Recognition (FG), (2008); Dreuw P., Stein D., Ney H., Enhancing a sign lLanguage translation system with vision-based features, Proceedings of Special Issue Gesture Workshop 2007, LNAI, 5085, pp. 108-113, (2009); Dreuw P., Ney H., Martinez G., Crasborn O., Piater J., Miguel Moya J., Wheatley M., The sign-speak project - Bridging the gap between signers and speakers, Proceedings of 4th Workshop on the Representation and Processing of Sign Languages: Corpora and Sign Language Technologies (CSLT 2010), pp. 73-80, (2010); Dreuw P., Forster J., Gweth Y., Stein D., Ney H., Mar-Tinez G., Verges Llahi J., Crasborn O., Ormel E., Du W., Hoyoux T., Piater J., Moya Lazaro J.M., Wheatley M., SignSpeak - Understanding, recognition, and translation of sign languages, Proceedings of 4th Workshop on the Representation and Processing of Sign Languages: Corpora and Sign Language Technologies (CSLT 2010), pp. 65-73, (2010); Efthimiou E., Fotinea S., Hanke T., Glauert J., Bowden R., Braffort A., Collet C., Maragos P., Goudenove F., DICTA-SIGN: Sign language recognition, generation and modelling with application in Deaf communication, Proceedings of 4th Workshop on the Representation and Processing of Sign Languages: Corpora and Sign Language Technologies (CSLT 2010), pp. 80-84, (2010); Hanke T., Konig L., Wagner S., Matthes S., The hamburg studio setup, Proceedings of 4th Workshop on the Representation and Processing of Sign Languages: Corpora and Sign Language Technologies (CSLT 2010), pp. 106-110, (2010); Karami A., Zanj B., Sarkaleh A., Persian sign language (PSL) recognition using wavelet transform and neural networks, Expert Systems with Applications, 38, 3, pp. 2661-2667, (2011); Koehn P., Och F.J., Marcu D., Statistical phrase-based translation, Proceedings of Human Language Technology Conference 2003 (HLT-NAACL 2003), pp. 127-133, (2003); Koehn P., Statistical Machine Translation, (2010); Matthews N., Young S., Parker D., Napier J., Looking across the hearing line?: Exploring young Deaf people's use of Web 2.0, M/C Journal, 13, 3, (2010); Montero J.M., Gutierrez-Arriola J.M., Palazuelos S., Enriquez E., Aguilera S., Pardo J.M., Emotional speech synthesis: From speech database to TTS, Proceedings of ICSLP-98, pp. 923-926, (1998); Montero J.M., Estrategias Para la Mejora de la Naturalidad y la Incorporación de Variedad Emocional A la Conversión Texto A Voz en Castellano, (2003); Munib Q., Habeeb M., Takruri B., Al-Malik H., American sign language (ASL) recognition based on Hough transform and neural networks, Expert Systems with Applications, 32, 1, pp. 24-37, (2007); Och J., Ney H., A systematic comparison of various alignment models, Computational Linguistics, 29, 1, pp. 19-51, (2003); Ortiz T., Local turns global: Expanding the Deaf community through communication technologies, Proceedings of TCC 2009, (2009); San-Segundo R., Pardo J.M., Ferreiros F., Sama V., Barra-Chicote R., Lucas J.M., Spoken Spanish generation from sign language, Interacting with Computers, 22, 2, pp. 123-139, (2010); San-Segundo R., Montero J.M., Cordoba R., Sama V., Fernandez F., D'Haro L.F., Design, development and field evaluation of a Spanish into sign language translation system, Pattern Analysis and Applications, 15, 2, pp. 203-224, (2011); Stolcke A., SRILM - An extensible language modelling toolkit, Proceedings of International Conference on Spoken Language Processing, 2, pp. 901-904, (2002); Sylvie O., Surendra R., Sign language analysis: A survey and the future beyond lexical meaning, IEEE Transactions on Pattern Analysis and Machine Intelligence, 27, 6, (2005); Tryggvason J., VANESSA: A System for Council Information Centre Assistants to Communicate Using Sign Language, (2004); Vogler C., Metaxas D., A framework for recognizing the simultaneous aspects of ASL, CVIU, 81, 3, pp. 358-384, (2001); Von Agris U., Schneider D., Zieren J., Kraiss K.-F., Rapid signer adaptation for isolated sign language recognition, Proceedings of CVPR Workshop V4HCI, (2006); Wang S.B., Quattoni A., Morency L.-P., Demirdjian D., Darrell T., Hidden Conditional Random Fields for Gesture Recognition, Proceedings of CVPR, 2, pp. 1521-1527; Wheatley M., Pabsch A., Sign Language in Europe, 4th Workshop on the Representation and Processing of Sign Languages: Corpora and Sign Language Technologies, (2010); Yamagishi J., Onishi K., Masuko T., Kobayashi T., Acoustic modeling of speaking styles and emotional expressions in HMM-based speech synthesis, IEICE Transactions on Informations and & Systems, E88-D, 3, pp. 503-509, (2005); Yamagishi J., Nose T., Zen H., Ling Z.-H., Toda T., Tokuda K., A robust speaker-adaptive HMM-based text-to-speech synthesis, IEEE Trans. Speech, Audio & Language Process, (2009); Yao G., Yao H., Liu X., Jiang F., Real time Large vocabulary continuous sign language recognition based on OP/Viterbi Algorithm, Proceedings of 18th ICPR, August 2006, 3, pp. 312-315, (2006); Yung-Hui L., Cheng-Yue T., Taiwan sign language (TSL) recognition based on 3D data and neural networks, Expert Systems with Applications, 36, 2, pp. 1123-1128, (2009); Zen H., Toda T., Nakamura M., Tokuda K., Details of Nitech HMM-based speech synthesis system for the Blizzard Challenge 2005, Proceedings of IEICE Transactions on Informations & Systems, E90-D, 1, pp. 325-333, (2007)","V. López-Ludeña; Grupo de Tecnología Del Habla, Dpto. Ingeniería Electrónica, Universidad Politécnica de Madrid, 28040-Madrid, Ciudad Universitaria s/n, Spain; email: veronicalopez@die.upm.es","","","","","","","","09574174","","ESAPE","","English","Expert Sys Appl","Article","Final","","Scopus","2-s2.0-84870239195"
"Lutfi S.; Montero J.M.; Barra-Chicote R.; Lucas-Cuesta J.M.; Gallardo-Antolin A.","Lutfi, Syaheerah (27567802400); Montero, J.M. (55960772400); Barra-Chicote, R. (27567444800); Lucas-Cuesta, J.M. (26664791600); Gallardo-Antolin, A. (6508171874)","27567802400; 55960772400; 27567444800; 26664791600; 6508171874","Expressive speech identifications based on hidden markov model","2009","HEALTHINF 2009 - Proceedings of the 2nd International Conference on Health Informatics","","","","488","494","6","5","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-70450181058&partnerID=40&md5=9af8eb61cd802e8a74f22b636bd95269","Speech Technology Group, Technical University of Madrid, Spain; Department of Signal Theory and Communications, Universidad Carlos III de Madrid, Spain","Lutfi S., Speech Technology Group, Technical University of Madrid, Spain; Montero J.M., Speech Technology Group, Technical University of Madrid, Spain; Barra-Chicote R., Speech Technology Group, Technical University of Madrid, Spain; Lucas-Cuesta J.M., Speech Technology Group, Technical University of Madrid, Spain; Gallardo-Antolin A., Department of Signal Theory and Communications, Universidad Carlos III de Madrid, Spain","This paper concerns a sub-area of a larger research field of Affective Computing, focusing on the employment of affect-recognition systems using speech modality. It is proposed that speech-based affect identification systems could play an important role as next generation biometric identification systems that are aimed at determining a person's'state of mind', or psycho-physiological state. The possible areas for the deployment of voice-affect recognition technology are discussed. Additionally, the experiments and results for emotion identification in speech based on a Hidden Markov Models (HMMs) classifier are also presented. The result from experiment suggests that certain speech feature is more precise to identify certain emotional state, and that happiness is the most difficult emotion to detect.","Affective computing; Biometrics; Emotion identification; Speech processing","Biometrics; Computer science; Object recognition; Speech processing; Speech recognition; Affect recognition; Affective computing; Biometric identification systems; Emotion identification; Emotional state; Expressive speech; Identification systems; Physiological state; Recognition systems; Research fields; Speech features; Speech modality; Hidden Markov models","","","","","","","Barra R, Montero J.M., Marias J., D'Haro L.F., Segundo R.S., Cordoba R.D., Prosodic and segmental rubrics in emotion identification, International Conference on Acoustics, Speech and Signal Processing (ICASSP), (2006); Benzeghiba M.F., Bourlard H., Mariethoz J., Speaker verification based on user-customized password, Institut Dalle Molle d'Intelligence Artificial Perceprive, (2001); Bullington J., Information Security Curriculum Development (InfoSecCD), (2005); Campbell N., Database of emotional speech, ISCA Workshop on Speech and Emotion, (2000); Castellanos G., Delgado E., Daza G., Sanchez L.G., Suarez J.F., Feature selection in pathology detection using hybrid multidimensional analysis, Annual International Conference of the IEEE Engineering in Medicine and Biology - Proceedings, pp. 5503-5506, (2006); Integrated system for emotion recognition for the enhancement of human performance detection of criminal intent, DARPA SB032-038, (2003); Donovan R.E., Eide E., The IBM trainable speech synthesis system, ICSLP, 98, (1998); Donovan R.E., Woodland P.C., Automatic speech synthesiser parameter estimation using HMMS, International Conference on Acoustic Speech Signal Processing, (1995); Douglas-Cowie E., Cowie R., Schroder M.I., A new emotion database: Considerations, sources and scope, ISCA Workshop on Speech and Emotion, (2000); Gamboa H., An Identity Authentication System Based On Human Computer Interaction Behaviour, (2003); Gamboa H., Fred A., A behavioural biometric system based on human computer interaction, Proc. of SPIE, 5404, (2004); Gray M., Urban surveillance and panopticism: will we recognize the facial recognition society?, Surveillance and Society, 1, pp. 314-330, (2003); Gunter S., Bunke H., HMM-based handwritten word recognition: on the optimization of the numberof states, training iterations and Gaussian components, Pattern Recognition, 37, pp. 2069-2079, (2004); Hansen J.H.L., Bou-Ghazale S.E., Sarikaya R., Pellom B., GetTing Started With The Susas: Speech Under Simulated And Actual Stress Database, (1998); Huang X., Spoken Language Processing, (2001); Huang X., Acero A., Hon H.-W., Spoken Language Processing: A Guide To Theory, Algortihm And System Development, (2001); Kumar N., Andreou A.G., Heteroscedastic discriminant analysis and reduced rank HMMs for improved speech recognition, Speech Communication, 26, 4, pp. 283-297, (1998); Montero J.M., Gutirrez-Arriola J., Palazuelos S., Enriquez E., Pardo J.M., Spanish emotional speech from database to TTS, ICSLP, (1998); Morales-Perez M., Echeverry-Correa J., Orozco-Gutierrez A., Castellanos-Dominguez G., Feature extraction of speech signals in emotion identification, IEEE 2008 International Conference of the Engineering in Medicine and Biology Society (EMBS', 8, (2008); Rabiner L., A tutorial on hidden Markov models and selected applications in speech recognition, Proc, of the IEEE, 77, pp. 257-285, (1989); Ronzhin A.L., Lee I.V., Karpov A.A., Skormin V.A., Automatic estimation of human's psychophysiological state by speech, 9th Conference of Speech and Computer SPECOM, 4, (2004); Affective computing, SRI Consulting Business Intelligence; Steinhardt B., Face-off: Is the use of biometrics an invasion of privacy?, Network World Inc., (2000); Jr. Vaclave M., Riha Z., Biometric authentication systems, ECOM-MONITOR, (2000); Young S.J., Jansen J., Ordell J.J., Ollason D., Woodland P.C., The htk hidden markov model toolkit book, Entropic Cambridge Research Laboratory, (1995)","S. Lutfi; Speech Technology Group, Technical University of Madrid, Spain; email: syaheerah@die.upm.es","","","","2nd International Conference on Health Informatics, HEALTHINF 2009","14 January 2009 through 17 January 2009","Porto","76656","","978-989811163-0","","","English","HEALTHINF - Proc. Int. Conf. Hlth. Informatics","Conference paper","Final","","Scopus","2-s2.0-70450181058"
"Yee Hui D.O.; Lutfi S.L.; Naim S.; Akhtar Z.; Azlan Mohamed A.S.; Siddique K.","Yee Hui, Deborah Ooi (57219472499); Lutfi, Syaheerah Lebai (27567802400); Naim, Syibrah (55413206700); Akhtar, Zahid (46661628200); Azlan Mohamed, Ahmad Sufril (57190968285); Siddique, Kamran (57191228422)","57219472499; 27567802400; 55413206700; 46661628200; 57190968285; 57191228422","The sound of trust: Towards modelling computational trust using voice-only cues at zero-acquaintance","2020","Advances in Science, Technology and Engineering Systems","5","4","","469","476","7","0","10.25046/AJ050456","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092894298&doi=10.25046%2fAJ050456&partnerID=40&md5=d554b99e76bddc28af3d0eb4ec95b67e","Universiti Sains Malaysia, School of Computer Sciences, Penang, 11800, Malaysia; Woosong University, Technology Department, Endicott College of International Studies, Daejeon, 34606, South Korea; University of Memphis, Tennessee, 38152, United States; Xiamen University Malaysia, Sepang, 43900, Malaysia","Yee Hui D.O., Universiti Sains Malaysia, School of Computer Sciences, Penang, 11800, Malaysia; Lutfi S.L., Universiti Sains Malaysia, School of Computer Sciences, Penang, 11800, Malaysia; Naim S., Woosong University, Technology Department, Endicott College of International Studies, Daejeon, 34606, South Korea; Akhtar Z., University of Memphis, Tennessee, 38152, United States; Azlan Mohamed A.S., Universiti Sains Malaysia, School of Computer Sciences, Penang, 11800, Malaysia; Siddique K., Xiamen University Malaysia, Sepang, 43900, Malaysia","Trust is essential in many interdependent human relationships. Trustworthiness is measured via the effectiveness of the relationships involving human perception. The decision to trust others is often made quickly (even at zero acquaintance). Previous research has shown the significance of voice in perceived trustworthiness. However, the listeners' characteristics were not considered. A system has yet to be produced that can quantitatively predict the degree of trustworthiness in a voice. This research aims to investigate the relationship between trustworthiness and different vocal features while considering the listener's physical characteristics, towards modelling a computational trust model. This study attempts to predict the degree of trustworthiness in voice by using an Artificial Neural Network (ANN) model. A set of 30 audio clips of white males were obtained, acoustically analyzed and then distributed to a large group of untrained Malaysian respondents who rated their degree of trust in the speakers of each audio clip on a scale of 0 to 10. The ANOVA test showed a statistically significant difference of trust ratings across different types and intensities of emotion, duration of audio clip, average fundamental frequencies, speech rates, articulation rates, average loudness, ethnicity of listener and ages of listener (p <.01). The findings conclude that Malaysians tend to trust white males who talk faster and longer, speak louder, have an f0 between 132.03Hz & 149.52Hz, and show a neutral emotion or rather stoic (arousal<.325). Results suggest that Indians are the most trusting Malaysian ethnic group, followed by Bumiputera from East Malaysia and then followed by Malays. Chinese are the least trusting Malaysian ethnic group. The data was fed into an ANN model to be evaluated, which yielded a perfect percentage accuracy (100%) in degree of trustworthiness 39.70% of the time. Given a threshold of two-point deviation, the ANN had a prediction accuracy of 76.86%. © 2020 ASTES Publishers. All rights reserved.","Artificial neural network; True; Voice; Zero acquaintance","","","","","","Xiamen University Malaysia, (XMUMRF/2019-C3/IECE/0006); Universiti Sains Malaysia, (1001/PKOMP/8014001, 304/PKOMP/6315137)","This work was supported by the Research Management Center, Xiamen University Malaysia under the XMUM Research Program Cycle 3 (Grant XMUMRF/2019-C3/IECE/0006). The authors also thank Universiti Sains Malaysia for the partial funding of this work from the grant no. 304/PKOMP/6315137 and 1001/PKOMP/8014001.","Ambady N., Krabbenhoft M. A., Hogan D., The 30-sec sale: Using thin-slice judgments to evaluate sales effectiveness, J. Consum. Psychol, 16, 1, pp. 4-13, (2006); Stirrat M., Perrett D. I., Valid Facial Cues to Cooperation and Trust: Male Facial Width and Trustworthiness, Psychol. Sci, 21, 3, pp. 349-354, (2010); Kenny D. A., West T. V, Zero acquaintance: Definitions, statistical model, findings, and process, First impressions, pp. 129-146, (2008); Ambady N., Rosenthal R., Half a minute: Predicting teacher evaluations from thin slices of nonverbal behavior and physical attractiveness, J. Pers. Soc. Psychol, 64, 3, (1993); Eisenkraft N., Accurate by way of aggregation: Should you trust your intuition-based first impressions?, J. Exp. Soc. Psychol, 49, 2, pp. 277-279, (2013); Hecht M. A., LaFrance M., How (Fast) Can I Help You? Tone of Voice and Telephone Operator Efficiency in Interactions 1, J. Appl. Soc. Psychol, 25, 23, pp. 2086-2098, (1995); Ambady N., Bernieri F. J., Richeson J. A., Toward a histology of social behavior: Judgmental accuracy from thin slices of the behavioral stream, 32, pp. 201-271, (2000); Mohammad S. M., Kiritchenko S., Using nuances of emotion to identify personality, Proc. ICWSM, (2013); Hohmann H. H., Malieva E., The concept of trust: Some notes on definitions, forms and sources, Trust Entrep.), pp. 7-23, (2005); Edwards C., Edwards A., Stoll B., Lin X., Massey N., Evaluations of an artificial intelligence instructor's voice: Social Identity Theory in human-robot interactions, Comput. Human Behav, 90, pp. 357-362, (2019); Goel A., Creeden B., Kumble M., Salunke S., Shetty A., Wiltgen B., Using watson for enhancing human-computer co-creativity, 2015 AAAI Fall Symposium Series, (2015); Folstad A., Nordheim C. B., Bjorkli C. A., What makes users trust a chatbot for customer service? An exploratory interview study, International Conference on Internet Science, pp. 194-208, (2018); Ciechanowski L., Przegalinska A., Magnuski M., Gloor P., In the shades of the uncanny valley: An experimental study of human-chatbot interaction, Futur. Gener. Comput. Syst, 92, pp. 539-548, (2019); Fenwick J., Barclay L., Schmied V., Chatting: an important clinical tool in facilitating mothering in neonatal nurseries, J. Adv. Nurs, 33, 5, pp. 583-593, (2001); Bos N., Olson J., Gergle D., Olson G., Wright Z., Effects of Four Computer-mediated Communications Channels on Trust Development, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, pp. 135-140, (2002); Qiu L., Benbasat I., Online Consumer Trust and Live Help Interfaces: The Effects of Text-to-Speech Voice and Three-Dimensional Avatars, Int. J. Human-Computer Interact, 19, 1, pp. 75-94, (2005); Greenspan S., Goldberg D., Weimer D., Basso A., Interpersonal Trust and Common Ground in Electronically Mediated Communication, Proceedings of the 2000 ACM Conference on Computer Supported Cooperative Work, pp. 251-260, (2000); Schirmer A., Feng Y., Sen A., Penney T. B., Angry, old, male-and trustworthy? How expressive and person voice characteristics shape listener trust, PLoS One, 14, 1, (2019); Hughes S. M., Harrison M. A., Your Cheatin' Voice Will Tell on You: Detection of Past Infidelity from Voice, EPsychol, 15, 2, (2017); Belin P., Boehme B., McAleer P., The sound of trustworthiness: Acoustic-based modulation of perceived voice personality, PLoS One, 12, 10, pp. 1-9, (2017); Doney P. M., Cannon J. P., Mullen M. R., Understanding the influence of national culture on the development of trust, Acad. Manag. Rev, 23, 3, pp. 601-620, (1998); Gefen D., Heart T. H., On the need to include national culture as a central issue in e-commerce trust beliefs, J. Glob. Inf. Manag, 14, 4, pp. 1-30, (2006); Zaheer S., Zaheer A., Trust across borders, J. Int. Bus. Stud, 37, 1, pp. 21-29, (2006); Niebuhr O., Vosse J., Brem A., What makes a charismatic speaker? A computer-based acoustic-prosodic analysis of Steve Jobs tone of voice, Comput. Human Behav, 64, pp. 366-382, (2016); Anolli L., Ciceri R., The voice of deception: Vocal strategies of naive and able liars, J. Nonverbal Behav, 21, 4, pp. 259-284, (1997); Zuckerman M., DeFrank R. S., Hall J. A., Larrance D. T., Rosenthal R., Facial and vocal cues of deception and honesty, J. Exp. Soc. Psychol, 15, 4, pp. 378-396, (1979); Kirchhubel C., Howard D. M., Detecting suspicious behaviour using speech: Acoustic correlates of deceptive speech-An exploratory investigation, Appl. Ergon, 44, 5, pp. 694-702, (2013); Torre I., White L., Goslin J., Behavioural mediation of prosodic cues to implicit judgements of trustworthiness, (2016); Korovaiko N., Thomo A., Trust prediction from user-item ratings, Soc. Netw. Anal. Min, 3, 3, pp. 749-759, (2013); DuBois T., Golbeck J., Srinivasan A., Predicting trust and distrust in social networks, 2011 IEEE third international conference on privacy, security, risk and trust and 2011 IEEE third international conference on social computing, pp. 418-424, (2011); Zong B., Xu F., Jiao J., Lv J., A broker-assisting trust and reputation system based on artificial neural network, 2009 IEEE International Conference on Systems, Man and Cybernetics, pp. 4710-4715, (2009); Bejou D., Wray B., Ingram T. N., Determinants of relationship quality: an artificial neural network analysis, J. Bus. Res, 36, 2, pp. 137-143, (1996); Lee J. J., Knox B., Breazeal C., Modeling the dynamics of nonverbal behavior on interpersonal trust for human-robot interactions, 2013 AAAI Spring Symposium Series, (2013); Ekonomou L., Greek long-term energy consumption prediction using artificial neural networks, Energy, 35, 2, pp. 512-517, (2010); Imhof M., Listening to Voices and Judging People, Int. J. List, 24, 1, pp. 19-33, (2010); Smith B. L., Brown B. L., Strong W. J., Rencher A. C., Effects of Speech Rate on Personality Perception, Lang. Speech, 18, 2, pp. 145-152, (1975); Ismail M. N., Chee S. S., Nawawi H., Yusoff K., Lim T. O., James W. P. T., Obesity in Malaysia, Obes. Rev, 3, 3, pp. 203-208, (2002); Swami V., Furnham A., Self-assessed intelligence: Inter-ethnic, rural-urban, and sex differences in Malaysia, Learn. Individ. Differ, 20, 1, pp. 51-55, (2010); Barros P., Churamani N., Lakomkin E., Siqueira H., Sutherland A., Wermter S., The OMG-Emotion Behavior Dataset, Proceedings of the International Joint Conference on Neural Networks, pp. 2018-July, (2018); Ekman P., Friesen W. V., Constants across cultures in the face and emotion, J. Pers. Soc. Psychol, 17, 2, pp. 124-129, (1971); Trouvain J., Schmidt S., Schroder M., Schmitz M., Barry W. J., Modelling personality features by changing prosody in synthetic speech, (2006); Quene H., On the just noticeable difference for tempo in speech, J. Phon, 35, 3, pp. 353-362, (2007); Yulin G., The Spectrum of Trust and Distrust, Jiangsu Soc. Sci, 1, (2012)","S.L. Lutfi; Universiti Sains Malaysia, School of Computer Sciences, Penang, 11800, Malaysia; email: syahherah@usm.my; K. Siddique; Xiamen University Malaysia, Sepang, 43900, Malaysia; email: kamran.siddique@xmu.edu.my","","ASTES Publishers","","","","","","24156698","","","","English","Adv.  Sci., Technol.  Eng.  Syst.","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85092894298"
"Mokhtar N.S.; Lutfi S.L.","Mokhtar, Najlaa Sadiq (57192924783); Lutfi, Syaheerah Lebai (27567802400)","57192924783; 27567802400","Identifying significant task-based predictors of emotion in learning","2016","Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)","9935 LNAI","","","129","142","13","0","10.1007/978-3-319-46218-9_11","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85009165756&doi=10.1007%2f978-3-319-46218-9_11&partnerID=40&md5=1081536ca3363946b30167c49fe6d221","School of Computer Sciences, Universiti Sains Malaysia, Minden, 11800, Pulau Pinang, Malaysia","Mokhtar N.S., School of Computer Sciences, Universiti Sains Malaysia, Minden, 11800, Pulau Pinang, Malaysia; Lutfi S.L., School of Computer Sciences, Universiti Sains Malaysia, Minden, 11800, Pulau Pinang, Malaysia","Emphatic computing is concerned with enabling a system to recognize a user’s current state and then providing the appropriate response to the user with the intention to support the user emotionally. However, in order to do so, the system must first identify the state of the user. Studies in computer-based tutoring are increasingly investigating ways to incorporate synthetic tutors that are equipped with computational models of empathy – in which these agents are trained to understand learners’ emotions and respond based on the detected learner state. However, cultural differences affect the way people express and detect emotions. This paper attempts to identify the task-based features that could discriminate the learner’s emotions in a Malaysian context. By studying several existing task-based features from literature, and combining them with new features, this study attempts to detect four frequent emotions that accompanies learning, namely, frustration, boredom, uncertainty and neutral. A user study is conducted with 33 students and results revealed that certain features can be used as predictors for the abovementioned emotions. Interestingly, results also showed that there is a tendency for students to choose synthetic tutors of the same race. © Springer International Publishing Switzerland 2016.","Emotions; Empathy; Intelligent tutoring system; Task-based features","Computation theory; Computational methods; Computer aided instruction; Education computing; Intelligent agents; Computational model; Cultural difference; Emotions; Empathy; Intelligent tutoring system; Malaysians; Task-based; User study; Multi agent systems","","","","","Universiti Sains Malaysia, (304/PKOMP/6312153)","The authors would like to thank Universiti Sains Malaysia for the funding of this work from the grant no. 304/PKOMP/6312153.","Davis M.H., Empathy: A Social Psychological Approach, (1994); Sabourin J., Mott B., Lester J., Computational models of affect and empathy for pedagogical virtual agents, Standards in Emotion Modeling, Lorentz Center International Center for Workshops in the Sciences; Aquino R.J., Battad J., Ngo C.F., Uy G., Trogo R., Suarez M., Towards empathic support provision for computer users, Theory and Practice of Computation, 5, pp. 15-27, (2012); D'Mello S., Picard R.W., Graesser A., Toward an affect-sensitive AutoTutor, IEEE Intell. Syst, 22, pp. 53-61, (2007); Rajendran R., Iyer S., Murthy S., Wilson C., Sheard J., A theory-driven approach to predict frustration in an ITS, IEEE Trans. Learn. Technol, 6, pp. 378-388, (2013); Syed Mohamad S.J.A.N., Learning Style among Multi-Ethnic Students in Four Selected Tertiary Institutions in the Klang Valley, (2006); Matsumoto D., Juang L., Culture and Psychology, (2012); Pardos Z.A., Baker R.S., San Pedro M., Gowda S.M., Gowda S.M., Affective states and state tests: Investigating how affect and engagement during the school year predict end-of-year learning outcomes, J. Learn. Anal, 1, pp. 107-128, (2014); Wang Z., Qiao X., Xie Y., An emotional intelligent e-learning system based on mobile agent technology, International Conference on Computer Engineering and Technology, 2009, ICCET 2009, pp. 51-54, (2011); Robison J., McQuiggan S., Lester J., Evaluating the consequences of affective feedback in intelligent tutoring systems, 3Rd International Conference on Affective Computing and Intelligent Interaction and Workshops, pp. 1-6, (2009); Rodrigo M.M.T., Baker R.S., Coarse-grained detection of student frustration in an introductory programming course, Proceedings of the Fifth International Workshop on Computing Education Research Workshop, pp. 75-80, (2009); McQuiggan S.W., Lester J.C., Modeling and evaluating empathy in embodied companion agents, Int. J. Hum.-Comput. Stud, 65, pp. 348-360, (2007); Daradoumis T., Arguedas M., Xhafa F., Current trends in emotional e-learning: New perspectives for enhancing emotional intelligence, 2013 7Th International Conference on Complex, Intelligent, and Software Intensive Systems (CISIS), pp. 34-39, (2013); D'Mello S.K., Craig S.D., Witherspoon A., McDaniel B., Graesser A., Automatic detection of learner’s affect from conversational cues, User Model. User-Adap. Interact, 18, pp. 45-80, (2008); Baker R.S., D'Mello S.K., Rodrigo M.M.T., Graesser A.C., Better to be frustrated than bored: The incidence, persistence, and impact of learners’ cognitive-affective states during interactions with three different computer-based learning environments, Int. J. Hum.-Comput. Stud, 68, pp. 223-241, (2010); Forbes-Riley K., Litman D., Friedberg H., Drummond J., Intrinsic and extrinsic evaluation of an automatic user disengagement detector for an uncertainty-adaptive spoken dialogue system, Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 91-102, (2012); Plass J.L., Heidig S., Hayward E.O., Homer B.D., Um E., Emotional design in multimedia learning: Effects of shape and color on affect and learning, Learn. Instruct, 29, pp. 128-140, (2014); Forbes-Riley K., Litman D., Benefits and challenges of real-time uncertainty detection and adaptation in a spoken dialogue computer tutor, Speech Commun, 53, pp. 1115-1136, (2011); Sabourin J.L., Lester J.C., Affect and engagement in Game-BasedLearning environments, IEEE Trans. Affect. Comput, 5, pp. 45-56, (2014); McQuiggan S.W., Robison J.L., Phillips R., Lester J.C., Modeling parallel and reactive empathy in virtual agents: An inductive approach, Proceedings of the 7Th International Joint Conference on Autonomous Agents and Multiagent Systems, 1, pp. 167-174, (2008); Elliott C.D., The Affective Reasoner: A Process Model of Emotions in A Multi-Agent System, (1992); Gratch J., Marsella S., A domain-independent framework for modeling emotion, Cogn. Syst. Res, 5, pp. 269-306, (2004); Picard R.W., Picard R., Affective Computing, (1997); Graesser A., McDaniel B., Chipman P., Witherspoon A., D'Mello S., Gholson B., Detection of emotions during learning with AutoTutor, Proceedings of the 28Th Annual Meetings of the Cognitive Science Society, pp. 285-290, (2006); Kapoor A., Picard R.W., Multimodal affect recognition in learning environments, Proceedings of the 13Th Annual ACM International Conference on Multimedia, pp. 677-682, (2005); Zhao H., Sun B., Hu X., Zhu X., The study of emotional education based on virtual reality in e-learning, 1St International Conference on Information Science and Engineering (ICISE), pp. 3540-3543, (2009); Hu Y., Zhao G., Virtual classroom with intelligent virtual tutor, International Conference on E-Education, E-Business, E-Management, and E-Learning, IC4E 2010, pp. 34-38, (2010); Chaffar S., Frasson C., Using an emotional intelligent agent to improve the learner’s performance, Proceedings of the Workshop on Social and Emotional Intelligence in Learning Environments in Conjunction with Intelligent Tutoring Systems, (2004); Lutfi S.L., Fernandez-Martinez F., Lorenzo-Trueba J., Barra-Chicote R., Montero J.M., I feel you: The design and evaluation of a domotic affect-sensitive spoken conversational agent, Sensors, 13, pp. 10519-10538, (2013); Hsiao I.H., Sosnovsky S., Brusilovsky P., Guiding students to the right questions: Adaptive navigation support in an e-learning system for Java programming, J. Comput. Assist. Learn, 26, pp. 270-283, (2010); Gulzar S., Yahya F., Nauman M., Mir Z., Mujahid S.H., Frustration among University Students in Pakistan, (2012); Blair C., School readiness: Integrating cognition and emotion in a neurobiological conceptualization of children’s functioning at school entry, Am. Psychol, 57, (2002); Pekrun R., Elliot A.J., Maier M.A., Achievement goals and achievement emotions: Testing a model of their joint relations with academic performance, J. Educ. Psychol, 101, (2009); Valiente C., Swanson J., Eisenberg N., Linking students’ emotions and academic achievement: When and why emotions matter, Child. Dev. Perspect, 6, pp. 129-135, (2012); Wong K.Y., Quek K.S., Do Chinese and Malay Students Report Different Ways of Studying Mathematics?, pp. 1-13, (2007); Pekrun R., Goetz T., Perry R.P., Kramer K., Hochstadt M., Molfenter S., Beyond test anxiety: Development and validation of the test emotions questionnaire (TEQ), Anxiety Stress Coping, 17, pp. 287-316, (2004)","S.L. Lutfi; School of Computer Sciences, Universiti Sains Malaysia, Minden, 11800, Malaysia; email: syaheerah@usm.my","Numao M.; Grasso F.; Suarez M.T.; Bex F.; Namazi-Rad M.-R.; Green N.; Baldoni M.; Baroglio C.","Springer Verlag","","15th Workshop on Computational Models of Natural Argument, CMNA XV 2015 and 6th International Workshop on Empathic Computing, IWEC-15","26 October 2015 through 26 October 2015","Bertinoro","187459","03029743","978-331946217-2","","","English","Lect. Notes Comput. Sci.","Conference paper","Final","","Scopus","2-s2.0-85009165756"
"Lutfi S.L.; Lahasan B.; Luna-Jiménez C.; Bamasood Z.A.; Akhtar Z.","Lutfi, Syaheerah Lebai (27567802400); Lahasan, Badr (56768228800); Luna-Jiménez, Cristina (57210646540); Bamasood, Zaher A. (58750739200); Akhtar, Zahid (46661628200)","27567802400; 56768228800; 57210646540; 58750739200; 46661628200","Effects of Facial Expressions and Gestures on the Trustworthiness of a Person","2023","IEEE Access","11","","","133891","133902","11","0","10.1109/ACCESS.2023.3334270","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178991493&doi=10.1109%2fACCESS.2023.3334270&partnerID=40&md5=70c103470bdd62e9b66d2ffab684a666","School of Computer Sciences, Universiti Sains Malaysia, Penang, Minden, 11800, Malaysia; Faculty of Computer and Information Technology, University of Shabwah, Shabwah, Yemen; Grupo de Tecnología del Habla y Aprendizaje Automático (THAU Group), Information Processing and Telecommunications Center, E.T.S.I. de Telecomunicación, Universidad Politécnica de Madrid, Madrid, 28040, Spain; Faculty of Computers and Information Technology, Hadhramout University, Hadhramout, Yemen; Hadramout Establishment for Human Development, Hadramout, Mukalla, Yemen; Department of Network and Computer Security, State University of New York Polytechnic Institute, Utica, 13502, NY, United States","Lutfi S.L., School of Computer Sciences, Universiti Sains Malaysia, Penang, Minden, 11800, Malaysia; Lahasan B., Faculty of Computer and Information Technology, University of Shabwah, Shabwah, Yemen; Luna-Jiménez C., Grupo de Tecnología del Habla y Aprendizaje Automático (THAU Group), Information Processing and Telecommunications Center, E.T.S.I. de Telecomunicación, Universidad Politécnica de Madrid, Madrid, 28040, Spain; Bamasood Z.A., School of Computer Sciences, Universiti Sains Malaysia, Penang, Minden, 11800, Malaysia, Faculty of Computers and Information Technology, Hadhramout University, Hadhramout, Yemen, Hadramout Establishment for Human Development, Hadramout, Mukalla, Yemen; Akhtar Z., Department of Network and Computer Security, State University of New York Polytechnic Institute, Utica, 13502, NY, United States","Trust is a fundamental element in human relationships, playing a crucial role in decision-making processes. Despite its significance, numerous dimensions of perceived trustworthiness remain unexplored and warrant further investigation. Previous literature has highlighted the influence of emotions and sentiments on how individuals perceive trustworthiness, with visual, vocal, and behavioral cues serving as essential markers. This preliminary study aims to expand the existing knowledge in the field by investigating trustworthiness traits manifested through facial and gesture expressions in emotional videos across diverse cultural contexts. To address this objective, an annotation platform was developed to collect annotation data using the benchmarked One-Minute-Gradual Emotion (OMG) audiovisual corpus, enabling the annotation of actors’ perceived trustworthiness levels alongside other inquiries related to emotional state, gesture, activeness, comfort, and speech integrity. The findings of this study demonstrate a positive correlation between higher levels of speaker activity, faster gesturing, and a relaxed demeanor with increased levels of trust gained from audiences. The proposal presented in this paper holds potential for future studies focused on trustworthiness annotation, facilitating the measurement of trust-related features. Moreover, this research serves as a critical step towards understanding the foundations of trustworthiness in the development of synthetic agents that require perceived trustworthiness, particularly in domains involving negotiations or emergency situations where rapid data collection plays a pivotal role in saving lives. 2023 The Authors. This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License.","Affective computing; emotion; face expression; gesture; man–machine interaction (MMI); trust modeling","Behavioral research; Data acquisition; Decision making; Face recognition; Human computer interaction; Affective Computing; Annotation; Emotion; Emotion recognition; Face; Face expressions; Gesture; Man-machine interaction; Man/machine interactions; Psychology; Trust models; Video; Emotion Recognition","","","","","Ayudas Program Propio Universidad Politécnica de Madrid; European Commission, EC; Universiti Putra Malaysia, UPM; Universiti Sains Malaysia, USM, (304/PKOMP/6315137); Ministerio de Ciencia e Innovación, MICINN, (PDC2021-120846-C42, PID2020-118112RB-C21, PID2020-118112RB-C22); Erasmus+, (2020-1-ES01-KA107-080401)","This work was supported in part by University Sains Malaysia under Grant 304/PKOMP/6315137, in part by the Spanish Ministry of Science and Innovation funded by MCIN/AEI/10.13039/501100011033 through the Project GOMINOLA under Grant PID2020-118112RB-C21 and Grant PID2020-118112RB-C22 and the Project AMIC-PoC under Grant PDC2021-120846-C42, in part by the European Union ‘‘NextGenerationEU/PRTR,’’ in part by the 2022 Ayudas Program Propio Universidad Politécnica de Madrid (UPM), and in part by the Erasmus+ Program under Grant 2020-1-ES01-KA107-080401.","Agrawal S., Dutta S., Patra B.K., Sentiment analysis of short informal text by tuning BERT-Bi-LSTM model, Proc. IEEE 19th Int. Conf. Smart Technol. (EUROCON), pp. 98-102, (2021); Alesina A., La Ferrara E., Who trusts others?, J. Public Econ., 85, 2, pp. 207-234, (2002); Azazi A., Lutfi S.L., Venkat I., Identifying universal facial emotion markers for automatic 3D facial expression recognition, Proc. Int. Conf. Comput. Inf. Sci. (ICCOINS), pp. 1-6, (2014); Azazi A., Lutfi S.L., Venkat I., Fernandez-Martinez F., Towards a robust affect recognition: Automatic facial expression recognition in 3D faces, Expert Syst. Appl., 42, 6, pp. 3056-3066, (2015); Barros P., Churamani N., Lakomkin E., Siqueira H., Sutherland A., Wermter S., The OMG-emotion behavior dataset, Proc. Int. Joint Conf. Neural Netw. (IJCNN), pp. 1-7, (2018); Belkin L.Y., Rothman N.B., Do I trust you? Depends on what you feel: Interpersonal effects of emotions on initial trust at zero-acquaintance, Negotiation Conflict Manage. Res., 10, 1, pp. 3-27, (2017); Berg J., Dickhaut J., McCabe K., Trust, reciprocity, and social history, Games and Economic Behaviour, pp. 122-142, (1995); Berry D.S., McArthur L.Z., Perceiving character in faces: The impact of age-related craniofacial changes on social perception, Psychol. Bull., 100, 1, pp. 3-18, (1986); Biglan A., Distressed behavior and its context, Behav. Analyst, 14, 2, pp. 157-169, (1991); Boothroyd L.G., Jones B.C., Burt D.M., Perrett D.I., Partner characteristics associated with masculinity, health and maturity in male faces, Personality Individual Differences, 43, 5, pp. 1161-1173, (2007); Bourke C., Douglas K., Porter R., Processing of facial emotion expression in major depression: A review, Austral. New Zealand J. Psychiatry, 44, 8, pp. 681-696, (2010); Bracht J., Feltovich N., Whatever you say, your reputation precedes you: Observation and cheap talk in the trust game, J. Public Econ., 93, 9-10, pp. 1036-1044, (2009); Brulhart M., Usunier J.-C., Does the trust game measure trust?, Econ. Lett., 115, 1, pp. 20-23, (2012); Busso C., Bulut M., Lee C.-C., Kazemzadeh A., Mower E., Kim S., Chang J.N., Lee S., Narayanan S.S., IEMOCAP: Interactive emotional dyadic motion capture database, Lang. Resour. Eval., 42, 4, pp. 335-359, (2008); Cameron L.D., Overall N.C., Suppression and expression as distinct emotion-regulation processes in daily interactions: Longitudinal and meta-analyses, Emotion, 18, 4, (2018); Chang L.J., Doll B.B., van't Wout M., Frank M.J., Sanfey A.G., Seeing is believing: Trustworthiness as a dynamic belief, Cognit. Psychol., 61, 2, pp. 87-105, (2010); Charness G., Du N., Yang C.-L., Trust and trustworthiness reputations in an investment game, Games Econ. Behav., 72, 2, pp. 361-375, (2011); Chaudhuri A., Gangadharan L., An experimental analysis of trust and trustworthiness, Southern Econ. J., 73, 4, pp. 959-985, (2007); Chen J., Zhong J., Zhang Y., Li P., Zhang A., Tan Q., Li H., Electrophysiological correlates of processing facial attractiveness and its influence on cooperative behavior, Neurosci. Lett., 517, 2, pp. 65-70, (2012); Chen Z., Huang D., Wang Y., Chen L., Fast and light manifold CNN based 3D facial expression recognition across pose variations, Proc. 26th ACM Int. Conf. Multimedia, pp. 229-238, (2018); Collignon O., Girard S., Gosselin F., Roy S., Saint-Amour D., Lassonde M., Lepore F., Audio-visual integration of emotion expression, Brain Res, 1242, pp. 126-135, (2008); Coulson M., Attributing emotion to static body postures: Recognition accuracy, confusions, and viewpoint dependence, J. Nonverbal Behav., 28, 2, pp. 117-139, (2004); Dael N., Mortillaro M., Scherer K.R., Emotion expression in body action and posture, Emotion, 12, 5, (2012); Delgado M.R., Frank R.H., Phelps E.A., Perceptions of moral character modulate the neural systems of reward during the trust game, Nature Neurosci, 8, 11, pp. 1611-1618, (2005); Deng J.J., Leung C.H.C., Li Y., Multimodal emotion recognition using transfer learning on audio and text data, Computational Science and Its Applications (Lecture Notes in Computer Science), 12951; Deutsch M., Trust and suspicion, J. Conflict Resolution, 2, 4, pp. 265-279, (1958); Cook A., Thompson M., Ross P., Virtual first impressions: Zoom backgrounds affect judgements of trust and competence, PLoS ONE, 18, 9; Napoles J., Silvey B.A., Montemayor M., The influences of facial expression and conducting gesture on college musicians’ perceptions of choral conductor and ensemble expressivity, Int. J. Music Educ., 39, 2, pp. 260-271, (2021); Schneider S., Krieglstein F., Beege M., Rey G.D., The impact of video lecturers’ nonverbal communication on learning—An experiment on gestures and facial expressions of pedagogical agents, Comput. Educ., 176, 2022; Ahmed N., Al Aghbari Z., Girija S., A systematic survey on multimodal emotion recognition using learning algorithms, Intell. Syst. With Appl., 17; Dunning D., Anderson J.E., Schlsser T., Ehlebracht D., Fetchenhauer D., Trust at zero acquaintance: More a matter of respect than expectation of reward, J. Personality Social Psychol., 107, 1, pp. 122-141, (2014); Eagly A.H., Ashmore R.D., Makhijani M.G., Longo L.C., What is beautiful is good, but. . .: A meta-analytic review of research on the physical attractiveness stereotype, Psychol. Bull., 110, 1, pp. 109-128, (1991); Ekman P., Friesen W.V., Constants across cultures in the face and emotion, J. Personality Social Psychol., 17, 2, pp. 124-129, (1971); Ekman P., An argument for basic emotions, Cognit. Emotion, 6, 3-4, pp. 169-200, (1992); Fasel B., Luettin J., Automatic facial expression analysis: A survey, Pattern Recognit, 36, 1, pp. 259-275, (2016); Martin A.F., Plaza A.P., Concepcion C.L., Calvo M.G., Trustworthiness of a smile as a function of changes in the eye expression, Psicothema, 29, 4, pp. 462-468, (2017); Fetchenhauer D., van der Vegt G., Honesty, trust and economic growth, Zeitschrift für Sozialpsychologie, 32, 3, pp. 189-200, (2001); Forgas J.P., Affective influences on attitudes and judgments, Handbook of Affective Sciences (Series in Affective Science), pp. 596-618, (2003); Fouragnan E., Chierchia G., Greiner S., Neveu R., Avesani P., Coricelli G., Reputational priors magnify striatal responses to violations of trust, J. Neurosci., 33, 8, pp. 3602-3611, (2013); Fukuyama F., Trust: The Social Virtues and the Creation of Prosperity, 99, (1995); Gagnon M., Cherif L., Roy-Charland A., Contextual cues about reciprocity impact ratings of smile sincerity, Cognition Emotion, 36, 6, pp. 1181-1195; Gross J.J., John O.P., Individual differences in two emotion regulation processes: Implications for affect, relationships, and well-being, J. Personality Social Psychol., 85, 2, pp. 348-362, (2003); Gunes H., Piccardi M., Bi-modal emotion recognition from expressive face and body gestures, J. Netw. Comput. Appl., 30, 4, pp. 1334-1345, (2007); Gunes H., Piccardi M., From mono-modal to multi-modal: Recognition using visual modalities, Intelligent Environments (Advanced Information and Knowledge Processing), (2009); Hess U., Blairy S., Kleck R.E., The influence of facial emotion displays, gender, and ethnicity on judgments of dominance and affiliation, J. Nonverbal Behav., 24, 4, pp. 265-283, (2000); Izard C.E., Basic emotions, relations among emotions, and emotion-cognition relations, Psychol. Rev., 99, 3, pp. 561-565, (1992); Johnson N.D., Mislin A.A., Trust games: A meta-analysis, J. Econ. Psychol., 32, 5, pp. 865-889, (2011); Knack S., Keefer P., Does social capital have an economic payoff? A cross-country investigation, Quart. J. Econ., 112, 4, pp. 1251-1288, (1997); Knutson B., Facial expressions of emotion influence interpersonal trait inferences, J. Nonverbal Behav., 20, 3, pp. 165-182, (1996); Koelstra S., Muhl C., Soleymani M., Lee J.-S., Yazdani A., Ebrahimi T., Pun T., Nijholt A., Patras I., DEAP: A database for emotion analysis;Using physiological signals, IEEE Trans. Affect. Comput., 3, 1, pp. 18-31, (2012); Kong D.T., Dirks K.T., Ferrin D.L., Interpersonal trust within negotiations: meta-analytic evidence, critical contingencies, and directions for future research, Acad. Manage. J., 57, 5, pp. 1235-1255, (2014); Kosfeld M., Heinrichs M., Zak P.J., Fischbacher U., Fehr E., Oxytocin increases trust in humans, Nature, 435, 7042, pp. 673-676, (2005); Krumhuber E., Manstead A.S.R., Cosker D., Marshall D., Rosin P.L., Kappas A., Facial dynamics as indicators of trustworthiness and cooperative behavior, Emotion, 7, 4, pp. 730-735, (2007); Kurien D.N., Body language: Silent communicator at the workplace, IUP J. Soft Skills, 4, 1-2, pp. 29-36, (2010); Lee J.J., Knox W.B., Wormwood J.B., Breazeal C., DeSteno D., Computationally modeling interpersonal trust, Frontiers Psychol, 4, (2013); Li Y., Chen Z., Liu X., Qi Y., Perceiving the facial trustworthiness: Facial age, emotional expression, and attractiveness, Quart. J. Exp. Psychol., 75, 5, pp. 818-829, (2022); Livingstone S.R., Russo F.A., The Ryerson audio-visual database of emotional speech and song (RAVDESS): A dynamic, multimodal set of facial and vocal expressions in North American English, PLOS ONE, 13, 5, (2018); Dunn J.R., Schweitzer M.E., Feeling and believing: The influence of emotion on trust, J. Personality Social Psychol., 88, 5, (2005); Lucas G., Stratou G., Lieblich S., Gratch J., Trust me: Multimodal signals of trustworthiness, Proc. 18th ACM Int. Conf. Multimodal Interact., pp. 5-12, (2016); Luna-Jimenez C., Lutfi S.L., Fernandez-Martinez F., Tick A., Measuring trust at zero-acquaintance: A cross-cultural study between Malaysians and Hungarians, Proc. IEEE 26th Int. Conf. Intell. Eng. Syst. (INES), pp. 267-272, (2022); Luna-Jimenez C., Lutfi S.L., Gil-Martin M., Kleinlein R., Montero J.M., Fernandez-Martinez F., Measuring trust at zero-acquaintance using acted-emotional videos, Proc. IberSPEECH, 2022, pp. 206-210; Luna-Jimenez C., Griol D., Callejas Z., Kleinlein R., Montero J.M., Fernandez-Martinez F., Multimodal emotion recognition on RAVDESS dataset using transfer learning, Sensors, 21, 22; Lutfi S.L., Montero J.M., Barra-Chicote R., Lucas-Cuesta J.M., Gallardo-Antolin A., Expressive speech identifications based on hidden Markov model, Proc. HEALTHINF, pp. 488-494, (2009); Lutfi S.L., Fernandez-Martinez F., Lucas-Cuesta J.M., Lopez-Lebon L., Montero J.M., A satisfaction-based model for affect recognition from conversational features in spoken dialog systems, Speech Com-mun, 55, 7-8, pp. 825-840, (2013); Maaoui C., Pruski A., Emotion recognition through physiological signals for human-machine communication, Cutting Edge Robotics, pp. 317-332, (2010); Manfredonia J., Bangerter A., Manyakov N.V., Ness S., Lewin D., Skalkin A., Boice M., Goodwin M.S., Dawson G., Hendren R., Leventhal B., Shic F., Pandina G., Automatic recognition of posed facial expression of emotion in individuals with autism spectrum disorder, J. Autism Develop. Disorders, 49, 1, pp. 279-293, (2019); Maslej-Kresnakova V., Sarnovsky M., Butka P., Machova K., Comparison of deep learning models and various text pre-processing techniques for the toxic comments classification, Appl. Sci., 10, 23; Matsumoto D., Hwang H.S.C., Culture, emotion, and expression, Cross-Cultural Psychology: Contemporary Themes and Perspectives, pp. 501-515, (2019); McArthur L.Z., Apatow K., Impressions of baby-faced adults, Social Cognition, 2, 4, pp. 315-342, (1984); Correa J.A.M., Abadi M.K., Patras N.I.S., AMIGOS: A dataset for affect, personality and mood research on individuals and groups, IEEE Trans. Affect. Comput., 12, 2, pp. 479-493, (2018); Mondloch C.J., Nelson N.L., Horner M., Asymmetries of influence: Differential effects of body postures on perceptions of emotional facial expressions, PLoS ONE, 8, 9, (2013); Montepare J.M., Dobish H., The contribution of emotion perceptions and their overgeneralizations to trait impressions, J. Nonverbal Behav., 27, 4, pp. 237-254, (2003); Montepare J.M., Zebrowitz L.A., Person perception comes of age: The salience and significance of age in social judgments, Advances in Experimental Social Psychology, 30, pp. 93-161, (1998); Mayers C.D., Tingley D., The influence of emotion on trust, Political Analysis, 24, 4, pp. 492-500, (2016); Niebuhr O., Vosse J., Brem A., What makes a charismatic speaker? A computer-based acoustic-prosodic analysis of steve jobs tone of voice, Comput. Hum. Behav., 64, pp. 366-382, (2016); Nojavanasghari B., Baltrusaitis T., Hughes C.E., Morency L.-P., EmoReact: A multimodal approach and dataset for recognizing emotional responses in children, Proc. 18th ACM Int. Conf. Multimodal Interact. (ICMI), pp. 137-144, (2016); Oosterhof N.N., Todorov A., The functional basis of face evaluation, Proc. Nat. Acad. Sci. USA, 105, 32, pp. 11087-11092, (2008); Pantic M., Bartlett M.S., Machine analysis of facial expressions, Face Recognition, pp. 377-416, (2007); Pantie M., Rothkrantz L.J.M., Automatic analysis of facial expressions: The state of the art, IEEE Trans. Pattern Anal. Mach. Intell., 22, 12, pp. 1424-1445, (2000); Pepino L., Riera P., Ferrer L., Emotion recognition from speech using wav2vec 2.0 embeddings, Proc. INTERSPEECH, 2021, pp. 3400-3404; Putnam R.D., Leonardi R., Nonetti R.Y., Making Democracy Work: Civic Traditions in Modern Italy, (1993); Ren J., Ding R., Li S., Zhang M., Wei D., Feng C., Xu P., Luo W., Features and extra-striate body area representations of diagnostic body parts in anger and fear perception, Brain Sci, 12, 4, (2022); Resnick P., Zeckhauser R., Trust among strangers in internet transactions: Empirical analysis of eBay’s reputation system, The Economics of the Internet and e-Commerce (Advances in Applied Microeconomics), 11, pp. 127-157, (2002); Bureau U.C., Memorandum 2018.02: Using two separate questions for race and ethnicity in 2018 end-to-end census test and 2020 census, (2018); Roter D.L., Frankel R.M., Hall J.A., Sluyter D., The expression of emotion through nonverbal behavior in medical visits, J. Gen. Internal Med., 21, 1, pp. 28-34, (2006); Ruiz N., Cognitive load measurement in multimodal interfaces; Sariyanidi E., Gunes H., Cavallaro A., Automatic analysis of facial affect: A survey of registration, representation, and recognition, IEEE Trans. Pattern Anal. Mach. Intell., 37, 6, pp. 1113-1133, (2015); Scharlemann J.P.W., Eckel C.C., Kacelnik A., Wilson R.K., The value of a smile: Game theory with a human face, J. Econ. Psychol., 22, 5, pp. 617-640, (2001); Secord P.F., Dukes W.F., Bevan W., Personalities in faces: I. An experiment in social perceiving, Genetic Psychol. Monographs, 49, (1954); Simpson J.A., Foundations of interpersonal trust, Social Psychology: Handbook of Basic Principles, pp. 587-607, (2007); Slepian M.L., Carr E.W., Facial expressions of authenticity: Emotion variability increases judgments of trustworthiness and leadership, Cognition, 183, pp. 82-98, (2019); Sofer C., Dotsch R., Wigboldus D.H.J., Todorov A., What is typical is good: The influence of face typicality on perceived trustworthiness, Psychol. Sci., 26, 1, pp. 39-47, (2015); Sullivan J.L., Transue J.E., The psychological underpinnings of democracy: A selective review of research on political tolerance, interpersonal trust, and social capital, Annu. Rev. Psychol., 50, 1, pp. 625-650, (1999); Todorov A., Olivola C.Y., Dotsch R., Mende-Siedlecki P., Social attributions from faces: Determinants, consequences, accuracy, and functional significance, Annu. Rev. Psychol., 66, 1, pp. 519-545, (2015); Torre I., Goslin J., White L., Zanatto D., Trust in artificial voices, Proc. Technol., Mind, Soc. TechMindSociety, Technol., Mind, Soc., pp. 1-6, (2018); White S.W., Abbott L., Wieckowski A.T., Capriola-Hall N.N., Aly S., Youssef A., Feasibility of automated training for facial emotion expression and recognition in autism, Behav. Therapy, 49, 6, pp. 881-888, (2018); Willinger M., Keser C., Lohmann C., Usunier J.C., A comparison of trust and reciprocity between France and Germany: Experimental investigation based on the investment game, J. Econ. Psychol., 24, 4, pp. 447-466, (2003); Wilson R.K., Eckel C.C., Judging a book by its cover: Beauty and expectations in the trust game, Political Res. Quart., 59, 2, pp. 189-202, (2006); Wu Y., Huang T.S., Human hand modeling, analysis and animation in the context of HCI, Proc. Int. Conf. Image Process., 3, pp. 6-10, (1999); Zadeh A., Zellers R., Pincus E., Morency L.-P., MOSI: Multimodal corpus of sentiment intensity and subjectivity analysis in online opinion videos, (2016); Zhao Y., Georganas N.D., Petriu E.M., Zhao Y., Human emotion recognition from body language of the head using soft computing techniques, J. Ambient Intell. Humanized Comput., 4, pp. 121-140, (2012); Du Z., Wu S., Huang D., Li W., Wang Y., Spatio-temporal encoder-decoder fully convolutional network for video-based dimensional emotion recognition, IEEE Trans. Affect. Comput., 12, 3, pp. 565-578; Han J., Zhang Z., Ren Z., Schuller B., EmoBed: Strengthening monomodal emotion recognition via training with crossmodal emotion embeddings, IEEE Trans. Affect. Comput., 12, 3, pp. 553-564","S.L. Lutfi; School of Computer Sciences, Universiti Sains Malaysia, Minden, Penang, 11800, Malaysia; email: Syaheerah@usm.my; B. Lahasan; Faculty of Computer and Information Technology, University of Shabwah, Shabwah, Yemen; email: albdr2002@gmail.com","","Institute of Electrical and Electronics Engineers Inc.","","","","","","21693536","","","","English","IEEE Access","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85178991493"
"Lahasan B.; Lutfi S.L.; San-Segundo R.","Lahasan, Badr (56768228800); Lutfi, Syaheerah Lebai (27567802400); San-Segundo, Rubén (8333266700)","56768228800; 27567802400; 8333266700","A survey on techniques to handle face recognition challenges: occlusion, single sample per subject and expression","2019","Artificial Intelligence Review","52","2","","949","979","30","46","10.1007/s10462-017-9578-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029545099&doi=10.1007%2fs10462-017-9578-y&partnerID=40&md5=5215ad96a1856d3b599c467f06226bbe","School of Computer Science, Univerisiti Sains Malaysia, Gelugor, 11800, Penang, Malaysia; Department of Computer Science, Faculty of Education-Shabwa, University of Aden, PO Box 6312, Aden, Yemen; Grupo Technología del Habla, E.T.S.I. Telecomunicación (ETSIT) Universidad Politécnica de Madrid (UPM), Madrid, Spain","Lahasan B., School of Computer Science, Univerisiti Sains Malaysia, Gelugor, 11800, Penang, Malaysia, Department of Computer Science, Faculty of Education-Shabwa, University of Aden, PO Box 6312, Aden, Yemen; Lutfi S.L., School of Computer Science, Univerisiti Sains Malaysia, Gelugor, 11800, Penang, Malaysia; San-Segundo R., Grupo Technología del Habla, E.T.S.I. Telecomunicación (ETSIT) Universidad Politécnica de Madrid (UPM), Madrid, Spain","Face recognition is receiving a significant attention due to the need of facing important challenges when developing real applications under unconstrained environments. The three most important challenges are facial occlusion, the problem of dealing with a single sample per subject (SSPS) and facial expression. This paper describes and analyzes various strategies that have been developed recently for overcoming these three major challenges that seriously affect the performance of real face recognition systems. This survey is organized in three parts. In the first part, approaches to tackle the challenge of facial occlusion are classified, illustrated and compared. The second part briefly describes the SSPS problem and the associated solutions. In the third part, facial expression challenge is illustrated. In addition, pros and cons of each technique are stated. Finally, several improvements for future research are suggested, providing a useful perspective for addressing new research in face recognition. © 2017, Springer Science+Business Media B.V.","Expression; Face recognition; Facial occlusion challenge; Single sample per subject (SSPS) problem","Surveys; Expression; Face recognition systems; Facial Expressions; Facial occlusions; Real applications; Single sample; Unconstrained environments; Face recognition","","","","","Universiti Sains Malaysia, (304/PKOMP/6312153)","Acknowledgements The authors would like to thank Universiti Sains Malaysia for the funding of this work from the Grant No. 304/PKOMP/6312153. Authors also express their gratitude to Ms. Amal Azazi for her insights and knowledge shared.","Abate A.F., Nappi M., Riccio D., Sabatino G., 2d and 3d face recognition: a survey, Pattern Recognit Lett, 28, 14, pp. 1885-1906, (2007); Ahonen T., Hadid A., Pietikainen M., Face description with local binary patterns: application to face recognition, IEEE Trans Pattern Anal Mach Intell, 28, 12, pp. 2037-2041, (2006); Aisha A., Muhammad S., Hussain S.J., Mudassar R., Face recognition invariant to partial occlusions, KSII Trans Internet Inf Syst (TIIS), 8, 7, pp. 2496-2511, (2014); Amutha R., A novel approach to face recognition under various facial expressions, occlusion and tilt angles, 2012 International Conference on Emerging Trends in Science, Engineering and Technology (INCOSET). IEEE, pp. 143-149, (2012); Andres A.M., Padovani S., Tepper M., Jacobo-Berlles J., Face recognition on partially occluded images using compressed sensing, Pattern Recognit Lett, 36, pp. 235-242, (2014); Ayarpadi K., Kannan E., Nair R.R., Anitha T., Srinivasan R., Scholar P., Face recognition under expressions and lighting variations using masking and synthesizing, Int J Eng Res Appl (IJERA), 2, 1, pp. 758-763, (2012); Bartlett M.S., Movellan J.R., Sejnowski T.J., Face recognition by independent component analysis, IEEE Trans Neural Netw, 13, 6, pp. 1450-1464, (2002); Belhumeur P.N., Hespanha J.P., Kriegman D.J., Eigenfaces vs. fisherfaces: recognition using class specific linear projection, IEEE Trans Pattern Anal Mach Intell, 19, 7, pp. 711-720, (1997); Bilge H.S., Kerimbekov Y., Ugurlu H.H., Dimensionality reduction based on Lorentzian manifold for face recognition, 2013 International Conference on Electronics, Computer and Computation (ICECCO), pp. 212-215, (2013); Bledsoe W., The model method in facial recognition, panoramic research inc, (1964); Cai J., Chen J., Liang X., Single-sample face recognition based on intra-class differences in a variation model, Sensors, 15, 1, pp. 1071-1087, (2015); Cevikalp H., Neamtu M., Wilkes M., Barkana A., Discriminative common vectors for face recognition, IEEE Trans Pattern Anal Mach Intell, 27, 1, pp. 4-13, (2005); Chadha A.R., Vaidya P.P., Roja M.M., Face recognition using discrete cosine transform for global and local features, 2011 International Conference on Recent Advancements in Electrical, Electronics and Control Engineering (Iconraeece), pp. 502-505, (2011); Chen W., Gao Y., Recognizing partially occluded faces from a single sample per class using string-based matching, Computer Vision-Eccv. Springer, pp. 496-509, (2010); Chen W., Gao Y., Face recognition using ensemble string matching, IEEE Trans Image Process, 22, 12, pp. 4798-4808, (2013); Chen X., Rynn P., Bowyer K.W., Fully automated facial symmetry axis detection in frontal color images, Fourth IEEE Workshop on Automatic Identification Advanced Technologies, (2005). IEEE, pp. 106-111, (2005); Chen X., Wang S., Liu W., Face recognition based on error detection under partial occlusion, 2015 12Th International Conference on Service Systems and Service Management (ICSSSM), pp. 1-4, (2015); Chen Y., Yang J., Luo L., Zhang H., Qian J., Tai Y., Zhang J., Adaptive noise dictionary construction via IRRPCA for face recognition, Pattern Recognit, 59, pp. 26-41, (2016); Chintalapati S., Raghunadh M., Illumination, expression and occlusion invariant pose-adaptive face recognition system for real-time applications, Int J Eng Trends Technol (IJETT), 8, 6, pp. 292-298, (2014); Chitra S., Balakrishnan G., A survey of face recognition on feature extraction process of dimensionality reduction techniques, J Theor Appl Inf Technol, 36, 1, pp. 92-100, (2012); Deng Y., Dai Q., Zhang Z., Graph Laplace for occluded face completion and recognition, IEEE Trans Image Process, 20, 8, pp. 2329-2338, (2011); Deng W., Hu J., Zhou X., Guo J., Equidistant prototypes embedding for single sample based face recognition with generic learning and incremental learning, Pattern Recognit, 47, 12, pp. 3738-3749, (2014); Ding R.-X., Du D.K., Huang Z.-H., Li Z.-M., Shang K., Variational feature representation-based classification for face recognition with single sample per person, J Vis Commun Image Represent, 30, pp. 35-45, (2015); Etemad K., Chellappa R., Discriminant analysis for recognition of human face images, JOSA A, 14, 8, pp. 1724-1733, (1997); Faaya T.H., Toygar O., Demiralp M., Mikhael W., Caballero A., Abatzoglou N., Tabrizi M., Leandre R., Garcia-Planas M., Chroas R., Recognizing faces under facial expression variations and partial occlusions, In: WSEAS International Conference. Proceedings. Mathematics and Computers in Science and Engineering, 7, (2008); Feng Z., Yang M., Zhang L., Liu Y., Zhang D., Joint discriminative dimensionality reduction and dictionary learning for face recognition, Pattern Recognit, 46, 8, pp. 2134-2143, (2013); Gao Y., Leung M.K., Face recognition using line edge map, IEEE Trans Pattern Anal Mach Intell, 24, 6, pp. 764-779, (2002); Gao Y., Qi Y., Robust visual similarity retrieval in single model face databases, Pattern Recognit, 38, 7, pp. 1009-1020, (2005); Gao Q.-X., Zhang L., Zhang D., Face recognition using FLDA with single training image per person, Appl Math Comput, 205, 2, pp. 726-734, (2008); Gao S., Jia K., Zhuang L., Ma Y., Neither global nor local: regularized patch-based representation for single sample per person face recognition, Int J Comput Vis, 111, 3, pp. 365-383, (2015); Gu G., Hou Z., Chen C., Zhao Y., A dimensionality reduction method based on structured sparse representation for face recognition, Artif Intell Rev, 46, 4, pp. 431-443, (2016); Guo G., Li S.Z., Chan K., Face recognition by support vector machines, Fourth IEEE International Conference on Automatic Face and Gesture Recognition, Proceedings. IEEE, pp. 196-201, (2000); Hafiz F., Shafie A.A., Mustafah Y.M., Face recognition from single sample per person by learning of generic discriminant vectors, Procedia Eng, 41, pp. 465-472, (2012); Haghighat M., Abdel-Mottaleb M., Alhalabi W., Fully automatic face normalization and single sample face recognition in unconstrained environments, Expert Syst Appl, 47, pp. 23-34, (2016); Han X., Yap M.H., Palmer I., Face recognition in the presence of expressions, J Softw Eng Appl, 5, 5, (2012); Harguess J., Aggarwal J., Is there a connection between face symmetry and face recognition?, In: 2011 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), pp. 66-73, (2011); He X., Niyogi P., Locality preserving projections, Advances in Neural Information Processing Systems, 5, pp. 153-160, (2004); Hsieh C.-K., Lai S.-H., Chen Y.-C., An optical flow-based approach to robust face recognition under expression variations, IEEE Trans Image Process, 19, 1, pp. 233-240, (2010); Hu Y.-S., Li J., Yang Z., Lu J.-G., Su J.-B., Joint dimensionality reduction for face recognition based on d-ksvd, 2016 International Conference on Machine Learning and Cybernetics (ICMLC), 2, pp. 483-488, (2016); Hu C., Ye M., Ji S., Zeng W., Lu X., A new face recognition method based on image decomposition for single sample per person problem, Neurocomputing, 160, pp. 287-299, (2015); Huang X., Zhao G., Zheng W., Pietikainen M., Towards a dynamic expression recognition system under facial occlusion, Pattern Recognit Lett, 33, 16, pp. 2181-2191, (2012); Huang J., Su K., El-Den J., Hu T., Li J., An MPCA/LDA based dimensionality reduction algorithm for face recognition, Math Probl Eng, 2014, pp. 1-12, (2014); Huang J., Yuen P.C., Chen W.-S., Lai J.-H., Component-based lDA method for face recognition with one training sample, IEEE International Workshop on Analysis and Modeling of Faces and Gestures, AMFG 2003, pp. 120-126, (2003); Jadhav D.V., Holambe R.S., Radon and discrete cosine transforms based feature extraction and dimensionality reduction approach for face recognition, Signal Process, 88, 10, pp. 2604-2609, (2008); JayaMohan C., Deepak M.S., Manuel M.A.E., Wise D.J.W., Face recognition under expressions and lighting variations using artificial intelligence and image synthesizing, Int J Comput Sci Netw Secur (IJCSNS), 15, 9, (2015); Kan M., Shan S., Su Y., Xu D., Chen X., Adaptive discriminant learning for face recognition, Pattern Recognit, 46, 9, pp. 2497-2509, (2013); Kanan H.R., Gao Y., Recognition of expression variant faces from one sample image per enrolled subject, 2009 16Th IEEE Intenational Conference on Image Processing (ICIP). IEEE, pp. 3309-3312, (2009); Kanan H.R., Faez K., Recognizing faces using adaptively weighted sub-gabor array from a single sample image per enrolled subject, Image Vis Comput, 28, 3, pp. 438-448, (2010); Kanan H.R., Faez K., Gao Y., Face recognition using adaptively weighted patch PZM array from a single exemplar image per person, Pattern Recognit, 41, 12, pp. 3799-3812, (2008); Khamele S.V., Mundada S.G., An approach for restoring occluded images for face-recognition, Int J Adv Res Comput Commun Eng, 4, 17, pp. 571-575, (2015); Kim K.I., Jung K., Kim H.J., Face recognition using kernel principal component analysis, IEEE Signal Process Lett, 9, 2, pp. 40-42, (2002); Kim J., Choi J., Yi J., Turk M., Effective representation using ICA for face recognition robust to local distortion and partial occlusion, IEEE Trans Pattern Anal Mach Intell, 27, 12, pp. 1977-1981, (2005); Kim T.Y., Lee K.M., Lee S.U., Yim C.-H., Occlusion invariant face recognition using two-dimensional PCA, Adv Comput Graph Comput Vis, 4, pp. 305-315, (2007); Kumar D.S., Kumaresan S.J., Real-time face recognition based on optical flow and histogram equalization, ICTACT J Image Video Process, 3, 4, pp. 626-629, (2013); Lahasan B.M., Venkat I., Lutfi S.L., Recognition of occluded faces using an enhanced EBGM algorithm, International Conference on Computer & Information Sciences 2014 (ICCOINS2014), (2014); Lahasan B.M., Venkat I., Al-Betar M.A., Lutfi S.L., De Wilde P., Recognizing faces prone to occlusions and common variations using optimal face subgraphs, Appl Math Comput, 283, pp. 316-332, (2016); Latha P., Ganesan L., Annadurai S., Face recognition using neural networks, Signal Process Int J (SPIJ), 3, 5, pp. 153-160, (2009); Levine M.D., Yu Y., Face recognition subject to variations in facial expression, illumination and pose using correlation filters, Comput Vis Image Underst, 104, 1, pp. 1-15, (2006); Li Y., Feng J., Reconstruction based face occlusion elimination for recognition, Neurocomputing, 101, pp. 68-72, (2013); Li Y., Gong S., Liddell H., Support vector regression and classification based multi-view face detection and recognition, Fourth IEEE International Conference on Automatic Face and Gesture Recognition, Proceedings, pp. 300-305, (2000); Li X., Mori G., Zhang H., Expression-invariant face recognition with expression classification, The 3Rd Canadian Conference on Computer and Robot Vision, 2006, (2006); Li L., Peng Y., Qiu G., Sun Z., Liu S., A survey of virtual sample generation technology for face recognition, Artif Intell Rev, 48, pp. 1-20, (2017); Liu J., Chen S., Zhang D., Tan X., An efficient pseudoinverse linear discriminant analysis method for face recognition, In: International Conference on Neural Information Processing, Hong Kong, China, (2006); Liu Z., Pu J., Wu Q., Zhao X., Using the original and symmetrical face training samples to perform collaborative representation for face recognition, Opt Int J Light Electron Opt, 127, 4, pp. 1900-1904, (2016); Lu C.-L., Tsai L.-W., Wang Y.-K., Fan K.-C., Robust face recognition under illumination and facial expression variations, 2010 International Conference on Machine Learning and Cybernetics (ICMLC), 6, pp. 3257-3263, (2010); Lu J., Tan Y.-P., Wang G., Discriminative multimanifold analysis for face recognition from a single training sample per person, IEEE Trans Pattern Anal Mach Intell, 35, 1, pp. 39-51, (2013); Luan X., Fang B., Liu L., Zhou L., Face recognition with contiguous occlusion using linear regression and level set method, Neurocomputing, 122, pp. 386-397, (2013); Luan X., Fang B., Liu L., Yang W., Qian J., Extracting sparse error of robust PCA for face recognition in the presence of varying illumination and occlusion, Pattern Recognit, 47, 2, pp. 495-508, (2014); Martinez A.M., Recognizing expression variant faces from a single sample image per class, In: 2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003, 1, pp. 1-353, (2003); Martinez A.M., Recognizing imprecisely localized, partially occluded, and expression variant faces from a single sample per class, IEEE Trans Pattern Anal Mach Intell, 24, 6, pp. 748-763, (2002); McCloskey S., Langer M., Siddiqi K., Removal of partial occlusion from single images, IEEE Trans Pattern Anal Mach Intell, 33, 3, pp. 647-654, (2011); McLaughlin N., Ming J., Crookes D., Robust multimodal person identification with limited training data, IEEE Trans Hum Mach Syst, 43, 2, pp. 214-224, (2013); Min R., Hadid A., Dugelay J., Improving the recognition of faces occluded by facial accessories, pp. 442-447, (2011); Min R., Hadid A., Dugelay J.-L., Efficient detection of occlusion prior to robust face recognition, Sci World J, (2014); Mliki H., Fendri E., Hammami M., Face recognition through different facial expressions, J Signal Process Syst, 81, 3, pp. 433-446, (2015); Nandini M., Bhargavi P., Sekhar G.R., Face recognition using neural networks, Int J Sci Res Publ, 3, 3, (2013); Neves J., Narducci F., Barra S., Proenca H., Biometric recognition in surveillance scenarios: a survey, Artif Intell Rev, 46, 4, pp. 515-541, (2016); Ou W., You X., Tao D., Zhang P., Tang Y., Zhu Z., Robust face recognition via occlusion dictionary learning, Pattern Recognit, 47, 4, pp. 1559-1572, (2014); Pang Y.H., Teoh A.B.J., Wong E.K., Abas F.S., Supervised locally linear embedding in face recognition, International Symposium on Biometrics and Security Technologies, (2008) ISBAST 2008, pp. 1-6, (2008); Priya G.N., Banu R.W., Occlusion invariant face recognition using mean based weight matrix and support vector machine, Sadhana, 39, 2, pp. 303-315, (2014); Ramachandran M., Zhou S.K., Jhalani D., Chellappa R., A method for converting a smiling face to a neutral face with applications to face recognition, In: IEEE International Conference on Acoustics, Speech, and Signal Processing, 2005. Proceedings. (ICASSP’05), 2, pp. 2-977, (2005); Raytchev B., Yoda I., Sakaue K., Multi-view face recognition by nonlinear dimensionality reduction and generalized linear models, 7Th International Conference on Automatic Face and Gesture Recognition, 2006. FGR 2006. IEEE, pp. 625-630, (2006); Roweis S.T., Saul L.K., Nonlinear dimensionality reduction by locally linear embedding, Science, 290, 5500, pp. 2323-2326, (2000); Satonkar Suhas S., Kurhe Ajay B., Prakash Khanale B., Face recognition using principal component analysis and linear discriminant analysis on holistic approach in facial images database, Int Organ Sci Res, 2, 12, pp. 15-23, (2012); Scholkopf B., Smola A., Muller K.-R., Nonlinear component analysis as a kernel eigenvalue problem, Neural Comput, 10, 5, pp. 1299-1319, (1998); Sharma A., Dubey A., Tripathi P., Kumar V., Pose invariant virtual classifiers from single training image using novel hybrid-eigenfaces, Neurocomputing, 73, 10, pp. 1868-1880, (2010); Sharma M., Prakash S., Gupta P., An efficient partial occluded face recognition system, Neurocomputing, 116, pp. 231-241, (2013); Singh A.K., Nandi G., Face recognition using facial symmetry, Proceedings of the Second International Conference on Computational Science, Engineering and Information Technology. ACM, pp. 550-554, (2012); Song F., Zhang D., Yang J., A novel dimensionality-reduction approach for face recognition, Neurocomputing, 69, 13, pp. 1683-1687, (2006); Tan X., Chen S., Zhou Z.-H., Zhang F., Recognizing partially occluded, expression variant faces from single training image per person with som and soft k-nn ensemble, IEEE Trans Neural Netw, 16, 4, pp. 875-886, (2005); Tan X., Chen S., Zhou Z.-H., Zhang F., Face recognition from a single image per person: a survey, Pattern Recognit, 39, 9, pp. 1725-1745, (2006); Tan X., Chen S., Zhou Z.-H., Liu J., Face recognition under occlusions and variant expressions with partial similarity, IEEE Trans Inf Forensics Secur, 4, 2, pp. 217-230, (2009); Tenenbaum J.B., De Silva V., Langford J.C., A global geometric framework for nonlinear dimensionality reduction, Science, 290, 5500, pp. 2319-2323, (2000); Troje N., Bulthoff H., Bilateral symmetry of human faces helps to generalize to novel views, 24Th Göttingen Neurobiology Conference, (1996); Tsai P., Tran T.P., Cao L., Expression-invariant facial identification, IEEE International Conference on Systems, Man and Cybernetics (2009) SMC 2009, pp. 5151-5155, (2009); Turk M., Pentland A., Eigenfaces for recognition, J Cogn Neurosci, 3, 1, pp. 71-86, (1991); Venkat I., Khader A.T., Subramanian K., Wilde P.D., Recognizing occluded faces by exploiting psychophysically inspired similarity maps, Pattern Recognit Lett, 34, 8, pp. 903-911, (2013); Vetter T., Synthesis of novel views from a single face image, Int J Comput Vis, 28, 2, pp. 103-116, (1998); Vijayalakshmi A., Raj P., An efficient method to recognize human faces from video sequences with occlusion?, World Comput Sci Inf Technol J (WCSIT), 5, 2, pp. 28-33, (2015); Vijayalakshmi A., Raj P., An approach to improvise recognition rate from occluded and pose variant faces, 2015 International Conference on Computation of Power, Energy Information and Commuincation (ICCPEIC). IEEE, pp. 0547-0552, (2015); Vimala K., Kalaivani V., Devi V.A., Optical flow based face recognition under expression variations, Int J Inf Sci Intell Syst, 2, 3, pp. 1-12, (2014); Vinay A., Vasuki V., Bhat S., Jayanth K., Murthy K.B., Natarajan S., Two dimensionality reduction techniques for surf based face recognition, Procedia Comput Sci, 85, pp. 241-248, (2016); Wan M., Yang G., Huang W., Jin Z., Class mean embedding for face recognition, Artif Intell Rev, 36, 4, pp. 285-297, (2011); Wang B., Li W., Li Z., Liao Q., Adaptive linear regression for single-sample face recognition, Neurocomputing, 115, pp. 186-191, (2013); Wang Y., Wang M., Chen Y., Zhu Q., A novel virtual samples-based sparse representation method for face recognition, Optik-Int J Light Electron Opt, 125, 15, pp. 3908-3912, (2014); Wang C., Zhang J., Chang G., Ke Q., Singular value decomposition projection for solving the small sample size problem in face recognition, J Vis Commun Image Represent, 26, pp. 265-274, (2015); Wei X., Li C.-T., Fixation and saccade based face recognition from single image per person with various occlusions and expressions, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, pp. 70-75, (2013); Wei C.-P., Wang Y.-C.F., Undersampled face recognition via robust auxiliary dictionary learning, IEEE Trans Image Process, 24, 6, pp. 1722-1734, (2015); Wei X., Li C.-T., Hu Y., Face recognition with occlusion using dynamic image-to-class warping (DICW), 10Th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), pp. 1-6, (2013); Wen Y., Liu W., Yang M., Fu Y., Xiang Y., Hu R., Structured occlusion coding for robust face recognition, Neurocomputing, 178, pp. 11-24, (2016); Wen Y., Liu W., Yang M., Fu Y., Xiang Y., Hu R., Structured Occlusion Coding for Robust Face Recognition, (2015); Weng R., Lu J., Tan Y., Robust point set matching for partial face recognition, IEEE Trans Image Process, 25, 3, pp. 1163-1176, (2016); Wright J., Yang A., Ganesh A., Sastry S., Ma Y., Robust face recognition via sparse representation, IEEE Trans Pattern Anal Mach Intell, 31, 2, pp. 210-227, (2009); Xiang-Dong Z.M.-L.L., Shi-Fu C., Face recognition using kernel methods, Comput Sci, 5, (2003); Yang M., Zhang L., Shiu S.C., Zhang D., Gabor feature based robust representation and classification for face recognition with gabor occlusion dictionary, Pattern Recogn, 46, 7, pp. 1865-1878, (2013); Yang M., Zhang L., Shiu S.C.-K., Zhang D., Robust kernel representation with statistical local features for face recognition, IEEE Trans Neural Netw Learn Syst, 24, 6, pp. 900-912, (2013); Yang G., Feng Y., Lu H., Sparse error via reweighted low rank representation for face recognition with various illumination and occlusion, Opt Int J Light Electron Opt, 126, 24, pp. 5376-5380, (2015); Yang M., Zhang L., Yang J., Zhang D., Robust sparse coding for face recognition, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). IEEE, pp. 625-632, (2011); Ye J., Li Q., A two-stage linear discriminant analysis via qr-decomposition, IEEE Trans Pattern Anal Mach Intell, 27, 6, pp. 929-941, (2005); Zhang D., Chen S., Zhou Z.-H., A new face recognition method based on svd perturbation for single example image per person, Appl Math Comput, 163, 2, pp. 895-907, (2005); Zhang T., Li X., Guo R.-Z., Producing virtual face images for single sample face recognition, Opt Int J Light Electron Opt, 125, 17, pp. 5017-5024, (2014); Zhao S., Hu Z.-P., A modular weighted sparse representation based on fisher discriminant and sparse residual for face recognition with occlusion, Inf Process Lett, 115, 9, pp. 677-683, (2015); Zhao S., Hu Z.-P., Double layers sparse representation for occluded face recognition, Opt Int J Light Electron Opt, 126, 21, pp. 3016-3019, (2015); Zhao L.-N., Hu W.-B., Cui L.-H., Face recognition feature comparison based SVD and FFT, J Signal Inf Process, 3, 2, pp. 259-262, (2012); Zhao Y., Liu Y., Liu Y., Zhong S., Hua K.A., Face recognition from a single registered image for conference socializing, Expert Syst Appl, 42, 3, pp. 973-979, (2015); Zhao Z.-Q., Cheung Y.-M., Hu H., Wu X., Corrupted and occluded face recognition via cooperative sparse representation, Pattern Recognit, 56, pp. 77-87, (2016); Zheng C.-H., Hou Y.-F., Zhang J., Improved sparse representation with low-rank representation for robust face recognition, Neurocomputing, 198, pp. 114-124, (2016)","B. Lahasan; Department of Computer Science, Faculty of Education-Shabwa, University of Aden, Aden, PO Box 6312, Yemen; email: bdr.lahasan@gmail.com","","Springer Netherlands","","","","","","02692821","","AIRVE","","English","Artif Intell Rev","Article","Final","","Scopus","2-s2.0-85029545099"
"Arasu D.B.L.; Mohamed A.S.A.; Ruhaiyem N.I.R.; Annamalai N.; Lutfi S.L.; Al Qudah M.M.","Arasu, Darshan Babu L. (57207817920); Mohamed, Ahmad Sufril Azlan (57190968285); Ruhaiyem, Nur Intan Raihana (57190964192); Annamalai, Nagaletchimee (57127041900); Lutfi, Syaheerah Lebai (27567802400); Al Qudah, Mustafa M. (57222567501)","57207817920; 57190968285; 57190964192; 57127041900; 27567802400; 57222567501","Human Stress Recognition from Facial Thermal-Based Signature: A Literature Survey","2021","CMES - Computer Modeling in Engineering and Sciences","129","3","","1","20","19","3","10.32604/CMES.2021.016985","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121910570&doi=10.32604%2fCMES.2021.016985&partnerID=40&md5=045006c5bd2e601be7b64c5c25f4cd72","School of Computer Sciences, Universiti Sains Malaysia, Penang, 11800, Malaysia; School of Distance Education, Universiti Sains Malaysia, Penang, 11800, Malaysia","Arasu D.B.L., School of Computer Sciences, Universiti Sains Malaysia, Penang, 11800, Malaysia; Mohamed A.S.A., School of Computer Sciences, Universiti Sains Malaysia, Penang, 11800, Malaysia; Ruhaiyem N.I.R., School of Computer Sciences, Universiti Sains Malaysia, Penang, 11800, Malaysia; Annamalai N., School of Distance Education, Universiti Sains Malaysia, Penang, 11800, Malaysia; Lutfi S.L., School of Computer Sciences, Universiti Sains Malaysia, Penang, 11800, Malaysia; Al Qudah M.M., School of Computer Sciences, Universiti Sains Malaysia, Penang, 11800, Malaysia","Stress is a normal reaction of the human organism which triggered in situations that require a certain level of activation. This reaction has both positive and negative effects on everyone’s life. Therefore, stress management is of vital importance in maintaining the psychological balance of a person. Thermal-based imaging technique is becoming popular among researchers due to its non-contact conductive nature. Moreover, thermal-based imaging has shown promising results in detecting stress in a non-contact and non-invasive manner. Compared to other non-contact stress detection methods such as pupil dilation, keystroke behavior, social media interaction and voice modulation, thermal-based imaging provides better features with clear boundaries and requires no heavy methodology. This paper presented a brief review of previous work on thermal imaging related stress detection in humans. This paper also presented the stages of stress detection based on thermal face signatures such as dataset type, thermal image face detection, feature descriptors and classification performance comparisons are presented. This paper can help future researchers to understand stress detection based on thermal imaging by presenting the popular methods previous researchers use for stress detection based on thermal images. © 2021 Tech Science Press. All rights reserved.","Skin temperature; Stress recognition; Stress state; Thermal imaging; Thermal signature","Classification (of information); Face recognition; Feature extraction; Infrared imaging; Human stress; Non-contact; Skin temperatures; Stress detection; Stress recognition; Stress state; Thermal; Thermal images; Thermal signatures; Thermal-imaging; Stresses","","","","","Universiti Sains Malaysia, (1001/PKOMP/8014001)","Funding Statement: This research was pursued under the Research University Grant by Universiti Sains Malaysia [1001/PKOMP/8014001].","Selye H., Confusion and controversy in the stress field, Journal of Human Stress, 1, 2, pp. 37-44, (1975); Lederbogen F., Baranyai R., Gilles M., Menart-Houtermans B., Tschoepe D., Et al., Effect of mental and physical stress on platelet activation markers in depressed patients and healthy subjects: A pilot study, Psychiatry Research, 127, 1–2, pp. 55-64, (2004); Otto M., Physical stress and bacterial colonization, FEMS Microbiology Reviews, 38, 6, pp. 1250-1270, (2014); Tripathi R. K., Salve B. A., Petare A. U., Raut A. A., Rege N. N., Effect of withania somnifera on physical and cardiovascular performance induced by physical stress in healthy human volunteers, International Journal of Basic & Clinical Pharmacology, 5, pp. 2510-2516, (2016); Pardeshi A. M., Kirtikar S. N., Comparison of anthropometric parameters and blood pressure changes in response to physical stress test in normotensive subjects with or without family history of hypertension, Indian Journal of Physiology and Pharmacology, 60, 2, pp. 208-212, (2016); Oktedalen O., The infuence of prolonged physical stress on gastric juice components in healthy man, Scand J. Gastroenterol, 23, 9, pp. 1132-1136, (1988); Wallen N. H., Held C., Rehnqvist N., Hjemdahl P., Effects of mental and physical stress on platelet function in patients with stable angina pectoris and healthy controls, European Heart Journal, 18, 5, pp. 807-815, (1997); Trapp M., Trapp E. M., Egger J. W., Domej W., Schillaci G., Et al., Impact of mental and physical stress on blood pressure and pulse pressure under normobaric versus hypoxic conditions, PLoS One, 9, 5, (2014); Irfan M., Raja G. K., Murtaza S., Mansoor R., Qayyum M., Et al., Physical stress may result in growth suppression and pubertal delay in working boys, Journal of Medical Hypotheses and Ideas, 6, 1, pp. 35-39, (2012); Kim H. S., A study on the skin stress recognition and beauty care status due to wearing masks, Journal of the Korean Applied Science and Technology, 38, 2, pp. 465-475, (2021); Cohen S., Kamarck T., Mermelstein R., A global measure of perceived stress, Journal of Health and Social Behavior, 24, pp. 385-396, (1983); Dupere V., Dion E., Harkness K., McCabe J., Thouin E., Et al., Adaptation and validation of the life events and difficulties schedule for use with high school dropouts, Journal of Research on Adolescence, 27, 3, pp. 683-689, (2017); Gillan W., Naquin M., Zannis M., Bowers A., Brewer J., Et al., Correlations among stress, physical activity and nutrition: School employee health behavior, ICHPER-SD Journal of Research, 8, 1, pp. 55-60, (2013); Mizuno M., Siddique K., Baum M., Smith S. A., Prenatal programming of hypertension induces sympathetic overactivity in response to physical stress, Hypertension, 61, 1, pp. 180-186, (2013); Taylor A. H., Dorn L., Stress, fatigue, health, and risk of road traffic accidents among professional drivers: The contribution of physical inactivity, Annual Review of Public Health, 27, pp. 371-391, (2006); Jones B. F., A reappraisal of the use of infrared thermal image analysis in medicine, IEEE Transactions on Medical Imaging, 17, 6, pp. 1019-1027, (1998); Jones B. F., Plassmann P., Digital infrared thermal imaging of human skin, IEEE Engineering in Medicine and Biology Magazine, 21, 6, pp. 41-48, (2002); Khan M. M., Cluster-analytic classification of facial expressions using infrared measurements of facial thermal features, (2008); Fujimasa I., Chinzei T., Saito I., Converting far infrared image information to other physiological data, IEEE Engineering in Medicine and Biology Magazine, 19, 3, pp. 71-76, (2000); Bale M., High-resolution infrared technology for soft-tissue injury detection, IEEE Engineering in Medicine and Biology Magazine, 17, 4, pp. 56-59, (1998); Hessler C., Abouelenien M., Burzo M., A survey on extracting physiological measurements from thermal images, Proceedings of the 11th PErvasive Technologies Related to Assistive Environments Conference, pp. 229-236, (2018); Zhao W., Zhao Z., Li C., Discriminative-CCA promoted by EEG signals for physiological-based emotion recognition, 2018 First Asian Conference on Affective Computing and Intelligent Interaction (ACII Asia), pp. 1-6, (2018); Barclay C. J., Launikonis B. S., Components of activation heat in skeletal muscle, Journal of Muscle Research and Cell Motility, 42, 1, pp. 1-16, (2021); Youssef A., Verachtert A., de Bruyne G., Aerts J. M., Reverse engineering of thermoregulatory cold-induced vasoconstriction/Vasodilation during localized cooling, Applied Sciences, 9, 16, (2019); Khan M. M., Ward R. D., Ingleby M., Classifying pretended and evoked facial expressions of positive and negative affective states using infrared measurement of skin temperature, ACM Transactions on Applied Perception, 6, 1, pp. 1-22, (2009); Pavidis I., Eberhardt N. L., Levine J. A., Human behavior: Seeing through the face of deception [Brief communication], Nature, 425, (2002); Pavlidis I., Continuous physiological monitoring, Proceedings of the 25th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (IEEE Cat. No. 03CH37439), 2, pp. 1084-1087, (2003); Pavlidis I., Levine J., Baukol P., Thermal image analysis for anxiety detection, Proceedings 2001 International Conference on Image Processing (Cat. No. 01CH37205), 2, pp. 315-318, (2001); Pavlidis I., Dowdall J., Sun N., Puri C., Fei J., Et al., Interacting with human physiology, Computer Vision and Image Understanding, 108, 1–2, pp. 150-170, (2007); Pavlidis I., Tsiamyrtzis P., Shastri D., Wesley A., Zhou Y., Et al., Fast by nature-how stress patterns define human experience and performance in dexterous tasks, Scientific Reports, 2, 1, pp. 1-9, (2012); Ebisch S. J., Aureli T., Bafunno D., Cardone D., Romani G. L., Et al., Mother and child in synchrony: Thermal facial imprints of autonomic contagion, Biological Psychology, 89, 1, pp. 123-129, (2012); Ioannou S., Ebisch S., Aureli T., Bafunno D., Ioannides H. A., Et al., The autonomic signature of guilt in children: A thermal infrared imaging study, PLoS One, 8, 11, (2013); Hirt C., Eckard M., Kunz A., Stress generation and non-intrusive measurement in virtual environments using eye tracking, Journal of Ambient Intelligence and Humanized Computing, 11, 12, pp. 5977-5989, (2020); Yamanaka K., Kawakami M., Convenient evaluation of mental stress with pupil diameter, International Journal of Occupational Safety and Ergonomics, 15, 4, pp. 447-450, (2009); Gunawardhane S. D., de Silva P. M., Kulathunga D. S., Arunatileka S. M., Non invasive human stress detection using key stroke dynamics and pattern variations, 2013 International Conference on Advances in ICT for Emerging Regions (ICTer), pp. 240-247, (2013); Lin H., Jia J., Guo Q., Xue Y., Li Q., Et al., User-level psychological stress detection from social media using deep neural network, Proceedings of the 22nd ACM International Conference on Multimedia, pp. 507-516, (2014); Hansen J. H., Patil S., Speech under stress: Analysis, modeling and recognition, Speaker classification I, pp. 108-137, (2007); Han H., Byun K., Kang H. G., A deep learning-based stress detection algorithm with speech signal, Proceedings of the 2018 Workshop on Audio-Visual Scene Understanding for Immersive Multimedia, pp. 11-15, (2018); Hansen J. H., Womack B. D., Feature analysis and neural network-based classification of speech under stress, IEEE Transactions on Speech and Audio Processing, 4, 4, pp. 307-313, (1996); Giannakakis G., Pediaditis M., Manousos D., Kazantzaki E., Chiarugie F., Et al., Stress and anxiety detection using facial cues from videos, Biomedical Signal Processing and Control, 31, pp. 89-101, (2017); Zhang J., Mei X., Liu H., Yuan S., Qian T., Detecting negative emotional stress based on facial expression in real time, 2019 IEEE 4th International Conference on Signal and Image Processing (ICSIP), pp. 430-434, (2019); Gao H., Yuce A., Thiran J. P., Detecting emotional stress from facial expressions for driving safety, 2014 IEEE International Conference on Image Processing (ICIP), pp. 5961-5965, (2014); Zhai J., Barreto A., Stress detection in computer users based on digital signal processing of noninvasive physiological variables, 2006 International Conference of the IEEE Engineering in Medicine and Biology Society, pp. 1355-1358, (2006); Shi Y., Nguyen M. H., Blitz P., French B., Fisk S., Et al., Personalized stress detection from physiological measurements, International Symposium on Quality of Life Technology, pp. 28-29, (2010); Hong K., Non-contact physical stress measurement using thermal imaging and blind source separation, Optical Review, 27, 1, pp. 116-125, (2020); Adachi H., Oiwa K., Nozawa A., Drowsiness level modeling based on facial skin temperature distribution using a convolutional neural network, IEEJ Transactions on Electrical and Electronic Engineering, 14, 6, pp. 870-876, (2019); Oiwa K., Nozawa A., Feature extraction of blood pressure from facial skin temperature distribution using deep learning, IEEJ Transactions on Electronics, Information and Systems, 139, 7, pp. 759-765, (2019); Al Qudah M. M., Mohamed A. S., Lutfi S. L., Affective state recognition using thermal-based imaging: A survey, Computer Systems Science & Engineering, 37, 1, pp. 47-62, (2021); Cho Y., Bianchi-Berthouze N., Physiological and affective computing through thermal imaging: A survey, Physiological and Affective Computing through Thermal Imaging: A Survey, (2019); Cho Y., Automated mental stress recognition through mobile thermal imaging, 2017 Seventh International Conference on Affective Computing and Intelligent Interaction (ACII), pp. 596-600, (2017); Elanthendral V. S., Rekha R. K., Rameshkumar M., Thermal imaging for facial expression–Fatigue detection, International Journal for Research in Applied Science & Engineering Technology, 2, (2014); Chu C. H., Peng S. M., Implementation of face recognition for screen unlockingon mobile device, Proceedings of the 23rd ACM International Conference on Multimedia, pp. 1027-1030, (2015); Zhu Z., Tsiamyrtzis P., Pavlidis I., Forehead thermal signature extraction in lie detection, 2007 29th Annual International Conference of the IEEE Engineering in Medicine and Biology Society, IEEE, pp. 243-246, (2007); Hong K., Yuen P., Chen T., Tsitiridis A., Kam F., Et al., Detection and classification of stress using thermal imaging technique, Optics and photonics for counterterrorism and crime fighting V, 7486, (2009); Cross C. B., Skipper J. A., Petkie D. T., Thermal imaging to detect physiological indicators of stress in humans, Thermosense: Thermal infrared applications XXXV, 8705, (2013); Rajoub B. A., Zwiggelaar R., Thermal facial analysis for deception detection, IEEE Transactions on Information Forensics and Security, 9, 6, pp. 1015-1023, (2014); Jenkins S. D., Brown R. D. H., A correlational analysis of human cognitive activity using infrared thermography of the supraorbital region, frontal EEG and self-report of core affective state, Comunicación Presentada en la 12a Conferencia Internacional de Termografía de Infrarrojo Cuantitativa, (2014); Sorostinean M., Ferland F., Tapus A., Reliable stress measurement using face temperature variation with a thermal camera in human-robot interaction, IEEE-RAS 15th International Conference on Humanoid Robots (Humanoids), pp. 14-19, (2015); Mohd M. N. H., Kashima M., Sato K., Watanabe M., Mental stress recognition based on noninvasive and non-contact measurement from stereo thermal and visible sensors, International Journal of Affective Engineering, 14, 1, pp. 9-17, (2015); Abouelenien M., Burzo M., Mihalcea R., Human acute stress detection via integration of physiological signals and thermal imaging, Proceedings of the 9th ACM International Conference on Pervasive Technologies Related to Assistive Environments, pp. 1-8, (2016); Baltaci S., Gokcay D., Stress detection in human–computer interaction: Fusion of pupil dilation and facial temperature features, International Journal of Human–Computer Interaction, 32, 12, pp. 956-966, (2016); Hong K., Liu G., Facial thermal image analysis for stress detection, International Journal of Engineering Research and Technology, 6, 10, pp. 94-98, (2017); Abdelrahman Y., Velloso E., Dingler T., Schmidt A., Vetere F., Cognitive heat: Exploring the usage of thermal imaging to unobtrusively estimate cognitive load, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, 1, 3, pp. 1-20, (2017); Powar N. U., Schneider T. R., Skipper J. A., Petkie D. T., Asari V. K., Et al., Thermal facial signatures for state assessment during deception, Electronic Imaging, 2017, 13, pp. 95-104, (2017); Vasavi S., Neeharica P., Poojitha M., Harika T., Framework for stress detection using thermal signature, International Journal of Virtual and Augmented Reality, 2, 2, pp. 1-25, (2018); Vasavi S., Neeharica P., Wadhwa B., Regression modelling for stress detection in humans by assessing most prominent thermal signature, IEEE 9th Annual Information Technology, Electronics and Mobile Communication Conference, pp. 755-762, (2018); Kopaczka M., Jantos T., Merhof D., Towards analysis of mental stress using thermal infrared tomography, Bildverarbeitung für die Medizin, pp. 157-162, (2018); Stoynova A., Infrared thermography monitoring of the face skin temperature as indicator of the cognitive state of a person, 14th Quantitative InfraRed Thermography Conference, pp. 30-35, (2018); He C., Mahfouf M., Torres-Salomao L. A., Facial temperature markers for mental stress assessment in human-machine interface (HMI) control system, ICINCO, 2, 2, pp. 31-38, (2018); Derakhshan A., Mikaeili M., Gedeon T., Nasrabadi A. M., Identifying the optimal features in multimodal deception detection, Multimodal Technologies and Interaction, 4, 2, (2020); Panasiuk J., Prusaczyk P., Grudzien  A., Kowalski M., Study on facial thermal reactions for psychophysical stimuli, Metrology and Measurement Systems, 27, 3, pp. 399-415, (2020); Reshma R., Emotional and physical stress detection and classification using thermal imaging technique, Annals of the Romanian Society for Cell Biology, 25, pp. 8364-8374, (2021); Kumar S., Iftekhar A. S. M., Goebel M., Bullock T., MacLean M. H., Et al., Stressnet: Detecting stress in thermal videos, Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pp. 999-1009, (2021); Engert V., Merla A., Grant J. A., Cardone D., Tusche A., Et al., Exploring the use of thermal infrared imaging in human stress research, PLoS One, 9, 3, (2014); Zheng Y., Face detection and eyeglasses detection for thermal face recognition, Image processing: Machine vision applications V, 8300, (2012); Cutler R. G., Face recognition using infrared images and eigenfaces, (1996); Chen X., Flynn P. J., Bowyer K. W., PCA-Based face recognition in infrared imagery: Baseline and comparative studies, Proceedings of the IEEE International SOI Conference(Cat. No. 03CH37443), pp. 127-134, (2003); Srivastava A., Liu X., Statistical hypothesis pruning for identifying faces from infrared images, Image and Vision Computing, 21, 7, pp. 651-661, (2003); Buddharaju P., Pavlidis I. T., Tsiamyrtzis P., Pose-invariant physiological face recognition in the thermal infrared spectrum, Conference on Computer Vision and Pattern Recognition Workshop, pp. 53-53, (2006); Heo J., Kong S. G., Abidi B. R., Abidi M. A., Fusion of visual and thermal signatures with eyeglass removal for robust face recognition, Conference on Computer Vision and Pattern Recognition Workshop, pp. 122-122, (2004); Gyaourova A., Bebis G., Pavlidis I., Fusion of infrared and visible images for face recognition, European Conference on Computer Vision, pp. 456-468, (2004); Socolinsky D. A., Selinger A., Thermal face recognition in an operational scenario, Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2, (2004); Wang J. G., Sung E., Venkateswarlu R., Registration of infrared and visible-spectrum imagery for face recognition, Proceedings of the Sixth IEEE International Conference on Automatic Face and Gesture Recognition, Proceedings, pp. 638-644, (2004); Chen X., Flynn P. J., Bowyer K. W., IR and visible light face recognition, Computer Vision and Image Understanding, 99, 3, pp. 332-358, (2005); Kong S. G., Heo J., Abidi B. R., Paik J., Abidi M. A., Recent advances in visual and infrared face recognition—A review, Computer Vision and Image Understanding, 97, 1, pp. 103-135, (2005); Zheng Y., A novel thermal face recognition approach using face pattern words, Biometric technology for human identification VII, 7667, (2010); Basu A., Routray A., Shit S., Deb A. K., Human emotion recognition from facial thermal image based on fused statistical feature and multi-class SVM, 2015 Annual IEEE India Conference, pp. 1-5, (2015); Hu M. K., Visual pattern recognition by moment invariants, IRE Transactions on Information Theory, 8, 2, pp. 179-187, (1962); Mostafa E., Hammoud R., Ali A., Farag A., Face recognition in low resolution thermal images, Computer Vision and Image Understanding, 117, 12, pp. 1689-1694, (2013); Reese K., Zheng Y., Elmaghraby A., A comparison of face detection algorithms in visible and thermal spectrums, International Conference on Advances in Computer Science and Application, (2012); Viola P., Jones M. J., Robust real-time face detection, International Journal of Computer Vision, 57, 2, pp. 137-154, (2004); Basbrain A. M., Gan J. Q., Clark A., Accuracy enhancement of the viola-jones algorithm for thermal face detection, International Conference on Intelligent Computing, pp. 71-82, (2017); Tran H., Dong C., Naghedolfeizi M., Zeng X., Using cross-examples in viola-jones algorithm for thermal face detection, Proceedings of the 2021 ACM Southeast Conference, pp. 219-223, (2021); Kowalski M. L., Grudzien  A., Ciurapinski  W., Detection of human faces in thermal infrared images, Metrology and Measurement Systems, 28, 2, pp. 307-321, (2021); Buddharaju P., Pavlidis I. T., Tsiamyrtzis P., Bazakos M., Physiology-based face recognition in the thermal infrared spectrum, IEEE Transactions on Pattern Analysis and Machine Intelligence, 29, 4, pp. 613-626, (2007); Prokoski F. J., Riedel R. B., Infrared identification of faces and body parts, Biometrics, pp. 191-212, (1996); Cho S. Y., Wang L., Ong W. J., Thermal imprint feature analysis for face recognition, 2009 IEEE International Symposium on Industrial Electronics, pp. 1875-1880, (2009); Kopaczka M., Nestler J., Merhof D., Face detection in thermal infrared images: A comparison of algorithm-and machine-learning-based approaches, International Conference on Advanced Concepts for Intelligent Vision Systems, pp. 518-529, (2017); Friedrich G., Yeshurun Y., Seeing people in the dark: Face recognition in infrared images, International Workshop on Biologically Motivated Computer Vision, pp. 348-359, (2002); Kopaczka M., Schock J., Nestler J., Kielholz K., Merhof D., A combined modular system for face detection, head pose estimation, face tracking and emotion recognition in thermal infrared images, IEEE International Conference on Imaging Systems and Techniques, pp. 1-6, (2018); Kopaczka M., Acar K., Merhof D., Robust facial landmark detection and face tracking in thermal infrared images using active appearance models, VISIGRAPP (4: VISAPP), pp. 150-158, (2016); Antonakos E., Alabort-i-Medina J., Tzimiropoulos G., Zafeiriou S. P., Feature-based lucas–kanade and active appearance models, IEEE Transactions on Image Processing, 24, 9, pp. 2617-2632, (2015); Chu W. T., Liu Y. H., Thermal facial landmark detection by deep multi-task learning, IEEE 21st International Workshop on Multimedia Signal Processing, pp. 1-6, (2019); Sonkusare S., Ahmedt-Aristizabal D., Aburn M. J., Nguyen V. T., Pang T., Et al., Detecting changes in facial temperature induced by a sudden auditory stimulus based on deep learning-assisted face tracking, Scientific Reports, 9, 1, pp. 1-11, (2019); Cao Z., Hidalgo G., Simon T., Wei S. E., Sheikh Y., Openpose: Realtime multi-person 2D pose estimation using part affinity fields, IEEE Transactions on Pattern Analysis and Machine Intelligence, 43, 1, pp. 172-186, (2019); Kumar S., Singh S. K., Occluded thermal face recognition using bag of CNN ($ Bo $ CNN), IEEE Signal Processing Letters, 27, pp. 975-979, (2020); Wu Z., Peng M., Chen T., Thermal face recognition using convolutional neural network, International Conference on Optoelectronics and Image Processing, pp. 6-9, (2016); Simonyan K., Zisserman A., Very deep convolutional networks for large-scale image recognition, (2014); He K., Zhang X., Ren S., Sun J., Deep residual learning for image recognition, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770-778, (2016); Muller M., Baier G., Rummel C., Schindler K., Stephani U., Et al., A multivariate approach to correlation analysis based on random matrix theory, Seizure prediction in epilepsy: From basic mechanisms to clinical applications, pp. 209-226, (2008); Berlovskaya E. E., Isaychev S. A., Chernorizov A. M., Ozheredov I. A., Adamovich T. V., Et al., Diagnosing human psychoemotional states by combining psychological and psychophysiological methods with measurements of infrared and THz radiation from face areas, Psychology in Russia: State of the Art, 13, 2, pp. 64-83, (2020); Kandus J. T., Using functional infrared thermal imaging to measure stress responses, (2018); Jacobs G. D., The physiology of mind–body interactions: The stress response and the relaxation response, The Journal of Alternative & Complementary Medicine, 7, 1, pp. 83-92, (2001); Garbey M., Sun N., Merla A., Pavlidis I., Contact-free measurement of cardiac pulse based on the analysis of thermal imagery, IEEE Transactions on Biomedical Engineering, 54, 8, pp. 1418-1426, (2007); Bara C. P., Papakostas M., Mihalcea R., A deep learning approach towards multimodal stress detection, AffCon@AAAI, CEUR Workshop Proceedings, pp. 67-81, (2020); Gupta S., Stress recognition from image features using deep learning, (2019); Irani R., Nasrollahi K., Dhall A., Moeslund T. B., Gedeon T., Thermal super-pixels for bimodal stress recognition, Sixth International Conference on Image Processing Theory, Tools and Applications, pp. 1-6, (2016)","A.S.A. Mohamed; School of Computer Sciences, Universiti Sains Malaysia, Penang, 11800, Malaysia; email: sufril@usm.my","","Tech Science Press","","","","","","15261492","","","","English","CMES Comput. Model. Eng. Sci.","Review","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85121910570"
"Naidu G.R.; Lutfi S.L.; Azazi A.A.; Lorenzo-Trueba J.; Martinez J.M.M.","Naidu, Ganapreeta Renunathan (57144023300); Lutfi, Syaheerah Lebai (27567802400); Azazi, Amal Abdulrahman (56606204300); Lorenzo-Trueba, Jaime (36986671800); Martinez, Juan Manuel Montero (55960772400)","57144023300; 27567802400; 56606204300; 36986671800; 55960772400","Cross-cultural perception of Spanish synthetic expressive voices among Asians","2018","Applied Sciences (Switzerland)","8","3","426","","","","1","10.3390/app8030426","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043519284&doi=10.3390%2fapp8030426&partnerID=40&md5=fc445bec9d30f0fd36327b90d4485453","School of Computer Sciences, University Sains Malaysia, Gelugor, Pulau Pinang, 11800, Malaysia; Speech Technology Group, ETSI Telecomunicacion, Universidad Politécnica de Madrid, Calle Ramiro de Maeztu, 7, Madrid, 28040, Spain","Naidu G.R., School of Computer Sciences, University Sains Malaysia, Gelugor, Pulau Pinang, 11800, Malaysia; Lutfi S.L., School of Computer Sciences, University Sains Malaysia, Gelugor, Pulau Pinang, 11800, Malaysia; Azazi A.A., School of Computer Sciences, University Sains Malaysia, Gelugor, Pulau Pinang, 11800, Malaysia; Lorenzo-Trueba J., Speech Technology Group, ETSI Telecomunicacion, Universidad Politécnica de Madrid, Calle Ramiro de Maeztu, 7, Madrid, 28040, Spain; Martinez J.M.M., Speech Technology Group, ETSI Telecomunicacion, Universidad Politécnica de Madrid, Calle Ramiro de Maeztu, 7, Madrid, 28040, Spain","Nonverbal cues play a vital role in contributing to how emotions are perceived, especially by outgroups. In this study, a cross-cultural perception experiment of Spanish Synthetic Expressive Voices (SEV) was conducted to investigate the perception rate among different groups of Asians towards the SEV. Ten (10) subjects from each ethnic group namely Japanese, Chinese, Vietnamese, and Malaysians participated in this test. The subjects were required to listen to and categorize the SEV corpus which contains 260 utterances with 4 emotions (anger, happiness, sadness, and surprise) and the neutral speech in different intensities and durations. Overall, the results indicate that duration and intensity of speech plays a significant role in perception. This paper concludes that listeners' perceptions are influenced by a speaker's nonverbal expression and it is important that these features (duration and intensity of speech) are considered when modelling synthetic speech for artificial agents in real-time applications in a cross-cultural user environment. © 2018 by the authors.","Artificial agents; Cross-cultural effects; Nonverbal; Perception; Prosody; Spanish","","","","","","ETSI Telecomunicacion; School of Computer Sciences, Universiti Sains Malaysia; Speech Technology Group; Unoki & Akagi Lab; Japan Advanced Institute of Science and Technology, JAIST; Universidad Autónoma de Madrid, UAM, (304/PKOMP/6312153)","Acknowledgments: Authors are thankful to School of Computer Sciences, Universiti Sains Malaysia and the Speech Technology Group, ETSI Telecomunicacion, Universidad Politecnica de Madrid, Spain for the support s supported by short-term grant: 304/PKOMP/6312153 awarded by. The authors would like to acknowledge the support of Masato Akagi, Reda Elbarogy, members of Unoki & Akagi Lab, Japan Advanced Institute of Science and Technology (JAIST).","Remland M.S., Nonverbal Communication in Everyday Life, (2017); Warren P., Prosody and language processing, Language Processing, pp. 155-188, (1999); Banse R., Scherer L., Acoustic profiles in vocal emotion expression, J. Pers. Soc. Psychol, 70, pp. 614-636, (1996); Juslin P.N., Laukka P., Communication of emotions in vocal expression and music performance: Different channels, same code?, Psychol. Bull, 129, pp. 770-814, (2003); Scherer K.R., Vocal communication of emotion: A review of research paradigms, Speech Commun, 40, pp. 227-256, (2003); Graham C.R., Hamblin A., Feldstein S., Recognition of emotion in English voices by speakers of Japanese, Spanish, and English, IRAL, 39, pp. 19-37, (2001); Thompson W.F., Balkwill L.-L., Decoding speech prosody in five languages, Semiotica, 158, pp. 407-424, (2006); Bryant G.A., Barrett H.C., Vocal emotion recognition across disparate cultures, J. Cognit. Cult, 8, pp. 135-148, (2008); Pell M.D., Paulmann S., Dara C., Alasseri A., Kotz S.A., Factors in the recognition of vocally expressed emotions: A comparison of four languages, J. Phon, 37, pp. 417-435, (2009); Elfenbein H.A., Ambady N., On the universality and cultural specificity of emotion recognition: A metaanalysis, Psychol. Bull, 128, pp. 203-235, (2002); Barra Chicote R., Montero Martinez J.M., Macias Guarasa J., Lutfi S.L., Lucas Cuesta J.M., Fernandez Martinez F., D'haro Enriquez L.F., San Segundo Hernandez R., Ferreiros Lopez J., Cordoba Herralde R.D., Et al., Spanish expressive voices: Corpus for emotion research in Spanish, Proceedings of the 6th Conference of Language Resources and Evaluation (Workshop on Corpora for Research on Emotion and Affect), (2008); Katsumi Y., Kim S., Sung K., Dolcos F., Dolcos S., When nonverbal greetings 'Make it or break it': The role of ethnicity and gender in the effect of handshake on social appraisals, J. Nonverbal Behav, 41, pp. 345-365, (2017); Scherer K.R., Vocal affect expression: A review and a model for future research, Psychol. Bull, 99, pp. 143-165, (1986); Wilson D., Wharton T., Relevance and prosody, J. Pragmat, 38, pp. 1559-1579, (2006); Root A.R., The pitch factors in speech-A survey, Q. J. Speech, 16, pp. 320-343, (1930); Plugge D.E., Voice qualities' in oral interpretation, Q. J. Speech, 28, pp. 442-444, (1942); Lewis M., Takai-Kawakami K., Kawakami K., Sullivan M.W., Cultural differences in emotional responses to success and failure, Int. J. Behav. Dev, 34, pp. 53-61, (2010); Beier E.G., Zautra A.J., Identification of vocal communication of emotions across cultures, J. Consult. Clin. Psychol, 39, (1972); Jacewicz E., Fox R.A., O'Neill K., Salmons J., Articulation rate across dialect, age, and gender, Lang. Var. Chang, 21, pp. 233-256, (2009); Adank P., Janse E., Perceptual learning of time-compressed and natural fast speech, J. Acoust. Soc. Am, 126, pp. 2649-2659, (2009); Heald S., Klos S., Nusbaum H., Understanding Speech in the Context of Variability, Neurobiology of Language, pp. 195-208, (2015); McCulloch G., The very idea of the phenomenological, Proc. Aristot. Soc, 93, pp. 39-57, (1993); Bassiouney R., (Ed.) Identity and Dialect Performance: A Study of Communities and Dialects, (2017); Iacobelli F., Cassell J., Ethnic identity and engagement in embodied conversational agents, Intelligent Virtual Agents, pp. 57-63, (2007); Cassell J., Social practice: Becoming enculturated in human-computer interaction Universal Access in Human-Computer Interaction, Applications and Services, pp. 303-313, (2009); Sharma L., Srivastava V., Performance enhancement of information retrieval via Artificial Intelligence, IJSRSET, 3, pp. 187-192, (2017); Reeves B., Nass C., How People Treat Computers, Television, and New Media Like Real People and Places, pp. 3-18, (1996); Nass C.I., Brave S., Wired for Speech: How Voice Activates and Advances the Human-Computer Relationship, (2005); Lorenzo-Trueba J., Watts O., Barra-Chicote R., Yamagishi J., King S., Simple4all proposals for the albayzin evaluations in speech synthesis, Proceedings of the IberSPEECH 2012, Madrid, (2012); Barra-Chicote R., Yamagishi J., King S., Montero J.M., Macias-Guarasa J., Analysis of statistical parametric and unit selection speech synthesis systems applied to emotional speech, Speech Commun, 52, pp. 394-404, (2010); (2013); Elfenbein H.A., O'Reilly C.A., Fitting in: The effects of relational demography and person-culture fit on group process and performance, Group Organ. Manag, 32, pp. 109-142, (2007); Petkova D., Cultural Diversity in People's Attitudes and Perceptions; Jones C.M., Jonsson I.M., Automatic recognition of affective cues in the speech of car drivers to allow appropriate responses, Proceedings of the 17th Australia conference on Computer-Human Interaction: Citizens Online: Considerations for Today and the Future, pp. 1-10, (2005); Iriondo I., Guaus R., Rodriguez A., Lazaro P., Montoya N., Blanco J.M., Bernadas D., Oliver J.M., Tena D., Longhi L., Validation of an acoustical modelling of emotional expression in Spanish using speech synthesis techniques, Proceedings of the ISCA Tutorial and ResearchWorkshop (ITRW) on Speech and Emotion, (2000); Paulmann S., Uskul A.K., Cross-cultural emotional prosody recognition: Evidence from Chinese and British listeners, Cognit. Emot, 28, pp. 230-244, (2014); Zahn-Waxler C., Friedman R.J., Cole P.M., Mizuta I., Hiruma N., Japanese and United States preschool children's responses to conflict and distress, Child Dev, 67, pp. 2462-2477, (1996); Mesquita B., Karasawa M., Different emotional lives, Cognit. Emot, 16, pp. 127-141, (2002); Hurley C.M., Teo W.J., Kwok J., Seet T., Peralta E., Chia S.Y., Diversity from within: The Impact of Cultural Variables on Emotion Expressivity in Singapore, IJPS, 8, (2016); Hei K.C., Ling W.N., David M.K., Communicating Disagreements among Malaysians: Verbal or Non-verbal?, Lang. India, 11, pp. 442-462, (2011); Lee Y.C., Wang T., Liberman M., Production and Perception of Tone 3 Focus in Mandarin Chinese, Front. Psychol, (2016); Hirata Y., Training native English speakers to perceive Japanese length contrasts in word versus sentence contexts, J. Acoust. Soc. Am, 116, pp. 2384-2394, (2004); Lutfi S.L., Fernandez-Martinez F., Lorenzo-Trueba J., Barra-Chicote R., Montero J.M., I feel you: The design and evaluation of a domotic affect-sensitive spoken conversational agent, Sensors, 13, pp. 10519-10538, (2013)","S.L. Lutfi; School of Computer Sciences, University Sains Malaysia, Gelugor, Pulau Pinang, 11800, Malaysia; email: syaheerah@usm.my","","MDPI AG","","","","","","20763417","","","","English","Appl. Sci.","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85043519284"
"Akhtar Z.; Siddique K.; Rattani A.; Lutfi S.L.; Falk T.H.","Akhtar, Zahid (46661628200); Siddique, Kamran (57191228422); Rattani, Ajita (55922829900); Lutfi, Syaheerah Lebai (27567802400); Falk, Tiago H. (7004897891)","46661628200; 57191228422; 55922829900; 27567802400; 7004897891","Why is multimedia quality of experience assessment a challenging problem?","2019","IEEE Access","7","","2936470","117897","117915","18","30","10.1109/ACCESS.2019.2936470","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072159043&doi=10.1109%2fACCESS.2019.2936470&partnerID=40&md5=909b84afac175bd7427eddff5b0e1a60","Department of Computer Science, University of Memphis, Memphis, 38152, TN, United States; Department of Information and Communication Technology, Xiamen University Malaysia, Sepang, 43900, Malaysia; Department of Electrical Engineering and Computer Science, Wichita State University, Wichita, 67260, KS, United States; School of Computer Science, Universiti Sains Malaysia, Penang, 11800, Malaysia; INRS-EMT, University of Quebec, Montreal, H5A 1K6, QC, Canada","Akhtar Z., Department of Computer Science, University of Memphis, Memphis, 38152, TN, United States; Siddique K., Department of Information and Communication Technology, Xiamen University Malaysia, Sepang, 43900, Malaysia; Rattani A., Department of Electrical Engineering and Computer Science, Wichita State University, Wichita, 67260, KS, United States; Lutfi S.L., School of Computer Science, Universiti Sains Malaysia, Penang, 11800, Malaysia; Falk T.H., INRS-EMT, University of Quebec, Montreal, H5A 1K6, QC, Canada","Quality of experience (QoE) assessment occupies a key role in various multimedia networks and applications. Recently, large efforts have been devoted to devise objective QoE metrics that correlate with perceived subjective measurements. Despite recent progress, limited success has been attained. In this paper, we provide some insights on why QoE assessment is so difficult by presenting few major issues as well as a general summary of quality/QoE formation and conception including human auditory and vision systems. Also, potential future research directions are described to discern the path forward. This is an academic and perspective article, which is hoped to complement existing studies and prompt interdisciplinary research. © 2019 BMJ Publishing Group. All rights reserved.","Audiovisual perception; Data-driven analysis; Multimedia quality; Objective quality metric; Quality of experience; Quality of services (QoS)","Multimedia services; Audio-visual perceptions; Data-driven analysis; Multimedia quality; Objective qualities; Quality of experience (QoE); Quality of service","","","","","Office of Research and Innovation; Xiamen University Malaysia, (XMUMRF/2019-C3/IECE/0006)","This work was supported by the Office of Research and Innovation, Xiamen University Malaysia under the XMUM Research Program Cycle 3, under Grant XMUMRF/2019-C3/IECE/0006.","Jekosch U., Voice and Speech Quality Perception: Assessment and Evaluation (Signals and Communication Technology), (2005); Hands D.S., A basic multimedia quality model, IEEE Trans. Multimedia, 6, 6, pp. 806-816, (2004); Avila A.R., Momin Z.A., Santos J.F., O'Shaughnessy D., Falk T., Feature pooling of modulation spectrum features for improved speech emotion recognition in the wild, IEEE Trans. Affective Comput.; Gupta R., Laghari K., Banville H., Falk T.H., Using affective brain-computer interfaces to characterize human influential factors for speech quality-of-experience perception modelling, Hum.-Centric Comput. Inf. Sci., 6, 1, (2016); Bech S., Zacharov N., Perceptual Audio Evaluation-Theory, Method and Application, (2006); Akhtar Z., Falk T.H., Audio-visual multimedia quality assessment: A comprehensive survey, IEEE Access, 5, pp. 21090-21117, (2017); You J., Reiter U., Hannuksela M.M., Gabbouj M., Perkis A., Perceptual-based quality assessment for audio-visual services: A survey, Signal Process., Image Commun., 25, 7, pp. 482-501, (2010); Girod B., What's wrong with mean-squared error?, Digital Images and Human Vision, (1993); Tian D., AlRegib G., FQM: A fast quality measure for efficient transmission of textured 3D models, Proc. Int. Conf. Multimedia, pp. 684-691, (2004); Wang Z., Bovik A.C., Mean squared error: Love it or leave it? A new look at signal fidelity measures, IEEE Signal Process. Mag., 26, 1, pp. 98-117, (2009); Barbedo J.G.A., Lopes A., A new cognitive model for objective assessment of audio quality, J. Audio Eng. Soc, 53, 1-2, pp. 22-31, (2005); Moller S., Raake A., Quality of Experience: Advanced Concepts, Applications and Methods, (2014); Merriam Webster Dictionary, (2011); Belmudez B., Audiovisual Quality Assessment and Prediction for Videotelephony, (2014); Rai A.K., Customer Relationship Management: Concepts and Cases, (2012); Pirsig R.M., Zen and the Art of Motorcycle Maintenance, (1974); Quality-Vocabulary, (1986); Managing for the Sustained Success of an Organization-A Quality Management Approach, (2009); Leffler K.B., Ambiguous changes in product quality, Amer. Econ. Assoc., 72, 5, pp. 956-967, (1982); Dale B.G., Barber K.D., Williams R.T., Van Der Wiele T., Managing quality in manufacturing versus services: A comparative analysis, Manag. Service Qual., Int. J., 7, 5, pp. 242-247, (1997); Gilmore H.L., Product conformance cost, Qual. Prog., 7, 15, pp. 16-19, (1974); Akinyele S.T., The spiritual perspective of quality: A scriptural dimension, IFE Psychol, 6, 2, pp. 62-77, (1974); Abramowicz W., Hofman R., Suryn W., Zyskowski D., SQuaRE based Web services quality model, Proc. Int. MultiConf. Eng. Comp. Scientists I, pp. 827-835, (2008); Touradj E., Quality of multimedia experience: Past, present and future, Proc. 17th ACM Int. Conf. Multimedia, pp. 3-4, (2009); Hoyle D., ISO 9000 Quality Systems Handbook, (2001); Brunnstrom K., Et al., Qualinet white paper on definitions of quality of experience, Proc. 5th Qualinet Meeting, pp. 1-24, (2013); Martens H., Martens M., Multivariate Analysis of Quality: An Introduction, (2001); Moller S., Quality of Telephone-Based Spoken Dialogue Systems, (2010); Zanker J., Sensation, Perception and Action: An Evolutionary Perspective, (2010); Goldstein E.B., Sensation and Perception, (2009); Fleming R.W., Visual perception of materials and their properties, Vis. Res., pp. 62-75, (2014); Neisser U., Cognition and Reality: Principles and Implications of Cognitive Psychology, (1976); Young R.A., Oh say, can you see? The physiology of vision, Proc. SPIE, 1453, pp. 92-123, (1991); Guyton A.C., Hall J.E., Textbook of Medical Physiology, 9, (1991); Baylor D.A., Photoreceptor signals and vision. Proctor lecture, Investigative Ophthalmol. Vis. Sci., 28, 1, pp. 34-49, (1987); Curcio C.A., Sloan K.R., Kalina R.E., Hendrickson A.E., Human photoreceptor topography, J. Comparative Neurol., 292, 4, pp. 497-523, (1990); Glickstein M., The discovery of the visual cortex, Sci. Amer., 259, pp. 118-127, (1988); Van Essen D.C., Organization of visual areas in macaque and human cerebral cortex, The Visual Neurosciences, pp. 507-521, (2003); Kuffler S.W., Nicholls J.G., Martin A.R., From Neuron to Brain, (1984); Davson H., Perkins E.S., Human eye, Encyclopdia Britannica, (2010); Hall D.A., Johnsrude I.S., Haggard M.P., Palmer A.R., Akeroyd M.A., Summerfield A.Q., Spectral and temporal processing in human auditory cortex, Cerebral Cortex, 12, 2, pp. 140-149, (2002); Michelson A.A., Studies in Optics, (1927); Campbell F.W., Robson J.G., Application of Fourier analysis to the visibility of gratings, J. Physiol., 197, 3, pp. 551-566, (1968); DeYoe E.A., Van Essen D.C., Concurrent processing streams in monkey visual cortex, Trends Neurosci, 11, 5, pp. 219-226, (1988); Paxinos G., Mai J.K., The Human Nervous System, (2004); Blauert J., Spatial Hearing: The Psychophysics of Human Sound Localization, (1999); The E-Model: A Computational Model for Use in Transmission Planning, (2005); Chen C.W., Chatzimisios P., Dagiuklas T., Atzori L., Multimedia Quality of Experience (QoE): Current Status and Future Requirements, (2015); Murray N., Qiao Y., Muntean G.-M., Lee B., Multiple-scent enhanced multimedia synchronization, ACM Trans. Multimedia Comput. Commun. Appl., 11, 1, pp. 1-28, (2014); Cisco Visual Networking Index: Forecast and Methodology, 2013-2018, (2014); Roscoe T., Bowen G., Script-driven packet marking for quality-of-service support in legacy applications, Proc. SPIE, 3969, pp. 166-176, (1999); Hassenzahl M., Burmester M., Lehner K., Platz A., Hedonic and Ergonomic quality aspects determine a software's appeal, Proc. Conf. Hum. Factors Comput. Syst., pp. 201-208, (2000); Laghari K.U.R., Gupta R., Antons J.-N., Schleicher R., Moller S., Falk T.H., Objective characterization of human behavioural characteristics for QoE assessment: A pilot study on the use of electroencephalography features, Proc. IEEE Globecom Workshops, pp. 1168-1173, (2013); Ghinea G., Thomas J.P., Quality of perception: User quality of service in multimedia presentations, IEEE Trans. Multimedia, 7, 4, pp. 786-789, (2005); Gulliver S.R., Ghinea G., Stars in their eyes: What eye-tracking reveals about multimedia perceptual quality, IEEE Trans. Syst., Man, Cybern. A, Syst., Humans, 34, 4, pp. 472-482, (2004); Apteker R.T., Fisher J.A., Kisimov V.S., Neishlos H., Video acceptability and frame rate, IEEE Multimedia Mag, 2, 3, pp. 32-40, (1995); Moller S., Engelbrecht K.-P., Kuhnel C., Wechsung I., Weiss B., A taxonomy of quality of service and quality of experience of multimodal human-machine interaction, Proc. Int. Workshop Qual. Multimedia Exper., pp. 7-12, (2009); Perkis A., Munkeby S., Hillestad O.I., A model for measuring quality of experience, Proc. 7th Nordic Signal Process. Symp., pp. 198-201, (2006); Kim H.-J., Lee K.-H., Zhang J., In-service feedback QoE framework, Proc. 3rd Int. Conf. Commun. Theory, Rel., Qual. Service, pp. 135-138, (2010); De Moor K., Ketyko I., Deryckere T., De Marez L., Martens L., Verleye G., Joseph W., Proposed framework for evaluating quality of experience in a mobile, testbed-oriented living lab setting, Mobile Netw. Appl., 15, 3, pp. 378-391, (2010); Song W., Tjondronegoro D., Docherty M., Understanding user experience of mobile video: Framework, measurement, and optimization, Mobile Multimedia-User and Technology Perspectives, pp. 1-30, (2012); Reichl P., Tuffin B., Schatz R., Logarithmic laws in service quality perception: Where microeconomics meets psychophysics and quality of experience, Telecommun. Syst. J., 52, 2, pp. 587-600, (2013); Lopez-Ludena V., Barra-Chicote R., Lutfi S., Montero J.M., San-Segundo R., LSespeak: A spoken language generator for Deaf people, Expert Syst. Appl., 40, 4, pp. 1283-1295, (2013); Piamrat K., Viho C., Bonnin J.-M., Ksentini A., Quality of experience measurements for video streaming over wireless networks, Proc. 6th Int. Conf. Inf. Technol., New Gener., pp. 1184-1189, (2009); Pouli V., Kafetzoglou S., Tsiropoulou E.E., Dimitriou A., Papavassiliou S., Personalized multimedia content retrieval through relevance feedback techniques for enhanced user experience, Proc. 13th Int. Conf. Telecommun. (ConTEL), pp. 1-8, (2015); Tsiropoulou E.E., Kousis G., Thanou A., Lykourentzou I., Papavassiliou S., Quality of experience in cyber-physical social systems based on reinforcement learning and game theory, Future Internet, 10, 11, (2018); Wamser F., Casas P., Seufert M., Moldovan C., Tran-Gia P., Hossfeld T., Modeling the YouTube stack: From packets to quality of experience, Comput. Netw., 109, 2, pp. 211-224, (2016); Doumanoglou A., Griffin D., Serrano J., Zioulis N., Phan T.K., Jimenez D., Zarpalas D., Alvarez F., Rio M., Daras P., Quality of experience for 3-D immersive media streaming, IEEE Trans. Broadcast., 64, 2, pp. 379-391, (2018); Tsiropoulou E.E., Thanou A., Papavassiliou S., Modelling museum visitors' quality of experience, Proc. 11th Int. Workshop Semantic Social Media Adaptation Personalization (SMAP), pp. 77-82, (2016); Lykourentzou I., Claude X., Naudet Y., Tobias E., Antoniou A., Lepouras G., Vassilakis C., Improving museum visitors' Quality of Experience through intelligent recommendations: A visiting style-based approach, Proc. Intell. Environ. (Workshops), pp. 507-518, (2013); Wehner N., Wassermann S., Casas P., Seufert M., Wamser F., Beauty is in the eye of the smartphone holder a data driven analysis of YouTube mobile QoE, Proc. 14th Int. Conf. Netw. Service Manage. (CNSM), pp. 343-347, (2018); Wassermann S., Wehner N., Casas P., Machine learning models for YouTube QoE and user engagement prediction in smartphones, ACM SIGMETRICS Perform. Eval. Rev., 46, 3, pp. 155-158, (2019); Algar M.J., De Diego I.M., Fernandez-Isabel A., Monjas M.A., Ortega F., Moguerza J.M., Jacynycz H., A quality of experience management framework for mobile users, Wireless Commun. Mobile Comput., 2019, (2019); Mrvelj S., Matulin M., Impact of packet loss on the perceived quality of UDP-based multimedia streaming: A study of user quality of experience in real-life environments, Multimedia Syst, 24, 1, pp. 33-53, (2018); Martinez H.B., Farias M.C., Full-reference audio-visual video quality metric, J. Electron. Imag., 23, 6, (2014); Hayashi T., Yamagishi K., Tominaga T., Takahashi A., Multimedia quality integration function for videophone services, Proc. IEEE Global Telecommun. Conf., pp. 2735-2739, (2007); Laghari K.U.R., Crespi N., Connelly K., Toward total quality of experience: A QoE model in a communication ecosystem, IEEE Commun. Mag., 50, 4, pp. 58-65, (2012); Gomez G., Hortiguela L., Perez Q., Lorca J., Garcia R., Aguayo-Torres M.C., YouTube QoE evaluation tool for Android wireless terminals, EURASIP J. Wireless Commun. Netw., 2014, (2014); Moller S., Engelbrecht K.-P., Kuhnel C., Wechsung I., Weiss B., Evaluation of multimodal interfaces for ambient intelligence, Human-Centric Interfaces for Ambient Intelligence, pp. 347-370, (2009); Falk T.H., Pomerantz Y., Laghari K., Moller S., Chau T., Preliminary findings on image preference characterization based on neurophysiological signal analysis: Towards objective QoE modeling, Proc. 4th Int. Workshop Qual. Multimedia Exper., pp. 146-147, (2012); Moldovan A.-N., Ghergulescu I., Weibelzahl S., Muntean C.H., User-centered EEG-based multimedia quality assessment, Proc. IEEE Int. Symp. Broadband Multimedia Syst. Broadcast, pp. 1-8, (2013); Requirements for an Objective Perceptual Multimedia Quality Model, (2010); Coverdale P., Moller S., Raake A., Takahashi A., Multimedia quality assessment standards in ITU-T SG12, IEEE Signal Process. Mag., 28, 6, pp. 91-97, (2011); Singh K.D., Rubino G., No-reference quality of experience monitoring in DVB-H networks, Proc. Wireless Telecommun. Symp. (WTS), pp. 1-6, (2010); Cherif W., Ksentini A., Negru D., No-reference quality of experience estimation of H264/SVC stream, Proc. IEEE Globecom Workshops, pp. 1346-1351, (2012); Gottron C., Konig A., Hollick M., Bergstrasser S., Hildebrandt T., Steinmetz R., Quality of experience of voice communication in large-scale mobile ad hoc networks, Proc. 2nd IFIP Wireless Days (WD), pp. 1-6, (2009); Ahmed A., Shafiq Z., Khakpour A., QoE analysis of a large-scale live video streaming event, ACM SIGMETRICS Perform. Eval. Rev., 44, 1, pp. 395-396, (2016); Menkovski V., Exarchakos G., Liotta A., Machine learning approach for quality of experience aware networks, Proc. Int. Conf. Intell. Netw. Collaborative Syst., pp. 461-466, (2010); Lopez-Martin M., Carro B., Lloret J., Egea S., Sanchez-Esguevillas A., Deep learning model for multimedia quality of experience prediction based on network flow packets, IEEE Commun. Mag., 56, 9, pp. 110-117, (2018); Venkatraman K., Raghuraman S., Tian Y., Prabhakaran B., Nahrst-Edt K., Annaswamy T., Quantifying and improving user quality of experience in immersive tele-rehabilitation, Proc. IEEE Int. Symp. Multimedia, pp. 207-214, (2014); Nauge M., Larabi M.-C., Fernandez C., Quality estimation based on interest points through hierarchical saliency maps, Proc. Eur. Workshop Vis. Inf. Process., pp. 186-191, (2011); Luo Q., Geng Y., Liu J., Li W., Saliency and texture information based full-reference quality metrics for video QoE assessment, Proc. IEEE Netw. Oper. Manage. Symp., pp. 1-6, (2014); Borowiak A., Reiter U., Quality evaluation of long duration AV content-An extended analysis using a novel assessment methodology, Multimedia Tools Appl, 74, 2, pp. 367-380, (2015); Taal C.H., Hendriks R.C., Heusdens R., Jensen J., A short-time objective intelligibility measure for time-frequency weighted noisy speech, Proc. IEEE Int. Conf. Acoust., Speech Signal Process., pp. 4214-4217, (2010); Goetze S., Warzybok A., Kodrasi I., Jungmann J.O., Cauchi B., Rennies J., Habets E.A.P., Mertins A., Gerkmann T., Doclo S., Kollmeier B., A study on speech quality and speech intelligibility measures for quality assessment of single-channel dereverberation algorithms, Proc. Int. Workshop Acoustic Signal Enhancement, pp. 233-237, (2014); Abiru K., Ueno H., Amemiya K., Improving quality of experience for users through distributed service platform technology, FUJITSU Sci. Tech. J, 52, pp. 56-63, (2016); Venkata Phani Kumar M., Mahapatra S., Quality of experience driven rate adaptation for adaptive HTTP streaming, IEEE Trans. Broadcast., 64, 2, pp. 602-620, (2018); Perez J., Delechelle E., On the measurement of image quality perception using frontal EEG analysis, Proc. Int. Conf. Smart Commun. Netw. Technol., pp. 1-5, (2013); Yuan Z., Chen S., Ghinea G., Muntean G.-M., User quality of experience of mulsemedia applications, ACM Trans. Multimedia Comput. Commun. Appl., 11, 1, pp. 1-19, (2014); Murray N., Lee B., Qiao Y., Miro-Muntean G., The influence of human factors on olfaction based mulsemedia quality of experience, Proc. 8th Int. Conf. Qual. Multimedia Exper., pp. 1-6, (2016); Fullerton M., Woods R.L., Vera-Diaz F.A., Peli E., Measuring perceived video quality of MPEG enhancement by people with impaired vision, J. Opt. Soc. Amer. A, Opt. Image Sci., 24, 12, pp. 174-187, (2007); Coutinho F., Prates R.O., Chaimowicz L., An analysis of information conveyed through audio in an FPS game and its impact on deaf players experience, Proc. Brazilian Symp. Games Digit. Entertainment, pp. 53-62, (2011); Moller S., Schmidt S., Zadtootaghaj S., New ITU-T standards for gaming QoE evaluation and management, Proc. 10th Int. Conf. Qual. Multimedia Exper., pp. 1-6, (2018); Sabet S.S., Hashemi M.R., Shirmohammadi S., Ghanbari M., A novel objective quality assessment method for perceptually-coded cloud gaming video, Proc. IEEE Conf. Multimedia Inf. Process. Retr., pp. 75-79, (2018); Wu C.-C., Chen K.-T., Chang Y.-C., Lei C.-L., Crowdsourcing multimedia QoE evaluation: A trusted framework, IEEE Trans. Multimedia, 15, 5, pp. 1121-1137, (2013); Lin Y.C., Shih Z.S., Crowdsourcing system on measuring quality of experience for Internet video streaming, Proc. IEEE Int. Conf. Consum. Electron.-Taiwan, pp. 1-2, (2016); Aldahdooh A., Masala E., Van Wallendael G., Barkowsky M., Reproducible research framework for objective video quality measures using a large-scale database approach, SoftwareX, 8, pp. 64-68, (2018); Aldahdooh A., Masala E., Van Wallendael G., Barkowsky M., Framework for reproducible objective video quality research with case study on PSNR implementations, Digit. Signal Process., 77, pp. 195-206, (2018); Murray N., Muntean G.-M., Qiao Y., Brennan S., Lee B., Modeling user quality of experience of olfaction-enhanced multimedia, IEEE Trans. Broadcast., 64, 2, pp. 539-551, (2018); Jalal L., Anedda M., Popescu V., Murroni M., QoE assessment for IoT-based multi sensorial media broadcasting, IEEE Trans. Broadcast., 64, 2, pp. 552-560, (2018); Mesfin G., Hussain N., Covaci A., Ghinea G., Using eye tracking and heart-rate activity to examine crossmodal correspondences QoE in mulsemedia, ACM Trans. Multimedia Comput., Commun., Appl., 15, 2, (2019); Saleme E.B., Santos C.A.S., Ghinea G., A mulsemedia framework for delivering sensory effects to heterogeneous systems, Multimedia Syst, 25, 4, pp. 421-447, (2019); Murroni M., Rassool R., Song L., Sotelo R., Guest editorial special issue on quality of experience for advanced broadcast services, IEEE Trans. Broadcast., 64, 2, pp. 335-340, (2018); Yang J., Ji C., Jiang B., Lu W., Meng Q., No reference quality assessment of stereo video based on saliency and sparsity, IEEE Trans. Broadcast., 64, 2, pp. 341-353, (2018); Korhonen J., Study of the subjective visibility of packet loss artifacts in decoded video sequences, IEEE Trans. Broadcast., 64, 2, pp. 354-366, (2018); Wu Q., Li H., Meng F., Ngan K.N., Toward a blind quality metric for temporally distorted streaming video, IEEE Trans. Broadcast., 64, 2, pp. 367-378, (2018); Battisti F., Carli M., Le Callet P., Paudyal P., Toward the assessment of quality of experience for asymmetric encoding in immersive media, IEEE Trans. Broadcast., 64, 2, pp. 392-406, (2018); Sawahata Y., Morita T., Estimating depth range required for 3-D displays to show depth-compressed scenes without inducing sense of unnaturalness, IEEE Trans. Broadcast., 64, 2, pp. 488-497, (2018); Shishikui Y., Sawahata Y., Effects of viewing ultra-high-resolution images with practical viewing distances on familiar impressions, IEEE Trans. Broadcast., 64, 2, pp. 498-507, (2018); Nafchi H.Z., Cheriet M., Efficient no-reference quality assessment and classification model for contrast distorted images, IEEE Trans. Broadcast., 64, 2, pp. 518-523, (2018); Bentaleb A., Begen A.C., Zimmermann R., QoE-aware bandwidth broker for HTTP adaptive streaming flows in an SDN-enabled HFC network, IEEE Trans. Broadcast., 64, 2, pp. 575-589, (2018); Huang W., Zhou Y., Xie X., Wu D., Chen M., Ngai E., Buffer state is enough: Simplifying the design of QoE-aware HTTP adaptive video streaming, IEEE Trans. Broadcast., 64, 2, pp. 590-601, (2018); Viola I., Rerabek M., Ebrahimi T., Impact of interactivity on the assessment of quality of experience for light field content, Proc. Int. Conf. Qual. Multimedia Exper. (QoMEX), pp. 1-6, (2017); Cserkaszky A., Kara P.A., Barsi A., Martini M.G., Expert evaluation of a novel light-field visualization format, Proc. 3DTV-Conf., True Vis.-Capture, Transmiss. Display 3D Video (3DTV-CON), pp. 1-4, (2018); Perra C., Song W., Liotta A., Effects of light field subsampling on the quality of experience in refocusing applications, Proc. Int. Conf. Qual. Multimedia Exper. (QoMEX), pp. 1-3, (2018); Viola I., Ebrahimi T., ValiD: Visual quality assessment for light field images dataset, Proc. 10th Int. Conf. Qual. Multimedia Exper. (QoMEX), pp. 1-3, (2018); Perra C., Assessing the quality of experience in viewing rendered decompressed light fields, Multimedia Tools Appl, 77, 16, pp. 21771-21790, (2018); Viola I., Takahashi K., Fujii T., Ebrahimi T., A comprehensive framework for visual quality assessment of light field tensor displays, Electron. Imag., 2019, 1, pp. 1-6, (2019); Tamboli R.R., Kara P.A., Cserkaszky A., Barsi A., Martini M.G., Appina B., Channappayya S.S., Jana S., 3D objective quality assessment of light field video frames, Proc. 3DTV-Conf., True Vis.-Capture, Transmiss. Display 3D Video (3DTV-CON), pp. 1-4, (2018); Kara P.A., Cserkaszky A., Martini M.G., Barsi A., Bokor L., Balogh T., Evaluation of the concept of dynamic adaptive streaming of light field video, IEEE Trans. Broadcast., 64, 2, pp. 407-421, (2018); Barakovic S., Skorin-Kapov L., Survey and challenges of QoE management issues in wireless networks, J. Comput. Netw. Commun., 2013, (2013); Ernst J.B., Kremer S.C., Rodrigues J.J.P.C., A survey of QoS/QoE mechanisms in heterogeneous wireless networks, Phys. Commun., 13, pp. 61-72, (2014); Su G.M., Su X., Bai Y., Wang M., Vasilakos A.V., Wang H., QoE in video streaming over wireless networks: Perspectives and research challenges, Wireless Netw, 22, 5, pp. 1571-1593, (2016); Cano M.-D., Cerdan F., Subjective QoE analysis of VoIP applications in a wireless campus environment, Springer Telecommun. Syst., 49, 1, pp. 5-15, (2012); Zhao M., Gong X., Liang J., Wang W., Que X., Cheng S., QoE-driven cross-layer optimization for wireless dynamic adaptive streaming of scalable videos over HTTP, IEEE Trans. Circuits Syst. Video Technol., 25, 3, pp. 451-465, (2015); Li J., Feng R., Liu Z., Sun W., Li Q., Modeling QoE of virtual reality video transmission over wireless networks, Proc. IEEE Global Commun. Conf. (GLOBECOM), pp. 1-7, (2018); Jimenez L.R., Solera M., Toril M., A network-layer QoE model for YouTube live in wireless networks, IEEE Access, 7, pp. 70237-70252, (2019); Fiedler M., Hossfeld T., Tran-Gia P., A generic quantitative relationship between quality of experience and quality of service, IEEE Netw, 24, 2, pp. 36-41, (2010); Shaikh J., Fiedler M., Collange D., Quality of experience from user and network perspectives, Ann. Telecommun., 65, 1, pp. 47-57, (2010); Alberti C., Renzi D., Timmerer C., Mueller C., Lederer S., Battista S., Mattavelli M., Automated QoE evaluation of dynamic adaptive streaming over HTTP, Proc. 5th Int. Workshop Qual. Multimedia Exper. (QoMEX), pp. 58-63, (2013); Narwaria M., Toward better statistical validation of machine learning-based multimedia quality estimators, IEEE Trans. Broadcast., 64, 2, pp. 446-460, (2018); Rego A., Canovas A., Jimenez J.M., Lloret J., An intelligent system for video surveillance in IoT environments, IEEE Access, 6, pp. 31580-31598, (2018); Martin A., Egana J., Florez J., Montalban J., Olaizola I.G., Quartulli M., Viola R., Zorrilla M., Network resource allocation system for QoE-aware delivery of media services in 5G networks, IEEE Trans. Broadcast., 64, 2, pp. 561-574, (2018); Nightingale J., Salva-Garcia P., Calero J.M.A., Wang Q., 5G-QoE: QoE modelling for ultra-HD video streaming in 5G networks, IEEE Trans. Broadcast., 64, 2, pp. 621-634, (2018)","Z. Akhtar; Department of Computer Science, University of Memphis, Memphis, 38152, United States; email: zmomin@memphis.edu","","Institute of Electrical and Electronics Engineers Inc.","","","","","","21693536","","","","English","IEEE Access","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85072159043"
"Alfurayj H.S.; Lutfi S.L.","Alfurayj, Haifa Saleh (58759310900); Lutfi, Syaheerah Lebai (27567802400)","58759310900; 27567802400","Exploring Bystanders' Roles in Labeled Cyberbullying Threads on Twitter: A preliminary analysis","2023","IEEE Region 10 Annual International Conference, Proceedings/TENCON","","","","1018","1023","5","0","10.1109/TENCON58879.2023.10322517","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179508041&doi=10.1109%2fTENCON58879.2023.10322517&partnerID=40&md5=a5fd6a9338bdcc86803db77b7168eb5b","School of Computer Sciences, Universiti Sains Malaysia Usm, Penang, Malaysia; Qassim University, Qassim, Saudi Arabia","Alfurayj H.S., School of Computer Sciences, Universiti Sains Malaysia Usm, Penang, Malaysia, Qassim University, Qassim, Saudi Arabia; Lutfi S.L., School of Computer Sciences, Universiti Sains Malaysia Usm, Penang, Malaysia","This study presents findings from an anal-ysis of a newly developed corpus, CYBY23, focused on cyberbullying, aiming to comprehensively examine labeled cyberbullying threads on the social media platform Twitter, with a specific emphasis on the role of bystanders. Previous corpora used for automatic cyberbullying detection have primarily focused on the main posts, disregarding the threaded responses. Con-sequently, these studies have overlooked valuable infor-mation regarding the involvement of bystanders, which is crucial for enhancing the accuracy of cyberbullying detection. This study addresses this gap by incorpo-rating bystander roles within the corpus, resulting in significant impact on annotators' perception and classification of cyberbullying instances. The findings suggest promising prospects for improved automated cyberbullying detection. Notably, the most frequently observed bystander roles align with the content of the main post. Surprisingly, impartial bystanders are most prevalent in cyberbullying threads characterized by high levels of aggression. This article provides a detailed analysis of the annotation process and examines the influence of bystanders roles in greater depth.  © 2023 IEEE.","aggression; bystander roles; bystander-labelled corpus; cyberbully; dataset","Computer crime; Aggression; Bystander role; Bystander-labeled corpus; Cyber bullying; Cyberbully; Dataset; Great depth; Preliminary analysis; Social media platforms; Social networking (online)","","","","","","","Olweus D., Bullying at School: Basic Facts and Effects of a School Based Intervention Program, J. Child Psychol. Psychiatry, 35, 7, pp. 1171-1190, (1994); Smith P.K., Del Barrio C., Tokunaga R., Definitions of bullying and cyberbullying: How useful are the terms?, Principles of cyberbullying research: Definition, measures, and methods, (2013); Salawu S., He Y., Lumsden J., Approaches to Automated Detection of Cyberbullying: A Survey, IEEE Trans. Affect. Comput., 11, 1, pp. 3-24, (2020); Alfurayj H.S., Yee N.S., Lutfi S.L., Bystanders Unveiled: Introducing a Comprehensive Cyberbullying Corpus with Bystander Information, IEEE Reg. 10 Annu. Int. Conf. Proceedings/TENCON, (2023); Rafiq R.I., Hosseinmardi H., Han R., Lv Q., Mishra S., Identifying Differentiating Factors for Cyberbullying in Vine and Instagram, Commun. Comput. Inf. Sci., 1410, pp. 348-361, (2021); Jacobs G., Van Hee C., Hoste V., Automatic classification of participant roles in cyberbullying: Can we detect victims, bullies, and bystanders in social media text?, Nat. Lang. Eng., 28, 2, pp. 141-166, (2020); Xu J.M., Jun K.S., Zhu X., Bellmore A., Learning from bullying traces in social media, NAACL HLT 2012-2012 Conf. North Am. Chapter Assoc. Comput. Linguist. Hum. Lang. Technol. Proc. Conf., pp. 656-666, (2012); Chatzakou D., Kourtellis N., Blackburn J., De Cristofaro E., Stringhini G., Vakali A., Mean birds: Detecting aggression and bullying on Twitter, WebSci 2017-Proc. 2017 ACM Web Sci. Conf., pp. 13-22, (2017); Raisi E., Huang B., Weakly supervised cyberbullying detection with participant-vocabulary consistency, Soc. Netw. Anal. Min., 8, 1, (2018); Van Hee C., Verhoeven B., Lefever E., De Pauw G., Daelemans W., Team T.T., Guidelines for the Fine-Grained Analysis of of Cyberbullying, version 1. 0. Tech. Rep. LT3 15-01, LT3, (2015); Tsvetkova M., Macy M.W., The social contagion of antisocial behavior, Sociol. Sci., 2, pp. 36-49, (2015); Villota E.J., Yoo S.G., An Experiment of Influences of Facebook Posts in Other Users, 2018 5th Int. Conf. eDemocracy eGovernment, ICEDEG 2018, pp. 83-88, (2018); Yokotani K., Takano M., Social contagion of cyberbullying via online perpetrator and victim networks, Comput. Human Behav., 119, (2021); Obermaier M., Fawzi N., Koch T., Bystanding or standing by How the number of bystanders affects the intention to intervene in cyberbullying, New Media Soc., 18, 8, pp. 1491-1507, (2016); Machackova H., Dedkova L., Mezulanikova K., Brief report: The bystander effect in cyberbullying incidents, J. Adolesc., 43, pp. 96-99, (2015)","","","Institute of Electrical and Electronics Engineers Inc.","","38th IEEE Region 10 Conference, TENCON 2023","31 October 2023 through 3 November 2023","Chiang Mai","194660","21593442","979-835030219-6","85QXA","","English","IEEE Reg 10 Annu Int Conf Proc TENCON","Conference paper","Final","","Scopus","2-s2.0-85179508041"
"Adamu H.; Lutfi S.L.; Malim N.H.A.H.; Hassan R.; Di Vaio A.; Mohamed A.S.A.","Adamu, Hassan (57222538575); Lutfi, Syaheerah Lebai (27567802400); Malim, Nurul Hashimah Ahamed Hassain (35090139100); Hassan, Rohail (56575985100); Di Vaio, Assunta (55922628500); Mohamed, Ahmad Sufril Azlan (57190968285)","57222538575; 27567802400; 35090139100; 56575985100; 55922628500; 57190968285","Framing twitter public sentiment on Nigerian government COVID-19 palliatives distribution using machine learning","2021","Sustainability (Switzerland)","13","6","3497","","","","25","10.3390/su13063497","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103101474&doi=10.3390%2fsu13063497&partnerID=40&md5=c68d161ce91902586e2c7e3bdb8b5a07","School of Computer Sciences, Universiti Sains Malaysia, Penang, 11800, Malaysia; Othman Yeop Abdullah Graduate School of Business (OYAGSB), Universiti Utara Malaysia (UUM), Kuala Lumpur, 50300, Malaysia; Department of Law, University of Naples “Parthenope”, Naples, 80132, Italy","Adamu H., School of Computer Sciences, Universiti Sains Malaysia, Penang, 11800, Malaysia; Lutfi S.L., School of Computer Sciences, Universiti Sains Malaysia, Penang, 11800, Malaysia; Malim N.H.A.H., School of Computer Sciences, Universiti Sains Malaysia, Penang, 11800, Malaysia; Hassan R., Othman Yeop Abdullah Graduate School of Business (OYAGSB), Universiti Utara Malaysia (UUM), Kuala Lumpur, 50300, Malaysia; Di Vaio A., Department of Law, University of Naples “Parthenope”, Naples, 80132, Italy; Mohamed A.S.A., School of Computer Sciences, Universiti Sains Malaysia, Penang, 11800, Malaysia","Sustainable development plays a vital role in information and communication technology. In times of pandemics such as COVID-19, vulnerable people need help to survive. This help includes the distribution of relief packages and materials by the government with the primary objective of lessening the economic and psychological effects on the citizens affected by disasters such as the COVID-19 pandemic. However, there has not been an efficient way to monitor public funds’ accountability and transparency, especially in developing countries such as Nigeria. The understanding of public emotions by the government on distributed palliatives is important as it would indicate the reach and impact of the distribution exercise. Although several studies on English emotion classification have been conducted, these studies are not portable to a wider inclusive Nigerian case. This is because Informal Nigerian English (Pidgin), which Nigerians widely speak, has quite a different vocabulary from Standard English, thus limiting the applicability of the emotion classification of Standard English machine learning models. An Informal Nigerian English (Pidgin English) emotions dataset is constructed, pre-processed, and annotated. The dataset is then used to classify five emotion classes (anger, sadness, joy, fear, and disgust) on the COVID-19 palliatives and relief aid distribution in Nigeria using standard machine learning (ML) algorithms. Six ML algorithms are used in this study, and a comparative analysis of their performance is conducted. The algorithms are Multinomial Naïve Bayes (MNB), Support Vector Machine (SVM), Random Forest (RF), Logistics Regression (LR), K-Nearest Neighbor (KNN), and Decision Tree (DT). The conducted experiments reveal that Support Vector Machine outperforms the remaining classifiers with the highest accuracy of 88%. The “disgust” emotion class surpassed other emotion classes, i.e., sadness, joy, fear, and anger, with the highest number of counts from the classification conducted on the constructed dataset. Additionally, the conducted correlation analysis shows a significant relationship between the emotion classes of “Joy” and “Fear”, which implies that the public is excited about the palliatives’ distribution but afraid of inequality and transparency in the distribution process due to reasons such as corruption. Conclusively, the results from this experiment clearly show that the public emotions on COVID-19 support and relief aid packages’ distribution in Nigeria were not satisfactory, considering that the negative emotions from the public outnumbered the public happiness. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.","COVID-19 palliatives; Machine learning; Nigerian Pidgin English Twitter dataset; Relief aid; Sentiment analysis; Social media","Nigeria; Varanidae; accountability; algorithm; COVID-19; developing world; government; machine learning; spatiotemporal analysis","","","","","RCMO; UNIVERSITI, (1001/PKOMP/8014001, 304/PKOMP/6315137)","Funding: This research was funded jointly by RCMO, UNIVERSITI SAINS MALAYSIA under the, grants number 1001/PKOMP/8014001 and 304/PKOMP/6315137 and Research University Grant (1001/PKOMP/8014001).","Siddiqui Abdul Hameed, A Sustainable Society: Its Meaning and Objectives, Int. J. Res. Sci. Innov, (2018); Impact of COVID-19 on the Sustainable Development Goals: Pursuing the Sustainable Development Goals (SDGs) in a World Reshaped by COVID-19, (2020); Szabo S., Nhau B., Tsusaka T.W., Kadigi R.M.J., Payne T., Kangile J.R., Park K.S., Couto M., Runsten L., Burgess N.D., Et al., Towards a Successful Post COVID-19 Transition of Monitoring, Evaluation, and Learning in Complex Sustainability Science Research-to-Policy Projects, Sustainability, 13, (2021); Rutkowska A., Kacperak K., Rutkowski S., Cacciante L., Kiper P., Szczegielniak J., The Impact of Isolation Due to COVID-19 on Physical Activity Levels in Adult Students, Sustainability, 13, (2021); Vaz E., COVID-19 in Toronto: A Spatial Exploratory Analysis, Sustainability, 13, (2021); COVID-19 Dashboard by the Center for Systems Science and Engineering (CSSE) at Johns Hopkins University (JHU); NCDC Coronavirus COVID-19 Microsite; Kemp S., Digital 2020: Nigeria. DataReportal-Global Digital Insights; Qiu M., Sha J., Utomo S., Listening to Forests: Comparing the Perceived Restorative Characteristics of Natural Soundscapes before and after the COVID-19 Pandemic, Sustainability, 13, (2021); Tetrevova L., Vavra J., Munzarova S., Communication of Socially-Responsible Activities by Higher Education Institutions, Sustainability, 13, (2021); Marinello S., Lolli F., Gamberini R., The Impact of the COVID-19 Emergency on Local Vehicular Traffic and Its Consequences for the Environment: The Case of the City of Reggio Emilia (Italy), Sustainability, 13, (2021); Ricciardelli A., Governance, Local Communities, and Citizens Participation, Global Encyclopedia of Public Administration, Public Policy, and Governance, (2018); Loshin D., Text Data Analytics: In Service of Smart Government; Barns S., Smart cities and urban data platforms: Designing interfaces for smart governance, City Cult. Soc, 12, pp. 5-12, (2018); Kumar A., Sharma A., Systematic literature review on opinion mining of big data for government intelligence, Webology, 14, pp. 6-47, (2017); Lennerholt C., van Laere J., Soderstrom E., Implementation Challenges of Self Service Business Intelligence: A Literature Review, Proceedings of the 51st Hawaii International Conference on System Sciences, 9, pp. 5055-5063, (2018); Khan K., Baharudin B., Khan A., Ullah A., Mining opinion components from unstructured reviews: A review, J. King Saud Univ. Comput. Inf. Sci, 26, pp. 258-275, (2014); Joshi S., Deshpande D., Twitter Sentiment Analysis System, Int. J. Comput. Appl, 180, pp. 35-39, (2018); Varrella S., Nigeria: Leading Social Media Platforms; Pidgin-West African Lingua Franca. BBC News, (2016); Desai R.D., Sentiment Analysis of Twitter Data, Proceedings of the 2nd International Conference on Intelligent Computing and Control Systems, pp. 114-117, (2018); Huang C.H., Hsieh S.H., Predicting BIM labor cost with random forest and simple linear regression, Autom. Constr, 118, (2020); Reddy D.M., Twitter Sentiment Analysis using Distributed Word and Sentence Representation, (2019); Meng L., Dong Z.S., Christenson L., Fulton L., Mining Public Opinion on Twitter about Natural Disaster Response Using Machine Learning Techniques, (2017); Squicciarini A., Tapia A., Stehle S., Sentiment analysis during Hurricane Sandy in emergency response, Int. J. Disaster Risk Reduct, 21, pp. 213-222, (2017); Rathee N., Joshi N., Kaur J., Sentiment Analysis Using Machine Learning Techniques on Python, Proceedings of the 2018 Second International Conference on Intelligent Computing and Control Systems (ICICCS), (2018); Kanish S., Henil P., Devanshi S., Manan S., A Comparative Analysis of Logistic Regression, Random Forest and KNN Models for the Text Classification, Augment. Hum. Res, 5, (2020); Oyewusi W.F., Adekanmbi O., Akinsande O., Semantic Enrichment of Nigerian Pidgin English for Contextual Sentiment Classification; Suh A., Li M., Digital Tracing during the COVID-19 Pandemic: User Appraisal, Emotion, and Continuance Intention, Sustainability, 13, (2021); Manguri K.N., Ramadhan R., Mohammed A.P., Twitter Sentiment Analysis on Worldwide COVID-19 Outbreaks, Kurd. J. Appl. Res, pp. 54-65, (2020); Bento A.I., Thuy N., Coady W., Felipe L.R., Yong Y.A., Kosali S., Evidence from internet search data shows information-seeking responses to news of local COVID-19 cases, Natl. Acad. Sci, 117, pp. 11220-11222, (2020); Hasan A., Moin S., Karim A., Shamshirband S., Machine Learning-Based Sentiment Analysis for Twitter Accounts, Math. Comput. Appl, 23, (2018); Ozturk N., Ayvaz S., Sentiment analysis on Twitter: A text mining approach to the Syrian refugee crisis, Telemat. Inform, 35, pp. 136-147, (2018); Yin H., Cui B., Lu H., Huang Y., Yao J., A unified model for stable and temporal topic detection from social media data, Proceedings of the International Conference Data Engineering, pp. 661-672, (2013); Sidarenka U., Sentiment Analysis of German Twitter, (2019); Sonawane S.S., Sentiment Analysis of Twitter Data: A Survey of Techniques, Int. J. Comput. Appl, 139, pp. 5-15, (2016); Nakov P., Ritter A., Rosenthal S., Sebastiani F., Stoyanov V., SemEval-2016 task 4: Sentiment analysis in twitter, Proceedings of the SemEval 2016-10th International Workshop on Semantic Evaluation, pp. 1-18, (2016); Chakriswaran P., Vincent D.R., Srinivasan K., Sharma V., Chang C.Y., Reina D.G., Emotion AI-driven sentiment analysis: A survey, future research directions, and open issues, Appl. Sci, 9, (2019); Balogun T.A., In defense of Nigerian pidgin, J. Lang. Cult, 4, pp. 90-98, (2013); Osoba J.B., Analysis of Discourse in Nigerian Pidgin, J. Univers. Lang, 16, pp. 131-159, (2015); Idegbekwe D., Anthropomorphisms and the Nigerian Pidgin Proverbs: A Linguistic Conceptual Metaphorical Analysis, EBSU J. Soc. Sci. Rev, 10, pp. 71-76, (2020); Bigi B., Caron B., Abiola O., Developing Resources for Automated Speech Processing of the African Language Naija (Nigerian Pidgin), Proceedings of the 8th Language & Technology Conference: Human Language Technologies as a Challenge for Computer Science and Linguistics, pp. 441-445, (2017); Sung Y.A., Kim K.W., Kwon H.J., Big Data Analysis of Korean Travelers’ Behavior in the Post-COVID-19 Era, Sustainability, 13, (2021); Zhao F., Zhu N., Hamalainen J., Protection of Children in Difficulty in China during the COVID-19 Pandemic, Sustainability, 13, (2021); Radulescu C.V., Ladaru G.R., Burlacu S., Constantin F., Ioanas C., Petre I.L., Impact of the COVID-19 Pandemic on the Romanian Labor Market, Sustainability, 13, (2021); Awwalu J., Umar N.A., Ibrahim M.S., Nonyelum O.F., A multinomial Naïve Bayes decision support system for COVID-19 detection, FUDMA J. Sci, 4, pp. 704-711, (2020); Kaklamanis M.M., Filippakis M., Touloupos M., Christodoulou K., An experimental comparison of machine learning classification algorithms for breast cancer diagnosis, Proceedings of the 16th European, Mediterranean, and Middle Eastern Conference, EMCIS 2019, 381, pp. 18-30, (2019); Jianqiang Z., Xiaolin G., Comparison research on text pre-processing methods on twitter sentiment analysis, IEEE Access, 5, pp. 2870-2879, (2017); Sahoo D., Liu C., Hoi S.C.H., Malicious URL Detection using Machine Learning: A Survey, (2017); Rohini J., Ambesh B., Animesh S., Abhishek K.S., A Survey on Various Approaches for Sentiment Analysis and Performance Optimization, Int. J. Eng. Res. Technol, 6, pp. 716-720, (2017); Khanvilkar G., Deepali V.P., Sentiment Analysis for Product Recommendation Using Random Forest, Int. J. Eng. Technol, 7, (2018); Joshi A.M., Prabhune S., Random forest: A hybrid implementation for sarcasm detection in public opinion mining, Int. J. Innov. Technol. Explor. Eng, 8, pp. 5022-5025, (2019); Pathan M., Patel N., Yagnik H., Shah M., Artificial cognition for applications in smart agriculture: A comprehensive review, Artif. Intell. Agric, 4, pp. 81-95, (2020); Varathan K.D., Anastasia G., Crestani F., Comparative Opinion Mining: A Review, J. Assoc. Inf. Sci. Technol, 64, pp. 811-829, (2017); Samuel J., Ali G.G., Rahman M.M., Esawi E., Samuel Y., COVID-19 public sentiment insights and machine learning for tweets classification, Information, 11, (2020); Karami A., Shah V., Vaezi R., Bansal A., Twitter speaks: A case of national disaster situational awareness, J. Inf. Sci, 46, pp. 313-324, (2020); Delizo J.P.D., Abisado M.B., De Los Trinos M.I.P., Philippine twitter sentiments during COVID-19 Pandemic using Multinomial Naïve Bayes, Int. J. Adv. Trends Comput. Sci. Eng, 64, pp. 408-412, (2020); Karisani N., Karisani P., Mining Coronavirus (COVID-19) Posts in Social Media, (2020); Emil E., Jozef B., Analysis of Online Consumer Behavior-Design of CRISP-DM Process Model, Agris On-Line Pap. Econ. Inform, 9, pp. 13-22, (2020); Population, total-Nigeria | Data; Kabir A.I., Karim R., Newaz S., Hossain M.I., The power of social media analytics: Text analytics based on sentiment analysis and word clouds on R, J. Inform. Econ, 22, pp. 25-38, (2018); Danisman T., Alpkocak A., Feeler: Emotion classification of text using vector space model, Conv. Commun. Interact. Soc. Intell, 1, (2008); Thomas B., Vinod P., Dhanya K.A., Multiclass emotion extraction from sentences, Int. J. Sci. Eng. Res, 5, pp. 12-15, (2014)","S.L. Lutfi; School of Computer Sciences, Universiti Sains Malaysia, Penang, 11800, Malaysia; email: syaheerah@usm.my","","MDPI AG","","","","","","20711050","","","","English","Sustainability","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85103101474"
"Amran A.S.; Ibrahim S.A.S.; Malim N.H.A.H.; Hamzah N.; Sumari P.; Lutfi S.L.; Abdullah J.M.","Amran, Annis Shafika (57668351100); Ibrahim, Sharifah Aida Sheikh (57667358300); Malim, Nurul Hashimah Ahamed Hassain (35090139100); Hamzah, Nurfaten (57218596367); Sumari, Putra (6602619198); Lutfi, Syaheerah Lebai (27567802400); Abdullah, Jafri Malin (7003289641)","57668351100; 57667358300; 35090139100; 57218596367; 6602619198; 27567802400; 7003289641","DataAcquisition and Data Processing using Electroencephalogram in Neuromarketing: A Review","2022","Pertanika Journal of Science and Technology","30","1","","19","33","14","2","10.47836/pjst.30.1.02","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129556700&doi=10.47836%2fpjst.30.1.02&partnerID=40&md5=3cf7dc694fc475941b9da4c8b33cb5c9","Department of Neurosciences, School of Medical Sciences, Universiti Sains Malaysia, USM, Kelantan, Kubang Kerian, Kota, Bharu, 15200, Malaysia; School of Computer Sciences, Universiti Sains Malaysia, USM, Pulau Pinang, 11800, Malaysia; Brain and Behavior Cluster, School of Medical Sciences, Universiti Sains Malaysia, USM, Kelantan, Kubang Kerian, Kota, Bharu, 15200, Malaysia","Amran A.S., Department of Neurosciences, School of Medical Sciences, Universiti Sains Malaysia, USM, Kelantan, Kubang Kerian, Kota, Bharu, 15200, Malaysia; Ibrahim S.A.S., School of Computer Sciences, Universiti Sains Malaysia, USM, Pulau Pinang, 11800, Malaysia, Brain and Behavior Cluster, School of Medical Sciences, Universiti Sains Malaysia, USM, Kelantan, Kubang Kerian, Kota, Bharu, 15200, Malaysia; Malim N.H.A.H., School of Computer Sciences, Universiti Sains Malaysia, USM, Pulau Pinang, 11800, Malaysia, Brain and Behavior Cluster, School of Medical Sciences, Universiti Sains Malaysia, USM, Kelantan, Kubang Kerian, Kota, Bharu, 15200, Malaysia; Hamzah N., Department of Neurosciences, School of Medical Sciences, Universiti Sains Malaysia, USM, Kelantan, Kubang Kerian, Kota, Bharu, 15200, Malaysia, Brain and Behavior Cluster, School of Medical Sciences, Universiti Sains Malaysia, USM, Kelantan, Kubang Kerian, Kota, Bharu, 15200, Malaysia; Sumari P., School of Computer Sciences, Universiti Sains Malaysia, USM, Pulau Pinang, 11800, Malaysia, Brain and Behavior Cluster, School of Medical Sciences, Universiti Sains Malaysia, USM, Kelantan, Kubang Kerian, Kota, Bharu, 15200, Malaysia; Lutfi S.L., School of Computer Sciences, Universiti Sains Malaysia, USM, Pulau Pinang, 11800, Malaysia, Brain and Behavior Cluster, School of Medical Sciences, Universiti Sains Malaysia, USM, Kelantan, Kubang Kerian, Kota, Bharu, 15200, Malaysia; Abdullah J.M., Department of Neurosciences, School of Medical Sciences, Universiti Sains Malaysia, USM, Kelantan, Kubang Kerian, Kota, Bharu, 15200, Malaysia, School of Computer Sciences, Universiti Sains Malaysia, USM, Pulau Pinang, 11800, Malaysia","Electroencephalogram (EEG) is a neurotechnology used to measure brain activity via brain impulses. Throughout the years, EEG has contributed tremendously to data-driven research models (e.g., Generalised Linear Models, Bayesian Generative Models, and Latent Space Models) in Neuroscience Technology and Neuroinformatic. Due to versatility, portability, cost feasibility, and non-invasiveness. It contributed to various Neuroscientific data that led to advancement in medical, education, management, and even the marketing field. In the past years, the extensive uses of EEG have been inclined towards medical healthcare studies such as in disease detection and as an intervention in mental disorders, but not fully explored for uses in neuromarketing. Hence, this study construes the data acquisition technique in neuroscience studies using electroencephalogram and outlines the trend of revolution of this technique in aspects of its technology and databases by focusing on neuromarketing uses. © Universiti Putra Malaysia Press.","And revolution; Consumer sciences; Eeg advancement; Eeg technology; Future VR-EEG integration; Neural signal processing; Neuromarketing","","","","","","Universiti Sains Malaysia","We would like to thank Universiti Sains Malaysia for the support given to complete the manuscript.","Abujelala M., Sharma A., Abellanoza C., Makedon F., Brain-EE: Brain enjoyment evaluation using commercial EEG headband, Proceedings of the 9th ACM International Conference on, (2016); Beres A. M., Time is of the essence: A review of electroencephalography (EEG) and event-related brain potentials (ERPs) in language research, Applied Psychophysiology Biofeedback, 42, 4, pp. 247-255, (2017); Bhagchandani A., Bhatt D., Chopade M., Various big data techniques to process and analyse neuroscience data, 2018 5th International Conference on “Computing for Sustainable Global Development, pp. 397-402, (2018); Boksem M. A. S., Smidts A., Brain responses to movie trailers predict individual preferences for movies and their population-wide commercial success, Journal of Marketing Research, 52, 4, pp. 482-492, (2015); Casson A. J., Abdulaal M., Dulabh M., Kohli S., Krachunov S., Trimble E., Electroencephalogram, Seamless healthcare monitoring, pp. 45-81, (2018); Coenen A., Zayachkivska O., Adolf Beck: A pioneer in electroencephalography in between Richard Caton and Hans Berger, Advances in Cognitive Psychology, 9, 4, pp. 216-221, (2013); Deolindo C. S., Ribeiro M. W., Aratanha M. A., Afonso R. F., Irrmischer M., Kozasa E. H., A critical analysis on characterising the meditation experience through the electroencephalogram, Frontiers in Systems Neuroscience, 14, pp. 1-29, (2020); Doma O. O., EEG as input for virtual reality, Encyclopedia of computer graphics and games, pp. 1-4, (2019); Hill H., Exploring the limitations of event-related potential measures in moving subjects. Case studies of four different technical modifications in ergometer rowing, BioRxiv, 31, pp. 1-23, (2019); House P. M., Pelzl S., Furrer S., Lanz M., Simova O., Voges B., Stodieck S. R. G., Bruckner K. E., Use the mixed reality tool “VSI Patient Education” for more comprehensible and imaginable patient education before epilepsy surgery and stereotactic implantation of DBS or stereo-EEG electrodes, Epilepsy Research, 159, (2020); Husain A. M., Sinha S. R., Continuous EEG monitoring: Principles and practice, Journal of Clinical Neurophysiology, 37, 3, pp. 274-274, (2020); Ibrahim S. A. S., Hamzah N., Wahab A. R. A., Abdullah J. M., Malim N. H. A. H., Sumari P., Idris Z., Mokhtar A. M., Ghani A. R. I., Halim S. A., Razak S. A., Big brain data initiative in universiti sains malaysia: Challenges in brain mapping for Malaysia, Malaysian Journal of Medical Sciences, 27, 4, pp. 1-8, (2020); Barnett S. B., Cerf M., A ticket for your thoughts: Method for predicting content recall and sales using neural similarity of moviegoers, Journal of Consumer Research, 44, 1, pp. 160-181, (2017); Kaplan R. M., The mind reader: The forgotten life of Hans Berger, discoverer of the EEG, Australasian Psychiatry, 19, 2, pp. 168-169, (2011); Koudelkova Z., Strmiska M., Introduction to the identification of brain waves based on thefrequency, MATEC Web of Conferences, 210, pp. 1-4, (2018); Lau-Zhu A., Lau M. P. H., McLoughlin G., Mobile EEG in research on neurodevelopmental disorders: Opportunities and challenges, Developmental Cognitive Neuroscience, 36, (2019); Lin M. H. J., Cross S. N. N., Jones W. J., Childers T. L., Applying EEG in consumer neuroscience, European Journal of Marketing, 52, 1-2, pp. 66-91, (2018); Liu X., Zhang J., Hou G., Wang Z., Virtual reality and its application in military, IOP Conference Series: Earth and Environmental Science, 170, 3, (2018); Maddirala A. K., Shaik R. A., Separation of sources from single-channel EEG signals using independent component analysis, IEEE Transactions on Instrumentation and Measurement, 67, 2, pp. 382-393, (2018); Maples-Keller J. L., Bunnell B. E., Kim S. J., Rothbaum B. O., The use of virtual reality technology in the treatment of anxiety and other psychiatric disorders, Harvard Review of Psychiatry, 25, 3, pp. 103-113, (2017); McIntosh J., Rodgers M., Marques B., Gibbard A., The use of VR for creating therapeutic environments for the health and well-being of military personnel, their families and their communities, Journal of Digital Landscape Architecture, 2019, 4, pp. 185-194, (2019); Mosslah A. A., Mahdi R. H., Al-Barzinji S. M., Brain-computer interface for biometric authentication by recording signal, Computer Science & Information Technology, 2019, pp. 153-162, (2019); Plassmann H., Venkatraman V., Huettel S., Yoon C., Consumer neuroscience: Applications, challenges, and possible solutions, Journal of Marketing Research, 52, 4, pp. 427-435, (2015); Read G. L., Innis I. J., Electroencephalography (EEG), The international encyclopedia of communication research methods, pp. 1-18, (2017); Reyes L. M. S., Resendiz J. R., Ramirez G. N. A., Trends of clinical EEG systems: A review, 2018 IEEE EMBS Conference on Biomedical Engineering and Sciences, IECBES 2018-Proceedings, pp. 571-576, (2019); Rojas G. M., Alvarez C., Montoya C. E., de la Iglesia-Vaya M., Cisternas J. E., Galvez M., Study of resting-state functional connectivity networks using EEG electrodes position as seed, Frontiers in Neuroscience, 12, pp. 1-12, (2018); Seal A., Reddy P. P. N., Chaithanya P., Meghana A., Jahnavi K., Krejcar O., Hudak R., Jiang Y. Z., An EEG database and its initial benchmark emotion classification performance, Computational and Mathematical Methods in Medicine, (2020); Siuly S., Li Y., Zhang Y., Significance of EEG signals in medical and health research, EEG signal analysis and classification, pp. 23-41, (2016); Suhaimi N. S., Mountstephens J., Teo J., EEG-based emotion recognition: A state-of-the-art review of current trends and opportunities, Computational Intelligence and Neuroscience, 2020, (2020); Tudor M., Tudor L., Tudor K. I., The history of electroencephalography, Acta Medica Croatica, 59, 4, pp. 307-313, (2005); Vaid S., Singh P., Kaur C., EEG signal analysis for BCI interface: A review, International Conference on Advanced Computing and Communication Technologies, ACCT, pp. 143-147, (2015); Xue G., Chen C., Lu Z. L., Dong Q., Brain imaging techniques and their applications in decisionmaking research, Acta Psychologica Sinica, 42, 1, pp. 120-137, (2010); Yu J. H., Sim K. B., Classification of color imagination using Emotiv EPOC and event-related potential in electroencephalogram, Optik, 127, 20, pp. 9711-9718, (2016)","N.H.A.H. Malim; School of Computer Sciences, Universiti Sains Malaysia, USM, Pulau Pinang, 11800, Malaysia; email: nurulhashimah@usm.my","","Universiti Putra Malaysia Press","","","","","","01287680","","","","English","Pertanika J. Sci. Technol.","Review","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85129556700"
"Barra-Chicote R.; Fernandez F.; Lutfi S.; Lucas-Cuesta J.M.; Macias-Guarasa J.; Montero J.M.; San-Segundo R.; Pardo J.M.","Barra-Chicote, R. (27567444800); Fernandez, F. (24075790400); Lutfi, S. (27567802400); Lucas-Cuesta, J.M. (26664791600); Macias-Guarasa, J. (12345467100); Montero, J.M. (55960772400); San-Segundo, R. (8333266700); Pardo, J.M. (57193752834)","27567444800; 24075790400; 27567802400; 26664791600; 12345467100; 55960772400; 8333266700; 57193752834","Acoustic emotion recognition using dynamic bayesian networks and multi-space distributions","2009","Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH","","","","336","339","3","11","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-70450192757&partnerID=40&md5=8b8ac597a9e9148fc6b2b819810e8edf","Universidad Politecnica de Madrid, Spain; University of Alcala, Spain","Barra-Chicote R., Universidad Politecnica de Madrid, Spain; Fernandez F., Universidad Politecnica de Madrid, Spain; Lutfi S., Universidad Politecnica de Madrid, Spain; Lucas-Cuesta J.M., Universidad Politecnica de Madrid, Spain; Macias-Guarasa J., University of Alcala, Spain; Montero J.M., Universidad Politecnica de Madrid, Spain; San-Segundo R., Universidad Politecnica de Madrid, Spain; Pardo J.M., Universidad Politecnica de Madrid, Spain","In this paper we describe the acoustic emotion recognition system built at the Speech Technology Group of the Universidad Politecnica de Madrid (Spain) to participate in the INTERSPEECH 2009 Emotion Challenge. Our proposal is based on the use of a Dynamic Bayesian Network (DBN) to deal with the temporal modelling of the emotional speech information. The selected features (MFCC, F0, Energy and their variants) are modelled as different streams, and the F0 related ones are integrated under a Multi Space Distribution (MSD) framework, to properly model its dual nature (voiced/unvoiced). Experimental evaluation on the challenge test set, show a 67.06% and 38.24% of unweighted recall for the 2 and 5-classes tasks respectively. In the 2-class case, we achieve similar results compared with the baseline, with a considerable less number of features. In the 5-class case, we achieve a statistically significant 6.5% relative improvement. Copyright © 2009 ISCA.","Automatic emotion recognition; Dynamic bayesian networks; Emotion challenge; Multi-space probability distribution","Acoustics; Distributed parameter networks; Face recognition; Fluorine containing polymers; Inference engines; Intelligent networks; Probability distributions; Speech communication; Speech recognition; Acoustic emotion recognition; Dynamic Bayesian network; Dynamic bayesian networks; Emotion recognition; Emotional speech; Experimental evaluation; Space distribution; Speech technology; Test sets; Bayesian networks","","","","","","","Schuller B., Steidl S., Batliner A., The Interspeech 2009 Emotion Challenge, Interspeech, (2009); Barra-Chicote R., Montero J.M., Macias-Guarasa J., D'haro L.F., San-Segundo R., Cordoba R., Prosodic and segmental rubrics in emotion identification, Proc. of International Conference on Acoustics, Speech and Signal Processing, pp. 1085-1088, (2006); Barra-Chicote R., Montero J.M., Macias-Guarasa J., Lufti S., Lucas J.M., Fernandez F., D'haro L.F., San-Segundo R., Ferreiros J., Cordoba R., Pardo J.M., Spanish Expressive Voices: Corpus for Emotion Research in Spanish, Proc. of 6th International Conference on Language Resources and Evaluation (LREC2008), (2008); Lutfi S.L., Montero J.M., Barra-Chicote R., Lucas-Cuesta J.M., Gallardo-Antoln A., Expressive speech identifications based on Hidden Markov Model, Proceedings of the International Conference on Health Informatics (HEALTHINF), pp. 488-494, (2009); Barra-Chicote R., Macias-Guarasa J., Montero J.M., Rincon C., Fernandez F., Cordoba R., In Search of Primary Rubrics for Language Independent Emotional Speech Identification, Proc. of IEEE Workshop on Intelligent Speech Processing, (2007); Young S.J., Evermann G., Gales M.J.F., Kershaw D., Moore G., Odell J.J., Ollason D.G., Povey D., Valtchev V., Woodland P.C., The HTK book version 3.4 Manual; HMM-based Speech Synthesis System (HTS), http://hts.sp.nitech.ac.jp, Last access, (2008); Gales M., Young S., The application of hidden Markov models in speech recognition, Foundations and Trends in Signal Processing, 1, 3, (2007); Murphy K.P., Dynamic Bayesian Networks: Representation, Inference and Learning, (2002); Tokuda K., Masuko T., Miyazaki N., Kobayashi T., Multi-Space Probability Distribution HMM, IECI TRANS, INF. & SYSTEMS, E85-D, 3, (2002); Bilmes J., Last access, (2009); Steidl S., Automatic Classification of Emotion-Related User States in Spontaneous Children's Speech, (2009)","R. Barra-Chicote; Universidad Politecnica de Madrid, Spain; email: barra@die.upm.es","","","","10th Annual Conference of the International Speech Communication Association, INTERSPEECH 2009","6 September 2009 through 10 September 2009","Brighton","78744","19909772","","","","English","Proc. Annu. Conf. Int. Speech. Commun. Assoc., INTERSPEECH","Conference paper","Final","","Scopus","2-s2.0-70450192757"
"Al Qudah M.M.M.; Mohamed A.S.A.; Lutfi S.L.","Al Qudah, Mustafa M. M. (57222567501); Mohamed, Ahmad S. A. (57190968285); Lutfi, Syaheerah L. (27567802400)","57222567501; 57190968285; 27567802400","Affective state recognition using thermal-based imaging: A survey","2021","Computer Systems Science and Engineering","37","1","","47","62","15","8","10.32604/CSSE.2021.015222","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103239312&doi=10.32604%2fCSSE.2021.015222&partnerID=40&md5=bef868e22b0f14d169bcdc8c900d2900","School of Computer Sciences, Universiti Sains Malaysia, Penang, 11800, Malaysia","Al Qudah M.M.M., School of Computer Sciences, Universiti Sains Malaysia, Penang, 11800, Malaysia; Mohamed A.S.A., School of Computer Sciences, Universiti Sains Malaysia, Penang, 11800, Malaysia; Lutfi S.L., School of Computer Sciences, Universiti Sains Malaysia, Penang, 11800, Malaysia","The thermal-based imaging technique has recently attracted the attention of researchers who are interested in the recognition of human affects due to its ability to measure the facial transient temperature, which is correlated with human affects and robustness against illumination changes. Therefore, studies have increasingly used the thermal imaging as a potential and supplemental solution to overcome the challenges of visual (RGB) imaging, such as the variation of light conditions and revealing original human affect. Moreover, the thermal-based imaging has shown promising results in the detection of psychophysiological signals, such as pulse rate and respiration rate in a contactless and noninvasive way. This paper presents a brief review on human affects and focuses on the advantages and challenges of the thermal imaging technique. In addition, this paper discusses the stages of thermal-based human affective state recognition, such as dataset type, preprocessing stage, region of interest (ROI), feature descriptors, and classification approaches with a brief performance analysis based on a number of works in the literature. This analysis could help beginners in the thermal imaging and affective recognition domain to explore numerous approaches used by researchers to construct an affective state system based on thermal imaging. © 2021 CRL Publishing. All rights reserved.","Affective state recognition; Feature extraction and classification; Spontaneous emotion; Thermal-based imaging","Classification (of information); Image segmentation; State estimation; Affective recognition; Classification approach; Feature descriptors; Illumination changes; Performance analysis; Psychophysiological signals; Region of interest; Transient temperature; Infrared imaging","","","","","Universiti Sains Malaysia","Funding Statement: This research was funded by the research university grant by Universiti Sains Malaysia [1001.PKOMP.8014001].","Greenblatt S., Toward a universal language of motion: Reflections on a seventeenth-century muscle man, LiNQ (Literature in North Queensland), 21, 2, pp. 56-62, (1994); Darwin C., Introduction to The First Edition, The Expression of Emotions in Man and Animals, (1872); Duchenne G. B., de Boulogne G. B. D., Cuthbertson R. A., Manstead A. S. R., Oatley K., A review of previous work on muscle action in facial expression, The Mechanism of Human Facial Expression, pp. 14-16, (1990); Ekman P., Friesen W. V., Constants across cultures in the face and emotion, Journal of Personality and Social Psychology, 17, 2, pp. 124-129, (1971); Russell J. A., A circumplex model of affect, Journal of Personality and Social Psychology, 39, 6, (1980); Chen C.H., Lee I.J., Lin L.Y., Augmented reality-based self-facial modeling to promote the emotional expression and social skills of adolescents with autism spectrum disorders, Research in Developmental Disabilities, 36, pp. 396-403, (2015); Fendri E., Boukhriss R. R., Hammami M., Fusion of thermal infrared and visible spectra for robust moving object detection, Pattern Analysis and Applications, 20, 4, pp. 907-926, (2017); Desideri L., Ottaviani C., Malavasi M., di Marzio R., Bonifacci P., Emotional processes in human-robot interaction during brief cognitive testing, Computers in Human Behavior, 90, 1, pp. 331-342, (2019); Lee M. S., Cho Y. R., Lee Y. K., Pae D. S., Lim M. T., Et al., PPG and EMG based emotion recognition using convolutional neural network, ICINCO 2019-Proc. of the 16th Int. Conf. on Informatics in Control, Automation and Robotics, pp. 595-600, (2019); Miller G. E., Cohen S., Ritchey A. K., Chronic psychological stress and the regulation of pro-inflammatory cytokines: A glucocorticoid-resistance model, Health Psychology, 21, 6, pp. 531-541, (2002); Vitetta L., Anton B., Cortizo F., Sali A., Mind-body medicine: Stress and its impact on overall health and longevity, Annals of the New York Academy of Sciences, 1057, 1, pp. 492-505, (2005); Gradus J. L., Posttraumatic stress disorder and death from suicide, Current Psychiatry Reports, 20, 11, (2018); Mowrer O. H., Introduction: Historical review and perespective, Learning Theory and Behavior, (1960); Frijda N. H., Emotional behavior, The Emotions, pp. 9-109, (1986); Ekman P., Universals and cultural differences in facial expressions of emotion, Nebraska Sym. on Motivation, 19, pp. 209-282, (1971); Scherer K. R., Schorr A., Johnstone T., Appraisal theory, Appraisal Processing in Emotion, (2001); Ortony A., Clore G., Appraisal theories: How cognition shapes affect into emotion, Handbook of Emotions, pp. 628-642, (2008); Fasel B., Luettin J., Automatic facial expression analysis: A survey, Pattern Recognition, 36, 1, pp. 259-275, (2003); Devito J. A., Silence and paralanguage as communication, ETC: A Review of General Semantics, 74, 3- 4, pp. 482-487, (2017); Knapp M. L., Hall J. A., Horgan T. G., Nonverbal communication: Basic perspectives, Nonverbal Communication in Human Interaction, pp. 3-19, (2013); Johar S., Emotion, affect and personality in speech: The bias of language and paralanguage, pp. 1-6, (2016); Khatri N. N., Shah Z. H., Patel S. A., Facial expression recognition: A survey, Int. Journal of Computer Science and Information Technologies (IJCSIT), 5, 1, pp. 149-152, (2014); Smith C., Scott H., A Componential approach to the meaning of facial expressions, The Psychology of Facial Expression (Studies in Emotion and Social Interaction), pp. 229-254, (1997); Kihlstrom J. F., Mulvaney S., Tobias B. A., Tobis I. P., The emotional unconscious, Cognition and Emotion, pp. 30-86, (2000); Friesen E., Ekman P., Facial action coding system: A technique for the measurement of facial movement, Consulting Psychologists Press, 3, (1978); Khalid B., Khan A. M., Akram M. U., Batool S., Person detection by fusion of visible and thermal images using convolutional neural network, Int. Conf. on Communication, Computing and Digital Systems (C-CODE), pp. 143-148, (2019); Shu L., Xie J., Yang M., Li Z., Li Z., Et al., A review of emotion recognition using physiological signals, Sensors, 18, 7, (2018); Kreibig S. D., Autonomic nervous system activity in emotion: A review, Biological Psychology, 84, 3, pp. 394-421, (2010); Samadiani N., Huang G., Cai B., Luo W., Chi C.H., Et al., A review on automatic facial expression recognition systems assisted by multimodal sensor data, Sensors (Basel), 19, 8, (2019); Jaimes A., Sebe N., Multimodal human-computer interaction: A survey, Computer Vision and Image Understanding, 108, 1-2, pp. 116-134, (2007); Mehta D., Siddiqui M. F. H., Javaid A. Y., Facial emotion recognition: A survey and real-world user experiences in mixed reality, Sensors, 18, 2, (2018); Gunes H., Schuller B., Pantic M., Cowie R., Emotion representation, analysis and synthesis in continuous space: A survey, International Conference on Automatic Face and Gesture Recognition, pp. 827-834, (2011); Busso C., Deng Z., Yildirim S., Bulut M., Lee C. M., Et al., Analysis of emotion recognition using facial expressions, speech and multimodal information, Proc. of the 6th Int. Conf. on Multimodal Interfaces (ICMI04), pp. 205-211, (2004); Corneanu C. A., Simon M. O., Cohn J. F., Guerrero S. E., Survey on RGB, 3D, thermal, and multimodal approaches for facial expression recognition: History, trends, and affect-related applications, IEEE Transactions on Pattern Analysis and Machine Intelligence, 38, 8, pp. 1548-1568, (2016); Shoumy N. J., Ang L. M., Seng K. P., Rahaman D. M., Zia T., Multimodal big data affective analytics: A comprehensive survey using text, audio, visual and physiological signals, Journal of Network and Computer Applications, 149, 1, (2020); Chunawale A., Bedekar D., Human emotion recognition using physiological signals: A survey, 2nd Int. Conf. on Communication and Information Processing (ICCIP-2020), (2020); Saganowski S., Dutkowiak A., Dziadek A., Dziezyc M., Komoszynska J., Et al., Emotion recognition using wearables: A systematic literature review-work-in-progress, IEEE Int. Conf. on Pervasive Computing and Communications Workshops (PerCom Workshops), pp. 1-6, (2020); Faust O., Hagiwara Y., Hong T. J., Lih O. S., Acharya U. R., Deep learning for healthcare applications based on physiological signals: A review, Computer Methods and Programs in Biomedicine, 161, 1, pp. 1-13, (2018); Bong S. Z., Murugappan M., Yaacob S., Methods and approaches on inferring human emotional stress changes through physiological signals: A review, Int. Journal of Medical Engineering and Informatics, 5, 2, pp. 152-162, (2013); Jerritta S., Murugappan M., Nagarajan R., Wan K., Physiological signals based human emotion recognition: A review, IEEE 7th Int. Colloquium on Signal Processing and its Applications, pp. 410-415, (2011); Ko B. C., A brief review of facial emotion recognition based on visual information, Sensors, 18, 2, (2018); Revina I. M., Emmanuel S., A survey on human face expression recognition techniques, Journal of King Saud University-Computer and Information Sciences, pp. 1-33, (2018); Filippini C., Perpetuini D., Cardone D., Chiarelli A. M., Merla A., Thermal infrared imaging-based affective computing and its application to facilitate human robot interaction: A review, Applied Sciences, 10, 8, (2020); Yang B., Li X., Hou Y., Meier A., Cheng X., Et al., Non-invasive (non-contact) measurements of human thermal physiology signals and thermal comfort/discomfort poses-a review, Energy and Buildings, 224, 1, (2020); Kumar C. N., Shivakumar G., A survey on human emotion analysis using thermal imaging and physiological variables, Int. Journal of Current Engineering and Scientific Research (IJCESR), 4, 4, pp. 122-126, (2017); Ponsi G., Panasiti M. S., Rizza G., Aglioti S. M., Thermal facial reactivity patterns predict social categorization bias triggered by unconscious and conscious emotional stimuli, Proc. of the Royal Society B: Biological Sciences, 284, 1861, (2017); Ioannou S., Gallese V., Merla A., Thermal infrared imaging in psychophysiology: Potentialities and limits, Psychophysiology, 51, 10, pp. 951-963, (2014); van Gastel M., Stuijk S., de Haan G., Robust respiration detection from remote photoplethysmography, Biomedical Optics Express, 7, 12, pp. 4941-4957, (2016); Cho Y., Automated mental stress recognition through mobile thermal imaging, Seventh Int. Conf. on Affective Computing and Intelligent Interaction (ACII), pp. 596-600, (2017); He X., Goubran R., Knoefel F., IR night vision video-based estimation of heart and respiration rates, IEEE Sensors Applications Symposium (SAS), pp. 1-5, (2017); Merla A., Di Donato L., Rossini P., Romani G., Emotion detection through functional infrared imaging: preliminary results, Biomedizinische Technick, 48, 2, pp. 284-286, (2004); Alkali A. H., Saatchi R., Elphick H., Burke D., Thermal image processing for real-time non-contact respiration rate monitoring, IET Circuits, Devices & Systems, 11, 2, pp. 142-148, (2017); Nakayama Y., Sun G., Abe S., Matsui T., Non-contact measurement of respiratory and heart rates using a CMOS camera-equipped infrared camera for prompt infection screening at airport quarantine stations, IEEE Int. Conf. on Computational Intelligence and Virtual Environments for Measurement Systems and Applications (CIVEMSA), pp. 1-4, (2015); Park S. B., Kim G., Baek H. J., Han J. H., Kim J. H., Remote pulse rate measurement from near-infrared videos, IEEE Signal Processing Letters, 25, 8, pp. 1271-1275, (2018); Yang M., Liu Q., Turner T., Wu Y., Vital sign estimation from passive thermal video, IEEE Conf. on Computer Vision and Pattern Recognition, pp. 1-8, (2008); Fei J., Pavlidis I., Thermistor at a distance: Unobtrusive measurement of breathing, IEEE Transactions on Biomedical Engineering, 57, 4, pp. 988-998, (2009); Murthy J. N., van Jaarsveld J., Fei J., Pavlidis I., Harrykissoon R. I., Et al., Thermal infrared imaging: A novel method to monitor airflow during polysomnography, Sleep, 32, 11, pp. 1521-1527, (2009); Basu A., Routray A., Shit S., Deb A. K., Human emotion recognition from facial thermal image based on fused statistical feature and multi-class SVM, Annual IEEE India Conf. (INDICON), pp. 1-5, (2015); Mohd M. N. H., Kashima M., Sato K., Watanabe M., Mental stress recognition based on non-invasive and non-contact measurement from stereo thermal and visible sensors, Int. Journal of Affective Engineering, 14, 1, pp. 9-17, (2015); Nguyen T., Tran K., Nguyen H., Towards thermal region of interest for human emotion estimation, 10th Int. Conf. on Knowledge and Systems Engineering (KSE), pp. 152-157, (2018); Wang S., Pan B., Chen H., Ji Q., Thermal augmented expression recognition, IEEE Transactions on Cybernetics, 48, 7, pp. 2203-2214, (2018); Yan X., Andrews T. J., Jenkins R., Young A.W., Cross-cultural differences and similarities underlying otherrace effects for facial identity and expression, Quarterly Journal of Experimental Psychology, 69, 7, pp. 1247-1254, (2018); Wang S., Liu Z., Wang Z., Wu G., Shen P., Et al., Analyses of a multimodal spontaneous facial expression database, IEEE Transactions on Affective Computing, 4, 1, pp. 34-46, (2013); Bhowmik M. K., Saha P., Singha A., Bhattacharjee D., Dutta P., Enhancement of robustness of face recognition system through reduced Gaussianity in Log-ICA, Expert Systems with Applications, 116, 1, pp. 96-107, (2019); Zhang X., Yin L., Cohn J. F., Canavan S., Reale M., Et al., Bp4d-spontaneous: A high-resolution spontaneous 3d dynamic facial expression database, Image and Vision Computing, 32, 10, pp. 692-706, (2014); Chu C.-H., Peng S.-M., Implementation of face recognition for screen unlocking on mobile device, Proc. of the 23rd ACM Int. Conf. on Multimedia, pp. 1027-1030, (2015); Jian B.-L., Chen C. L., Huang M. W., Yau H. T., Emotion-specific facial activation maps based on infrared thermal image sequences, IEEE Access, 7, pp. 48046-48052, (2019); Elanthendral V., Rekha R., Rameshkumar M., Thermal imaging for facial expression-fatigue detection, International Journal for Research in Applied Science & Engineering Technology (IJRASET), 2, XII, pp. 14-17, (2014); Nguyen H., Chen F., Kotani K., Le B., Fusion of visible images and thermal image sequences for automated facial emotion estimation, Journal of Mobile Multimedia, 10, 3-4, pp. 294-308, (2014); Kopaczka M., Kolk R., Merhof D., A fully annotated thermal face database and its application for thermal facial expression recognition, IEEE Int. Instrumentation and Measurement Technology Conf. (I2MTC), pp. 1-6, (2018); Merhof D., Acar K., Kopaczka M., Robust facial landmark detection and face tracking in thermal infrared images using active appearance models, Int. Conf. on Computer Vision Theory and Applications, pp. 150-158, (2016); Mostafa E., Farag A., Shalaby A., Ali A., Gault T., Et al., Long term facial parts tracking in thermal imaging for uncooperative emotion recognition, IEEE Sixth Int. Conf. on Biometrics: Theory, Applications and Systems (BTAS), pp. 1-6, (2013); Wang S., He S., Wu Y., He M., Ji Q., Fusion of visible and thermal images for facial expression recognition, Frontiers of Computer Science, 8, 2, pp. 232-242, (2014); Shi X., Wang S., Zhu Y., Expression recognition from visible images with the help of thermal images, Proc. of the 5th ACM on Int. Conf. on Multimedia Retrieval, pp. 563-566, (2015); Siddiqui M. F. H., Javaid A. Y., A multimodal facial emotion recognition framework through the fusion of speech with visible and infrared images, Multimodal Technologies and Interaction, 4, 3, (2020); Wang S., He S., Spontaneous facial expression recognition by fusing thermal infrared and visible images, Intelligent Autonomous Systems 12. Advances in Intelligent Systems and Computing, 194, pp. 263-272, (2013); Nayak S., Panda S. K., Uttarkabat S., A non-contact framework based on thermal and visual imaging for classification of affective states during HCI, 4th Int. Conf. on Trends in Electronics and Informatics (ICOEI)(48184), pp. 653-660, (2020); Kolli A., Fasih A., Al Machot F., Kyamakya K., Non-intrusive car driver's emotion recognition using thermal camera, International Workshop on Nonlinear Dynamics and Synchronization, INDS. Proc. of the Joint INDS'11 & ISTET'11, pp. 1-5, (2011); Latif M., Sidek S., Rusli N., Fatai S., Emotion detection from thermal facial imprint based on GLCM features, ARPN J. Eng. Appl. Sci, 11, 1, pp. 345-350, (2016); Kopaczka M., Kolk R., Merhof D., A fully annotated thermal face database and its application for thermal facial expression recognition, IEEE Int. Instrumentation and Measurement Technology Conf. (I2MTC), pp. 1-6, (2018); Cross C. B., Skipper J. A., Petkie D. T., Thermal imaging to detect physiological indicators of stress in humans, Proc. SPIE Thermosense: Thermal Infrared Applications XXXV, 8705, (2013); Carrapico R., Mourao A., Magalhaes J., Cavaco S., A comparison of thermal image descriptors for face analysis, 23rd European Signal Processing Conf. (EUSIPCO), pp. 829-833, (2015); Perez-Rosas V., Narvaez A., Burzo M., Mihalcea R., Thermal imaging for affect detection, PETRA '13: The 6th Int. Conf. on Pervasive Technologies Related to Assistive Environments, pp. 1-4, (2013); Liu P., Yin L., Spontaneous facial expression analysis based on temperature changes and head motions, 11th IEEE Int. Conf. and Workshops on Automatic Face and Gesture Recognition (FG), pp. 1-6, (2015); Wang S., He M., Gao Z., He S., Ji Q., Emotion recognition from thermal infrared images using deep Boltzmann machine, Frontiers of Computer Science, 8, 4, pp. 609-618, (2014); Boccanfuso L., Wang Q., Leite I., Li B., Torres C., Et al., A thermal emotion classifier for improved human-robot interaction, 25th IEEE Int. Sym. on Robot and Human Interactive Communication (RO-MAN), pp. 718-723, (2016); Latif M., Yusof M. H., Sidek S., Rusli N., Texture descriptors based affective states recognition-frontal face thermal image, IEEE EMBS Conf. on Biomedical Engineering and Sciences (IECBES), pp. 80-85, (2016); Nguyen H., Kotani K., Chen F., Le B., Estimation of human emotions using thermal facial information, Fifth Int. Conf. on Graphic and Image Processing (ICGIP2013) Proc, 9069, (2014); Goulart C., Valadao C., Delisle-Rodriguez D., Caldeira E., Bastos T., Et al., Emotion analysis in children through facial emissivity of infrared thermal imaging, PloS One, 14, 3, (2019); Khan M. M., Ward R. D., Ingleby M., Classifying pretended and evoked facial expressions of positive and negative affective states using infrared measurement of skin temperature, ACM Transactions on Applied Perception (TAP), 6, 1, pp. 1-22, (2009); Haamer R. E., Rusadze E., Lusi I., Ahmed T., Escalera S., Et al., Review on emotion recognition databases, Human-Robot Interaction-Theory and Application, (2017); Wang S., Liu Z., Lv S., Lv Y., Wu G., Et al., A natural visible and infrared facial expression database for expression recognition and emotion inference, IEEE Transactions on Multimedia, 12, 7, pp. 682-691, (2010); Nguyen H., Kotani K., Chen F., Le B., A thermal facial emotion database and its analysis, Pacific-Rim Sym. on Image and Video Technology, pp. 397-408, (2013); Ordun C., Raff E., Purushotham S., The use of AI for thermal emotion recognition: A review of problems and limitations in standard design and data, pp. 1-13, (2020); Zhu X., Ramanan D., Face detection, pose estimation, and landmark localization in the wild, IEEE Conf. on Computer Vision and Pattern Recognition, pp. 2879-2886, (2012); Trujillo L., Olague G., Hammoud R., Hernandez B., Automatic feature localization in thermal images for facial expression recognition, IEEE Computer Society Conf. on Computer Vision and Pattern Recognition (CVPR'05)-Workshops, (2005); Cruz-Albarran I. A., Benitez-Rangel J. P., Osornio-Rios R. A., Morales-Hernandez L. A., Human emotions detection based on a smart-thermal system of thermographic images, Infrared Physics & Technology, 81, 1, pp. 250-261, (2017); Stemberger J., Allison R. S., Schnell T., Thermal imaging as a way to classify cognitive workload, Canadian Conf. on Computer and Robot Vision, pp. 231-238, (2010); Jarlier S., Grandjean D., Delplanque S., N'Diaye K., Cayeux I., Et al., Thermal analysis of facial muscles contractions, IEEE Transactions on Affective Computing, 2, 1, pp. 2-9, (2011); Rivera H., Goulart C., Favarato A., Valadao C., Caldeira E., Et al., Development of an automatic expression recognition system based on facial action coding system, Simpósio Brasileiro de Automação Inteligente (SBAI2017), pp. 615-620, (2017); Ojala T., Pietikainen M., Maenpaa T., Multiresolution gray-scale and rotation invariant texture classification with local binary patterns, IEEE Transactions on Pattern Analysis and Machine Intelligence, 24, 7, pp. 971-987, (2002); Mallat K., Dugelay J. L., A benchmark database of visible and thermal paired face images across multiple variations, Int. Conf. of the Biometrics Special Interest Group (BIOSIG), pp. 1-5, (2018)","A.S.A. Mohamed; School of Computer Sciences, Universiti Sains Malaysia, Penang, 11800, Malaysia; email: sufril@usm.my","","Tech Science Press","","","","","","02676192","","CSSEE","","English","Comput Syst Sci Eng","Article","Final","All Open Access; Hybrid Gold Open Access","Scopus","2-s2.0-85103239312"
"Lucas-Cuesta J.M.; Ferreiros J.; Fernández-Martínez F.; Echeverry J.D.; Lutfi S.","Lucas-Cuesta, J.M. (26664791600); Ferreiros, J. (12345343100); Fernández-Martínez, F. (6602973640); Echeverry, J.D. (36630259000); Lutfi, S. (27567802400)","26664791600; 12345343100; 6602973640; 36630259000; 27567802400","On the dynamic adaptation of language models based on dialogue information","2013","Expert Systems with Applications","40","4","","1069","1085","16","2","10.1016/j.eswa.2012.08.029","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84870250513&doi=10.1016%2fj.eswa.2012.08.029&partnerID=40&md5=e81460621d890644a963cd7303f95ed7","Speech Technology Group, Universidad Politécnica de Madrid, 28040 Madrid, Avenida Complutense 30, Spain","Lucas-Cuesta J.M., Speech Technology Group, Universidad Politécnica de Madrid, 28040 Madrid, Avenida Complutense 30, Spain; Ferreiros J., Speech Technology Group, Universidad Politécnica de Madrid, 28040 Madrid, Avenida Complutense 30, Spain; Fernández-Martínez F., Speech Technology Group, Universidad Politécnica de Madrid, 28040 Madrid, Avenida Complutense 30, Spain; Echeverry J.D., Speech Technology Group, Universidad Politécnica de Madrid, 28040 Madrid, Avenida Complutense 30, Spain; Lutfi S., Speech Technology Group, Universidad Politécnica de Madrid, 28040 Madrid, Avenida Complutense 30, Spain","We present an approach to adapt dynamically the language models (LMs) used by a speech recognizer that is part of a spoken dialogue system. We have developed a grammar generation strategy that automatically adapts the LMs using the semantic information that the user provides (represented as dialogue concepts), together with the information regarding the intentions of the speaker (inferred by the dialogue manager, and represented as dialogue goals). We carry out the adaptation as a linear interpolation between a background LM, and one or more of the LMs associated to the dialogue elements (concepts or goals) addressed by the user. The interpolation weights between those models are automatically estimated on each dialogue turn, using measures such as the posterior probabilities of concepts and goals, estimated as part of the inference procedure to determine the actions to be carried out. We propose two approaches to handle the LMs related to concepts and goals. Whereas in the first one we estimate a LM for each one of them, in the second one we apply several clustering strategies to group together those elements that share some common properties, and estimate a LM for each cluster. Our evaluation shows how the system can estimate a dynamic model adapted to each dialogue turn, which helps to significantly improve the performance of the speech recognition, which leads to an improvement in both the language understanding and the dialogue management tasks. © 2012 Elsevier Ltd. All rights reserved.","Dialogue-based information; Dynamic adaptation; Language models; Semantic clustering; Speech recognition; Spoken dialogue system","Computational linguistics; Estimation; Managers; Semantics; Speech processing; Dialogue-based information; Dynamic adaptations; Language model; Semantic clustering; Spoken dialogue system; Speech recognition","","","","","Ministerio de Educación, Cultura y Deporte, MECD, (AP2007–00463); Ministerio de Ciencia e Innovación, MICINN, (DPI2007-66846-C02-02, DPI2010-21247-C02-02, TIN2008-06856-C05-05)","This work has been partially supported by the Spanish Ministry of Science and Innovation, under contracts TIN2008-06856-C05-05 (SD-TEAM UPM), DPI2007-66846-C02-02 (ROBONAUTA) and DPI2010-21247-C02-02 (INAPRA), and by the Spanish Ministry of Education, under contract AP2007–00463 (FPU Grant).","Bacchiani M., Riley M., Roark B., Sproat R., MAP adaptation of stochastic grammars, Computer Speech and Language, 20, pp. 41-68, (2006); Bacchiani M., Roark B., Unsupervised language model adaptation, Proceedings of the International Conference on Acoustic, Speech and Signal Processing (ICASSP), 1, pp. 224-227, (2003); Bellegarda J.R., Exploiting latent semantic information in statistical language modeling, Proceedings of IEEE, 88, 8, pp. 1279-1296, (2000); Bellegarda J.R., An overview of statistical language model adaptation, Proceedings of the International Workshop on Adaptation Methods for Speech Recognition, pp. 165-174, (2001); Bellegarda J.R., Statistical language model adaptation: Review and perspectives, Speech Communication, 42, pp. 93-108, (2004); Bellegarda J.R., Butzberger J.W., Chow Y.L., Coccaro N.B., Naik D., A novel word clustering algorithm based on latent semantic analysis, Proceedings of the International Conference on Acoustic, Speech and Signal Processing (ICASSP), 1, pp. 172-175, (1996); Chen L., Gauvain J.L., Lamel L., Adda G., Adda M., Using information retrieval methods for language model adaptation, Proceedings of the 7th European Conference on Speech Communication and Technology (EUROSPEECH), pp. 255-258, (2001); Darroch J.N., Ratcliff D., Generalized iterative scaling for log-linear models, The Annals of Mathematical Statistics, 43, 5, pp. 1470-1480, (1972); Federico M., Bayesian estimation methods for n-gram language model adaptation, Proceedings of the International Conference on Spoken Language Processing (ICSLP), pp. 240-243, (1996); Federico M., Bertoldi N., Broadcast news LM adaptation over time, Computer Speech and Language, 18, pp. 417-435, (2004); Fernandez F., Ferreiros J., Sama V., Montero J.M., San-Segundo R., MacIas-Guarasa J., Speech interface for controlling a Hi-Fi audio system based on a bayesian belief networks approach for dialog modeling, Proceedings of the 9th European Conference on Speech Communication and Technology (INTERSPEECH), pp. 3421-3424, (2005); Fugen C., Holzapfel H., Waibel A., Tight coupling of speech recognition and dialog management - Dialog-context dependent grammar weighting for speech recognition, Proceedings of the International Conference on Spoken Language Processing (ICSLP), 1, pp. 169-172, (2004); Gruenstein A., Wang C., Seneff S., Context-sensitive statistical language modeling, Proceedings of the 5th International Conference on Speech Communication and Technology (INTERSPEECH), pp. 17-20, (2005); Hsu B.J., Generalized linear interpolation of language models, Proceedings of the IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU), pp. 136-140, (2007); Iyer R., Ostendorf M., Rohlicek J.R., Language modeling with sentence-level mixtures, Proceedings of the ARPA HLT Workshop, pp. 82-87, (1994); Iyer R.M., Ostendorf M., Modeling long distance dependence in language: Topic mixture versus dynamic cache models, IEEE Transactions on Speech and Audio Processing, 7, 1, pp. 30-39, (1999); Jelinek F., Merialdo B., Roukos S., Strauss M., A dynamic language model for speech recognition, Proceedings of the DARPA Workshop on Speech and Natural Language, pp. 293-295, (1991); Justo R., Torres M.I., Word segments in category-based language models for automatic speech recognition, Lecture Notes in Computer Science, 4477, pp. 249-256, (2007); Klakow D., Log-linear interpolation of language models, Proceedings of the International Conference on Spoken Language Processing (ICSLP), 5, pp. 1695-1698, (1998); Kneser R., Steinbiss V., On the dynamic adaptation of stochastic language models, Proceedings of the International Conference on Audio Speech and Signal Processing (ICASSP), 2, pp. 586-589, (1993); Kuhn R., De Mori R., A cache-based natural language model for speech recognition, IEEE Transactions on Pattern Analysis and Machine Intelligence, 12, 6, pp. 570-583, (1990); Landauer T.K., Foltz P.W., Laham D., An introduction to latent semantic analysis, Discourse Processes, 25, pp. 259-284, (1998); Lau R., Rosenfeld R., Roukos S., Trigger-based language models: A maximum entropy approach, Proceedings of the IEEE International Conference on Acoustic, Speech and Signal Processing (ICASSP), 2, pp. 45-48, (1993); Lecorve G., Gravier G., Sebillot P., Constraint selection for topic-based MDI adaptation of language models, Proceedings of the 9th International Conference on Speech Communication and Technology (INTERSPEECH), pp. 368-371, (2009); Liu X., Gales J.M.F., Woodland P.C., Context dependent language model adaptation, Proceedings of the 8th International Conference on Speech Communication and Technology (INTERSPEECH), pp. 837-840, (2008); Ljolje A., Hindle D.M., Riley M.D., Sproat R.W., The AT& T LVCSR-2000 system, NIST LVCSR Workshop, (2000); Lobacheva Y., Discourse Mixture Language Modeling, (2000); Lopez-Cozar R., Callejas Z., Combining language models in the input interface of a spoken dialogue system, Computer Speech and Language, 20, pp. 420-440, (2006); Lopez-Cozar R., Callejas Z., ASR post-correction for spoken dialogue systems based on semantic, syntactic, lexical and contextual information, Speech Communication, 50, pp. 745-766, (2008); Lopez-Cozar R., Griol D., New technique to enhance the performance of spoken dialogue systems based on dialogue states-dependent language models and grammatical rules, Proceedings of the 10th International Conference on Speech Communication and Technology (INTERSPEECH), pp. 2998-3001, (2010); Lucas-Cuesta J.M., Fernandez F., Ferreiros J., Using dialogue-based dynamic language models for improving speech recognition, Proceedings of the 9th International Conference on Speech Communication and Technology (INTERSPEECH), pp. 2471-2474, (2009); Lucas-Cuesta J.M., Fernandez F., Lopez V., Ferreiros J., San-Segundo R., Clustering of syntactic and discursive information for the dynamic adaptation of Language Models, Revista de la Sociedad Española de Procesamiento Del Lenguaje Natural, 45, pp. 175-182, (2010); Lucas-Cuesta J.M., Fernandez F., Salazar J., Ferreiros J., San-Segundo R., Managing speaker identity and user profiles in a spoken dialogue system, Revista de la Sociedad Española de Procesamiento Del Lenguaje Natural, 43, pp. 77-84, (2009); Lucas-Cuesta J.M., Fernandez-Martinez F., Dragos G., Lutfi S., Ferreiros J., Evaluation of a user-adapted spoken language dialogue system: Measuring the relevance of the contextual information sources, Proceedings of the 3rd International Conference on Agents and Artificial Intelligence (ICAART), pp. 218-223, (2011); Manning C.D., Schutze H., Foundations of Statistical Natural Language Processing, (2002); Martins C., Teixeira A., Neto J., Dynamic language modeling for European Portuguese, Computer Speech and Language, 24, pp. 750-773, (2010); Popovici C., Baggia P., Specialized language models using dialogue predictions, Proceedings of the International Conference on Audio Speech and Signal Processing (ICASSP), 2, pp. 815-818, (1997); Rao P.S., Monkowski M.D., Roukos S., Language model adaptation via minimum discrimination information, Proceedings of the International Conference on Audio Speech and Signal Processing (ICASSP), pp. 161-164, (1995); Raux A., Mehta N., Ramachandran D., Gupta R., Dynamic language modeling using bayesian networks for spoken dialog systems, Proceedings of the 10th International Conference on Speech Communication and Technology (INTERSPEECH), pp. 3030-3033, (2010); Riccardi G., Gorin A.L., Stochastic language adaptation over time and state in natural spoken dialog systems, IEEE Transactions on Speech and Audio Processing, 8, 1, pp. 3-10, (2000); Riccardi G., Potamianos A., Narayanan S., Language model adaptation for spoken language system, Proceedings of the International Conference on Spoken Language Processing (ICSLP), pp. 2327-2330, (1998); Rosenfeld R., Adaptive Statistical Language Modeling: A Maximum Entropy Approach, (1994); Rosenfeld R., Huang X., Improvements in stochastic language modeling, Proceedingso of the DARPA Workshop on Speech and Natural Language, pp. 107-111, (1992); Saykham K., Chotimongkol A., Wutiwiwatchai C., Online temporal language model adaptation for a thai broadcast news transcription system, Proceedings of the 7th International Conference on Language Resources and Evaluation (LREC), pp. 1690-1694, (2010); Shi Q., Chu S.M., Liu W., Kuo H.K., Liu Y., Qin Y., Search and classification based language model adaptation, Proceedings of the 8th International Conference on Speech Communication and Technology (INTERSPEECH), pp. 1578-1581, (2008); Solsona R.A., Fosler-Lussier E., Kuo K.H.J., Potamianos A., Zitouni I., Adaptive language models for spoken dialogue systems, Proceedings of the International Conference on Audio Speech and Signal Processing (ICASSP), 1, pp. 37-40, (2002); Strakova J., Pecina P., Czech information retrieval with syntax-based language models, Proceedings of the 7th International Conference on Language Resources and Evaluation (LREC), pp. 1359-1362, (2010); Tam Y.C., Schultz T., Unsupervised language model adaptation using latent semantic marginals, Proceedings of the 8th International Conference on Speech Communication and Technology (INTERSPEECH), pp. 2206-2209, (2006); Tur G., Stolcke A., Unsupervised language model adaptation for meeting recognition, Proceedings of the International Conference on Audio Speech and Signal Processing (ICASSP), 4, pp. 173-176, (2007); Ueberla J., Analyzing and Improving Statistical Language Models for Speech Recognition, (1994); Visweswariah K., Printz H., Language models conditioned on dialog state, Proceedings of the 7th European Conference on Speech Communication and Technology (EUROSPEECH), pp. 251-254, (2001); Wessel F., Baader A., Robust dialogue-state dependent language modeling using leaving-one-out, Proceedings of the International Conference on Audio Speech and Signal Processing (ICASSP), pp. 41-744, (1999); Yamamoto H., Hanazawa K., Miki K., Shinoda K., Dynamic language model adaptation using keyword category classification, Proceedings of the 10th International Conference on Speech Communication and Technology (INTERSPEECH), pp. 2426-2429, (2010)","J.M. Lucas-Cuesta; Speech Technology Group, Universidad Politécnica de Madrid, 28040 Madrid, Avenida Complutense 30, Spain; email: juanmak@die.upm.es","","","","","","","","09574174","","ESAPE","","English","Expert Sys Appl","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-84870250513"
"Lutfi S.L.; Fernandez-Martinez F.; Casanova-Garcia A.; Lopez-Lebon L.; Montero J.M.","Lutfi, Syaheerah Lebai (27567802400); Fernandez-Martinez, Fernando (6602973640); Casanova-Garcia, Andres (55588425100); Lopez-Lebon, Lorena (55588306100); Montero, Juan Manuel (55960772400)","27567802400; 6602973640; 55588425100; 55588306100; 55960772400","Assessing user bias in affect detection within context-based spoken dialog systems","2012","Proceedings - 2012 ASE/IEEE International Conference on Privacy, Security, Risk and Trust and 2012 ASE/IEEE International Conference on Social Computing, SocialCom/PASSAT 2012","","","6406341","893","898","5","0","10.1109/SocialCom-PASSAT.2012.112","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84873644156&doi=10.1109%2fSocialCom-PASSAT.2012.112&partnerID=40&md5=556deefca62a21b222cc73e235609b0c","Speech Technology Group, Universidad Politécnica de Madrid, Madrid, Spain; School of Computer Sciences, University Science of Malaysia, Penang, Malaysia","Lutfi S.L., Speech Technology Group, Universidad Politécnica de Madrid, Madrid, Spain, School of Computer Sciences, University Science of Malaysia, Penang, Malaysia; Fernandez-Martinez F., Speech Technology Group, Universidad Politécnica de Madrid, Madrid, Spain; Casanova-Garcia A., Speech Technology Group, Universidad Politécnica de Madrid, Madrid, Spain; Lopez-Lebon L., Speech Technology Group, Universidad Politécnica de Madrid, Madrid, Spain; Montero J.M., Speech Technology Group, Universidad Politécnica de Madrid, Madrid, Spain","This paper presents an empirical evidence of user bias within a laboratory-oriented evaluation of a Spoken Dialog System. Specifically, we addressed user bias in their satisfaction judgements. We question the reliability of this data for modeling user emotion, focusing on contentment and frustration in a spoken dialog system. This bias is detected through machine learning experiments that were conducted on two datasets, users and annotators, which were then compared in order to assess the reliability of these datasets. The target used was the satisfaction rating and the predictors were conversational/dialog features. Our results indicated that standard classifiers were significantly more successful in discriminating frustration and contentment and the intensities of these emotions (reflected by user satisfaction ratings) from annotator data than from user data. Indirectly, the results showed that conversational features are reliable predictors of the two abovementioned emotions. © 2012 IEEE.","Affect detection; Contentment; conversational features; Frustration; Spoken Conversational Agent","Affect detection; Contentment; Conversational agents; conversational features; Frustration; Human computer interaction","","","","","","","Ai H., Raux A., Bohus D., Eskenazi M., Litman D., Comparing spoken dialog corpora collected with recruited subjects versus real users, 8th SIGdial Workshop on Discourse and Dialogue, (2007); Bailey J.E., Pearson S.W., Development of a tool for measuring and analyzing computer user satisfaction, Management Science, 24, pp. 530-545, (1983); Callejas Z., Lopez-Cozar R., Influence of contextual information in emotion annotation for spoken dialogue systems, Speech Commun., 50, 5, pp. 416-433, (2008); Callejas Z., Lopez-Cozar R., Relations between de-facto criteria in the evaluation of a spoken dialogue system, Speech Commun., 50, pp. 646-665, (2008); Callejas Z., Lopez-Cozar R., On the use of kappa coefficients to measure the reliability of the annotation of nonacted emotions, Proceedings of the 4th IEEE Tutorial and Research Workshop on Perception and Interactive Technologies for Speech-Based Systems: Perception in Multimodal Dialogue Systems, PIT '08, pp. 221-232, (2008); Cassell J., Sistine Gap: Essays in the History and Philosophy of Artificial Life, Chapter Body Language: Lessons from the Near-Human, (2007); Cowie R., Douglas-Cowie E., Martin J.-C., Devillers L., A Blueprint for An Affectively Competent Agent: Cross-fertilization between Emotion Psychology, Affective Neuroscience and Affective Computing, Chapter the Esential Role of Human Databases for Learning in and Validation of Affectively Competent Agents, pp. 151-165, (2010); Payr K., Trappl R., Agent Culture: Human-Agent Interaction in A Multicultural World, pp. 45-71, (2004); D'Mello S.K., Craig S.D., Witherspoon A., McDaniel B., Graesser A., Automatic detection of learner's affect from conversational cues, User Model User-Adap. Inter, 18, pp. 45-80, (2008); Doll W.J., Torkzadeh G., The measurement of end-user computing satisfaction, MIS Quarterly, 12, pp. 259-274, (1988); Dybkjaer L., Bernsen N.O., Minker W., Evaluation and usability of multimodal spoken language dialogue systems, Speech Commun., 43, pp. 33-54, (2004); Edlund J., Gustafson J., Heldner M., Hjalmarsson A., Towards human-like spoken dialogue systems, Speech Commun., 50, 8-9, pp. 630-645, (2008); Ekman P., Friesen W., The Facial Action Coding System: A Technique for the Measurement of Facial Movement, (1978); Fernandez-Martinez F., Blazquez J., Ferreiros J., Barra-Chicote R., MacIas-Guarasa J., Lucas-Cuesta J.M., Evaluation of a spoken dialog system for controlling a hifi audio system, Proceedings of the IEEE Workshop on Spoken Language Technology, (2008); Fernandez-Martinez F., Ferreiros J., Lucas-Cuesta J.M., Echeverry J.D., San-Segundo R., Cordoba R., Flexible, robust and dynamic dialogue modeling with a speech dialogue interface for controlling a hi-fi audio system, Proceedings of the IEEE Workshop on Database and Expert Systems Applications (DEXA 2010); Fernandez-Martinez F., Lucas-Cuesta J.M., Chicote R.B., Ferreiros J., MacIas-Guarasa J., HIFI-AV: An audio-visual corpus for spoken language human-machine dialogue research in Spanish, Proceedings of the Seventh Conference on International Language Resources and Evaluation (LREC'10), (2010); Forbes-Riley K., Litman D., Designing and evaluating a wizarded uncertainty-adaptive spoken dialogue tutoring system, Comput. Speech Lang., 25, 1, pp. 105-126, (2011); Forbes-Riley K., Litman D., Benefits and challenges of realtime uncertainty detection and adaptation in a spoken dialogue computer tutor, Speech Commun., 53, 9-10, pp. 1115-1136, (2011); Gelbrich K., Beyond just being dissatisfied: How angry and helpless customers react to failures when using self-service technologies, Schmalenbach Business Review, 61, pp. 40-59, (2009); Grothendieck J., Gorin A., Borges N., Social correlates of turn-taking behavior, Proceedings of the 2009 IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP '09, pp. 4745-4748, (2009); Kernbach S., Schutte N.S., The impact of service provider emotional intelligence on customer satisfaction, Journal of Services Marketing, 19, 7, pp. 438-444, (2005); Laukka P., Neiberg D., Forsell M., Karlsson I., Elenius K., Expression of affect in spontaneous speech: Acoustic correlates and automatic detection of irritation and resignation, Comput. Speech Lang., 25, 1, pp. 84-104, (2011); Locke E.A., The Nature and Causes of Job Satisfaction, (1976); Lopez-Cozar R., Silovsky J., Griol D., New technique for recognition of user emotional states in spoken dialog systems, Proceedings of the 11th Anual Meeting of the Special Interest Group on Discourse and Dialog (SIGDIAL, pp. 281-288, (2010); Mairesse F., Walker M.A., Mehl M.R., Moore R.K., Using linguistic cues for the automatic recognition of personality in conversation and text, Journal of Artificial Intelligence Research, 30, pp. 457-500, (2007); Moller S., Quality of Telephone-Based Spoken Dialogue Systems, (2005); Picard R.W., Proceedings of HCI International (The 8th International Conference on Human-Computer Interaction) on Human-Computer Interaction: Ergonomics and User Interfaces, 1, pp. 829-833, (1999); Podsakoff P.M., MacKenzie S.B., Podsakoff N.P., Common method biases in behavioral research: A critical review of the literature and recommended remedies, Journal of Applied Psychology, 88, pp. 879-903, (2003); Rani P., Sarkar N., Adams J., Anxiety-based affective communication for implicit human-machine interaction, Advanced Engineering Informatics, 21, 3, pp. 323-334, (2007); Reeves B., Nass C., The Media Equation: How People Treat Computers, Television and New Media Like Real People and Places, (1996); Robison J., Rowe J., McQuiggan S., Lester J., Predicting user psychological characteristics from interactions with empathetic virtual agents, Proceedings of the 9th International Conference on Intelligent Virtual Agents, IVA '09, pp. 330-336, (2009); Saris W.E., Krosnick J.E., Shaeffer E.M., Comparing Questions with Agree/disagree Response Options to Questions with Construct-specific Response Options, (2005); Shen L., Wang M., Shen R., Affective e-learning: Using emotional data to improve learning in pervasive learning environment, Educational Technology and Society, 12, 2, pp. 176-189, (2009); Sung J.-Y., Guo L., Grinter R.E., Christensen H.I., My Roomba is Rambo: Intimate Home Appliances, UbiComp, (2007); Tcherkassof A., Bollon T., Dubois M., Pansu P., Adam J.-M., Facial expressions of emotions: A methodological contribution to the study of spontaneous and dynamic emotional faces, Journal of Social Psychology, 37, pp. 1325-1345, (2007); Witten I.H., Frank E., Data Mining: Practical Machine Learning Tools and Techniques, (2005); Yildirim S., Narayanan S., Potamianos A., Detecting emotional state of a child in a conversational computer game, Comput. Speech Lang., 25, 1, pp. 29-44, (2011)","S.L. Lutfi; Speech Technology Group, Universidad Politécnica de Madrid, Madrid, Spain; email: syaheerah@die.upm.es","","","Academy of Science and Engineering (ASE); IEEE Computer Society","2012 ASE/IEEE International Conference on Social Computing, SocialCom 2012 and the 2012 ASE/IEEE International Conference on Privacy, Security, Risk and Trust, PASSAT 2012","3 September 2012 through 5 September 2012","Amsterdam","95460","","978-076954848-7","","","English","Proc. - ASE/IEEE Int. Conf. Priv., Secur., Risk Trust ASE/IEEE Int. Conf. Soc. Comput., SocialCom/PASSAT","Conference paper","Final","All Open Access; Green Open Access","Scopus","2-s2.0-84873644156"
"Luna-Jimenez C.; Lutfi S.L.; Fernandez-Martinez F.; Tick A.","Luna-Jimenez, Cristina (57210646540); Lutfi, Syaheerah Lebai (27567802400); Fernandez-Martinez, Fernando (6602973640); Tick, Andrea (23669171700)","57210646540; 27567802400; 6602973640; 23669171700","Measuring Trust at Zero-Acquaintance: A Cross-cultural Study between Malaysians and Hungarians","2022","INES 2022 - 26th IEEE International Conference on Intelligent Engineering Systems 2022, Proceedings","","","","267","272","5","1","10.1109/INES56734.2022.9922615","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141878248&doi=10.1109%2fINES56734.2022.9922615&partnerID=40&md5=3ff1a6617ae985ad8aad7ed005513d21","Inf. Processing and Telecom. Center, Universidad Politécnica de Madrid, Madrid, Spain; School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, Malaysia; University of Óbuda, Faculty of Business and Management, Obuda, Hungary","Luna-Jimenez C., Inf. Processing and Telecom. Center, Universidad Politécnica de Madrid, Madrid, Spain; Lutfi S.L., School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, Malaysia; Fernandez-Martinez F., Inf. Processing and Telecom. Center, Universidad Politécnica de Madrid, Madrid, Spain; Tick A., University of Óbuda, Faculty of Business and Management, Obuda, Hungary","Trust is critical in communication, especially in a cross-cultural setting. However, there is still not much open source annotated data for trust studies, which may be due to the lack of a suitable annotation platform or a reliable method for measuring trust. This article aims to fill this gap by presenting a pilot study with our annotation platform. Specifically, we asked participants to rate perceived trustworthiness on short emotional videos from the RAVDESS dataset at zero-Acquaintance. The results confirm two key findings that should be considered when rating emotional videos: The emotion and the order in which the videos are displayed. After auditing our annotated data, we have also identified two types of bias that might skew our model's predictions: A task bias and a cultural bias. To understand their potential impact when building trustworthiness prediction models, we analyzed the data statistically and developed pilot trustworthiness' regressors models. As for the cross-cultural statistical analysis, Spearman's correlation matrices show that Malaysian and Hungarian cultures attach similar importance to some traits when evaluating perceived trustworthiness, e.g., authenticity and attractiveness. However, they differ in others (such as expressiveness or friendliness). Hungarians place more importance on friendliness, while Malaysians rely more on expressiveness. Regarding the models, the top regressor achieved a 0.62 correlation value between predictions and ground truths. This fact supports the adequacy of our methodology to annotate videos in terms of trustworthiness.  © 2022 IEEE.","affective computing; annotation platform; cross-cultural; human-computer interaction; trust recognition; trustworthiness","Behavioral research; Human computer interaction; Trusted computing; Affective Computing; Annotation platform; Cross-cultural; Cross-cultural study; Cultural settings; Hungarians; Malaysians; Open-source; Trust recognition; Trustworthiness; Forecasting","","","","","AMIC-PoC, (PDC2021-120846-C42); European Commission, EC; Universiti Sains Malaysia, USM, (304/PKOMP/6315137); Ministerio de Ciencia e Innovación, MICINN, (MCIN/AEI/10.13039/501100011033, PID2020-118112RB-C21, PID2020-118112RBC22)","In our future experiments, we will extend the annotation process to other datasets with demographically more diverse subjects and annotators. Future forms will also include prior ’practice’ videos to allow respondents to get familiar with the annotation process. Also, the order and emotions displayed per person will be randomized to avoid bias. Finally, we will use the final annotations to train deep machine learning models to predict perceived trustworthiness. ACKNOWLEDGMENTS The work leading to these results was supported by University Sains Malaysia from the grant no. 304/PKOMP/6315137 and the Spanish Ministry of Science and Innovation through the projects GOMINOLA (PID2020-118112RB-C21 and PID2020-118112RBC22, funded by MCIN/AEI/10.13039/501100011033), and AMIC-PoC (PDC2021-120846-C42, funded by MCIN/AEI/10.13039/501100011033 and by the European Union “NextGenerationEU/PRTR”).","Brennan J., Recognition trust, Philosophical Studies, 178, 11, pp. 3799-3818; Kumar A., Capraro V., Perc M., The evolution of trust and trustworthiness, J. R. Soc. Interface, 17, 169, (2020); Rousseau D.M., Sitkin S.B., Burt R.S., Camerer C., Not so Different after All: A Cross-Discipline View of Trust, Academy of Management Review, 23, 3, pp. 393-404, (1998); Bickmore T.W., Picard R.W., Establishing and Maintaining Long-Term Human-Computer Relationships, ACM Trans. Comput.-Hum. Interact, 12, 2, pp. 293-327, (2005); Rheu M., Shin J.Y., Peng W., Huh-Yoo J., Systematic Review: Trust-Building Factors and Implications for Conversational Agent Design, International Journal of Human-Computer Interaction, 37, 1, pp. 81-96; De Visser E.J., Pak R., Shaw T.H., From ?automation? to ?autonomy?: The importance of trust repair in human-machine interaction, Ergonomics, 61, 10, pp. 1409-1427, (2018); Braga D.D.S., Niemann M., Hellingrath B., Neto F.B.D.L., Survey on Computational Trust and Reputation Models, ACM Comput. Surv, 51, 5101, pp. 1-40, (2018); Li J., Mao B., Liang Z., Zhang Z., Lin Q., Yao X., Trust and trustworthiness: What they are and how to achieve them, Kassel, Germany; Uslaner E.M., The Oxford Handbook of Social and Political Trust, (2017); Bauer P.C., Freitag M., Measuring Trust, (2017); Berg J., Dickhaut J., McCabe K., Trust, Reciprocity, and Social History, Games and Economic Behavior, 10, 1, pp. 122-142, (1995); Dang Q.-V., Ignat C.-L., Computational Trust Model for Repeated Trust Games, Tianjin, China, pp. 34-41, (2016); Lee J.J., Knox B., Baumann J., Breazeal C., Desteno D., Computationally Modeling Interpersonal Trust, Frontiers in Psychology, 4, (2013); Lucas G., Stratou G., Lieblich S., Gratch J., Trust Me: Multimodal Signals of Trustworthiness, Tokyo, Japan, pp. 5-12, (2016); Caulfield F., Ewing L., Bank S., Rhodes G., Judging trustworthiness from faces: Emotion cues modulate trustworthiness judgments in young children, British Journal of Psychology (London, England 2016, 107, 3, pp. 503-518, (1953); Kraus M., Wagner N., Callejas Z., Minker W., The role of trust in proactive conversational assistants, IEEE Access, 9, 2021, pp. 112821-112836; Cassell J., Sullivan J., Prevost S., Churchill E.F., Embodied Conversational Agents, (2000); Gupta V., Agarwal M., Arora M., Chakraborty T., Singh R., Vatsa M., Bag-of-Lies: A Multimodal Dataset for Deception Detection 2019, IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW, 2019, pp. 83-90; Speth J., Vance N., Czajka A., Bowyer K.W., Wright D., Flynn P., Deception Detection and Remote Physiological Monitoring: A Dataset and Baseline Experimental Results, 2021, pp. 1-8; Soldner F., Perez-Rosas V., Mihalcea R., Box of lies: Multimodal deception detection in dialogues, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, 1, pp. 1768-1777; Gauder L., Riera P., Pepino L., Silvina B., Vidal J., Luciana F., Gravano A., Trust-UBA: A Corpus for the Study of the Manifestation of Trust in Speech, (2020); Livingstone S.R., Russo F.A., The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS), PLoS ONE, 13, no 5, (2018); Abdulmohsin H.A., Wahab B., Abdul H., Abdul M., Hossen A., A new proposed statistical feature extraction method in speech emotion recognition, Computers & Electrical Engineering, 93; Garcia-Ordas M.T., Alaiz-Moreton H., Benitez-Andrades J.A., Garcia-Rodriguez I., Garcia-Olalla O., Benavides C., Sentiment analysis in non-fixed length audios using a Fully Convolutional Neural Network, Biomedical Signal Processing and Control, 69; Baltrusaitis T., Zadeh A., Lim Y.C., Morency L., Openface 2.0: Facial behavior analysis toolkit 2018 13th, IEEE International Conference on Automatic Face & Gesture Recognition (FG, 2018, pp. 59-66, (2018); Frank E., Hall M.A., Witten I.H., The WEKA Workbench. Online Appendix for ""data Mining: Practical Machine Learning Tools and Techniques"", Morgan Kaufmann, Fourth Edition, 2016, (2016); Eyben F., Scherer K., Schuller B., Sundberg J., Andre E., Busso C., Devillers L., Epps J., Laukka P., Narayanan S., Truong K.P., The Geneva Minimalistic Acoustic Parameter Set (GeMAPS) for Voice Research and Affective Computing?, IEEE Transactions on Affective Computing, 7, 2, pp. 190-202, (2016); Rezlescu C., Penton T., Walsh V., Et al., Dominant Voices and Attractive Faces: The Contribution of Visual and Auditory Information to Integrated Person Impressions, J Nonverbal Behav, 39, pp. 355-370, (2015); Abend P., Lena P., Markus K.S., Coquerelle M., Grammer K., The sound of female shape: A redundant signal of vocal and facial attractiveness, Evolution and Human Behavior, 36, 3, pp. 174-181, (2015); Strangert E., Gustafson J., What makes a good speaker? subject ratings, acoustic measurements and perceptual evaluations, INTERSPEECH 2008, 9th Annual Conference of the International Speech Communication Association, Brisbane, Australia, September 22-26 2008, pp. 1688-1691; Comission E., Average Rating of Trust by Domain, Sex, Age and Educational Attainment Level, (2015); Ortiz-Ospina E., Roser ""trust M., (2016); Guiso L., Sapienza P., Zingales L., Does Culture Affect Economic Outcomes?, Journal of Economic Perspectives, 20, 2, pp. 23-48, (2006); Fantom N., Serajuddin U., The World Bank?s Classification of Countries by Income, (2016); Zhang J., Zheng L., Zhang S., Xu W., Zheng Y., Vocal characteristics predict infidelity intention and relationship commitment in men but not in women, Personality and Individual Differences, 168","","","Institute of Electrical and Electronics Engineers Inc.","IEEE Control Systems Chapter; IEEE Hungary Section; IEEE Joint Chapter of IES and RAS; IEEE SMC Chapter","26th IEEE International Conference on Intelligent Engineering Systems, INES 2022","12 August 2022 through 15 August 2022","Crete","183801","","978-166549209-6","","","English","INES - IEEE Int. Conf. Intell. Eng. Syst. , Proc.","Conference paper","Final","","Scopus","2-s2.0-85141878248"
"Alsalibi B.; Venkat I.; Subramanian K.G.; Lutfi S.L.; De Wilde P.","Alsalibi, Bisan (56596818100); Venkat, Ibrahim (36338095000); Subramanian, K.G. (7202235940); Lutfi, Syaheerah Lebai (27567802400); De Wilde, Philippe (8275283600)","56596818100; 36338095000; 7202235940; 27567802400; 8275283600","The impact of bio-inspired approaches toward the advancement of face recognition","2015","ACM Computing Surveys","48","1","5","","","","15","10.1145/2791121","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84939779092&doi=10.1145%2f2791121&partnerID=40&md5=caa08ce48a1233853b62e1766736aedb","School of Computer Sciences, Universiti Sains Malaysia, Penang, 11800, Malaysia; University of Kent, United Kingdom","Alsalibi B., School of Computer Sciences, Universiti Sains Malaysia, Penang, 11800, Malaysia; Venkat I., School of Computer Sciences, Universiti Sains Malaysia, Penang, 11800, Malaysia; Subramanian K.G., School of Computer Sciences, Universiti Sains Malaysia, Penang, 11800, Malaysia; Lutfi S.L., School of Computer Sciences, Universiti Sains Malaysia, Penang, 11800, Malaysia; De Wilde P., University of Kent, United Kingdom","An increased number of bio-inspired face recognition systems have emerged in recent decades owing to their intelligent problem-solving ability, flexibility, scalability, and adaptive nature. Hence, this survey aims to present a detailed overview of bio-inspired approaches pertaining to the advancement of face recognition. Based on a well-classified taxonomy, relevant bio-inspired techniques and their merits and demerits in countering potential problems vital to face recognition are analyzed. A synthesis of various approaches in terms of key governing principles and their associated performance analysis are systematically portrayed. Finally, some intuitive future directions are suggested on how bio-inspired approaches can contribute to the advancement of face biometrics in the years to come. © 2015 ACM 0360-0300/2015/08-ART5 $15.00.","Artificial neural networks; Bio-inspired computing; Evolutionary algorithms; Face recognition; Feature selection; Optimization; Swarm intelligence","Artificial intelligence; Biometrics; Evolutionary algorithms; Feature extraction; Neural networks; Optimization; Problem solving; Bio-inspired approach; Bio-inspired computing; Bio-inspired techniques; Face recognition systems; Intelligent problems; Performance analysis; Potential problems; Swarm Intelligence; Face recognition","","","","","","","AT&T laboratories Cambridge, ORL Face Database, (1992); Center for biological and computational learning, MIT CBCL Face Database, (1996); The university of Sheffield, The Umist Face Database, (1998); Abate A., Nappi M., Riccio D., Sabatino G., 2D and 3D face recognition: A survey, Pattern Recognition Letters, 28, 14, pp. 1885-1906, (2007); Abdel-kader R., Ramadan R., Rizk R., Rotation invariant face recognition based on hybrid LPT/DCT features, International Journal of Intelligent Systems and Technologies, 3, (2008); Abdulameer M.H., Abdullah S.N.H.S., Othman Z.A., Face recognition based on opposition particle swarm optimization and support vector machine, Proceedings of the 2013 IEEE International Conference on Signal and Image Processing Applications (ICSIPA'13), pp. 417-424, (2013); Ackley D., Hinton G., Sejnowski T., A learning algorithm for Boltzmann machines, Cognitive Science, 9, 1, pp. 147-169, (1985); Aly S., Shimada A., Tsuruta N., Taniguchi R.I., Robust face recognition using multiple self-organized gabor features and local similarity matching, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR'10), pp. 2909-2912, (2010); Aly S., Tsuruta N., Taniguchi R.-I., Face recognition under varying illumination using Mahalanobis self-organizing map, Artificial Life and Robotics, 13, 1, pp. 298-301, (2008); Azzawi A.A.G., Al-Saedi M.A.H., Face recognition based on mixed between selected feature by multiwavelet and particle swarm optimization, Proceedings of the 2010 Developments in E-systems Engineering (DESE'10), pp. 199-204, (2010); Balasubramanian M., Palanivel S., Ramalingam V., Real time face and mouth recognition using radial basis function neural networks, Expert Systems with Applications, 36, 3, pp. 6879-6888, (2009); Belhumeur P.N., Hespanha J.P., Kriegman D.J., Eigenfaces vs. Fisherfaces: Recognition using class specific linear projection, IEEE Transactions on Pattern Analysis and Machine Intelligence, 19, 7, pp. 711-720, (1997); Bhati R., Face recognition system using multi layer feed forward neural networks and principal component analysis with variable learning rate, Proceedings of the 2010 IEEE International Conference on Communication Control and Computing Technologies (ICCCCT'10), pp. 719-724, (2010); Bowyer K., Chang K., Flynn P., A survey of approaches and challenges in 3D and multi-modal 3D + 2D face recognition, Computer Vision and Image Understanding, 101, 1, pp. 1-15, (2006); Bozorgtabar B., Azami H., Noorian F., Illumination invariant face recognition using fuzzy LDA and FFNN, Journal of Signal and Information Processing, 3, pp. 45-50, (2012); Bozorgtabar B., Noorian F., Rad G.A.R., Comparison of different PCA based face recognition algorithms using genetic programming, 2010 5th International Symposium on Telecommunications (IST'10), pp. 801-805, (2010); Bozorgtabar B., Noorian F., Rad G.A.R., A genetic programming approach to face recognition, 2011 IEEE GCC Conference and Exhibition (GCC'11), pp. 194-197, (2011); Breiman L., Breiman L., Bagging predictors, Machine Learning. Kluwer Academic Publishers, pp. 123-140, (1996); Brostoff J., Roth D., Roitt I., Immunology, (1998); Bruce V., Hancock P.J.B., Burton A.M., Human face perception and identification, Face Recognition. NATO ASI Series, 163, pp. 51-72, (1998); Chacon M., Perea P.R., Performance analysis of the feedforward and SOM neural networks in the face recognition problem, Proceedings of the IEEE Symposium on Computational Intelligence in Image and Signal Processing, 2007 (CIISP'07), pp. 313-318, (2007); Chakrabarty A., Jain H., Chatterjee A., Volterra kernel based face recognition using artificial bee colony optimization, Engineering Applications of Artificial Intelligence, 26, 3, pp. 1107-1114, (2013); Chakraborti T., Chatterjee A., A novel binary adaptive weight {GSA} based feature selection for face recognition using local gradient patterns, modified census transform, and local binary patterns, Engineering Applications of Artificial Intelligence, 33, pp. 80-90, (2014); Chand C.R.V., Face and gender recognition using genetic algorithm and hopfield neural network, Global Journal of Computer Science and Technology, 10, 1, pp. 2-3, (2010); Chellappa R., Sinha P., Phillips P.J., Face recognition by computers and humans, Computer, 43, 2, pp. 46-55, (2010); Chen J., Mahfouf M., Artificial immune systems as a bio-inspired optimization technique and its engineering applications, Handbook of Research on Artificial Immune Systems and Natural Computing: Applying Complex Adaptive Technologies, pp. 22-48, (2009); Chen Q., Kotani K., Lee F., Ohmi T., Face recognition using self-organizing maps, self-organizing maps, Self-organizing Maps, (2010); Chen S., Chng E.S., Alkadhimi K., Regularized orthogonal least squares algorithm for constructing radial basis function networks, International Journal on Control, 64, 5, pp. 829-837, (1996); Cheng G., Shi C., Zhu K., Gong K., The application of binary particle swarm algorithm in face recognition, Proceedings of the 2011 7th International Conference on Computational Intelligence and Security (CIS'11), pp. 1229-1233, (2011); Chiachia G., Falcao A.X., Pinto N., Rocha A., Cox D., Learning person-specific representations from faces in the wild, IEEE Transactions on Information Forensics and Security, 9, 12, pp. 2089-2099, (2014); Chiachia G., Falcao A.X., Rocha A., Person-specific face representation for recognition, Proceedings of the 2011 International Joint Conference on Biometrics (IJCB'11), pp. 1-8, (2011); Chien B.-C., Lin J.Y., Hong T.-P., Learning discriminant functions with fuzzy attributes for classification using genetic programming, Expert Systems with Applications, 23, 1, pp. 31-37, (2002); Choi K., Toh K.-A., Byun H., A random network ensemble for face recognition, Advances in Biometrics. Lecture Notes in Computer Science, 5558, pp. 92-101, (2009); Coello Coello C.A., Lamont G.B., Van Veldhuizen D.A., Evolutionary Algorithms for Solving Multi-objective Problems (Genetic and Evolutionary Computation), (2006); Colombo A., Cusano C., Schettini R., UMB-DB: A database of partially occluded 3D faces, Proceedings of the 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), pp. 2113-2119, (2011); Cox D., Pinto N., Beyond simple features: A large-scale feature search approach to unconstrained face recognition, Proceedings of the 2011 IEEE International Conference on Automatic Face Gesture Recognition and Workshops (FG'11), pp. 8-15, (2011); Crdenas M., Melin P., Cruz L., In soft computing for recognition based on biometrics, Studies in Computational Intelligence, 312, pp. 303-315, (2010); Darestani M., Sheikhan M., Khademi M., Face recognition using contourletbased features and hybrid PSO-neural model, Proceedings of the 2013 5th Conference on Information and Knowledge Technology (IKT'13), pp. 1818-1186, (2013); Das S., Abraham A., Konar A., Swarm intelligence algorithms in bioinformatics, Computational Intelligence in Bioinformatics. Studies in Computational Intelligence, 94, pp. 113-147, (2008); Dawkins R., The Selfish Gene, (1976); De Castro L.N., Fundamentals of natural computing: An overview, Physics of Life Reviews, 4, 1, pp. 1-36, (2006); De Castro L.N., Fundamentals of Natural Computing: Basic Concepts, Algorithms, and Applications, (2006); Delorme A., Thorpe S., Face identification using one spike per neuron: Resistance to image degradations, Neural Networks: The Official Journal of the International Neural Network Society, 14, 6-7, pp. 795-803, (2001); Deng Z., Zhang Y., Complex systems modeling using scale-free highlyclustered echo state network, Proceedings of the International Joint Conference on Neural Networks (IJCNN'06), pp. 3128-3135, (2006); Dinesh K., Shakti K., Rai C., Feature selection for face recognition: A memetic algorithmic approach, Journal of Zhejiang University - Science A, 10, 8, pp. 1140-1153, (2009); Dolkar D., Saha B., Optimal face recognition method using ant colony based back propagation network, Proceedings of the 4th International Conference on Computers and Devices for Communication, 2009 (CODEC'09), pp. 1-4, (2009); Dorigo M., Blum C., Ant colony optimization theory: A survey, Theoretical Computer Science, 344, 2-3, pp. 243-278, (2005); Du L., Jia Z., Xue L., Human face recognition based on principal component analysis and particle swarm optimization-bp neural network, Proceedings of the 3rd International Conference on Natural Computation, 2007 (ICNC'07), 3, pp. 287-291, (2007); Eiben A.E., Smith J.E., Introduction to Evolutionary Computing, (2008); Er M.J., Chen W., Wu S., High-speed face recognition based on discrete cosine transform and RBF neural networks, IEEE Transactions on Neural Networks, 16, 3, pp. 679-691, (2005); Esbati H., Shirazi J., Face recognition with PCA and KPCA using elman neural network and SVM, World Academy of Science, Engineering and Technology, pp. 174-178, (2011); Espejo P.G., Ventura S., Herrera F., A survey on the application of genetic programming to classification, Computer Vision and Image Understanding Part C, 40, 2, pp. 121-144, (2010); Fan X., Brijesh. Verma, Face Recognition: A New Feature Selection and Classification Technique, pp. 713-721, (2004); Fogel D.B., Evolutionary Computation: The Fossil Record, (1998); Fraga L.G., Coello Coello C.A., A review of applications of evolutionary algorithms in pattern recognition, Pattern Recognition, Machine Intelligence and Biometrics, pp. 3-28, (2011); Freund Y., Schapire R., A short introduction to boosting, Journal of Japanese Society for Artificial Intelligence, 14, 5, pp. 771-780, (1999); Fu-gang Y., An improved artificial immune algorithm, Proceedings of the 2010 Sixth International Conference on Natural Computation (ICNC'10), 6, pp. 2837-2841, (2010); Gamarra M., Quintero C., Using genetic algorithm feature selection in neural classification systems for image pattern recognition, Ingeniera e Investigacin, 33, pp. 52-58, (2013); Gan J.-Y., Liu F., Face recognition using wavelet packets decomposition and hopfield neural network, Proceedings of the International Conference on Wavelet Analysis and Pattern Recognition, 2009 (ICWAPR'09), pp. 335-339, (2009); Gao W., Cao B., Shan S., Chen X., Zhou D., Zhang X., Zhao D., The CAS-peal large-scale Chinese face database and baseline evaluations, IEEE Transactions on Systems, Man and Cybernetics, Part A: Systems and Humans, 38, 1, pp. 149-161, (2008); Georghiades A., Belhumeur P., Kriegman D., From few to many: Illumination cone models for face recognition under variable lighting and pose, IEEE Transactions on Pattern Analysis and Machine Intelligence, 23, 6, pp. 643-660, (2001); Georghiades A., Belhumeur P., Kriegman D., Fg-net Aging Database, (2010); Gilad-Gutnick S., Yovel G., Sinha P., Recognizing degraded faces: The contribution of configural and featural cues, Perception, 41, pp. 1497-1511, (2012); Graves A., Eck D., Beringer N., Schmidhuber J., Biologically plausible speech recognition with LSTM neural nets, Proceedings of Bio-ADIT, pp. 127-136, (2004); Grgic M., Delac K., Databases, Face Recognition Homepage, (2009); Hafiz F., Shafie A.A., Encoding of facial images into illumination-invariant spike trains, Proceedings of the 2012 International Conference on Computer and Communication Engineering (ICCCE), pp. 132-137, (2012); Harand M., Ahmadabadi M.N., Araabi B., Lucas C., Feature selection using genetic algorithm and it's application to face recognition, Proceedings of the 2004 IEEE Conference on Cybernetics and Intelligent Systems, 2, pp. 1368-1373, (2004); He H., Garcia E., Learning from imbalanced data, IEEE Transactions on Knowledge and Data Engineering, 21, 9, pp. 1263-1284, (2009); Ho T.K., Hull J.J., Srihari S.N., Decision combination in multiple classifier systems, IEEE Transactions on Pattern Analysis and Machine Intelligence, 16, 1, pp. 66-75, (1994); Holland J., Genetic algorithms and the optimal allocation of trials, SIAM Journal on Computing, pp. 88-105, (1973); Hopfield J.J., Neural networks and physical systems with emergent collective computational abilities, Proceedings of the National Academy of Sciences of the United States of America, 79, 8, pp. 2554-2558, (1982); Ibrahem H., Nasef M., Emam M., Genetic programming based face recognition, International Journal of Computer Applications, 69, 27, pp. 1-6, (2013); Isaacs A., Ray T., Smith W., A hybrid evolutionary algorithm with simplex local search, Proceedings of the 2007 IEEE Congress on Evolutionary Computation (CEC'07), pp. 1701-1708, (2007); Islam S., Bennamoun M., Owens R.A., Davies R., A review of recent advances in 3D ear- and expression-invariant face biometrics, ACM Computing Surveys, 44, 3, (2012); Jaeger H., The ""Echo State"" approach to analysing and training recurrent neural networks, GMD Report, (2001); Jakhar R., Kaur N., Singh R., Face recognition using bacteria foraging optimization-based selected features, International Journal of Advanced Computer Sciences and Applications, pp. 106-111, (2011); Jerne N.K., Towards a network theory of the immune system, Annals in Immunology (Institute Pasteur), 125, 100, pp. 373-389, (1974); Kanan H.R., Faez K., Hosseinzadeh M., Face recognition system using ant colony optimization-based selected features, Proceedings of the IEEE Symposium on Computational Intelligence in Security and Defense Applications, 2007 (CISDA'07), pp. 57-62, (2007); Karaboga D., Basturk B., A powerful and efficient algorithm for numerical function optimization: Artificial bee colony (ABC) algorithm, Journal of Global Optimization, 39, 3, pp. 459-471, (2007); Karaboga D., Gorkemli B., Ozturk C., Karaboga N., A comprehensive survey: Artificial bee colony (ABC) algorithm and applications, Artificial Intelligence Review, pp. 1-37, (2012); Karungaru S., Fukumi M., Akamatsu N., Face recognition using genetic algorithm based template matching, Proceedings of the IEEE International Symposium on Communications and Information Technology, 2004 (ISCIT'04), 2, pp. 1252-1257, (2004); Katagiri H., Hirasama K., Hu J., Genetic network programming - Application to intelligent agents, Proceedings of the 2000 IEEE International Conference on Systems, Man, and Cybernetics, 5, pp. 3829-3834, (2000); Kato H., Chakraborty G., Ogata N., Chakraborty B., A real-time angle aware face recognition system based on artificial neural network, Proceedings of the 2011 3rd International Conference on Awareness Science and Technology (iCAST'11), pp. 521-526, (2011); Kaur H., Panchal V.K., Kumar R., A novel approach based on nature inspired intelligence for face feature extraction and recognition, Proceedings of the 2013 6th International Conference on Contemporary Computing (IC3'13), pp. 149-153, (2013); Kennedy J., Eberhart R., Particle swarm optimization, Proceedings of the IEEE International Conference on Neural Networks, 4, pp. 1942-1948, (1995); Kim D.-S., Jeon I.-J., Lee S.-Y., Rhee P.-K., Chung D.-J., Embedded face recognition based on fast genetic algorithm for intelligent digital photography, IEEE Transactions on Consumer Electronics, 52, 3, pp. 726-734, (2006); Kishore J.K., Patnaik L., Mani V., Agrawal K., Application of genetic programming for multicategory pattern classification, IEEE Transactions on Evolutionary Computation, 4, 3, pp. 242-258, (2000); Kittler J., Hatef M., Duin R., Matas J., On combining classifiers, IEEE Transactions on Pattern Analysis and Machine Intelligence, 20, 3, pp. 226-239, (1998); Kohonen T., Self-organizing Maps, (1985); Kong S., Heo J., Abidi B., Paik J., Abidi M., Recent advances in visual and infrared face recognition - A review, Computer Vision and Image Understanding, 97, pp. 103-135, (2005); Krzysztof C., Klopotek M., Wierzchon S., Applying the immunological network concept to clustering document collections, Handbook of Research on Artificial Immune Systems and Natural Computing: Applying Complex Adaptive Technologies, pp. 160-179, (2009); Kumar A., Singh M., A comparative analysis of feed-forward and elman neural networks for face recognition using principal component analysis, International Journal of Advanced Research in Computer Engineering and Technology (IJARCET), 1, (2012); Kumar D., Kumar S., Rai C.S., Memetic algorithms for feature selection in face recognition, Proceedings of the 8th International Conference on Hybrid Intelligent Systems, 2008 (HIS'08), pp. 931-934, (2008); Kumar D., Rai C.S., Kumar S., Face recognition using self-organizing map and principal component analysis, Proceedings of the International Conference on Neural Networks and Brain, 2005 (ICNN B'05), 3, pp. 1469-1473, (2005); Kurita T., Pic M., Takahashi T., Recognition and detection of occluded faces by a neural network classifier with recursive data reconstruction, Proceedings of the IEEE Conference on Advanced Video and Signal Based Surveillance, 2003, pp. 53-58, (2003); Lanzarini L., Ronchetti F., Estrebou C., Lens L., Bariviera A.F., Face recognition based on fuzzy probabilistic SOM, 2013 Joint IFSA World Congress and NAFIPS Annual Meeting (IFSA/NAFIPS'13), pp. 310-314, (2013); Lawrence S., Giles C.L., Tsoi A.C., Back A., Face recognition: A convolutional neural-network approach, IEEE Transactions on Neural Networks, 8, 1, pp. 98-113, (1997); Lee Y., Filliben J., Micheals R., Phillips J., Sensitivity analysis for biometric systems: A methodology based on orthogonal experiment designs, Computer Vision and Image Understanding, 117, 5, pp. 532-550, (2013); Lefebvre G., Garcia C., A probabilistic self-organizing map for facial recognition, Proceedings of the 19th International Conference on Pattern Recognition, 2008 (ICPR'08), pp. 1-4, (2008); Levada A., Correa D., Salvadeo D., Saito J., Mascarenhas N., Novel approaches for face recognition: Template-matching using dynamic time warping and LSTM neural network supervised classification, Proceedings of the 15th International Conference on Systems, Signals and Image Processing, 2008 (IWSSIP'08), pp. 241-244, (2008); Li M., Du W., Yuan L., Feature selection of face recognition based on improved chaos genetic algorithm, Proceedings of the 2010 3rd International Symposium on Electronic Commerce and Security (ISECS'10), pp. 74-78, (2010); Li W.-J., Wang C.-J., Xu D.-X., Chen S.-F., Illumination invariant face recognition based on neural network ensemble, 16th IEEE International Conference on Tools with Artificial Intelligence, 2004 (ICTAI'04), pp. 486-490, (2004); Liu N., Wang H., Feature extraction with genetic algorithms based nonlinear principal component analysis for face recognition, Proceedings of the 18th International Conference on Pattern Recognition - Volume 03 (ICPR'06), pp. 461-464, (2006); Loderer M., Pavlovicova J., Optimization of LBP parameters, Proceedings of the 56th International Symposium on ELMAR-2014, pp. 1-4, (2014); Luh G.-C., Face recognition using PCA based immune networks with single training sample per person, Proceedings of the 2011 International Conference on Machine Learning and Cybernetics (ICMLC'11), 4, pp. 1773-1779, (2011); Madane S., Banu W., Srinivasan P., Madane S., Implementation of high speed face recognition based on karhunen loeve transform and fishers discriminant, radial basis function of echo state neural network, International Journal of Soft Computing, 3, 3, pp. 248-253, (2008); Maglogiannis I., Sarimveis H., Kiranoudis C., Chatziioannou A., Oikonomou N., Aidinis V., Radial basis function neural networks classification for the recognition of idiopathic pulmonary fibrosis in microscopic images, IEEE Transactions on Information Technology in Biomedicine, 12, 1, pp. 42-54, (2008); Makhsoos N., Ebrahimpour R., Hajiany A., Face recognition based on neuro-fuzzy system, IJCSNS International Journal of Computer Science and Network Security, 9, 4, pp. 319-326, (2009); Mallipeddi R., Lee M., Ensemble based face recognition using discriminant PCA features, Proceedings of the 2012 IEEE Congress on Evolutionary Computation (CEC'12), pp. 1-7, (2012); Martinez A., Benavente R., The AR Face Database, (1998); Martnez-estudillo A., Hervs-Martnez C., Martnez-Estudillo F., Hybridization of evolutionary algorithms and local search by means of a clustering method, IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics, 36, 3, pp. 534-545, (2005); Masip D., Lapedriza A., Vitria J., Boosted online learning for face recognition, IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics, 39, 2, pp. 530-538, (2009); Meins N., Jirak D., Weber C., Wermter S., Adaboost and hopfield neural networks on different image representations for robust face detection, Proceedings of the 12th International Conference on Hybrid Intelligent Systems (HIS'12), pp. 531-536, (2012); Milare C.R., De Almeida Prado Alves Batista G.E., Andre Carvalho C.-F., A hybrid approach to learn with imbalanced classes using evolutionary algorithms, Logic Journal of the IGPL, 19, 2, pp. 293-303, (2011); Min R., Kose N., Dugelay J.-L., KinectFaceDB: A kinect database for face recognition, IEEE Transactions on Systems, Man, and Cybernetics: Systems, 44, 11, pp. 1534-1548, (2014); Moreno A.B., Sanchez A., GavabDB: A 3D face database, Workshop on Biometrics on the Internet, pp. 77-85, (2004); Muller M., Tremer M., Bodenstein C., Wurtz R., A spiking neural network for situation-independent face recognition, Proceedings of the New Challenges in Neural Computation, pp. 62-69, (2011); Nam G.P., Jun. Miura, Fuzzy-based illumination normalization for face recognition, Proceedings of the 2013 IEEE Workshop on Advanced Robotics and its Social Impacts (ARSO'13), pp. 131-136, (2013); Neshatian K., Zhang M., Dimensionality reduction in face detection: A genetic programming approach, Proceedings of the 24th International Conference on Image and Vision Computing New Zealand, 2009 (IVCNZ'09), pp. 391-396, (2009); Priyanka G., Sinha N., Implementation of binary PSO based face recognition system using image preprocessing, International Association of Computer Science & Information Technology (IACSIT), (2011); Panda R., Naik M.K., Panigrahi B.K., Face recognition using bacterial foraging strategy, Swarm and Evolutionary Computation, 1, 3, pp. 138-146, (2011); Passino K.M., Biomimicry of bacterial foraging for distributed optimization and control, IEEE Control Systems, 22, 3, pp. 52-67, (2002); Patole V.A., Pachghare V.K., Kulkarni P., Self organizing maps to build intrusion detection system, International Journal of Computer Applications, 1, 7, pp. 1-4, (2010); Paugam-Moisy H., Bohte S., Computing with spiking neuron Networks, Handbook of Natural Computing, (2009); Paun G., From cells to computers: Membrane computing a quick overview, DNA Computing. Lecture Notes in Computer Science, 3384, pp. 268-280, (2005); Phillips P.J., Flynn P.J., Scruggs T., Bowyer K.W., Chang J., Hoffman K., Marques J., Min J., Worek W., Overview of the face recognition grand challenge, Proceedings of the 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05), 1, pp. 947-954, (2005); Phillips P.J., Moon H., Rauss P., Rizvi S.A., The FERET evaluation methodology for face-recognition algorithms, Proceedings of the 1997 Conference on Computer Vision and Pattern Recognition (CVPR'97), (1997); Pigeon S., Vandendorpe L., The M2VTS multimodal face database (Release 1.00), Audio- and Video-based Biometric Person Authentication. Lecture Notes in Computer Science, 1206, pp. 403-409, (1997); Pinto N., Stone Z., Zickler T., Cox D., Scaling up biologically-inspired computer vision: A case study in unconstrained face recognition on facebook, 2011 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPRW'11), pp. 35-42, (2011); Pisharady P.K., Saerbeck M., Pose invariant face recognition using neurobiologically inspired features, International Journal of Future Computer and Communication, 2012, pp. 316-320, (2012); Prasad M.S.R.S., Panda S.S., Deepthi G., Anisha V., Face recognition using PCA and feed forward neural networks, International Journal of Computer Science and Telecommunications, 2, 8, pp. 79-82, (2011); Raghavendra R., Dorizzi B., A novel adaptive inertia particle swarm optimization (AIPSO) algorithm for improving multimodal biometric recognition, 2011 International Conference on Hand-based Biometrics (ICHB'11), pp. 1-6, (2011); Ramadan R., Rehab Abdel-Kader, Face recognition using particle swarm optimization-based selected features, International Journal of Signal Processing, Image Processing and Pattern Recognition, 2, pp. 51-66, (2009); Rozenberg G., Bck T., Kok J., Handbook of Natural Computing, (2011); Sagheer A., Improved SOM search algorithm for high-dimensional data with application to face recognition across pose and illumination, Proceedings of the 2010 International Conference of Soft Computing and Pattern Recognition (SoCPaR'10), pp. 247-252, (2010); Salan T., Iftekharuddin K.M., Large pose invariant face recognition using feature-based recurrent neural network, Proceedings of the 2012 International Joint Conference on Neural Networks (IJCNN'12), pp. 1-7, (2012); Savran A., Alyz N., Dibekliolu H., Eliktutan O., Gkberk B., Sankur B., Akarun L., Bosphorus database for 3D face analysis, Biometrics and Identity Management, 5372, pp. 47-56, (2008); Scheenstra A., Ruifrok A., Veltkamp R.C., A survey of 3D face recognition methods, Lecture Notes in Computer Science, pp. 891-899, (2005); Schuessler O., Loyola D., Parallel training of artificial neural networks using multithreaded and multicore CPUs, Adaptive and Natural Computing Algorithms. Lecture Notes in Computer Science, 6593, pp. 70-79, (2011); Sedai S., Rhee P.-K., Bio-inspired adaboost method for efficient face recognition, Frontiers in the Convergence of Bioscience and Information Technologies, 2007 (FBIT'07), pp. 715-718, (2007); Shieh M.-Y., Chiou J.-S., Hu Y.-C., Wang K.-Y., Applications of PCA and SVM-PSO based real-time face recognition system, Mathematical Problems in Engineering, 2014, (2014); Shih P., Liu C., Extracting efficient color features for face recognition using evolutionary computation, Proceedings of the 6th International Conference on Computational Intelligence and Multimedia Applications, pp. 285-290, (2005); Shin J.-H., Smith D., Swiercz W., Staley K., Rickard J.T., Montero J., Kurgan L.A., Cios K.J., Recognition of partially occluded and rotated images with a network of spiking neurons, IEEE Transactions on Neural Networks, 21, 11, pp. 1697-1709, (2010); Sim T., Baker S., Bsat M., The CMU pose, illumination, and expression (PIE) database, Proceedings of the 5th IEEE International Conference on Automatic Face and Gesture Recognition (FGR'02), (2002); Simon D., Evolutionary Optimization Algorithms: Biologically-inspired and Population-based Approaches to Computer Intelligence, (2013); Sinha P., Balas B., Ostrovsky Y., Russel R., Face recognition by humans: Nineteen results all computer vision researchers should know about, Proceedings of the IEEE, 94, 11, pp. 1948-1962, (2006); Palod S.N., Shrivastav S.K., Purohit P.K., Review of genetic algorithm based face recognition, International Journal of Engineering Science and Technology, 3, 2, pp. 1478-1483, (2011); Storn R., Price K., Differential evolution - A simple and efficient heuristic for global optimization over continuous spaces, Journal of Global Optimization, 11, 4, pp. 341-359, (1997); Suga N., Amplitude spectrum representation in the doppler-shifted-CF processing area of the auditory cortex of the mustache bat, Science, 196, pp. 64-67, (1977); Sun Y., Zhou D., Face recognition using DWT compression and PSO-based DCT feature selection, Proceedings of the Third International Conference on Digital Image Processing (ICDIP'11), pp. 800921-800921, (2011); Suzuki K., Artificial Neural Networks - Methodological Advances and Biomedical Applications, (2011); Svozil D., Kvasnicka V., Pospichal J., Introduction to multi-layer feed-forward neural networks, Chemometrics and Intelligent Laboratory Systems, 39, 1, pp. 43-62, (1997); Tan F., Fu X., Zhang Y., Bourgeois A.G., A genetic algorithm-based method for feature subset selection, Soft Computing, 12, 2, pp. 111-120, (2007); Tan X., Chen S., Zhou Z.-H., Zhang F., Recognizing partially occluded, expression variant faces from single training image per person with SOM and soft k-NN ensemble, IEEE Transactions on Neural Networks, 16, 4, pp. 875-886, (2005); Tan X., Chen S., Zhou Z.-H., Zhang F., Recognizing partially occluded, expression variant faces from single training image per person with SOM and soft k-NN ensemble, IEEE Transactions on Neural Networks, 16, 4, pp. 875-886, (2005); Tang Y., Salakhutdinov R., Hinton G., Deep mixtures of factor analysers, Proceedings of the 29th International Conference on Machine Learning, (2012); Thomaz C.E., Giraldi G.A., A new ranking method for principal components analysis and its application to face image analysis, Image Vision Computing, 28, 6, pp. 902-913, (2010); Tran Q.D., Liatsis P., Optimal weight selection in matching score fusion based face recognition, Proceedings of the 2011 18th International Conference on Systems, Signals and Image Processing (IWSSIP'11), pp. 1-4, (2011); Tran Q.D., Liatsis P., Optimal weight selection in matching score fusion based face recognition, Proceedings of the 2011 18th International Conference on Systems, Signals and Image Processing (IWSSIP'11), pp. 1-4, (2011); Tsai P.-W., Khan M.K., Pan J.-S., Liao B.-Y., Interactive artificial bee colony supported passive continuous authentication system, IEEE Systems Journal, 8, 2, pp. 395-405, (2014); Valdez F., Melin P., Parra H., Parallel genetic algorithms for optimization of modular neural networks in pattern recognition, Proceedings of the 2011 International Joint Conference on Neural Networks (IJCNN'11), pp. 314-319, (2011); Valuvanathorn S., Nitsuwat S., Huang M.L., Multi-feature face recognition based on PSO-SVM, Proceedings of the 2012 10th International Conference on ICT and Knowledge Engineering (ICT Knowledge Engineering'12), pp. 140-145, (2012); Venkatesan S., Madane S.R., Face recognition system with genetic algorithm and ant colony optimization, International Journal of Innovation, Management and Technology, 1, 5, pp. 469-471, (2010); Villegas O.O., Quintero M.A., Sanchez V.G., De Jesus Dominguez H., A novel evolutionary face recognition algorithm using particle swarm optimization, Proceedings of the 2009 5th International Conference on Signal-image Technology Internet-based Systems (SITIS'09), pp. 42-47, (2009); Vu S., Caplier A., Biologically inspired processing for lighting robust face recognition, State of the Art in Biometrics, pp. 123-142, (2011); Wang J., Plataniotis K.N., Lu J., Venetsanopoulos A.N., On solving the face recognition problem with one training sample per subject, Pattern Recognition, 39, 9, pp. 1746-1762, (2006); Wang K., Jia H., Face recognition by Hopfield neural network and no-balance binary tree support vector machine, Proceedings of the Second International Conference on Digital Image Processing, (2010); Wang X., Xiao J., PSO-based model predictive control for nonlinear processes, Proceedings of the 1st International Conference on Advances in Natural Computation - Volume Part II (ICNC'05), pp. 196-203, (2005); Wei J., Jian-qi Z., Xiang Z., Face recognition method based on support vector machine and particle swarm optimization, Expert Systems with Applications, 38, 4, pp. 4390-4393, (2011); Wi N.T.N., Kiong L.C., Biological inspired pose-invariant face recognition, World Automation Congress, 2012 (WAC'12), pp. 1-6, (2012); Wong Y.W., Seng K.P., Ang L.-M., Radial basis function neural network with incremental learning for face recognition, IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics, 41, 4, pp. 940-949, (2011); Wysoski S.G., Benuskova L., Kasabov N., Fast and adaptive network of spiking neurons for multi-view visual pattern recognition, Neurocomputing, 71, 13-15, pp. 2563-2575, (2008); Yadav D., Vatsa M., Singh R., Tistarelli M., Bacteria foraging fusion for face recognition across age progression, 2013 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW'13), pp. 173-179, (2013); Yan G., Li C., An effective refinement artificial bee colony optimization algorithm based on chaotic search and application for PID control tuning, Journal of Computational Information Systems, 7, 9, pp. 3309-3316, (2011)","","","Association for Computing Machinery","","","","","","03600300","","ACSUE","","English","ACM Comput Surv","Article","Final","","Scopus","2-s2.0-84939779092"
"Azazi A.; Lutfi S.L.; Venkat I.","Azazi, Amal (56606204300); Lutfi, Syaheerah Lebai (27567802400); Venkat, Ibrahim (36338095000)","56606204300; 27567802400; 36338095000","Analysis and evaluation of SURF descriptors for automatic 3D facial expression recognition using different classifiers","2014","2014 4th World Congress on Information and Communication Technologies, WICT 2014","","","7077296","23","28","5","8","10.1109/WICT.2014.7077296","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84946690687&doi=10.1109%2fWICT.2014.7077296&partnerID=40&md5=05f3cedd3f5f94bd2c578d302021f1f7","School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, Malaysia","Azazi A., School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, Malaysia; Lutfi S.L., School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, Malaysia; Venkat I., School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, Malaysia","Emotion recognition plays a vital role in the field of Human-Computer Interaction (HCI). Among the visual human emotional cues, facial expressions are the most commonly used and understandable cues. Different machine learning techniques have been utilized to solve the expression recognition problem; however, their performance is still disputed. In this paper, we investigate the capability of several classification techniques to discriminate between the six universal facial expressions using Speed Up Robust Features (SURF). The evaluation were conducted using the BU-3DFE database with four classifiers, namely, Support Vector machine (SVM), Neural Network (NN), k-Nearest Neighbors (k-NN), and Naïve Bayes (NB). Experimental results show that the SVM was successful in discriminating between the six universal facial expressions with an overall recognition accuracy of 79.36%, which is significantly better than the nearest accuracy achieved by Naïve Bayes at significance level p < 0.05. © 2014 IEEE.","3D Facial Expression Recognition; Human-computer interaction; k-nearest neighbors; Naïve Bayes; Neural Network; Support Vector machine","Artificial intelligence; Classification (of information); Human computer interaction; Learning systems; Motion compensation; Nearest neighbor search; Neural networks; Sodium; Support vector machines; 3-D facial expression recognition; Analysis and evaluation; Classification technique; Expression recognition; Human computer interaction (HCI); K-nearest neighbors; Machine learning techniques; Universal facial expressions; Face recognition","","","","","","","Segal J., Jaffe J., The Language of Emotional Intelligence, (2008); Bahreini K., Nadolski R., Westera W., Towards multimodal emotion recognition in e-learning environments, Interactive Learning Environments,no. Ahead-of-print, pp. 1-16, (2014); Khosla R., Chu M.-T., Kachouie R., Yamada K., Yoshihiro F., Yamaguchi T., Interactive multimodal social robot for improving quality of care of elderly in australian nursing homes, Proceedings of the 20th ACM International Conference on Multimedia. ACM, pp. 1173-1176, (2012); Kolli A., Fasih A., Al Machot F., Kyamakya K., Nonintrusive car driver's emotion recognition using thermal camera, Joint 3rd Int'l Workshop on Nonlinear Dynamics and Synchronization (INDS) & 16th Int'l Symposium on Theoretical Electrical Engineering (ISTET). IEEE, pp. 1-5, (2011); Puccinelli N.M., Motyka S., Grewal D., Can you trust a customer's expression insights into nonverbal communication in the retail context, Psychology & Marketing, 27, 10, pp. 964-988, (2010); Yang J., Honavar V., Feature subset selection using a genetic algorithm, Feature Extraction, Construction and Selection, pp. 117-136, (1998); Azazi A., Lutfi S.L., Venkat I., Identifying universal facial emotion markers for automatic 3D facial expression recognition, International Conference on Computer & Information Sciences (ICCOINS2014), (2014); Mpiperis I., Malassiotis S., Strintzis M.G., Bilinear models for 3D face and facial expression recognition, IEEE Transactions on Information Forensics and Security, 3, 3, pp. 498-511, (2008); Gong B., Wang Y., Liu J., Tang X., Automatic facial expression recognition on a single 3D face by exploring shape deformation, Proceedings of the 17th ACM International Conference on Multimedia. ACM, pp. 569-572, (2009); Lemaire P., Ardabilian M., Chen L., Daoudi M., Fully automatic 3D facial expression recognition using differential mean curvature maps and histograms of oriented gradients, 10th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG). IEEE, pp. 1-7, (2013); Zhao X., Huang D., Dellandrea E., Chen L., Automatic 3D facial expression recognition based on a bayesian belief net and a statistical facial feature model, 20th International Conference on Pattern Recognition (ICPR). IEEE, pp. 3724-3727, (2010); Lemaire P., Ben Amor B., Ardabilian M., Chen L., Daoudi M., Fully automatic 3D facial expression recognition using a region-based approach, Proceedings of the 2011 Joint ACM Workshop on Human Gesture and Behavior Understanding. ACM, 2011, pp. 53-58; Berretti S., Amor B.B., Daoudi M., Del Bimbo A., 3D facial expression recognition using sift descriptors of automatically detected keypoints, The Visual Computer, 27, 11, pp. 1021-1036, (2011); Tekguc U., Soyel H., Demirel H., Feature selection for person-independent 3D facial expression recognition using NSGA-II, 24th International Symposium on Computer and Information Sciences (ISCIS). IEEE, pp. 35-38, (2009); Soyel H., Tekguc U., Demirel H., Application of NSGAII to feature selection for facial expression recognition, Computers & Electrical Engineering, 37, 6, pp. 1232-1240, (2011); Rabiu H., Saripan M.I., Mashohor S., Marhaban M.H., 3D facial expression recognition using maximum relevance minimum redundancy geometrical features, EURASIP Journal on Advances in Signal Processing, 2012, 1, pp. 1-8, (2012); Wang J., Yin L., Wei X., Sun Y., 3D facial expression recognition based on primitive surface feature distribution, IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2, pp. 1399-1406, (2006); Bartlett M.S., Littlewort G., Frank M., Lainscsek C., Fasel I., Movellan J., Recognizing facial expression: Machine learning and application to spontaneous behavior, IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2, pp. 568-573, (2005); Hupont I., Baldassarri S., Del Hoyo R., Cerezo E., Effective emotional classification combining facial classifiers and user assessment, Articulated Motion and Deformable Objects, pp. 431-440, (2008); Khan R.A., Meyer A., Konik H., Bouakaz S., Framework for reliable, real-time facial expression recognition for low resolution images, Pattern Recognition Letters, 34, 10, pp. 1159-1168, (2013); Gu X.D., Yau S.-T., Computational conformal geometry, Intl Pr of Boston Inc, 3, (2008); Uricar M., Franc V., Hlavac V., Detector of facial landmarks learned by the structured output svm, Proceedings of International Conference on Computer Vision Theory and Applications, 1, pp. 547-556, (2012); Vapnik V.N., The Nature of Statistical Learning Theory, (1995); Wasserman P.D., Advanced Methods in Neural Computing, (1993); Fix E., Hodges J.L., Discriminatory analysisnonparametric discrimination: Consistency properties, DTIC Document, Tech. Rep., (1951); Langley P., Iba W., Thompson K., An analysis of bayesian classifiers, AAAI, 90, pp. 223-228, (1992); Yin L., Wei X., Sun Y., Wang J., Rosato M.J., A 3D facial expression database for facial behavior research, 7th International Conference on Automatic Face and Gesture Recognition. IEEE, pp. 211-216, (2006); Martinez A., Du S., A model of the perception of facial expressions of emotion by humans: Research overview and perspectives, The Journal of Machine Learning Research, 13, 1, pp. 1589-1608, (2012)","","","Institute of Electrical and Electronics Engineers Inc.","","2014 4th World Congress on Information and Communication Technologies, WICT 2014","8 December 2014 through 11 December 2014","Melaka","111785","","978-147998115-1","","","English","Congr. Inf. Commun. Technol., WICT","Conference paper","Final","","Scopus","2-s2.0-84946690687"
"Lebai Lutfi S.; Ferńandez-Martínez F.; Lorenzo-Trueba J.; Barra-Chicote R.; Montero J.M.","Lebai Lutfi, Syaheerah (27567802400); Ferńandez-Martínez, Fernando (6602973640); Lorenzo-Trueba, Jaime (36986671800); Barra-Chicote, Roberto (27567444800); Montero, Juan Manuel (55960772400)","27567802400; 6602973640; 36986671800; 27567444800; 55960772400","NEMOHIFI: An affective HiFi agent","2013","ICMI 2013 - Proceedings of the 2013 ACM International Conference on Multimodal Interaction","","","","319","320","1","0","10.1145/2522848.2531755","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892563635&doi=10.1145%2f2522848.2531755&partnerID=40&md5=afd7ca6cbe28f1dba09961ada88f3832","School of Computer Sciences, University Sains Malaysia, 11800 Penang, Malaysia; Departamento de Teoría de la Señal Y Comunicaciones, University Carlos III de Madrid, 28911 Madrid, Spain; Grupo Technología del Habla, Universidad Politécnica de Madrid, 28040 Madrid, Spain","Lebai Lutfi S., School of Computer Sciences, University Sains Malaysia, 11800 Penang, Malaysia; Ferńandez-Martínez F., Departamento de Teoría de la Señal Y Comunicaciones, University Carlos III de Madrid, 28911 Madrid, Spain; Lorenzo-Trueba J., Grupo Technología del Habla, Universidad Politécnica de Madrid, 28040 Madrid, Spain; Barra-Chicote R., Grupo Technología del Habla, Universidad Politécnica de Madrid, 28040 Madrid, Spain; Montero J.M., Grupo Technología del Habla, Universidad Politécnica de Madrid, 28040 Madrid, Spain","This demo concerns a recently developed prototype of an emotionally-sensitive autonomous HiFi Spoken Conversational Agent, called NEMOHIFI. The baseline agent was developed by the Speech Technology Group (GTH) and has recently been integrated with an emotional engine called NEMO (Need-inspired Emotional Model) to enable it to adapt to users' emotion and respond to the users using appropriate expressive speech. NEMOHIFI controls and manages the HiFi audio system, and for end users, its functions equate a remote control, except that instead of clicking, the user interacts with the agent using voice. A pairwise comparison between the baseline (non-adaptive) and NEMO-HIFI showed that the latter was not only statistically substantially preferred by users to the former, but they are also significantly more satisfied with it than the former. © 2013 Authors.","affective agent; affective hifi, spoken conversational agent; nemo; nemohifi; speech technology","Conversational agents; Emotional models; End users; Expressive speech; nemo; nemohifi; Pair-wise comparison; Speech technology; Interactive computer systems","","","","","","","Fernandez-Martinez F., Ferreiros J., Lucas-Cuesta J.M., Echeverry J.D., San-Segundo R., Cordoba R., Flexible, Robust and Dynamic Dialogue Modeling with a Speech Dialogue Interface for Controlling a Hi-Fi Audio System, Proceedings of the IEEE Workshop on Database and Expert Systems Applications (DEXA 2010), Springer, 2010; Fernandez-Martinez F., Ferreiros J., Lucas-Cuesta J.M., Montero J.M., San-Segundo R., Cordoba R., Towards building intelligent speech interfaces through the use of more flexible, robust and natural dialogue management solutions, Interacting with Computers, 24, pp. 82-498, (2012); Lorenzo-Trueba J., Watts O., Barra-Chicote R., Yamagishi J., King S., Montero J.M., Simple4All proposals for the Albayzin Evaluations in Speech Synthesis, VII Jornadas de Tecnología del Habla (Iberspeech2012), (2012); Ekman P., Friesen W., The Facial Action Coding System: A Technique for the Measurement of Facial Movement, (1978); Lutfi S., Fernandez-Martinez F., Lucas-Cuesta J., Lopez-Lebon L., A Satisfaction-based Model for Affect Recognition from Conversational Features in Spoken Dialog Systems, Speech Communication, (2013); Lutfi S., User-centric Need-driven Affective Model for Spoken Conversational Agents: Design and Evaluation","S. Lebai Lutfi; School of Computer Sciences, University Sains Malaysia, 11800 Penang, Malaysia; email: syaheerah@cs.usm.my","","","ACM SIGCHI","2013 15th ACM International Conference on Multimodal Interaction, ICMI 2013","9 December 2013 through 13 December 2013","Sydney, NSW","102005","","978-145032129-7","","","English","ICMI - Proc. ACM Int. Conf. Multimodal Interact.","Conference paper","Final","","Scopus","2-s2.0-84892563635"
"Lebai Lutfi S.; Fernández-Martínez F.; Lucas-Cuesta J.M.; López-Lebón L.; Montero J.M.","Lebai Lutfi, Syaheerah (27567802400); Fernández-Martínez, Fernando (6602973640); Lucas-Cuesta, Juan Manuel (26664791600); López-Lebón, Lorena (55588306100); Montero, Juan Manuel (55960772400)","27567802400; 6602973640; 26664791600; 55588306100; 55960772400","A satisfaction-based model for affect recognition from conversational features in spoken dialog systems","2013","Speech Communication","55","7-8","","825","840","15","11","10.1016/j.specom.2013.04.005","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84879108451&doi=10.1016%2fj.specom.2013.04.005&partnerID=40&md5=fe6de5894e1173e99999ca8200f3363d","Speech Technology Group, Universidad Politécnica de Madrid, Spain; School of Computer Sciences, University Science of Malaysia, Penang, Malaysia; Multimedia Processing Group (GPM), Department of Signal Theory and Communications, Universidad Carlos III de Madrid, Spain","Lebai Lutfi S., Speech Technology Group, Universidad Politécnica de Madrid, Spain, School of Computer Sciences, University Science of Malaysia, Penang, Malaysia; Fernández-Martínez F., Multimedia Processing Group (GPM), Department of Signal Theory and Communications, Universidad Carlos III de Madrid, Spain; Lucas-Cuesta J.M., Speech Technology Group, Universidad Politécnica de Madrid, Spain; López-Lebón L., Speech Technology Group, Universidad Politécnica de Madrid, Spain; Montero J.M., Speech Technology Group, Universidad Politécnica de Madrid, Spain","Detecting user affect automatically during real-time conversation is the main challenge towards our greater aim of infusing social intelligence into a natural-language mixed-initiative High-Fidelity (Hi-Fi) audio control spoken dialog agent. In recent years, studies on affect detection from voice have moved on to using realistic, non-acted data, which is subtler. However, it is more challenging to perceive subtler emotions and this is demonstrated in tasks such as labeling and machine prediction. This paper attempts to address part of this challenge by considering the role of user satisfaction ratings and also conversational/dialog features in discriminating contentment and frustration, two types of emotions that are known to be prevalent within spoken human-computer interaction. However, given the laboratory constraints, users might be positively biased when rating the system, indirectly making the reliability of the satisfaction data questionable. Machine learning experiments were conducted on two datasets, users and annotators, which were then compared in order to assess the reliability of these datasets. Our results indicated that standard classifiers were significantly more successful in discriminating the abovementioned emotions and their intensities (reflected by user satisfaction ratings) from annotator data than from user data. These results corroborated that: first, satisfaction data could be used directly as an alternative target variable to model affect, and that they could be predicted exclusively by dialog features. Second, these were only true when trying to predict the abovementioned emotions using annotator's data, suggesting that user bias does exist in a laboratory-led evaluation. © 2013 Elsevier B.V. All rights reserved.","Affective spoken dialog system; Automatic affect detection; Conversational cues; Dialog features; Domestic environment; HiFi agent; Predicting user satisfaction; Social intelligence; User bias","Behavioral research; Forecasting; Affect detection; Conversational cues; Dialog features; Domestic environments; Social intelligence; Spoken dialog systems; User bias; User satisfaction; Human computer interaction","","","","","CAM-UPM; INAPRA, (DPI2010-21247-C02-02, MA2VICMR, TIN2008-06856-C05-03); ITALIHA; TIMPANO, (TIN2011-28169-C05-03); Seventh Framework Programme, FP7, (287678); Comunidad de Madrid, (S2009/TIC-1542); European Commission, EC; Ministry of Higher Education, Malaysia, MOHE; Universiti Sains Malaysia","The work leading to these results has received funding from the European Union under Grant agreement No. 287678. It has also been supported by TIMPANO(TIN2011-28169-C05-03), ITALIHA(CAM-UPM), INAPRA (DPI2010-21247-C02-02), SD-TEAM (TIN2008-06856-C05-03) and MA2VICMR (Comunidad Autonoma de Madrid, S2009/TIC-1542) projects. The corresponding author thanks University Science of Malaysia and the Malaysian Ministry of Higher Education for the PhD funding. Authors also thank all the other members of the Speech Technology Group for the continuous and fruitful discussion on these topics.","Ai H., Litman D., Forbes-Riley K., Rotaru K., Tetreault J., Purandare A., Using system and user performance features to improve emotion detection in spoken tutoring systems, Proceedings of Interspeech, pp. 797-800, (2006); Ai H., Raux A., Bohus D., Eskenazi M., Litman D., Comparing spoken dialog corpora collected with recruited subjects versus real users, Eighth SIGdial Workshop on Discourse and Dialogue, (2007); Ang J., Dhillon R., Krupski A., Shriberg E., Stolcke A., Prosody-based automatic detection of annoyance and frustration in human-computer dialog, Proceedings of International Conference on Spoken, Language Processing (ICSLP), (2002); Bailey J.E., Pearson S.W., Development of a tool for measuring and analyzing computer user satisfaction, Management Science, 24, pp. 530-545, (1983); Banse R., Scherer K.R., Acoustic Profiles in Vocal Emotion Expression, Journal of Personality and Social Psychology, 70, 3, pp. 614-636, (1996); Barra-Chicote R., Fernandez F., Lutfi S., Lucas-Cuesta . J M., Macias-Guarasa J., Montero J., San-Segundo R., Pardo J., Acoustic emotion recognition using dynamic bayesian networks and multi-space distributions, Proceedings of Interspeech, pp. 336-339; Barra-Chicote R.J.M., Montero J.M.D., Haro L., Segundo R.S., De Cordoba R., Prosodic and segmental rubrics in emotion identification, Proceedings of International Conference on Acoustics, Speech And, Signal Processing (ICASSP), pp. 1085-1088; Barra-Chicote R., Macias-Guarasa J., Montero J., Rincon C., Fernandez F., Cordoba R., Search of primary rubrics for language independent emotional speech identification, Proceedings of WISP; Barra-Chicote R., Yamagishi J., King S., Montero J.M., Macias-Guarasa J., Analysis of statistical parametric and unit selection speech synthesis systems applied to emotional speech, Speech Communication, 52, 5, pp. 394-404, (2010); Batliner A., Steidl S., Schuller B., Seppi D., Vogt T., Wagner J., Devillers L., Vidrascu L., Aharonson V., Kessous L., Amir N., Whodunnit: Searching for the most important feature types signalling emotion-related user states in speech, Computer Speech and Language, 25, 1, pp. 4-28, (2011); Burkhardt F., Van Ballegooy M., Engelbrecht K.-P., Polzehl T., Stegmann J., Emotion detection in dialog systems: Applications, strategies and challenges, Proceedings of IEEE, (2009); Callejas Z., Lopez-Cozar R., Influence of contextual information in emotion annotation for spoken dialogue systems, Speech Communication, 50, 5, pp. 416-433, (2008); Callejas Z., Lopez-Cozar R., On the use of kappa coefficients to measure the reliability of the annotation of non-acted emotions, Proceedings of the Fourth IEEE Tutorial and Research Workshop on Perception and Interactive Technologies for Speech-Based Systems: Perception in Multimodal Dialogue Systems, PIT '08, pp. 221-232, (2008); Callejas Z., Lopez-Cozar R., Relations between de-facto criteria in the evaluation of a spoken dialogue system, Speech Communication, 50, pp. 646-665, (2008); Charfuelan M., Lopez . C E., Gil . J R., Rodriguez . M C., Gomez . L H., A General Evaluation Framework to Assess Spoken Language Dialog Systems: Experience with Call Center Agent Systems, (2000); Cowie R., Douglas-Cowie E., Martin J.-C., Devillers L., A Blueprint for An Affectively Competent Agent: Cross-Fertilization between Emotion Psychology, Affective Neuroscience and Affective Computing, (2010); Danieli M., Gerbino E., Metrics for evaluating dialogue strategies in a spoken language system, AAAI Spring Symposium on Empirical Methods in Discourse Interpretation and Generation, pp. 34-39, (1995); Devillers L., Campbell N., Special issue of computer speech and language on affective speech in real-life interactions, Computer Speech and Language, 25, 1, pp. 1-3, (2011); Devillers L., Rosset S., Bonneau-Maynard H., Lamel L., Annotations for Dynamic Diagnosis of the Dialog State, (2002); D'Mello . S K., Craig . S D., Witherspoon A., McDaniel B., Graesser A., Automatic detection of learner's affect from conversational cues, User Model User-Adap. Inter, 18, pp. 45-80, (2008); Doll W.J., Torkzadeh G., The measurement of end-user computing satisfaction, MIS Quarterly, 12, pp. 259-274, (1988); Dybkjr L., Bernsen N.O., Minker W., Evaluation and usability of multimodal spoken language dialogue systems, Speech Communication, 43, pp. 33-54, (2004); Ekman P., Friesen W., The Facial Action Coding System: A Technique for the Measurement of Facial Movement, (1978); Engelbrecht K.-P., Godde F., Hartard F., Ketabdar H., Moller S., Modeling user satisfaction with hidden markov model, Proceedings of the 10th Anual Meeting of the Special Interest Group in Discourse And, Dialogue, pp. 170-177, (2009); Fernandez-Martinez F., Blazquez J., Ferreiros J., Barra-Chicote R., Macias-Guarasa J., Lucas-Cuesta . J M., Evaluation of a spoken dialog system for controlling a hifi audio system, Proceedings of the IEEE Workshop on Spoken Language Technology, (2008); Fernandez-Martinez F., Ferreiros J., Lucas-Cuesta J.M., Echeverry J.D., San-Segundo R., Cordoba R., September, Flexible, robust and dynamic dialogue modeling with a speech dialogue interface for controlling a hi-fi audio system, Proceedings of the IEEE Workshop on Database and Expert Systems Applications (DEXA 2010), (2010); Fernandez-Martinez F., Lucas-Cuesta J.M., Chicote R.B., Ferreiros J., Macias-Guarasa J., HIFI-AV: An audio-visual corpus for spoken language human-machine dialogue research in Spanish, Proceedings of the Seventh Conference on International Language Resources and Evaluation (LREC'10), (2010); Field A., Discovering Statistics Using SPSS, (2005); Forbes-Riley K., Litman D., Benefits and challenges of real-time uncertainty detection and adaptation in a spoken dialogue computer tutor, Speech Communication, 53, 910, pp. 1115-1136, (2011); Forbes-Riley K., Litman D., Designing and evaluating a wizarded uncertainty-adaptive spoken dialogue tutoring system, Computer Speech and Language, 25, 1, pp. 105-126, (2011); Gelbrich K., Beyond just being dissatisfied: How angry and helpless customers react to failures when using self-service technologies, Schmalenbach Business Review, 61, pp. 40-59, (2009); Grichkovtsova I., Morel M., Lacheret A., The role of voice quality and prosodic countour in affective speech perception, Speech Communication, 54, 3, pp. 414-429, (2012); Grothendieck J., Gorin A., Borges N., Social correlates of turn-taking behavior, Proceedings of the 2009 IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP '09, pp. 4745-4748, (2009); Hone K.S., Graham R., Towards a tool for the subjective assessment of speech system interfaces (sassi), Natural Language Engineering, 6, 3-4, pp. 287-305, (2000); Kernbach S., Schutte N.S., The impact of service provider emotional intelligence on customer satisfaction, Journal of Services Marketing, 19, 7, pp. 438-444, (2005); Laukka P., Neiberg D., Forsell M., Karlsson I., Elenius K., Expression of affect in spontaneous speech: Acoustic correlates and automatic detection of irritation and resignation, Computer Speech and Language, 25, 1, pp. 84-104, (2011); Lee C.M., Narayanan S.S., Toward detecting emotions in spoken dialogs, IEEE Transactions on Speech and Audio Processing, 13, 2, pp. 293-303, (2005); Liscombe J., Riccardi G., Hakkani-Tur D., Using context to improve emotion detection in spoken dialog systems, 9th European Conference on Speech Communication and Technology, pp. 1845-1848, (2005); Litman D., Forbes-Riley K., Recognizing student emotions and attitudes on the basis of utterances in spoken tutoring dialogues with both human and computer tutors, Speech Communication, 48, pp. 559-590, (2006); Locke E.A., The Nature and Causes of Job Satisfaction, (1976); Lutfi S., Barra-Chicote R., Lucas-Cuesta J., Montero J., Nemo: Need-inspired emotional expressions within a task-independent framework, Proceedings of Brain Inspired Cognitive Systems (BICS), (2010); Lutfi S., Montero J., Barra-Chicote R., Lucas-Cuesta J., Gallardo-Antolin A., Expressive speech identifications based on hidden markov model, Proceedings of the International Conference on Health Informatics (HEALTHINF), pp. 488-494, (2009); Lutfi S.L., Sanz-Moreno C., Montero J., Integrating a need module into a task-independent framework for modelling emotion: A theoretical approach, Proceedings of the Ninth International Conference on Epigenetic Robotics (EPIROB), pp. 221-222, (2009); Mairesse F., Walker M.A., Mehl M.R., Moore R.K., Using linguistic cues for the automatic recognition of personality in conversation and text, Journal of Artificial Intelligence Research, 30, pp. 457-500, (2007); Moller S., Quality of Telephone-Based Spoken Dialogue Systems, (2005); Moller S., Smeele P., Boland H., Krebber J., Evaluating spoken dialogue systems according to de-facto standards: A case study, Computer Speech and Language, 21, 1, pp. 26-53, (2007); Nicholson J., Takahashi K., Nakatsu R., Emotion Recognition in Speech Using Neural Networks, Neural Computing and Applications, 9, 4, pp. 290-296, (2000); Oudeyer P.Y., The production and recoginiton of emotions in speech: Features and algorithms, International Journal of Human-Computer Studies, 59, pp. 157-183, (2003); Pell M.D., Paulmann S., Dara C., Alasseri A., Kotz S.A., Factors in the recognition of vocally expressed emotions: A comparison of four languages, Journal of Phonetics, 37, pp. 417-435, (2009); Picard R.W., Affective computing for HCI, Proceedings of HCI International (The Eighth International Conference on Human-Computer Interaction) on Human-Computer Interaction: Ergonomics and User Interfaces, 1 VOL., pp. 829-833, (1999); Podsakoff P.M., MacKenzie S.B., Lee J.-Y., Podsakoff N.P., Common Method Biases in Behavioral Research: A Critical Review of the Literature and Recommended Remedies, Journal of Applied Psychology, 88, 5, pp. 879-903, (2003); Porayska-Pomsta K., Mavrikis M., Pain H., Diagnosing and acting on student affect: The tutors perspective, User Model User-Adap. Inter, 18, 1-2, pp. 125-173, (2008); Perceptual evaluation of speech quality (pesq): An objective method for end-to-end speech quality assessment of narrow-band telephone networks and speech codecs, Tech. Rep.; International Telecommunication Union, (2001); Reeves B., Nass C., The Media Equation: How People Treat Computers, Television and New Media Like Real People and Places, (1996); Riccardi G., Hakkani-Tur D., Grounding emotions in human-machine conversational systems, Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), 3814, pp. 144-154, (2005); Saris W.E., Krosnick J.E., Shaeffer E.M., Comparing questions with agree/disagree response options to questions with construct-specific response options, Survey Research Methods, 4, 1, pp. 61-79, (2010); Schuller B., Steidl S., Batliner A., Burkhardt F., Devillers L., Muller C., Narayanan S., Paralinguistics in speech and language state-of-the-art and the challenge, Computer Speech and Language, (2012); Shami M., Verhelst W., Automatic classification of expressiveness in speech: A multi-corpus study, Speaker Classification II, 4441 VOL., pp. 43-56, (2007); Tcherkassof A., Bollon T., Dubois M., Pansu P., Adam J.-M., Facial expressions of emotions: A methodological contribution to the study of spontaneous and dynamic emotional faces, Journal of Social Psychology, 37, pp. 1325-1345, (2007); Toivanen J., Vayrynen E., Seppanen T., Automatic discrimination of emotion from finnish, Language and Speech, 47, pp. 383-412, (2004); Truong K.P., Van Leeuwen D.A., De Jong F.M., Speech-based recognition of self-reported and observed emotion in a dimensional space, Speech Communication, 54, 9, pp. 1049-1063, (2012); Vidrascu L., Devillers L., Detection of real-life emotions in call centers, INTERSPEECH, Pp. 1841-1844., (2005); Vogt T., Andre E., 2005. Comparing featre sets for acted and spontaneous speech in view of automatic emotion recognition, Proceedings of IEEE International Conference on Multimedia and Expo, pp. 474-477; Walker M., Kamm A., Bol J., Developing and testing general models of spoken dialogue system performance, Proceedings of Language Resources and Evaluation Conference, LREC-2000, (2000); Witten I.H., Frank E., Data Mining: Practical Machine Learning Tools and Techniques, (2005)","S. Lebai Lutfi; Speech Technology Group, Universidad Politécnica de Madrid, Spain; email: syaheerah@die.upm.es","","","","","","","","01676393","","SCOMD","","English","Speech Commun","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-84879108451"
"Lutfi S.L.; Montero J.M.; Ainon R.N.; M.don Z.","Lutfi, Syaheerah L. (27567802400); Montero, Juan M. (55960772400); Ainon, Raja N. (24779480300); M.don, Zuraida (55164727100)","27567802400; 55960772400; 24779480300; 55164727100","eXTRA: A culturally enriched malay text to speech system","2008","AISB 2008 Convention: Communication, Interaction and Social Intelligence - Proceedings of the AISB 2008 Symposium on Affective Language in Human and Machine","1","","","77","83","6","2","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84859254862&partnerID=40&md5=a2fb175d50397f5dc97f2d14fc09057a","Language Technology Group, Technical University of Madrid, Spain; Language Engineering Lab, University Malaya, Malaysia; Faculty of Language and Linguistics, University Malaya, Malaysia","Lutfi S.L., Language Technology Group, Technical University of Madrid, Spain; Montero J.M., Language Technology Group, Technical University of Madrid, Spain; Ainon R.N., Language Engineering Lab, University Malaya, Malaysia; M.don Z., Faculty of Language and Linguistics, University Malaya, Malaysia","This paper concerns the incorporation of naturalness into Malay Text-to-Speech (TTS) systems through the addition of a culturally-localized affective component. Previous studies on emotion theories were examined to draw up assumptions about emotions. These studies also include the findings from observations by anthropologists and researchers on culturalspecific emotions, particularly, the Malay culture. These findings were used to elicit the requirements for modeling affect in the TTS that conforms to the people of the Malay culture in Malaysia. The goal is to introduce a novel method for generating Malay expressive speech by embedding a localized'emotion layer'called eXpressive Text Reader Automation Layer, abbreviated as eXTRA. In a pilot project, the prototype is used with Fasih, the first Malay Text-to-Speech system developed by MIMOS Berhad, which can read unrestricted Malay text in four emotions: anger, sadness, happiness and fear. In this paper however, concentration is given to the first two emotions. eXTRA is evaluated through open perception tests by both native and non-native listeners. The results show more than sixty percent of recognition rate, which confirmed the satisfactory performance of the approaches.","","Emotion theories; Expressive speech; Malaysia; Non-native listeners; Pilot projects; Recognition rates; Text-readers; Text-to-speech system; Speech communication","","","","","","","Nass C., Isbister K., Lee E., Truth is beauty: Researching embodied conversational agents, Embodied Conversational Agents, pp. 374-402, (2000); Maldonado H., Hayes-Roth B., Toward cross-Cultural believability in character design, Agent Culture: Human- Agent Interaction in A Multicultural World, pp. 143-175, (2004); Research Finds That Culture Is Key to Interpreting Facial Expressions, (2007); Krenn B., Et al., Life-Like agents for the internet: A cross- cultural case study, Agent Culture: Human-Agent Interaction in A Multicultural World, (2004); Hayes-Roth B., Doyle P., Animate characters, Autonomous Agents and Multi-Agent Systems, 1, 2, pp. 195-230, (1998); Reeves B., Nass C., The Media Equation: How People Treat Computers, Televisions, and New Media Like Real People and Places, (1996); Silzer P.J., Miffed, upset, angry or furious? Translating emotion words, ATA 42nd Annual Conference, (2001); Brave S., Nass C., Emotion in human-computer interaction, The Human-Computer Interaction Handbook: FundamentALS, Evolving Technologies and Emerging Applications, pp. 81-93, (2003); Nass C., Et al., The Effects of Emotion of Voice in Synthesized and Recorded Speech, (2000); Wazir-Jahan K., Emotions of Culture: A Malay Perspective, (1990); Mohamad M., The Malay Dilemma, (1981); Razak A.A., Abidin M.I.Z., Komiya R., Emotion pitch variation analysis in malay and english voice samples,  Asia-Pacific Conference on Communications 2003, (2003); El-Imam Y.A., Don Z.M., Text-to-speech conversion of standard Malay, International Journal of Speech Technology, 3, 2, pp. 129-146, (2000); Syaheerah L.L., Et al., Template-driven emotions generation in malay text-to-speech: A preliminary experiment, 4th International Conference of Information Technology in Asia (CITA 05), (2005); Syaheerah L.L., Et al., Adding emotions to malay synthesized speech using diphone-based templates, 7th International Conference on Information and Web-based Applications & Services (IiWAS 05), (2005); Tiun S., Kong T.E., Building a speech corpus for malay TTS system, National Computer Science Postgraduate Colloquium 2005 (NaCPS'05), (2005); Wu C.-H., Chen J.-H., Template-driven generation of prosodic information for chinese concatenate synthesis, IEEE International Conference on Acoustics, Speech and Signal Processing, (1999); Murray I.R., Arnott J.L., Synthesizing emotions in speech: Is it time to get excited?,  International Conference on Spoken Language Processing 1996, (1996); Boersma P., Weenink D., Praat, (2005); Bulut M., Narayanan S., Syrdal A.K., Expressive speech synthesis using a concatenative synthesizer, ICSLP, (2002); Murray I.R., Arnott J.L., Toward the simulation of emotion in synthetic speech: A review of the literature on human vocal emotion, Journal of the Acoustical Society of America, 93, 2, pp. 1097-1108, (1993); Murray I.R., Arnott J.L., Rohwer E.A., Emotional stress in synthetic speech: Progress and future directions, Speech Communication, 20, 1-2, pp. 85-91, (1996)","S.L. Lutfi; Language Technology Group, Technical University of Madrid, Spain; email: syaheerah@die.upm.es","","","","AISB 2008 Symposium on Affective Language in Human and Machine","1 April 2008 through 4 April 2008","Aberdeen","89197","","1902956613; 978-190295661-9","","","English","AISB Conv.: Commun., Interact. Soc. Intell. - Proc. AISB Symp. Affective Lang. Hum. Mach.","Conference paper","Final","","Scopus","2-s2.0-84859254862"
"Azazi A.; Lebai Lutfi S.; Venkat I.; Fernández-Martínez F.","Azazi, Amal (56606204300); Lebai Lutfi, Syaheerah (27567802400); Venkat, Ibrahim (36338095000); Fernández-Martínez, Fernando (6602973640)","56606204300; 27567802400; 36338095000; 6602973640","Towards a robust affect recognition: Automatic facial expression recognition in 3D faces","2015","Expert Systems with Applications","42","6","","3056","3066","10","43","10.1016/j.eswa.2014.10.042","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84919798976&doi=10.1016%2fj.eswa.2014.10.042&partnerID=40&md5=8be63441c1bcd18a8ce47846384e2d27","School of Computer Sciences, Universiti Sains Malaysia, Minden, Pulau Pinang, 11800, Malaysia; Departamento de Teoría de la Señal y Comunicaciones, Universidad Carlos III de Madrid, Madrid, Spain","Azazi A., School of Computer Sciences, Universiti Sains Malaysia, Minden, Pulau Pinang, 11800, Malaysia; Lebai Lutfi S., School of Computer Sciences, Universiti Sains Malaysia, Minden, Pulau Pinang, 11800, Malaysia; Venkat I., School of Computer Sciences, Universiti Sains Malaysia, Minden, Pulau Pinang, 11800, Malaysia; Fernández-Martínez F., Departamento de Teoría de la Señal y Comunicaciones, Universidad Carlos III de Madrid, Madrid, Spain","Facial expressions are a powerful tool that communicates a person's emotional state and subsequently his/her intentions. Compared to 2D face images, 3D face images offer more granular cues that are not available in the 2D images. However, one major setback of 3D faces is that they impose a higher dimensionality than 2D faces. In this paper, we attempt to address this problem by proposing a fully automatic 3D facial expression recognition model that tackles the high dimensionality problem in a twofold solution. First, we transform the 3D faces into the 2D plane using conformal mapping. Second, we propose a Differential Evolution (DE) based optimization algorithm to select the optimal facial feature set and the classifier parameters simultaneously. The optimal features are selected from a pool of Speed Up Robust Features (SURF) descriptors of all the prospective facial points. The proposed model yielded an average recognition accuracy of 79% using the Bosphorus database and 79.36% using the BU-3DFE database. In addition, we exploit the facial muscular movements to enhance the probability estimation (PE) of Support Vector Machine (SVM). Joint application of feature selection with the proposed enhanced PE (EPE) yielded an average recognition accuracy of 84% using the Bosphorus database and 85.81% using the BU-3DFE database, which is statistically significantly better (at p<0.01 and p<0.001, respectively) if compared to the individual exploit of the optimal features only. © 2014 Elsevier Ltd. All rights reserved.","3D Facial expression recognition; Action units; Conformal mapping; Differential Evolution; Probability estimation; Speed Up Robust Features; Support vector machines","Classification (of information); Conformal mapping; Database systems; Evolutionary algorithms; Feature extraction; Gesture recognition; Optimization; Support vector machines; 3-D facial expression recognition; Action Unit; Differential Evolution; Probability estimation; Speed up; Face recognition","","","","","Universiti Sains Malaysia, (304/PKOMP/6312153)","The authors would like to thank Universiti Sains Malaysia for the partial funding of this work from the grant no. 304/PKOMP/6312153 .","Bahreini K., Nadolski R., Westera W., Towards multimodal emotion recognition in e-learning environments, Interactive Learning Environments, pp. 1-16, (2014); Bay H., Tuytelaars T., Gool L.V., SURF: Speeded up robust features, Proceedings of the Ninth European Conference on Computer Vision, pp. 404-417, (2006); Ben Ammar M., Neji M., Alimi A.M., Gouarderes G., The affective tutoring system, Expert Systems with Applications, 37, pp. 3013-3023, (2010); Berretti S., Amor B.B., Daoudi M., Del Bimbo A., 3D facial expression recognition using sift descriptors of automatically detected keypoints, The Visual Computer, 27, pp. 1021-1036, (2011); Berretti S., Bimbo A.D., Pala P., Amor B.B., Daoudi M., A set of selected SIFT features for 3D facial expression recognition, 20th International Conference on Pattern Recognition, pp. 4125-4128, (2010); Burcin K., Vasif N.V., Down syndrome recognition using local binary patterns and statistical evaluation of the system, Expert Systems with Applications, 38, pp. 8690-8695, (2011); Chun S.-Y., Lee C.-S., Lee S.-H., Facial expression recognition using extended local binary patterns of 3D curvature, Multimedia and Ubiquitous Engineering, pp. 1005-1012, (2013); Eck M., Derose T., Duchamp T., Hoppe H., Lounsbery M., Stuetzle W., Multiresolution analysis of arbitrary meshes, Proceedings of the 22nd Annual Conference on Computer Graphics and Interactive Techniques, pp. 173-182, (1995); Ekman P., Universals and cultural differences in facial expressions of emotion, Nebraska Symposium on Motivation, (1971); Ekman P., Friesen W.V., Measuring facial movement, Environmental Psychology and Nonverbal Behavior, 1, pp. 56-75, (1976); Ekman P., Friesen W.V., Facial Action Coding System, (1977); Fang T., Zhao X., Ocegueda O., Shah S.K., Kakadiaris I.A., 3D/4D facial expression analysis: An advanced annotated face model approach, Image and Vision Computing, 30, pp. 738-749, (2012); Gong B., Wang Y., Liu J., Tang X., Automatic facial expression recognition on a single 3D face by exploring shape deformation, Proceedings of the 17th ACM International Conference on Multimedia, pp. 569-572, (2009); Gonzalez-Diaz I., Cortes T.M., Gallardo-Antolin A., Diaz-De Maria F., Temporal segmentation and keyframe selection methods for user-generated video search-based annotation, Expert Systems with Applications, 42, pp. 488-502, (2015); Gu X., Yau S.-T., Computing conformal structures of surfaces, Communications in Information and Systems, 2, pp. 121-146, (2002); Gu X., Yau S.-T., Global conformal surface parameterization, Proceedings of the 2003 Eurographics/ACM SIGGRAPH Symposium on Geometry Processing, pp. 127-137, (2003); Gu X.D., Yau S.-T., Computational Conformal Geometry, 3, (2008); Khosla R., Chu M.-T., Kachouie R., Yamada K., Yoshihiro F., Yamaguchi T., Interactive multimodal social robot for improving quality of care of elderly in Australian nursing homes, Proceedings of the 20th ACM International Conference on Multimedia, pp. 1173-1176, (2012); Lau B.T., Portable real time emotion detection system for the disabled, Expert Systems with Applications, 37, pp. 6561-6566, (2010); Lemaire P., Ben Amor B., Ardabilian M., Chen L., Daoudi M., Fully automatic 3D facial expression recognition using a region-based approach, Proceedings of the 2011 Joint ACM Workshop on Human Gesture and Behavior Understanding, pp. 53-58, (2011); Lemaire P., Chen L., Ardabilian M., Daoudi M., Et al., Fully automatic 3D facial expression recognition using differential mean curvature maps and histograms of oriented gradients, Workshop 3D Face Biometrics, (2013); Li X., Ruan Q., An G., Ruan C., 3D facial expression recognition based on variation faces, International Conference on Signal Processing, 1, pp. 775-778, (2012); Li X., Ruan Q., An G., Ruan C., 3D facial expression recognition based on variation faces, 11th International Conference on Signal Processing (ICSP), 2012, 1, pp. 775-778, (2012); Maalej A., Amor B.B., Daoudi M., Srivastava A., Berretti S., Shape analysis of local facial patches for 3D facial expression recognition, Pattern Recognition, 44, pp. 1581-1589, (2011); Martinez A., Du S., A model of the perception of facial expressions of emotion by humans: Research overview and perspectives, The Journal of Machine Learning Research, 13, pp. 1589-1608, (2012); Moreira Almeida S.G., Gadelha Guimaraes F., Arturo Ramirez J., Feature extraction in Brazilian sign language recognition based on phonological structure and using RGB-D sensors, Expert Systems with Applications, 41, pp. 7259-7271, (2014); Mpiperis I., Malassiotis S., Strintzis M.G., Bilinear models for 3D face and facial expression recognition, IEEE Transactions on Information Forensics and Security, 3, pp. 498-511, (2008); Owusu E., Zhan Y., Mao Q.R., A neural-adaboost based facial expression recognition system, Expert Systems with Applications, 41, pp. 3383-3390, (2014); Puccinelli N.M., Motyka S., Grewal D., Can you trust a customer's expression? Insights into nonverbal communication in the retail context, Psychology & Marketing, 27, pp. 964-988, (2010); Rosato M., Chen X., Yin L., Automatic registration of vertex correspondences for 3D facial expression analysis, Biometrics: Theory, Applications and Systems, 2008, pp. 1-7, (2008); Sandbach G., Zafeiriou S., Pantic M., Yin L., Static and dynamic 3D facial expression recognition: A comprehensive survey, Image and Vision Computing, 30, pp. 683-697, (2012); Savran A., Alyuz N., Dibekliotlu H., Celiktutan O., Gokberk B., Sankur B., Bosphorus database for 3D face analysis, Biometrics and Identity Management, pp. 47-56, (2008); Savran A., Sankur B., Automatic detection of facial actions from 3D data, 2009 IEEE 12th International Conference on Computer Vision Workshops (ICCV Workshops), pp. 1993-2000, (2009); Segal J., Jaffe J., The Language of Emotional Intelligence, (2008); Sha T., Song M., Bu J., Chen C., Tao D., Feature level analysis for 3D facial expression recognition, Neurocomputing, 74, pp. 2135-2141, (2011); Soyel H., Demirel H., 3D facial expression recognition with geometrically localized facial features, International Symposium on Computer and Information Sciences, pp. 1-4, (2008); Soyel H., Tekguc U., Demirel H., Application of NSGA-II to feature selection for facial expression recognition, Computers & Electrical Engineering, 37, pp. 1232-1240, (2011); Storn R., Price K., Differential evolution-A simple and efficient heuristic for global optimization over continuous spaces, Journal of Global Optimization, 11, pp. 341-359, (1997); Sun Y., Yin L., Evaluation of 3D facial feature selection for individual facial model identification, 18th International Conference on Pattern Recognition, 4, pp. 562-565, (2006); Tang H., Huang T.S., 3D facial expression recognition based on automatically selected features, Computer Society Conference on Computer Vision and Pattern Recognition Workshops, pp. 1-8, (2008); Tekguc U., Soyel H., Demirel H., Feature selection for person-independent 3D facial expression recognition using NSGA-II, International Symposium on Computer and Information Sciences, pp. 35-38, (2009); Tsalakanidou F., Malassiotis S., Real-time 2D+3D facial action and expression recognition, Pattern Recognition, 43, pp. 1763-1775, (2010); Uricar M., Detector of facial landmarks learned by the structured output SVM, VISAPP'12: Proceedings of the 7th International Conference on Computer Vision Theory and Applications, pp. 547-556, (2012); Valstar M.F., Mehu M., Jiang B., Pantic M., Scherer K., Meta-analysis of the first facial expression recognition challenge, IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics, 42, pp. 966-979, (2012); Vapnik V.N., The Nature of Statistical Learning Theory, (1995); Venkatesh Y.V., Kassim A.A., Yuan J., Nguyen T.D., On the simultaneous recognition of identity and expression from BU-3DFE datasets, Pattern Recognition Letters, 33, pp. 1785-1793, (2012); Vretos N., Nikolaidis N., Pitas I., 3D facial expression recognition using Zernike moments on depth images, International Conference on Image Processing, pp. 773-776, (2011); Wang Y., Meng M., Zhen Q., Learning encoded facial curvature information for 3D facial emotion recognition, International Conference on Image and Graphics, pp. 529-532, (2013); Wang J., Yin L., Wei X., Sun Y., 3D facial expression recognition based on primitive surface feature distribution, IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2, pp. 1399-1406, (2006); Whitehill J., Bartlett M., Movellan J., Automatic facial expression recognition for intelligent tutoring systems, IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops, pp. 1-6, (2008); Wu T.-F., Lin C.-J., Weng R.C., Probability estimates for multi-class classification by pairwise coupling, The Journal of Machine Learning Research, 5, pp. 975-1005, (2004); Yang J., Honavar V., Feature subset selection using a genetic algorithm, Feature Extraction, Construction and Selection, pp. 117-136, (1998); Yin L., Wei X., Sun Y., Wang J., Rosato M.J., A 3D facial expression database for facial behavior research, 7th International Conference on Automatic Face and Gesture Recognition, pp. 211-216, (2006); Yun T., Guan L., Human emotional state recognition using real 3D visual features from Gabor library, Pattern Recognition, 46, pp. 529-538, (2013); Yurtkan K., Demirel H., Feature selection for improved 3D facial expression recognition, Pattern Recognition Letters, 38, pp. 26-33, (2014); Zeng W., Li H., Chen L., Morvan J.-M., Gu X.D., An automatic 3D expression recognition framework based on sparse representation of conformal images, 10th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), pp. 1-8, (2013)","","","Elsevier Ltd","","","","","","09574174","","ESAPE","","English","Expert Sys Appl","Article","Final","","Scopus","2-s2.0-84919798976"
"Lahasan B.; Lebai Lutfi S.; Venkat I.; Al-Betar M.A.; San-Segundo R.","Lahasan, Badr (56768228800); Lebai Lutfi, Syaheerah (27567802400); Venkat, Ibrahim (36338095000); Al-Betar, Mohammed Azmi (57202908939); San-Segundo, Rubén (8333266700)","56768228800; 27567802400; 36338095000; 57202908939; 8333266700","Optimized symmetric partial facegraphs for face recognition in adverse conditions","2018","Information Sciences","429","","","194","214","20","6","10.1016/j.ins.2017.11.013","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85034668482&doi=10.1016%2fj.ins.2017.11.013&partnerID=40&md5=995d71915d5e419c337451c9c8d57f86","School of Computer Sciences, Universiti Sains Malaysia, Penang, 11800, USM, Malaysia; Department of Information Technology, Al-Huson University College, Al-Balqa Applied University, Jordan; Grupo Technología del Habla, E.T.S.I. Telecomunicación (ETSIT) Universidad Politécnica de Madrid (UPM), Spain","Lahasan B., School of Computer Sciences, Universiti Sains Malaysia, Penang, 11800, USM, Malaysia; Lebai Lutfi S., School of Computer Sciences, Universiti Sains Malaysia, Penang, 11800, USM, Malaysia; Venkat I., School of Computer Sciences, Universiti Sains Malaysia, Penang, 11800, USM, Malaysia; Al-Betar M.A., Department of Information Technology, Al-Huson University College, Al-Balqa Applied University, Jordan; San-Segundo R., Grupo Technología del Habla, E.T.S.I. Telecomunicación (ETSIT) Universidad Politécnica de Madrid (UPM), Spain","In this paper, we propose a memetic based framework called Optimized Symmetric Partial Facegraphs (OSPF) to recognize faces prone to adverse conditions such as facial occlusions, expression and illumination variations. Faces are initially segmented into facial components and optimal landmarks are automatically generated by exploiting the bilateral symmetrical property of human faces. The proposed approach combines an improved harmony search algorithm and an intelligent single particle optimizer to take advantage of their global and local search capabilities. Basically, the hybridization version aids to compute the optimal landmarks. These landmarks further serve as the building blocks to intuitively construct the partial facegraphs. The efficiency of the proposed approach has been investigated in addressing the facial occlusion problem when only one exemplar face image per subject is available using comprehensive experimental validations. The proposed approach yields improved recognition rates when compared to recent state-of-the-art techniques. © 2017","Face recognition; Facial occlusion; Harmony search algorithm; Intelligent single particle optimizer; Symmetric partial facegraphs","Learning algorithms; Optimization; Automatically generated; Experimental validations; Facial occlusions; Harmony search algorithms; Illumination variation; Improved harmony search algorithms; Intelligent single particle optimizer; Symmetric partial facegraphs; Face recognition","","","","","Universiti Sains Malaysia, (304/PKOMP/ 6312153)","The authors would like to thank Universiti Sains Malaysia for the partial funding of this work from the grant no. 304/PKOMP/ 6312153 .   ","Abual-Rub M.S., Al-Betar M.A., Abdullah R., Khader A.T., A hybrid harmony search algorithm for ab initio protein tertiary structure prediction, Netw. Model. Anal. Health Inf. Bioinf., 1, 3, pp. 69-85, (2012); Al-Betar M.A., Khader A.T., Zaman M., University course timetabling using a hybrid harmony search metaheuristic algorithm, IEEE Trans. Syst. Man Cybern. Part C, 42, 5, pp. 664-681, (2012); Azeem A., Sharif M., Raza M., Murtaza M., A survey: face recognition techniques under partial occlusion., Int. Arab J. Inf. Technol., 11, 1, pp. 1-10, (2014); Aziz M., Tayarani-N M.-H., An adaptive memetic particle swarm optimization algorithm for finding large-scale latin hypercube designs, Eng. Appl. Artif. Intell., 36, pp. 222-237, (2014); Bolme. D.S., Thesis on elastic bunch graph matching, (2003); BoussaiD I., Lepagnot J., Siarry P., A survey on optimization metaheuristics, Inf Sci., 237, pp. 82-117, (2013); Chakraborti T., Chatterjee A., A novel binary adaptive weight gsa based feature selection for face recognition using local gradient patterns, modified census transform, and local binary patterns, Eng. Appl. Artif. Intell., 33, pp. 80-90, (2014); Chen W., Gao Y., Face recognition using ensemble string matching, IEEE Trans. Image Process., 22, 12, pp. 4798-4808, (2013); Chen Y., Yang J., Luo L., Zhang H., Qian J., Tai Y., Zhang J., Adaptive noise dictionary construction via irrpca for face recognition, Pattern Recognit., (2016); Ding R.-X., Du D.K., Huang Z.-H., Li Z.-M., Shang K., Variational feature representation-based classification for face recognition with single sample per person, J. Vis. Commun. Image Represent, 30, pp. 35-45, (2015); Ekenel H.K., Stiefelhagen R., Why Is Facial Occlusion a Challenging Problem?, Advances in Biometrics, pp. 299-308, (2009); Gao Y., Leung M.K., Face recognition using line edge map, IEEE Trans. Pattern Anal. Mach. Intell., 24, 6, pp. 764-779, (2002); Geem Z.W., Novel derivative of harmony search algorithm for discrete design variables, Appl. Math. Comput., 199, 1, pp. 223-230, (2008); Geem Z.W., Kim J.H., Loganathan G., A new heuristic optimization algorithm: harmony search, Simulation, 76, 2, pp. 60-68, (2001); Haghighat M., Abdel-Mottaleb M., Alhalabi W., Fully automatic face normalization and single sample face recognition in unconstrained environments, Expert Syst. Appl., 47, pp. 23-34, (2016); Harguess J., Aggarwal J., Is there a connection between face symmetry and face recognition?, IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), 2011, pp. 66-73, (2011); Huang G.B., Ramesh M., Berg T., Learned-Miller E., Labeled faces in the wild: a database for studying face recognition in unconstrained environments, Technical Report, (2007); Ji Z., Liao H., Wang Y., Wu Q., A novel intelligent particle optimizer for global optimization of multimodal functions, IEEE Congress on Evolutionary Computation, 2007. CEC 2007., pp. 3272-3275, (2007); Kanan H.R., Faez K., Recognizing faces using adaptively weighted sub-gabor array from a single sample image per enrolled subject, Image Vis. Comput., 28, 3, pp. 438-448, (2010); Kanan H.R., Faez K., Gao Y., Face recognition using adaptively weighted patch pzm array from a single exemplar image per person, Pattern Recognit., 41, 12, pp. 3799-3812, (2008); Kumar D., Kumar S., Rai C., Feature selection for face recognition: a memetic algorithmic approach, J. Zhejiang University-Science A, 10, 8, pp. 1140-1152, (2009); Lades M., Vorbruggen J., Buhmann J., Lange J., Von Der Malsburg C., Wurtz R., Konen W., Distortion invariant object recognition in the dynamic link architecture, IEEE Trans. Comput., 42, 3, pp. 300-311, (1993); Lahasan B., Lutfi S.L., San-Segundo R., A survey on techniques to handle face recognition challenges: occlusion, single sample per subject and expression, Artif. Intell. Rev., pp. 1-31, (2017); Lahasan B.M., Venkat I., Al-Betar M.A., Lutfi S.L., De Wilde P., Recognizing faces prone to occlusions and common variations using optimal face subgraphs, Appl. Math. Comput., 283, pp. 316-332, (2016); Lahasan B.M., Venkat I., Lutfi S.L., Recognition of occluded faces using an enhanced ebgm algorithm, International Conference on Computer and Information Sciences (ICCOINS), 2014, pp. 1-5, (2014); Lee K., Geem Z., A new structural optimization method based on the harmony search algorithm, Comput. Struct., 82, 9-10, pp. 781-798, (2004); Lenc L., Kral P., Automatic face recognition system based on the sift features, Comput. Elect. Eng., (2015); Liu F., Tang J., Song Y., Bi Y., Yang S., Local structure based multi-phase collaborative representation for face recognition with single sample per person, Inf Sci., 346, pp. 198-215, (2016); Mahdavi M., Fesanghary M., Damangir E., An improved harmony search algorithm for solving optimization problems, Appl. Math. Comput., 188, 2, pp. 1567-1579, (2007); Mahoor M.H., Ansari A., Abdel-Mottaleb M., Multi-modal (2-d and 3-d) face modeling and recognition using attributed relational graph, 15th IEEE International Conference on Image Processing, 2008. ICIP 2008., pp. 2760-2763, (2008); Manjarres D., Landa-Torres I., Gil-Lopez S., Del Ser J., Bilbao M., Salcedo-Sanz S., Geem Z., A survey on applications of the harmony search algorithm, Eng. Appl. Artif. Intell., 26, 8, pp. 1818-1831, (2013); Martinez A.M., Benavente R., (1998); Phillips P.J., Beveridge J.R., Draper B.A., Givens G., Toole A.J., Bolme D.S., Dunlop J., Lui Y.M., Sahibzada H., Weimer S., An introduction to the good, the bad, & the ugly face recognition challenge problem, Automatic Face & Gesture Recognition and Workshops (FG 2011), 2011 IEEE International Conference on, pp. 346-353, (2011); Phillips P.J., Flynn P.J., Scruggs T., Bowyer K.W., Chang J., Hoffman K., Marques J., Min J., Worek W., Overview of the face recognition grand challenge, Computer vision and pattern recognition, 2005. CVPR 2005. IEEE computer society conference on, 1, pp. 947-954, (2005); Priya G.N., BANU R.W., Occlusion invariant face recognition using mean based weight matrix and support vector machine, Sadhana, 39, 2, pp. 303-315, (2014); Singh A.K., Nandi G., Face recognition using facial symmetry, Proceedings of the Second International Conference on Computational Science, Engineering and Information Technology, pp. 550-554, (2012); Sinha P., Balas B., Ostrovsky Y., Russell R., Face recognition by humans: nineteen results all computer vision researchers should know about, Proc. IEEE, 94, 11, pp. 1948-1962, (2007); Su Y., Shan S., Chen X., Gao W., Adaptive generic learning for face recognition from a single sample per person, IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2010, pp. 2699-2706, (2010); Tan X., Chen S., Zhou Z.-H., Zhang F., Face recognition from a single image per person: a survey, Pattern Recognit., 39, 9, pp. 1725-1745, (2006); Venkat I., Khader A.T., Subramanian K., Wilde P.D., Recognizing occluded faces by exploiting psychophysically inspired similarity maps, Pattern Recognit. Lett., 34, 8, pp. 903-911, (2013); Viola P., Jones M., Rapid object detection using a boosted cascade of simple features, IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2001. CVPR 2001. Proceedings of the 2001, 1, pp. I-511, (2001); Wiskott L., Fellous J.-M., Kuiger N., Von der Malsburg C., Face recognition by elastic bunch graph matching, IEEE Trans.Pattern Anal. Mach. Intell., 19, 7, pp. 775-779, (1997); Wright J., Yang A., Ganesh A., Sastry S., Ma Y., Robust face recognition via sparse representation, IEEE Trans.Pattern Anal. Mach. Intell., 31, 2, pp. 210-227, (2009); Xu Y., Li Z., Zhang B., Yang J., You J., Sample diversity, representation effectiveness and robust dictionary learning for face recognition, Inf Sci., 375, pp. 171-182, (2017); Xu Y., Zhang Z., Lu G., Yang J., Approximately symmetrical face images for image preprocessing in face recognition and sparse representation based classification, Pattern Recognit., 54, pp. 68-82, (2016); Xu Y., Zhu X., Li Z., Liu G., Lu Y., Liu H., Using the original and “symmetrical face” training samples to perform representation based two-step face recognition, Pattern Recognit., 46, 4, pp. 1151-1158, (2013); Yan H., Wang P., Chen W., Liu J., (2015); Zeng J., A self-adaptive intelligent single-particle optimizer compression algorithm, Neural Comput. Appl., 25, 6, pp. 1285-1292, (2014); Zhou J., Ji Z., Shen L., Zhu Z., Chen S., Pso based memetic algorithm for face recognition Gabor filters selection, Memetic Computing (MC), 2011 IEEE Workshop on, pp. 1-6, (2011); Zhu Z., Zhou J., Ji Z., Shi Y.-H., Dna sequence compression using adaptive particle swarm optimization-based memetic algorithm, IEEE Trans. Evolutionary Comput., 15, 5, pp. 643-658, (2011)","S. Lebai Lutfi; School of Computer Sciences, Universiti Sains Malaysia, Penang, 11800, Malaysia; email: syaheerah@usm.my","","Elsevier Inc.","","","","","","00200255","","ISIJB","","English","Inf Sci","Article","Final","","Scopus","2-s2.0-85034668482"
"Alfurayj H.S.; Yee N.S.; Lutfi S.L.","Alfurayj, Haifa Saleh (58759310900); Yee, Ng Sui (58759313100); Lutfi, Syaheerah Lebai (27567802400)","58759310900; 58759313100; 27567802400","Bystanders Unveiled: Introducing a Comprehensive Cyberbullying Corpus with Bystander Information","2023","IEEE Region 10 Annual International Conference, Proceedings/TENCON","","","","1012","1017","5","1","10.1109/TENCON58879.2023.10322359","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179515930&doi=10.1109%2fTENCON58879.2023.10322359&partnerID=40&md5=f5327bf85dac4313b9542295b01a9c9b","School of Computer Sciences, Universiti Sains Malaysia Usm, Penang, Malaysia; Qassim University, Qassim, Saudi Arabia","Alfurayj H.S., School of Computer Sciences, Universiti Sains Malaysia Usm, Penang, Malaysia, Qassim University, Qassim, Saudi Arabia; Yee N.S., School of Computer Sciences, Universiti Sains Malaysia Usm, Penang, Malaysia; Lutfi S.L., School of Computer Sciences, Universiti Sains Malaysia Usm, Penang, Malaysia","This paper introduces a new cyberbullying dataset, CYBY23, that includes Twitter threads containing both the main posts and the replies from bystanders. The dataset is organized based on conversation ID and consists of 112 threads, totaling around 639 tweets. The unique aspect of this dataset is the inclusion of labels for bystanders' roles, which provides a comprehensive understanding of the bullying incident and helps identify the level of aggressiveness in cyberbullying. This type of information is not available in existing datasets that only label isolated tweets. By incorporating bystanders' roles, annotators gain a deeper understanding of real-world scenarios, leading to improved machine learning performance and better classification of cyberbullying. The dataset is freely available, promoting collaboration among researchers, ensuring result reliability, and enabling the reuse of Twitter datasets. It also offers a cost-effective way for non-technical researchers to leverage Twitter data in their scientific investigations.  © 2023 IEEE.","aggression; bystander roles; bystander-role label; corpus; cyberbully","Computer crime; Social networking (online); Aggression; Bystander role; Bystander-role label; Corpus; Cyber bullying; Cyberbully; Learning performance; Machine-learning; Real-world scenario; Reuse; Cost effectiveness","","","","","","","Olweus D., Bullying at School: Basic Facts and Effects of a School Based Intervention Program, J. Child Psychol. Psychiatry, 35, 7, pp. 1171-1190, (1994); Machackova H., Bystander reactions to cyberbullying and cyberaggression: Individual, contextual, and social factors, Curr. Opin. Psychol., 36, pp. 130-134, (2020); Olweus D., Limber S.P., Some problems with cyberbullying research, Curr. Opin. Psychol., 19, pp. 139-143, (2018); Pabian S., Vandebosch H., Poels K., Van Cleemput K., Bastiaensens S., Exposure to cyberbullying as a bystander: An investigation of desensitization effects among early adolescents, Comput. Human Behav., 62, pp. 480-487, (2016); Smith P.K., Del Barrio C., Tokunaga R., Definitions of bullying and cyberbullying: How useful are the terms?, Principles of cyberbullying research: Definition, measures, and methods, (2013); Chatzakou D., Kourtellis N., Blackburn J., De Cristofaro E., Stringhini G., Vakali A., Mean birds: Detecting aggression and bullying on Twitter, WebSci 2017-Proc. 2017 ACM Web Sci. Conf., pp. 13-22, (2017); Ziems C., Vigfusson Y., Morstatter F., Aggressive, repetitive, intentional, visible, and imbalanced: Refining representations for cyberbullying classification, Proc. 14th Int. AAAI Conf. Web Soc. Media, ICWSM 2020, pp. 808-819, (2020); Founta A.M., Et al., Large scale crowdsourcing and characterization of twitter abusive behavior, 12th Int. AAAI Conf. Web Soc. Media, ICWSM 2018, pp. 491-500, (2018); Davidson T., Warmsley D., Macy M., Weber I., Automated hate speech detection and the problem of offensive language, Proc. 11th Int. Conf. Web Soc. Media, ICWSM 2017, pp. 512-515, (2017); Gomez R., Gibert J., Gomez L., Karatzas D., Exploring hate speech detection in multimodal publications, Proc.-2020 IEEE Winter Conf. Appl. Comput. Vision, WACV 2020, pp. 1459-1467, (2020); Golbeck J., Et al., A large human-labeled corpus for online harassment research, WebSci 2017-Proc. 2017 ACM Web Sci. Conf., pp. 229-233, (2017); Wang J., Fu K., Lu C.T., SOSNet: A Graph Convolutional Network Approach to Fine-Grained Cyberbullying Detection, Proc.-2020 IEEE Int. Conf. Big Data, Big Data 2020, pp. 1699-1708, (2020); Xu J.M., Jun K.S., Zhu X., Bellmore A., Learning from bullying traces in social media, NAACL HLT 2012-2012 Conf. North Am. Chapter Assoc. Comput. Linguist. Hum. Lang. Technol. Proc. Conf., pp. 656-666, (2012); Jacobs G., Van Hee C., Hoste V., Automatic classification of participant roles in cyberbullying: Can we detect victims, bullies, and bystanders in social media text?, Nat. Lang. Eng., 28, 2, pp. 141-166, (2022); Kumar R., TRAC-1 Shared Task on Aggression Identification: IIT (ISM)@ COLING ' 18, Proc. first Work. Trolling, Aggress. cyberbullying (TRAC-2018)., pp. 58-65, (2018); Rafiq R.I., Hosseinmardi H., Han R., Lv Q., Mishra S., Mattson S.A., Careful what you share in six seconds: Detecting cyberbullying instances in Vine, Proc. 2015 IEEE/ACM Int. Conf. Adv. Soc. Networks Anal. Mining, ASONAM 2015, pp. 617-622, (2015); Van Hee C., Verhoeven B., Lefever E., De Pauw G., Daelemans W., Team T.T., Guidelines for the Fine-Grained Analysis of of Cyberbullying, version 1. 0. Tech. Rep. LT3 15-01, LT3, (2015); Salawu S., He Y., Lumsden J., Approaches to Automated Detection of Cyberbullying: A Survey, IEEE Trans. Affect. Comput., 11, 1, pp. 3-24, (2020); Rafiq R.I., Hosseinmardi H., Han R., Lv Q., Mishra S., Identifying Differentiating Factors for Cyberbullying in Vine and Instagram, Commun. Comput. Inf. Sci., vol. 1410 CCIS, pp. 348-361, (2021)","","","Institute of Electrical and Electronics Engineers Inc.","","38th IEEE Region 10 Conference, TENCON 2023","31 October 2023 through 3 November 2023","Chiang Mai","194660","21593442","979-835030219-6","85QXA","","English","IEEE Reg 10 Annu Int Conf Proc TENCON","Conference paper","Final","","Scopus","2-s2.0-85179515930"
"Ahmad Z.; Lutfi S.L.; Kushan A.L.; Yixing R.T.","Ahmad, Zaaba (35172590500); Lutfi, Syaheerah Lebai (27567802400); Kushan, Albin Lemuel (57196192361); Yixing, Randall Tay (57196193008)","35172590500; 27567802400; 57196192361; 57196193008","Personality prediction of malaysian facebook users: Cultural preferences and features variation","2017","Advanced Science Letters","23","8","","7900","7903","3","4","10.1166/asl.2017.9604","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032185453&doi=10.1166%2fasl.2017.9604&partnerID=40&md5=feefec195b5c6146ea9d8c92d7a36c50","Faculty of Computer Science and Mathematics, Universiti Teknologi MARA (UiTM) Melaka Kampus Jasin, Merlimau, 77300, Melaka, Malaysia; School of Computer Sciences, Universiti Sains Malaysia, Minden, 11800, Penang, Malaysia","Ahmad Z., Faculty of Computer Science and Mathematics, Universiti Teknologi MARA (UiTM) Melaka Kampus Jasin, Merlimau, 77300, Melaka, Malaysia; Lutfi S.L., School of Computer Sciences, Universiti Sains Malaysia, Minden, 11800, Penang, Malaysia; Kushan A.L., Faculty of Computer Science and Mathematics, Universiti Teknologi MARA (UiTM) Melaka Kampus Jasin, Merlimau, 77300, Melaka, Malaysia; Yixing R.T., School of Computer Sciences, Universiti Sains Malaysia, Minden, 11800, Penang, Malaysia","Social media offer sample information for automatic personality prediction (APP). Users freely share their public information on social media. Apart from that, their usage behaviour also provide a rich source of data for prediction. Automatic prediction of personality trait is vital to improve the user experience and to tailor social media services to users’ needs and preferences. The study in APP based on social media data has thus far focused on Western countries such as the United States and Europe and there is little to no work done in South East Asia, much less in Malaysia. Hence, this paper aims to predict user traits based on social media by gathering certain information pertaining social network usage behaviour based on features such as likes, number of comments, number of friends, etc. A person’s personality is described by the characteristics of extraversion and neuroticism main features that can be seen as an echo of communications behaviour. Personality traits of extraversion, neuroticism and shyness will be the focus, as Malaysians are known to be shy and passive. Therefore, the above mentioned features will not only be explored in a more detailed scope, but also focused on other factors or behaviours that constitute shyness. © 2017 American Scientific Publishers. All rights reserved.","Facebook; Natural language processing; Personality prediction; Text classification","","","","","","","","Malaysians have Most Facebook Friends, (2010); Lee E., Science of Extraversion, (2014); Schrammel J., Kffel C., Tscheligi M., Personality traits, usage patterns and information disclosure in on-line communities, BCS HCI 09: Proceedings of the 2009 British Computer Society Conference on Human-Computer Interaction, pp. 169-174, (2009); Selfhout M., Burk W., Branje S., Denissen J., van Aken M., Meeus W., Journal of Personality, 78, (2010); Jung C.J., Psychologische Typen, (1921); Shyness and Social Phobia, (2014); Whitten M., Psych Central, (2001); Cain S., Quiet: The Power of Introverts in a World that Can’t Stop Talking, (2012); Coplan R.J., Rose-Krasnor L., Weeks M., Kingsbury A., Kingsbury M., Bullock A., Developmental Psychology, (2012); Paulhus D.L., Morgan K.L., Journal of Personality and Social Psychology, 72, (1997); Chen X., Rubin K., Sun Y., Social Reputation and Peer Relationships in Chinese and Canadian Children: A Cross-Cultural Study, (1992); Golbeck J., Robles C., Turner K., Predicting personality with social media, CHI’11 Extended Abstracts on Human Factors in Computing Systems, pp. 253-262, (2011); Tausczik Y.R., Pennebaker J.W., Journal of Language and Social Psychology, 29, (2010); Gill A.J., Nowson S., Oberlander J., What are they blogging about? Personality, topic and motivation in blogs, Proceedings of the International AAAI Conference on Weblogs and Social Media, pp. 18-25, (2009); Golbeck J., Robles C., Edmondson M., Turner K., Predicting personality from twitter, Proceedings of IEEE International Conference on Social Computing, pp. 149-156, (2011); Pennebaker J., Francis M., Booth R., Linguistic Inquiry and Word Count: LIWC 2001, (2001); Zabid A.M., Ling C., Journal of Education for Business, 79, (2003); Malaysian Communications and Multimedia Commission, (2015); Witten I.H., Frank E., Data Mining: Practical Machine Learning Tools and Techniques, (2005)","","","American Scientific Publishers","","","","","","19366612","","","","English","Adv. Sci. Lett.","Article","Final","","Scopus","2-s2.0-85032185453"
"Daud S.A.A.; Lutfi S.L.","Daud, Siti Asmaq Ahmad (57193734155); Lutfi, Syaheerah Lebai (27567802400)","57193734155; 27567802400","Towards the detection of learner's uncertainty through face","2017","Proceedings - 2016 4th International Conference on User Science and Engineering, i-USEr 2016","","","7857965","227","231","4","2","10.1109/IUSER.2016.7857965","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016178769&doi=10.1109%2fIUSER.2016.7857965&partnerID=40&md5=3dbbc188a22b446d9b1f0644b6e87f0f","School of Computer Sciences, Universiti Sains Malaysia, Penang, 11800, Malaysia","Daud S.A.A., School of Computer Sciences, Universiti Sains Malaysia, Penang, 11800, Malaysia; Lutfi S.L., School of Computer Sciences, Universiti Sains Malaysia, Penang, 11800, Malaysia","This research aims to detect uncertainty based on facial expression in a learning context with the use of the Facial Action Coding System (FACS). Although FACS has been used to categorize facial uncertainty, very few studies have worked in this field. Most studies rather focus on uncertainty detection using voice, even though uncertainty is more apparent through facial cues compared to vocal cues, and this warrants for the collection and analysis of a facial corpus. Hence, an effort to collect a facial corpus of uncertainty were made and the corpus is then analyzed. Data was collected through an experiment that entailed using stimuli to induce the uncertainty of the subject. The data was annotated in order to verify the images before proceeding to preprocessing and feature extraction techniques. The feature extraction of the images was carried out using Gabor Wavelets and classification to train the data is used Support Vector Machine (SVM). © 2016 IEEE.","emotion detection; facial action coding system (FACS); Gabor wavelets; image processing; support vector machine (SVM); uncertainty","Extraction; Face recognition; Feature extraction; Gabor filters; Image coding; Image processing; Signal encoding; Support vector machines; Uncertainty analysis; Emotion detection; Facial Action Coding System; Facial Expressions; Feature extraction techniques; Gabor wavelets; Learning context; uncertainty; Computer keyboards","","","","","Universiti Sains Malaysia, (304/PKOMP/6312153)","The authors thank Universiti Sains Malaysia for the funding of this work from the grant no. 304/PKOMP/6312153.","(2015); Lutfi S.L., Fernandez-Martinez F., Lucas-Cuesta J.M., Lopez-Lebon L., Montero J.M., A satisfaction-based model for affect recognition from conversational features in spoken dialog systems, Speech Communication, 55, 7, pp. 825-840, (2013); Forbes-Riley K., Litman D., Rotaru M., Responding to student uncertainty during computer tutoring: An experimental evaluation, International Conference on Intelligent Tutoring Systems, pp. 60-69, (2008); Baker R.S., D'Mello S.K., Rodrigo M.M.T., Graesser A.C., Better to be frustrated than bored: The incidence, persistence, and impact of learners' cognitive-affective states during interactions with three different computer-based learning environments, International Journal of Human-Computer Studies, 68, 4, pp. 223-241, (2010); Forbes-Riley K., Litman D., Benefits and challenges of real-time uncertainty detection and adaptation in a spoken dialogue computer tutor, Speech Communication, 53, 9, pp. 1115-1136, (2011); Mokhtar N.S., Lutfi S.L., Identifying significant predictors of emotion in learning, International Workshop on Empathetic Computing, PRIMA 2015, (2015); Bettadapura V., Face Expression Recognition and Analysis: State of the Art, pp. 1203-6722, (2012); Ekman P., Friesen W.V., Measuring facial movement, Environmental Psychology and Nonverbal Behavior, 1, 1, pp. 56-75, (1976); Abdullah A.A., Automatic and person-independent detection of 3d facial expressions using enhanced support vector machine with probability estimation, IEEE Digital Library, (2015); Song K.T., Chien S.C., Facial expression recognition based on mixture of basic expressions and intensities, IEEE International Conference on Systems, Man, and Cybernetics, (2012); Su M.C., Hsieh Y., Huang D.Y., A simple approach to facial expression recognition, Proceedings of the 2007 WSEAS International Conference on Computer Engineering and Applications, 456-461, (2007); Schrank T., Schuppler B., Automatic detection of uncertainty in spontaneous German dialogue, Sixteenth Annual Conference of the International Speech Communication Association, (2015); Sebe N., Lew M.S., Sun Y., Cohen I., Gevers T., Huang T.S., Authentic facial expression analysis, Image and Vision Computing, 25, pp. 1856-1863, (2007); Kotsia I., Pitas I., Facial expression recognition in image sequences using geometric deformation features and support vector machines, IEEE Trans. Image Processing, 16, 1, pp. 172-187, (2007); Dornaika F., Davoine F., Simultaneous facial action tracking and expression recognition in the presence of head motion, Int. J. Computere Vision, 76, 3, pp. 257-281, (2008); Rabiu H., Saripan M.I., Mashohor S., Marhaban M.H., 3D facial expression recognition using maximum relevance minimum redundancy geometrical features, EURASIP Journal on Advances in Signal Processing, 1, pp. 1-8, (2012); Kotsiantis S.B., Zaharakis I., Pintelas P., Supervised machine learning: A review of classification techniques, Informatica, 31, pp. 249-268, (2007); Kappas A., Hess U., Barr C.L., Kleck R.E., The effect of vertical viewing angle on the perception of facial expressions, Journal of Nonverbal Behavior, 4, 18, pp. 263-280, (1994); Stratou G., Ghosh A., Debevec P., Morency L.P., Exploring the effect of illumination on automatic expression recognition using the ICT-3DRFE database, Image and Vision Computing, 10, 30, pp. 728-737, (2012); Cowie R., Sawey M., GTrace-General Trace Program from queen'S, Belfast, (2011); Tian Y.I., Kanade T., Cohn J.F., Recognizing acton units for facial expression analysis, IEEE Transactions on Pattern Analysis and Machine Intelligence, 23, 2, (2001); Wiskott L., Fellous J.M., Kuiger N., Von Der Malsburg C., Face recognition by elastic bunch graph matching, Pattern Analysis and Machine Intelligence, IEEE Transactions on, 19, 7, pp. 775-779, (1997); Callejas Z., Lopez-Cozar R., On the use of kappa coefficients to measure the reliability of the annotation of non-acted emotions, Perception in Multimodal Dialogue Systems, pp. 221-232, (2008)","","","Institute of Electrical and Electronics Engineers Inc.","","4th International Conference on User Science and Engineering, i-USEr 2016","23 August 2016 through 25 August 2016","Melaka","126522","","978-150902631-9","","","English","Proc. - Int. Conf. User Sci. Eng., i-USEr","Conference paper","Final","","Scopus","2-s2.0-85016178769"
"Hall L.; Lutfi S.; Nazir A.; Hodgson J.; Hall M.; Ritter C.; Jones S.; Mascarenhas S.; Cooper B.; Paiva A.; Aylett R.","Hall, Lynne (7402375048); Lutfi, Syaheerah (27567802400); Nazir, Asad (26537933200); Hodgson, John (7202644709); Hall, Marc (55457049700); Ritter, Christopher (36473722200); Jones, Susan (7405932159); Mascarenhas, Samuel (35105447700); Cooper, Bridget (56223275300); Paiva, Ana (7102683774); Aylett, Ruth (55101098300)","7402375048; 27567802400; 26537933200; 7202644709; 55457049700; 36473722200; 7405932159; 35105447700; 56223275300; 7102683774; 55101098300","Games based learning for exploring cultural conflict","2011","AISB 2011: AI and Games","","","","61","69","8","1","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84863956316&partnerID=40&md5=7e572d72372f4a76be206b312ec6acf9","Department of Computing and Technology, University of Sunderland, United Kingdom; Departamento de Ingeniería Electrónica E.T.S.I. Telecomunicación, Universidad Politécnica de Madrid, Spain; School of Maths and Computer Science, Heriot-Watt University, United Kingdom; INESC-ID, Portugal","Hall L., Department of Computing and Technology, University of Sunderland, United Kingdom; Lutfi S., Departamento de Ingeniería Electrónica E.T.S.I. Telecomunicación, Universidad Politécnica de Madrid, Spain; Nazir A., School of Maths and Computer Science, Heriot-Watt University, United Kingdom; Hodgson J., Department of Computing and Technology, University of Sunderland, United Kingdom; Hall M., Department of Computing and Technology, University of Sunderland, United Kingdom; Ritter C., School of Maths and Computer Science, Heriot-Watt University, United Kingdom; Jones S., Department of Computing and Technology, University of Sunderland, United Kingdom; Mascarenhas S., INESC-ID, Portugal; Cooper B., Department of Computing and Technology, University of Sunderland, United Kingdom; Paiva A., INESC-ID, Portugal; Aylett R., School of Maths and Computer Science, Heriot-Watt University, United Kingdom","In this paper we discuss the early stage design of MIXER, a technology enhance educational application focused at supporting children in learning about cultural conflict, achieved through the use of a game with an effective embodied AI agent. MIXER is being developed re-using existing technology applied to a different context and purpose with the aim of creating an educational and enjoyable experience for 9-11 year olds. This paper outlines MIXER's underpinning technology and theory. It presents early stage design and development, highlighting current research directions.","","Design and Development; Educational Applications; Research directions; Mixers (machinery)","","","","","","","Aboud F.E., Children and Prejudice, (1988); Aboud F.E., Doyle A.-B., Parental and peer influences on children's racial attitudes, International Journal of Intercultural Relations, 20, 3-4, pp. 371-383, (1996); Aquino F.K., Reed II A., The self-importance of moral identity, Journal of Personality and Social Psychology, 86, 3, pp. 1423-1440, (2002); Reed II A., Aquino K.F., Moral identity and the expanding circle of moral regard toward out-groups, Journal of Personality and Social Psychology, 84, 6, pp. 1270-1286, (2003); Aylett R., Figueiredo R., Louchait S., Dias J., Paiva A., Making it up as you go along - Improvising stories for pedagogical purposes, Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), 4133, pp. 304-315, (2006); Aylett S.R., Et al., Fear not! - an emergent narrative approach to virtual dramas for anti-bullying education virtual storytelling, Using Virtual Reality Technologies for Storytelling Lecture Notes in Computer Science, 4871, pp. 202-205, (2007); Banks C.W., Rompf W.J., Evaluative bias and preference behaviour in black and white children, Child Development, 44, pp. 776-783, (1973); Corenblum B., What children remember about ingroup and outgroup peers: Effects of stereotypes on children's processing of information about group members, Journal of Experimental Child Psychology, 86, 1, pp. 32-66, (2003); Active engagement techniques, Pedagogy and Practice, (2004); Leading in learning, Pedagogy and Practice, (2004); Dias J., Paiva A., Feeling and reasoning: A computational model for emotional characters, Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), 3808, pp. 127-140, (2005); Hall L., Woods S., Aylett R., FearNot! Involving children in the design of a virtual learning environment. 2006, International Journal of Artificial Intelligence in Education, 16, 4, pp. 327-351, (2006); Hewstone M., Brown R.J., Contact is not enough: An intergroup perspective on the contact hypothesis, Contact and Conflict in Tergroup Encounters, pp. 1-44, (1986); Hofstede G., Hofstede G J., Minkov M., Cultures and Organizations: Software for the Mind, (2010); Hofstede G.J., Exploring Culture: Exercises, Stories and Synthetic Cultures, (2002); Liebkind K., McAlister A.L., Extended contact through peer modelling to promote tolerance in findland, European Journal of Social Psychology, 29, pp. 765-780, (1999); Lunzer E., Gardner K., Learning from the Written Word, (1984); Mascarenhas S., Et al., Using rituals to express cultural differences in synthetic characters, Proceedings of the 8th International Conference on Autonomous Agents and Multiagent Systems, 1, (2009); Malik K., The Meaning of Race, (1996); Nesdale D., The development of prejudice in children, Understanding Prejudice, Racism and Racial Conflicts, pp. 57-73, (2001); Nesdale D., Social Identity Processes and Ethnic Prejudice in Children, pp. 219-245, (2004); Ortony A., Clore G., Collins A., The Cognitive Structure of Emotions, (1988); Quillian L., Prejudice as a response to perceived group threat: Population composition and anti- immigrant and racial prejudice in europe, Sociological Review, 60, pp. 586-611, (1995); Rice S.A., Ruiz R.A., Padilla A.M., Person conception, self-identity, and ethnic group preference in anglo, black and chicano preschool and third grade children, Journal of Cross-cultural Psychology, 5, 1, pp. 100-108, (1974); Steele C.M., The psychology of self-affirmation: Sustaining the integrity of the self, Advances in Experimental Social Psychology, pp. 261-302, (1988); Steele C.M., Spencer S.J., Lynch M., Self-image resilience and dissonance: The role of affirmational resources, Journal of Personality and Social Psychology, 64, 6, pp. 885-896, (1993); Targowska A.U., Exploring Young Children's'Racial'Attitudes in An Australian Context - The Link between Research and Practice, (2001); Tajfel H., Turner J.C., An integrative theory of integroup conflict, The Social Psychology of Intergroup Relations, (1979); Thiagarajan S., Barnga: A Simulation Game on Cultural Clashes, (1990); Vala M., Et al., ION framework - A simulation environment for worlds with virtual agents, Intelligent Virtual Agent Lecture Notes in Computer Science, 5773, pp. 418-424, (2009); Weiland A., Coughlin R., Self-identification and preference. A comparison of white and mexican- american first and third graders, Journal of Crosscultural Psychology, 10, 3, pp. 356-365, (1979); Wright S.C., Et al., The extended contact effect: Knowledge of cross-group friendships and prejudice, Journal of Personality and Social Psychology, 73, 1, pp. 73-90, (1997)","L. Hall; Department of Computing and Technology, University of Sunderland, United Kingdom; email: lynne.hall@sunderland.ac.uk","","","","4th Symposium on AI and Games - A Symposium at AISB 2011","4 April 2011 through 7 April 2011","York","91180","","978-190818701-7","","","English","AISB: AI Games","Conference paper","Final","","Scopus","2-s2.0-84863956316"
"Chai A.-D.; Lebai Lutfi S.","Chai, Ai-Dii (57208396883); Lebai Lutfi, Syaheerah (27567802400)","57208396883; 27567802400","Expressive malay online speech interface (EMOSI)","2019","Lecture Notes in Electrical Engineering","547","","","51","58","7","0","10.1007/978-981-13-6447-1_7","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064590010&doi=10.1007%2f978-981-13-6447-1_7&partnerID=40&md5=c79aa44a333d67c741ab9ba09485a28a","School of Computer Sciences, Universiti Sains Malaysia, Minden, 11800, Penang, Malaysia","Chai A.-D., School of Computer Sciences, Universiti Sains Malaysia, Minden, 11800, Penang, Malaysia; Lebai Lutfi S., School of Computer Sciences, Universiti Sains Malaysia, Minden, 11800, Penang, Malaysia","Speech Synthesis plays an important role in enhancing human-machine interaction. In recent decades, researchers are paying more attention on the emotional expression in the synthetic voice. This is because the appropriate emotion can help improve the naturalness of the synthetic voice and thus increase its acceptability by the public. This project aims at developing a HMM-based Malay emotional speech synthesizer that is practical to be deployed in real life application. In order to make it applicable to the public, an Expressive Malay Online Speech Interface (EMOSI) that is able to synthesize any form of Malay text input in different expression will be created. © Springer Nature Singapore Pte Ltd. 2019.","Emotional expression; HMM; Malay; Speech synthesis","Robotics; Speech synthesis; Emotional expressions; Emotional speech; Human machine interaction; Malay; Malay texts; Online speech; Real-life applications; Synthetic voices; Computer vision","","","","","","","Trueba J., Design and Test of an Expressive Speech Synthesis System Based on Speaker Adaptation Techniques (Unpublished master’s Thesis), (2012); Hofer G.O., Emotional Speech Synthesis (Unpublished master’s Thesis); Text to Speech; Ze H., Senior A., Schuster M., Statistical parametric speech synthesis using deep neural networks, 2013 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 7962-7966, (2013); Tien-Ping T., Ranaivo-Malancon B., Malay Grapheme to Phoneme Tool for Automatic Speech Recognition; Hanifa R., Isa K., Mohamad S., Malay speech recognition for different ethnic speakers: An exploratory study, IEEE Symp. Comput. Appl. Ind. Electron. (ISCAIE), pp. 91-96, (2017); Cherry K., What are the 6 Major Theories of Emotion?; Gunes H., Automatic, Dimensional and Continuous Emotion Recognition, (2010); Posner J., Russell J.A., Peterson B.S., The circumplex model of affect: An integrative approach to affective neuroscience, cognitive development, and psychopathology, Dev. Psychopathol., 17, 3, pp. 715-734, (2005); El-Imam Y.A., Don Z.M., Text-to-speech conversion of standard Malay, Int. J. Speech Technol., 3, 2, pp. 129-146, (2000); How Words Can Be Misleading: A Study of Syllable Timing and ‘stress’ in Malay, (2017); Yamagishi J., The Centre for Speech Technology Research [Web Log Post]; (2007)","S. Lebai Lutfi; School of Computer Sciences, Universiti Sains Malaysia, Minden, 11800, Malaysia; email: syaheerah@usm.my","Md Zawawi M.A.; Teoh S.S.; Abdullah N.B.; Mohd Sazali M.I.S.","Springer Verlag","","10th International Conference on Robotic, Vision, Signal Processing and Power Applications, ROVISP 2018","14 August 2018 through 15 August 2018","Penang","225019","18761100","978-981136446-4","","","English","Lect. Notes Electr. Eng.","Conference paper","Final","","Scopus","2-s2.0-85064590010"
"Lahasan B.M.; Venkat I.; Al-Betar M.A.; Lutfi S.L.; Wilde P.D.","Lahasan, Badr Mohammed (56768228800); Venkat, Ibrahim (36338095000); Al-Betar, Mohammed Azmi (57202908939); Lutfi, Syaheerah Lebai (27567802400); Wilde, Philippe De (8275283600)","56768228800; 36338095000; 57202908939; 27567802400; 8275283600","Recognizing faces prone to occlusions and common variations using optimal face subgraphs","2016","Applied Mathematics and Computation","283","","","316","332","16","8","10.1016/j.amc.2016.02.047","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84977612501&doi=10.1016%2fj.amc.2016.02.047&partnerID=40&md5=16570a31806b12cf6cdf0e2b2357f525","School of Computer Sciences, Universiti Sains Malaysia (USM), Penang, 11800, Malaysia; Department of Computer Science, Faculty of Education-Shabwa, University of Aden, PO Box 6312, Aden, Yemen; Department of Information Technology, Al-Huson University College, Al-Balqa Applied University, Al-Huson, P.O. Box 50, Irbid, Jordan; Pro-Vice-Chancellor Research & Innovation, The University of Kent, Canterbury Kent CT2 7NZ, United Kingdom","Lahasan B.M., School of Computer Sciences, Universiti Sains Malaysia (USM), Penang, 11800, Malaysia, Department of Computer Science, Faculty of Education-Shabwa, University of Aden, PO Box 6312, Aden, Yemen; Venkat I., School of Computer Sciences, Universiti Sains Malaysia (USM), Penang, 11800, Malaysia; Al-Betar M.A., Department of Information Technology, Al-Huson University College, Al-Balqa Applied University, Al-Huson, P.O. Box 50, Irbid, Jordan; Lutfi S.L., School of Computer Sciences, Universiti Sains Malaysia (USM), Penang, 11800, Malaysia; Wilde P.D., Pro-Vice-Chancellor Research & Innovation, The University of Kent, Canterbury Kent CT2 7NZ, United Kingdom","An intuitive graph optimization face recognition approach called Harmony Search Oriented-EBGM (HSO-EBGM) inspired by the classical Elastic Bunch Graph Matching (EBGM) graphical model is proposed in this contribution. In the proposed HSO-EBGM, a recent evolutionary approach called harmony search optimization is tailored to automatically determine optimal facial landmarks. A novel notion of face subgraphs have been formulated with the aid of these automated landmarks that maximizes the similarity entailed by the subgraphs. For experimental evaluation, two sets of de facto databases (i.e., AR and Face Recognition Grand Challenge (FRGC) ver2.0) are used to validate and analyze the behavior of the proposed HSO-EBGM in terms of number of subgraphs, varying occlusion sizes, face images under controlled/ideal conditions, realistic partial occlusions, expression variations and varying illumination conditions. For a number of experiments, results justify that the HSO-EBGM shows improved recognition performance when compared to recent state-of-the-art face recognition approaches. © 2016 Elsevier Inc.","Face recognition; Graphical model; Harmony search; Occlusion; Optimization","Computer graphics; Graphic methods; Optimization; Elastic bunch graph matching; Experimental evaluation; Face recognition grand challenges; GraphicaL model; Harmony search; Harmony search optimizations; Illumination conditions; Occlusion; Face recognition","","","","","Universiti Sains Malaysia","This research is supported by the RUI Grant: RUI#1001/pkomp/811290 awarded by Universiti Sains Malaysia.    ","Abdullah M.F.A., Sayeed M.S., Muthu K.S., Bashier H.K., Azman A., Ibrahim S.Z., Face recognition with symmetric local graph structure (slgs), Expert Syst. Appl., 41, 14, pp. 6131-6137, (2014); Abdulrahman M., Gwadabe T.R., Abdu F.J., Eleyan A., Gabor wavelet transform based facial expression recognition using pca and lbp, Proceedings of the 2014 Twenty Second IEEE Signal Processing and Communications Applications Conference (SIU), pp. 2265-2268, (2014); Abual-Rub M.S., Al-Betar M.A., Abdullah R., Khader A.T., A hybrid harmony search algorithm for ab initio protein tertiary structure prediction, Netw. Model. Anal. Health Inf. Bioinform., 1, 3, pp. 69-85, (2012); Al-Betar M.A., Doush I.A., Khader A.T., Awadallah M.A., Novel selection schemes for harmony search, Appl. Math. Comput., 218, 10, pp. 6095-6117, (2012); Al-Betar M.A., Khader A.T., A harmony search algorithm for university course timetabling, Ann. OR, 194, 1, pp. 3-31, (2012); Al-Betar M.A., Khader A.T., Doush I.A., Memetic techniques for examination timetabling, Ann. OR, 218, 1, pp. 23-50, (2014); Al-Betar M.A., Khader A.T., Zaman M., University course timetabling using a hybrid harmony search metaheuristic algorithm, IEEE Trans. Syst. Man Cybern Part C Appl. Rev., 42, 5, pp. 664-681, (2012); Alia O., Mandava R., The variants of the harmony search algorithm: an overview, Artif. Intell. Rev., 36, pp. 49-68, (2011); Alkareem Y.A.Z.A., Venkat I., Al-Betar M.A., Khader A.T., Edge preserving image enhancement via harmony search algorithm, Proceedings of the Fourth Conference on Data Mining and Optimization, DMO 2012, Langkawi, Malaysia, pp. 47-52, (2012); Azeem A., Sharif M., Raza M., Murtaza M., A survey: face recognition techniques under partial occlusion., Int. Arab. J. Inf. Technol., 11, 1, pp. 1-10, (2014); Bolme D.S., Thesis On Elastic Bunch Graph Matching, (2003); Borgi M.A., Labate D., El Arbi M., Amar C.B., Sparse multi-stage regularized feature learning for robust face recognition, Expert Syst. Appl., 42, 1, pp. 269-279, (2015); Chen W., Gao Y., Face recognition using ensemble string matching, IEEE Trans. Image Process., 22, 12, pp. 4798-4808, (2013); Deng Y., Dai Q., Zhang Z., Graph Laplace for occluded face completion and recognition, IEEE Trans. Image Process., 20, 8, pp. 2329-2338, (2011); Ekenel H.K., Stiefelhagen R., Why is facial occlusion a challenging problem?, Advances in Biometrics, 5558, pp. 299-308, (2009); Ensari T., Chorowski J., Zurada J., Occluded face recognition using correntropy-based nonnegative matrix factorization, Proceedings of the 2012 Eleventh International Conference on Machine Learning and Applications (ICMLA), 1, pp. 606-609, (2012); Gao J.-Q., Fan L.-Y., Xu L.-Z., Median null (sw)-based method for face feature recognition, Appl. Math. Comput., 219, 12, pp. 6410-6419, (2013); Gao Y., Leung M.K., Face recognition using line edge map, IEEE Trans. Pattern Anal. Mach. Intell., 24, 6, pp. 764-779, (2002); Geem Z.W., Optimal scheduling of multiple dam system using harmony search algorithm, Computational and Ambient Intelligence, pp. 316-323, (2007); Geem Z.W., Novel derivative of harmony search algorithm for discrete design variables, Appl. Math. Comput., 199, 1, pp. 223-230, (2008); Geem Z.W., Kim J.H., Loganathan G., A new heuristic optimization algorithm: harmony search, Simulation, 76, 2, pp. 60-68, (2001); Gonzalez R.C., Woods R.E., (2002); Kanan H.R., Faez K., Recognizing faces using adaptively weighted sub-Gabor array from a single sample image per enrolled subject, Image Vis. Comput., 28, 3, pp. 438-448, (2010); Kanan H.R., Faez K., Gao Y., Face recognition using adaptively weighted patch pzm array from a single exemplar image per person, Pattern Recognit., 41, 12, pp. 3799-3812, (2008); Kumar D., Et al., Harmony search algorithm for feature selection in face recognition, Computational Intelligence and Information Technology, pp. 554-559, (2011); Lades M., Vorbruggen J., Buhmann J., Lange J., Von Der Malsburg C., Wurtz R., Konen W., Distortion invariant object recognition in the dynamic link architecture, IEEE Trans. Comput., 42, 3, pp. 300-311, (1993); Lee K., Geem Z., A new structural optimization method based on the harmony search algorithm, Comput. Struct., 82, 9-10, pp. 781-798, (2004); Li X.X., Dai D.Q., Zhang X.F., Ren C.X., Structured sparse error coding for face recognition with occlusion, IEEE Trans. Image Process., 22, 5, pp. 1889-1900, (2013); Manjarres D., Landa-Torres I., Gil-Lopez S., Del Ser J., Bilbao M., Salcedo-Sanz S., Geem Z., A survey on applications of the harmony search algorithm, Eng. Appl. Artif. Intell., 26, 8, pp. 1818-1831, (2013); Martinez A.M., Recognizing imprecisely localized, partially occluded, and expression variant faces from a single sample per class, IEEE Trans. Pattern Anal. Mach. Intell., 24, 6, pp. 748-763, (2002); Martinez A.M., The AR face database, CVC Technical Report, 24, (1998); Min R., Hadid A., Dugelay J.-L., Improving the recognition of faces occluded by facial accessories, 2011 IEEE International Conference on Automatic Face & Gesture Recognition and Workshops (FG 2011), pp. 442-447, (2011); Phillips P.J., Flynn P.J., Scruggs T., Bowyer K.W., Chang J., Hoffman K., Marques J., Min J., Worek W., Overview of the face recognition grand challenge, Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, CVPR 2005, 1, pp. 947-954, (2005); Phillips P.J., Moon H., Rizvi S., Rauss P.J., Et al., The Feret evaluation methodology for face-recognition algorithms, IEEE Trans. Pattern Anal. Mach. Intell, 22, 10, pp. 1090-1104, (2000); Sawalha R., Doush I.A., Face recognition using harmony search-based selected features., Int. J. Hybrid Inf. Technol., 5, 2, pp. 1-16, (2012); Senaratne R., Halgamuge S., Hsu A., Face recognition by extending elastic bunch graph matching with particle swarm optimization, J. Multimed., 4, 4, pp. 204-214, (2009); Sinha P., Balas B., Ostrovsky Y., Russell R., Face recognition by humans: Nineteen results all computer vision researchers should know about, Proc. IEEE, 94, 11, pp. 1948-1962, (2006); Venkat I., Khader A.T., Subramanian K., Wilde P.D., Recognizing occluded faces by exploiting psychophysically inspired similarity maps, Pattern Recognit. Lett., 34, 8, pp. 903-911, (2013); Wei X., Li C.-T., Lei Z., Yi D., Li S.Z., Dynamic image-to-class warping for occluded face recognition, IEEE Trans. Inf. Forensics Secur., 9, 12, pp. 2035-2050, (2014); Wiskott L., Fellous J.-M., Kuiger N., Von der Malsburg C., Face recognition by elastic bunch graph matching, IEEE Trans. Pattern Anal. Mach. Intell., 19, 7, pp. 775-779, (1997); Wright J., Yang A., Ganesh A., Sastry S., Ma Y., Robust face recognition via sparse representation, IEEE Trans. Pattern Anal. Mach. Intell., 31, 2, pp. 210-227, (2009); Xiaorong P., Zhihu Z., Heng T., Tai L., Partially occluded face recognition using subface hidden markov models, Proceedings of the 2012 Seventh International Conference on Computing and Convergence Technology (ICCCT), pp. 720-725, (2012); Yan H., Wang P., Chen W.D., Liu J., Face Recognition Based on Gabor Wavelet Transform and Modular 2DPCA, International Conference on Power Electronics and Energy Engineering (PEEE 2015), pp. 245-248, (2015); Yang A., Zhou Z., Balasubramanian A., Sastry S., Ma Y., Fast ℓ<sub>1</sub>- minimization algorithms for robust face recognition, IEEE Trans. Image Process., 22, 8, pp. 3234-3246, (2013); Zhao Y., Liu Y., Liu Y., Zhong S., Hua K.A., Face recognition from a single registered image for conference socializing, Expert Syst. Appl., 42, 3, pp. 973-979, (2015)","B.M. Lahasan; School of Computer Sciences, Universiti Sains Malaysia (USM), Penang, 11800, Malaysia; email: bmo12_com009@student.usm.my","","Elsevier Inc.","","","","","","00963003","","AMHCB","","English","Appl. Math. Comput.","Article","Final","All Open Access; Green Open Access","Scopus","2-s2.0-84977612501"
"Burhanuddin M.B.B.; Lutfi S.L.","Burhanuddin, Muhammad Bukhari Bin (57193737736); Lutfi, Syaheerah Lebai (27567802400)","57193737736; 27567802400","Detection of shyness in smiles","2017","Proceedings - 2016 4th International Conference on User Science and Engineering, i-USEr 2016","","","7857948","133","138","5","0","10.1109/IUSER.2016.7857948","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85016170141&doi=10.1109%2fIUSER.2016.7857948&partnerID=40&md5=871cd2ebe16d3cfd0bb241e57f53ec6d","School of Computer Sciences, Universiti Sains Malaysia, Georgetown, Penang, 11800, Malaysia","Burhanuddin M.B.B., School of Computer Sciences, Universiti Sains Malaysia, Georgetown, Penang, 11800, Malaysia; Lutfi S.L., School of Computer Sciences, Universiti Sains Malaysia, Georgetown, Penang, 11800, Malaysia","Automatic recognition of emotion through facial expressions remains an active area of study. This study concerns the detection of shyness in smiles. As far as our knowledge is concerned, detecting the emotion of shyness through smile thus far has not been studied. Experiment was conducted where test subjects underwent an experiment with a stimuli designed to elicit shyness in their smiles. The expected results will be able to distinguish between shy-smile and non-shy smile. This paper reports the design of the data collection and the results obtained from the experiment. © 2016 IEEE.","detection; machine learning; shyness; smile","Engineering; Error detection; Industrial engineering; Active area; Automatic recognition of emotions; Data collection; Facial Expressions; shyness; smile; Learning systems","","","","","","","Kadzin A.E., Encyclopedia of psychology, American Psychological Association, 8, (2000); Hoque M.E., McDuff D.J., Picard R.W., Exploring temporal patterns in classifying frustrated and delighted smiles, Affective Computing, IEEE Transactions on, 3, 3, pp. 323-334, (2012); Malouff J., Helping Young Children Overcome Shyness, (1998); McCormick M.P., Cappella E., Oconnor E.E., McClowry S.G., Context matters for social-emotional learning: Examining variation in program impact by dimensions of school climate, American Journal of Community Psychology, 56, 1-2, pp. 101-119, (2015); Zabid A.M., Ling C., Malaysian employer perceptions about local and foreign mba graduates, Journal of Education for Business, 79, 2, pp. 111-117, (2003); Tao J., Tan T., Affective computing: A review, Affective Computing and Intelligent Interaction, pp. 981-995, (2005); Picard R.W., Affective Computing; Heiser N.A., Turner S.M., Beidel D.C., Shyness: Relationship to social phobia and other psychiatric disorders, Behaviour Research and Therapy, 41, 2, pp. 209-221, (2003); Mishra P., Affective feedback from computers and its effect on perceived ability and affect: A test of the computers as social actor hypothesis, Journal of Educational Multimedia and Hypermedia, 15, 1, (2006); Sheeks M.S., Birchmeier Z.P., Shyness, sociability, and the use of computer-mediated communication in relationship development, CyberPsychology & Behavior, 10, 1, pp. 64-70, (2007); Hoque M., Picard R.W., Acted vs. Natural frustration and delight: Many people smile in natural frustration, Automatic Face & Ges-ture Recognition and Workshops (FG 2011), 2011 IEEE International Conference On. IEEE, pp. 354-359, (2011); Lu J., Allwood J., Ahlsen E., A study on cultural variations of smile based on empirical recordings of Chinese and swedish first encounters, Jia, 46, 31, (2011); Afshan A., Askari I., Manickam L.S.S., Shyness, self-construal, extraversion-introversion, neuroticism, and psychoticism, SAGE Open, 5, 2, (2015); Crozier W.R., Shyness, self-perception, and reticence, Self-perception: International Perspectives on Individual Differences, 2, pp. 53-76, (2001); Crozier W.R., Shyness and students' perceptions of seminars, Psychology Learning & Teaching, 4, 1, pp. 27-34, (2005); Mann S., Emotional labour in organizations, Leadership & Organization Development Journal, 18, 1, pp. 4-12, (1997); Kokin J., Facial expression recognition and interpretation in shy children, Ph.D. Dissertation, University of Ottawa, (2015); London B., Downey G., Bonica C., Paltin I., Social causes and consequences of rejection sensitivity, Journal of Research on Adolescence, 17, 3, pp. 481-506, (2007); Sessa F.M., Avenevoli S., Steinberg L., Morris A.S., Correspondence among informants on parenting: Preschool children, mothers, and observers, Journal of Family Psychology, 15, 1, (2001); Hopko D.R., Stowell J., Jones W.H., Armento M.E., Cheek J.M., Psychometric properties of the revised cheek and buss shyness scale, Journal of Personality Assessment, 84, 2, pp. 185-192, (2005); Cheek J.M., Melchior L.A., Carpentieri A.M., Shyness and selfconcept, Perception of Self in Emotional Disorder and Psychotherapy, pp. 113-131, (1986); Rimmer J., Good J., Harris E., Balaam M., Class participation and shyness: Affect and learning to program, The 23rd Annual Workshop of Psychology of Programmers Interest Group (PPIG), (2011); Kreijns K., Kirschner P.A., Jochems W., Van Buuren H., Measuring perceived sociability of computer-supported collaborative learning environments, Computers & Education, 49, 2, pp. 176-192, (2007); Glover S., Catarina A., Chami N., People React to Being Called Beautiful. Chicago High School for the Art; Cowie R., Sawey M., Gtrace-general Trace Program from Queens, (2011); Plutchik R., The nature of emotions human emotions have deep evolutionary roots, a fact that may explain their complexity and provide tools for clinical practice, American Scientist, 89, 4, pp. 344-350, (2001); Dahlback N., Jonsson A., Ahrenberg L., Wizard of oz studies: Why and how, Proceedings of the 1st International Conference on Intelligent User Interfaces. ACM, pp. 193-200, (1993); Henderson L., Zimbardo P., Graham J., Social fitness and technology use: Adolescent interview study, USA: StanfordUniversity and Shyness Institute, (2002)","","","Institute of Electrical and Electronics Engineers Inc.","","4th International Conference on User Science and Engineering, i-USEr 2016","23 August 2016 through 25 August 2016","Melaka","126522","","978-150902631-9","","","English","Proc. - Int. Conf. User Sci. Eng., i-USEr","Conference paper","Final","","Scopus","2-s2.0-85016170141"
"Azazi A.; Lutfi S.L.; Venkat I.","Azazi, Amal (56606204300); Lutfi, Syaheerah Lebai (27567802400); Venkat, Ibrahim (36338095000)","56606204300; 27567802400; 36338095000","Identifying universal facial emotion markers for automatic 3D facial expression recognition","2014","2014 International Conference on Computer and Information Sciences, ICCOINS 2014 - A Conference of World Engineering, Science and Technology Congress, ESTCON 2014 - Proceedings","","","6868369","","","","4","10.1109/ICCOINS.2014.6868369","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938786473&doi=10.1109%2fICCOINS.2014.6868369&partnerID=40&md5=2480a786f14e761d76a74077957e3777","School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, Malaysia","Azazi A., School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, Malaysia; Lutfi S.L., School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, Malaysia; Venkat I., School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, Malaysia","Facial expressions convey human emotions as a simple and effective non-verbal communication method. Motivated by this special characteristic, facial expression recognition rapidly gains attention in social computing fields, especially in Human Computer Interaction (HCI). Identifying the optimal set of facial emotion markers is an important technique that not only reduces the feature vector dimensionality, but also impacts the recognition accuracy. In this paper, we propose a new emotion marker identification algorithm for automatic and person-independent 3D facial expression recognition system. First, we mapped the 3D face images into the 2D plane via conformal geometry to reduce the dimensionality. Then, the identification algorithm is designed to seek the best discriminative markers and the classifier parameters simultaneously by integrating three techniques viz., Differential Evolution (DE), Support Vector Machine (SVM) and Speed Up Robust Feature (SURF). The proposed system yielded an average recognition rate of 79% and outperformed the previous studies using the Bosphorus database. © 2014 IEEE.","3D facial expression recognition; DE; Emotion marker identification; HCI; SURF; SVM","Evolutionary algorithms; Human computer interaction; Optimization; Social computing; Support vector machines; 3-D facial expression recognition; Differential Evolution; Facial expression recognition; Human computer interaction (HCI); Identification algorithms; Marker identifications; Non-verbal communications; SURF; Face recognition","","","","","","","Ekman P., Friesen W.V., Measuring facial movement, Environmental Psychology and Nonverbal Behavior, 1, 1, pp. 56-75, (1976); Pantic M., Rothkrantz L.J.M., Automatic analysis of facial expressions: The state of the art, IEEE Transactions on Pattern Analysis and Machine Intelligence, 22, 12, pp. 1424-1445, (2000); Sandbach G., Zafeiriou S., Pantic M., Yin L., Static and dynamic 3D facial expression recognition: A comprehensive survey, Image and Vision Computing, (2012); Valstar M.F., Mehu M., Jiang B., Pantic M., Scherer K., Metaanalysis of the first facial expression recognition challenge, IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics, 42, 4, pp. 966-979, (2012); Storn R., Price K., Differential evolution-a simple and efficient heuristic for global optimization over continuous spaces, Jornal of Global Optimization, 11, 4, pp. 341-359, (1997); Deb K., Multi-objective optimization, Multi-objective Optimization Using Evolutionary Algorithms, pp. 13-46, (2001); Mishra S., Global Optimization by Differential Evolution and Particle Swarm Methods: Evaluation on Some Benchmark Functions, (2006); Rosato M., Chen X., Yin L., Automatic registration of vertex correspondences for 3D facial expression analysis, 2nd IEEE International Conference on Biometrics: Theory, Applications and Systems. IEEE, pp. 1-7, (2008); Vretos N., Nikolaidis N., Pitas I., 3D facial expression recognition using zernike moments on depth images, 18th IEEE International Conference on Image Processing (ICIP). IEEE, pp. 773-776, (2011); Berretti S., Amor B.B., Daoudi M., Del Bimbo A., 3D facial expression recognition using sift descriptors of automatically detected keypoints, The Visual Computer, 27, 11, pp. 1021-1036, (2011); Li X., Ruan Q., An G., Ruan C., 3D facial expression recognition based on variation faces, IEEE 11th International Conference on Signal Processing (ICSP), 1, pp. 775-778, (2012); Lemaire P., Chen L., Ardabilian M., Daoudi M., Et al., Fully automatic 3D facial expression recognition using differential mean curvature maps and histograms of oriented gradients, Workshop 3D Face Biometrics, (2013); Chun S.-Y., Lee C.-S., Lee S.-H., Facial expression recognition using extended local binary patterns of 3D curvature, Multimedia and Ubiquitous Engineering, pp. 1005-1012, (2013); Wang Y., Meng M., Zhen Q., Learning encoded facial curvature information for 3D facial emotion recognition, International Conference on Image and Graphics. IEEE, pp. 529-532, (2013); Liu H., Yu L., Toward integrating feature selection algorithms for classification and clustering, IEEE Transactions on Knowledge and Data Engineering, 17, 4, pp. 491-502, (2005); Yang J., Honavar V., Feature subset selection using a genetic algorithm, Feature Extraction, Construction and Selection, pp. 117-136, (1998); Tang H., Huang T.S., 3D facial expression recognition based on automatically selected features, IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops. IEEE, pp. 1-8, (2008); Soyel H., Demirel H., Optimal feature selection for 3D facial expression recognition with geometrically localized facial features, Fifth International Conference on Soft Computing, Computing with Words and Perceptions in System Analysis, Decision and Control (ICSCCW). IEEE, pp. 1-4, (2009); Tekguc U., Soyel H., Demirel H., Feature selection for personindependent 3D facial expression recognition using NSGA-II, 24th International Symposium on Computer and Information Sciences (ISCIS). IEEE, pp. 35-38, (2009); Soyel H., Tekguc U., Demirel H., Application of NSGA-II to feature selection for facial expression recognition, Computers & Electrical Engineering, 37, 6, pp. 1232-1240, (2011); Sun Y., Yin L., Evaluation of 3D facial feature selection for individual facial model identification, 18th International Conference on Pattern Recognition (ICPR), 4, pp. 562-565, (2006); Gu X., Wang Y., Chan T.F., Thompson P.M., Yau S.-T., Genus zero surface conformal mapping and its application to brain surface mapping, IEEE Transactions on Medical Imaging, 23, 8, pp. 949-958, (2004); Wang S., Wang Y., Jin M., Gu X.D., Samaras D., Conformal geometry and its applications on 3D shape matching, recognition, and stitching, IEEE Transactions on Pattern Analysis and Machine Intelligence, 29, 7, pp. 1209-1220, (2007); Szeptycki P., Ardabilian M., Chen L., Zeng W., Gu D., Samaras D., Conformal mapping-based 3D face recognition, Fifth International Symposium on 3D Data Processing, Visualization and Transmission( 3DPVT), pp. 1-8, (2010); Gu X., Yau S.-T., Global conformal surface parameterization, Proceedings of the 2003 Eurographics/ACM SIGGRAPH Symposium on Geometry Processing, pp. 127-137, (2003); Gu X.D., Yau S.-T., Computational Conformal Geometry, 3, (2008); Eck M., Derose T., Duchamp T., Hoppe H., Lounsbery M., Stuetzle W., Multiresolution analysis of arbitrary meshes, Proceedings of the 22nd Annual Conference on Computer Graphics and Interactive Techniques. ACM, pp. 173-182, (1995); Uricar M., Franc V., Hlavac V., Detector of facial landmarks learned by the Structured Output SVM, Proceedings of International Conference on Computer Vision Theory and Applications, 1, pp. 547-556, (2012); Bay H., Tuytelaars T., Gool L.V., SURF: Speeded up robust features, Proceedings of the Ninth European Conference on Computer Vision, pp. 404-417, (2006); Lowe D.G., Distinctive image features from scale-invariant keypoints, International Journal of Computer Vision, 60, 2, pp. 91-110, (2004); Savran A., Alyuz N., Dibeklioglu H., Eliktutan O.C., Gokberk B., Sankur B., Akarun L., Bosphorus database for 3D face analysis, Biometrics and Identity Management, pp. 47-56, (2008)","","","Institute of Electrical and Electronics Engineers Inc.","","2014 International Conference on Computer and Information Sciences, ICCOINS 2014","3 June 2014 through 5 June 2014","Kuala Lumpur","112912","","978-147994391-3","","","English","Int. Conf. Comput. Inf. Sci., ICCOINS - Conf. World Eng., Sci. Technol. Congr., ESTCON - Proc.","Conference paper","Final","","Scopus","2-s2.0-84938786473"
"Lucas-Cuesta J.M.; Fernández-Martínez F.; Rada G.D.; Lutfi S.L.; Ferreiros J.","Lucas-Cuesta, Juan Manuel (26664791600); Fernández-Martínez, Fernando (6602973640); Rada, G. Dragos (42662153900); Lutfi, Syaheerah L. (27567802400); Ferreiros, Javier (12345343100)","26664791600; 6602973640; 42662153900; 27567802400; 12345343100","Evaluation of a user-adapted spoken language dialogue system: Measuring the relevance of the contextual information sources","2011","ICAART 2011 - Proceedings of the 3rd International Conference on Agents and Artificial Intelligence","1","","","218","223","5","1","","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79960109523&partnerID=40&md5=76c0b7152179992e524605eeba6dc3e3","Speech Technology Group, Universidad Politécnica de Madrid, Madrid, Spain","Lucas-Cuesta J.M., Speech Technology Group, Universidad Politécnica de Madrid, Madrid, Spain; Fernández-Martínez F., Speech Technology Group, Universidad Politécnica de Madrid, Madrid, Spain; Rada G.D., Speech Technology Group, Universidad Politécnica de Madrid, Madrid, Spain; Lutfi S.L., Speech Technology Group, Universidad Politécnica de Madrid, Madrid, Spain; Ferreiros J., Speech Technology Group, Universidad Politécnica de Madrid, Madrid, Spain","We present an evaluation of a spoken language dialogue system with a module for the management of user-related information, stored as user preferences and privileges. The flexibility of our dialogue management approach, based on Bayesian Networks (BN), together with a contextual information module, which performs different strategies for handling such information, allows us to include user information as a new level into the Context Manager hierarchy. We propose a set of objective and subjective metrics to measure the relevance of the different contextual information sources. The analysis of our evaluation scenarios shows that the relevance of the short-term information (i.e. the system status) remains pretty stable throughout the dialogue, whereas the dialogue history and the user profile (i.e. the middle-term and the long-term information, respectively) play a complementary role, evolving their usefulness as the dialogue evolves.","Contextual information; Natural language processing; Real-user evaluation; Spoken language dialogue systems; User interfaces; User profiles","Artificial intelligence; Bayesian networks; Computational linguistics; Inference engines; Natural language processing systems; Speech processing; User interfaces; Contextual information; NAtural language processing; Real-user evaluation; Spoken language dialogue system; User profile; Information management","","","","","","","Callejas Z., Lopez-Cozar R., Relations between de-facto criteria in the evaluation of a spoken dialogue system, Speech Communication, 50, pp. 646-665, (2008); Chin D., Empirical Evaluation of User Models and User-Adapted Systems, User Modeling and User-Adapted Interaction, 11, pp. 181-194, (2001); Dybkjaer L., Bernsen N., Minker W., Evaluation and usability of multimodal spoken language dialogue systems, Speech Communication, 43, pp. 33-54, (2004); Fernandez F., Blazquez J., Ferreiros J., Barra R., Macias-Guarasa J., Lucas-Cuesta J., Evaluation of a Spoken Dialogue System for Controlling a Hifi Audio System, Proceedings of the IEEE Workshop on Spoken Language Technology (SLT08), pp. 137-140, (2008); Fernandez R., Ferreiros J., Sama V., Montero J., San-Segundo R., Macias-Guarasa J., Speech Interface for Controlling a Hi-Fi Audio System Based on a Bayesian Belief Networks Approach for Dialog Modeling, Proceedings of the 9th European Conference on Speech Communication and Technology (INTERSPEECH05), pp. 3421-3424, (2005); Gena C., Methods and Techniques for the Evaluation of User-Adaptive Systems, The Knowledge Engineering Review, 20, 1, pp. 1-37, (2005); Litman D.J., Pan S., Designing and evaluating an adaptive spoken dialogue system, User Modelling and User-Adapted Interaction, 12, 2-3, pp. 111-137, (2002); Lucas-Cuesta J., Fernandez F., Salazar J., Ferreiros J., San-Segundo R., Managing Speaker Identity and User Profiles in a Spoken Dialogue System, Sociedad Espanola de Procesamiento de Lenguaje Natural (SEPLN), 43, pp. 77-84, (2009); Moller S., Smeele P., Boland H., Krebber J., Evaluating Spoken Dialogue Systems According to De-Facto Standards: A Case Study, Computer, Speech and Language, 21, pp. 26-53, (2007); Walker M., Litman D., Kamm C., Abella A., PARADISE: A Framework for Evaluating Spoken Dialogue Agents, Proceedings ACL/EACL, pp. 271-280, (1997); Zukerman I., Litman D., Natural language processing and user modeling: Synergies and limitations, User Modelling and User-Adapted Interaction, 11, 1-2, pp. 129-158, (2001)","J. M. Lucas-Cuesta; Speech Technology Group, Universidad Politécnica de Madrid, Madrid, Spain; email: juanmak@die.upm.es","","","Inst. Syst. Technol. Inf., Control Commun. (INSTICC)","3rd International Conference on Agents and Artificial Intelligence, ICAART 2011","28 January 2011 through 30 January 2011","Rome","85505","","978-989842540-9","","","English","ICAART - Proc. Int. Conf. Agents Artif. Intell.","Conference paper","Final","","Scopus","2-s2.0-79960109523"
"Lahasan B.M.; Venkat I.; Lutfi S.L.","Lahasan, Badr Mohammed (56768228800); Venkat, Ibrahim (36338095000); Lutfi, Syaheerah Lebai (27567802400)","56768228800; 36338095000; 27567802400","Recognition of occluded faces using an enhanced EBGM algorithm","2014","2014 International Conference on Computer and Information Sciences, ICCOINS 2014 - A Conference of World Engineering, Science and Technology Congress, ESTCON 2014 - Proceedings","","","6868371","","","","3","10.1109/ICCOINS.2014.6868371","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84938786134&doi=10.1109%2fICCOINS.2014.6868371&partnerID=40&md5=2b0ae9312adf252f8183d2daa9d81eed","School of Computer Sciences, Universiti Sains Malaysia, Penang, Malaysia","Lahasan B.M., School of Computer Sciences, Universiti Sains Malaysia, Penang, Malaysia; Venkat I., School of Computer Sciences, Universiti Sains Malaysia, Penang, Malaysia; Lutfi S.L., School of Computer Sciences, Universiti Sains Malaysia, Penang, Malaysia","A new approach to recognize occluded faces is presented in this paper to enhance the conventional Elastic Bunch Graph Matching (EBGM) technique. In the conventional EBGM approach, facial landmarks need to be chosen manually in the initial stage and a single graph per face had been modeled. Our proposed approach intuitively fuses a Harmony search based optimization algorithm over the EBGM approach to automatically choose optimal land marks for a given face. Further, instead of using a single graph, we deploy component level sub-graphs and locate optimal landmarks by maximizing the similarity between each of the sub-graphs. Experimental results show that the proposed automatic method achieves an improved recognition rate when compared to the conventional EBGM approach. © 2014 IEEE.","Elastic bunch graph maching; Face recognition; Facial occlusion; Harmony search; Similarity measure","Pattern matching; Automatic method; Component levels; Elastic bunch graph matching; Elastic bunch graphs; Facial landmark; Facial occlusions; Harmony search; Similarity measure; Face recognition","","","","","","","Min R., Hadid A., Dugelay J., Improving the Recognition of Faces Occluded by Facial Accessories, pp. 442-447, (2011); Ekenel H.M., Stiefelhagen R., Why is Facial Occlusion A Challenging Problem, 5558, pp. 299-308, (2009); Martinez A.M., Recognizing imprecisely localized, partially occluded, and expression variant faces from a single sample per class, Pattern Analysis and Machine Intelligence, IEEE Transactions on, 24, 6, pp. 748-763, (2002); Wright J., Yang A., Ganesh A., Sastry S., Ma Y., Robust face recognition via sparse representation, Pattern Analysis and Machine Intelligence, IEEE Transactions on, 31, 2, pp. 210-227, (2009); Venkat I., Khader A.T., Subramanian K., Wilde P.D., Recognizing occluded faces by exploiting psychophysically inspired similarity maps, Pattern Recognition Letters, 34, 8, pp. 903-911, (2013); Wiskott L., Fellous J.-M., Kuiger N., Malsburg Der C.Von, Face recognition by elastic bunch graph matching, Pattern Analysis and Machine Intelligence, IEEE Transactions on, 19, 7, pp. 775-779, (1997); Bolme D.S., Thesis on Elastic Bunch Graph Matching, (2003); Geem J.H.L.G.V., Kim Z.W., A new heuristic optimization algorithm: Harmony search, Simulation, 76, pp. 60-68, (2001); Geem C.L.P.Y., Tseng Z.W., Harmony Search for Generalized Orienteering Problem: Best Touring in China, 3612, pp. 741-750, (2005); The ORL Database of Faces, Developed by AT&T Laboratories Cambridge","","","Institute of Electrical and Electronics Engineers Inc.","","2014 International Conference on Computer and Information Sciences, ICCOINS 2014","3 June 2014 through 5 June 2014","Kuala Lumpur","112912","","978-147994391-3","","","English","Int. Conf. Comput. Inf. Sci., ICCOINS - Conf. World Eng., Sci. Technol. Congr., ESTCON - Proc.","Conference paper","Final","","Scopus","2-s2.0-84938786134"
