"Authors","Author full names","Author(s) ID","Title","Year","Source title","Volume","Issue","Art. No.","Page start","Page end","Page count","Cited by","DOI","Link","Affiliations","Authors with affiliations","Abstract","Author Keywords","Index Keywords","Molecular Sequence Numbers","Chemicals/CAS","Tradenames","Manufacturers","Funding Details","Funding Texts","References","Correspondence Address","Editors","Publisher","Sponsors","Conference name","Conference date","Conference location","Conference code","ISSN","ISBN","CODEN","PubMed ID","Language of Original Document","Abbreviated Source Title","Document Type","Publication Stage","Open Access","Source","EID"
"Talib N.A.; Rahman M.F.A.; Najib A.S.A.; Noor M.H.M.","Talib, N.A. (57196875994); Rahman, M.F.A. (55436750500); Najib, A.S.A. (57208525754); Noor, M.H.M. (36656106400)","57196875994; 55436750500; 57208525754; 36656106400","Implementation of piezoelectric sensor in gait measurement system","2019","Proceedings - 8th IEEE International Conference on Control System, Computing and Engineering, ICCSCE 2018","","","8685027","20","25","5","3","10.1109/ICCSCE.2018.8685027","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065027112&doi=10.1109%2fICCSCE.2018.8685027&partnerID=40&md5=b0176f7f163dff7a0ef5dcf214247b84","Faculty of Electrical Engineering, University Technology MARA Pulau Pinang, Permatang Pauh, Penang, 13500, Malaysia","Talib N.A., Faculty of Electrical Engineering, University Technology MARA Pulau Pinang, Permatang Pauh, Penang, 13500, Malaysia; Rahman M.F.A., Faculty of Electrical Engineering, University Technology MARA Pulau Pinang, Permatang Pauh, Penang, 13500, Malaysia; Najib A.S.A., Faculty of Electrical Engineering, University Technology MARA Pulau Pinang, Permatang Pauh, Penang, 13500, Malaysia; Noor M.H.M., Faculty of Electrical Engineering, University Technology MARA Pulau Pinang, Permatang Pauh, Penang, 13500, Malaysia","Gait measurement system may expose related fields for applications in sports, activity tracking, and in the treatment of specific diseases. Available technology such as image processing, force plate, and insole shoe device are showing that gait analysis is famous research study in a recent year. But the available method is more expensive with the used of wide area for experimental. Moreover, the used of image processing technique and force plate required a fix location as it need to be installed for subject recruitment. A wearable technology such as insole can help in this scenario by develop the measurement gait systems to a wide set of patients or healthy people. In this proposed project, the measurement for gait using low cost sensor is designed for gait pattern detection during walking. This present a force sensor that will designed using foot insole technique for real-time monitoring during walking. This device is made up of flexible insole with three piezo sensing elements using integrated electronic board of data acquisition, and monitoring system for data analysis. Design and development of the system is tested and the signal presented show a different force applied at different part of feet. System tested directly by performing some activity from 15 subjects who differed in body mass (range: 35-80 kg). Activity that is performs show a different signal pattern such as heel strike, midstance, stance, toe-off and walking activities. This project results have a possibility to increase the use of wearable device to capture the data with a relevant parameter as well as improve data analysis for a better system performance. © 2018 IEEE.","gait analysis; heel strike; insole; piezoelectric sensor; toe off; walking pattern","Control systems; Data acquisition; Data handling; Electric sensing devices; Gait analysis; Image processing; Information analysis; Pattern recognition; Piezoelectric devices; Piezoelectric transducers; Piezoelectricity; Wearable sensors; Heel strikes; insole; Piezoelectric sensors; toe off; Walking pattern; Monitoring","","","","","","","Web of Science [v.5.25.1]-Web of Science Core Collection Results; Domingues M.F., Et al., Insole optical fiber sensor architecturefor remote gait analysis-an eHealth Solution, IEEE Internet Things J., 99, (2017); Zhang X., Zhao Y., Duan Z., Liu Y., Design and test of a soft plantar force measurement system for gait detection, Sensors, 12, 12, pp. 16628-16640, (2012); Theologis T.N., Gait analysis, Children's Orthopaedics and Fractures, pp. 67-74, (2010); Kitayama I., Hada S., Kawauchi T., Yokota H., Hamada T., Development of a portable device for gait analysis, and gait analysis on stairs and uneven terrain, 6th World Congress of Biomechanics (WCB 2010), pp. 644-647, (2010); Howell A.M., Kobayashi T., Hayes H.A., Foreman K.B., Bamberg S.J.M., Kinetic gait analysis using a low-cost insole, IEEE Trans. Biomed. Eng, 60, 12, pp. 3284-3290, (2013); Lin F., Wang A., Zhuang Y., Tomita M.R., Xu W., Smart insole: A wearable sensor device for unobtrusive gait monitoring in daily life, IEEE Trans. Ind. Inform, 12, 6, pp. 2281-2291, (2016); Hamid R., Et al., Development of a wearable plantar force measurement device for gait analysis in remote conditions, 2017 39th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), pp. 139-142, (2017); Lee S.W., Yi T., Jung J.W., Bien Z., Design of a gait phase recognition system that can cope with EMG electrode location variation, IEEE Trans. Autom. Sci. Eng, 14, 3, pp. 1429-1439, (2017); Lou C., Et al., A graphene-based flexible pressure sensor with applications to plantar pressure measurement and gait analysis, Materials, 10, 9, (2017)","","","Institute of Electrical and Electronics Engineers Inc.","","8th IEEE International Conference on Control System, Computing and Engineering, ICCSCE 2018","23 November 2018 through 25 November 2018","Penang","147373","","978-153866324-0","","","English","Proc. - IEEE Int. Conf. Control Syst., Comput. Eng., ICCSCE","Conference paper","Final","","Scopus","2-s2.0-85065027112"
"Osman M.K.; Noor M.H.M.; Mashor M.Y.; Jaafar H.","Osman, M.K. (7201930443); Noor, Mohd Halim Mohd (36656106400); Mashor, M.Y. (6603280096); Jaafar, H. (43262241400)","7201930443; 36656106400; 6603280096; 43262241400","Compact single hidden layer feedforward network for mycobacterium tuberculosis detection","2011","Proceedings - 2011 IEEE International Conference on Control System, Computing and Engineering, ICCSCE 2011","","","6190565","432","436","4","9","10.1109/ICCSCE.2011.6190565","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84862113556&doi=10.1109%2fICCSCE.2011.6190565&partnerID=40&md5=08bbaac8449a130d7833179c0ebfa197","Faculty of Electrical Engineering, Universiti Teknologi MARA (UiTM), Malaysia; Research Group, School of Mechatronic Engineering, Universiti Malaysia Perlis, Malaysia; Department of Pathology, School of Medical Science, Universiti Sains Malaysia, Malaysia","Osman M.K., Faculty of Electrical Engineering, Universiti Teknologi MARA (UiTM), Malaysia; Noor M.H.M., Faculty of Electrical Engineering, Universiti Teknologi MARA (UiTM), Malaysia; Mashor M.Y., Research Group, School of Mechatronic Engineering, Universiti Malaysia Perlis, Malaysia; Jaafar H., Department of Pathology, School of Medical Science, Universiti Sains Malaysia, Malaysia","Advances in imaging technology and artificial intelligence have greatly enhanced the research and development of computer-aided tuberculosis (TB) diagnosis system. The system aims to assist medical technologist and improve the accuracy of clinical diagnosis. A typical architecture of a computer-aided TB diagnosis system consists of image processing, feature extraction and classification. Finding an effective classifier for the system has been regarded as a critical topic, in order to improve the detection performance and avoid making false decision. In this study, the recent method called compact single hidden layer feedforward neural network (C-SLFN) trained by an improved Extreme Learning Machine (ELM) is evaluated for detecting the TB bacilli. Six affine moment invariants are extracted from segmented tissue slide images and fed into the C-SLFN. The network is trained and classified the input patterns into three classes: TB, overlapped TB and non-TB. Further, the study compares the network performance with a SLFN trained using the standard ELM algorithm. The results obtained from this study suggested that the standard ELM still outperformed the C-SLFN in term of classification accuracy. The standard ELM, however requires a large number of hidden nodes compares to the C-SLFN. © 2011 IEEE.","compact single hidden layer feedforward neural network; Extreme Learning Machine; image processing; tuberculosis bacilli detection","Artificial intelligence; Bacilli; Computer aided diagnosis; Control systems; Feature extraction; Feedforward neural networks; Image processing; Learning systems; Network performance; Tissue; Tubes (components); Affine moment invariants; Classification accuracy; Clinical diagnosis; Detection performance; Diagnosis systems; Extreme learning machine; Feature extraction and classification; Feed-forward network; Hidden layers; Hidden nodes; Imaging technology; Input patterns; Mycobacterium tuberculosis; Research and development; Single-hidden layer feedforward neural networks; Network layers","","","","","","","Global Tuberculosis Control. A Short Update to the 2009 Report, (2009); Veropoulos K., Campbell C., Learmonth G., Image processing and neural computing used in the diagnosis of tuberculosis, Proc. IEE Colloquium on Intelligent Methods in Healthcare and Medical Applications (Digest No. 1998/514), (1998); Veropoulos K., Campbell C., Learmonth G., Knight B., Simpson J., The automated identification of tubercle bacilli using image processing and neural computing techniques, Proc. 8th International Conference on Artificial Neural Networks, pp. 797-802, (1998); Veropoulos K., Cristianini N., Campbell C., The application of support vector machines to medical decision support: A case study, Advanced Course in Artificial Intelligence (ACAI'99), (1999); Khutlang R., Krishnan S., Dendere R., Whitelaw A., Veropoulos K., Learmonth G., Douglas T.S., Classification of Mycobacterium tuberculosis in images of ZN-stained sputum smears, IEEE Transactions on Information Technology in Biomedicine, (2009); Osman M.K., Mashor M.Y., Jaafar H., Segmentation of tuberculosis bacilli in ziehl-neelsen tissue slide images using hibrid multilayered perceptron network, Proc. 10th International Conference on Information Sciences Signal Processing and Their Applications (ISSPA 2010), pp. 365-368, (2010); Osman M.K., Mashor M.Y., Jaafar H., Detection of mycobacterium tuberculosis in ziehl-neelsen stained tissue images using zernike moments and hybrid multilayered perceptron network, Proc. 2010 IEEE International Conference on Systems Man and Cybernetics (SMC 2010), pp. 4049-4055, (2010); Osman M.K., Ahmad F., Saad Z., Mashor M.Y., Jaafar H., A genetic algorithm-neural network approach for mycobacterium tuberculosis detection in ziehl-neelsen stained tissue slide images, Proc. 2010 10th International Conference on Intelligent Systems Design and Applications (ISDA 2010), pp. 1229-1234, (2010); Huynh H.T., Kim J.J., Won Y., DNA microarray classification with compact single hidden-layer feedforward neural networks, Proc. Frontiers in the Convergence of Bioscience and Information Technologies (FBIT 2007), pp. 193-198, (2007); Huang G., Zhu Q., Siew C., Extreme learning machine: Theory and applications, Neurocomputing, 70, 1-3, pp. 489-501, (2006); Osman M.K., Mashor M.Y., Saad Z., Jaafar H., Segmentation of tuberculosis bacilli in ziehl-neelsen-stained tissue images based on k-mean clustering procedure, Proc. 3rd International Conference on Intelligent & Advanced Systems (ICIAS2010), (2010); Flusser J., Suk T., Pattern recognition by affine moment invariants, Pattern Recognition, 26, 1, pp. 167-174, (1993)","M.K. Osman; Faculty of Electrical Engineering, Universiti Teknologi MARA (UiTM), Malaysia; email: khusairi@ppinang.uitm.edu.my","","","","2011 IEEE International Conference on Control System, Computing and Engineering, ICCSCE 2011","25 November 2011 through 27 November 2011","Penang","89794","","978-145771642-3","","","English","Proc. - IEEE Int. Conf. Control Syst., Comput. Eng., ICCSCE","Conference paper","Final","","Scopus","2-s2.0-84862113556"
"Noor M.H.M.; Salcic Z.; Wang K.I.-K.","Noor, M.H.M. (36656106400); Salcic, Z. (7003306034); Wang, K.I.-K. (7501398184)","36656106400; 7003306034; 7501398184","Dynamic sliding window method for physical activity recognition using a single tri-axial accelerometer","2015","Proceedings of the 2015 10th IEEE Conference on Industrial Electronics and Applications, ICIEA 2015","","","7334092","102","107","5","15","10.1109/ICIEA.2015.7334092","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84960909327&doi=10.1109%2fICIEA.2015.7334092&partnerID=40&md5=35b9407116055855e6832164be3d2612","Department of Electrical and Computer Engineering, University of Auckland, Auckland, New Zealand","Noor M.H.M., Department of Electrical and Computer Engineering, University of Auckland, Auckland, New Zealand; Salcic Z., Department of Electrical and Computer Engineering, University of Auckland, Auckland, New Zealand; Wang K.I.-K., Department of Electrical and Computer Engineering, University of Auckland, Auckland, New Zealand","Previous studies on physical activity recognition have utilized various fixed window sizes for signal segmentation selected based on past experiments and hardware limitations. Specifically, there is no optimum fixed window size because it is subject to the characteristics of the activity signals. This paper presents a novel approach of activity signal segmentation for enhanced physical activity recognition. Central to the approach is that the window size could be dynamically adjusted by using signal information to determine the most effective segmentation. The approach recognizes not only well defined static and dynamic activities, but also transitional activities. The presented approach has been implemented, evaluated and compared with an existing approach and the fixed sliding window approach in a number of experiments. Results have shown that dynamic window segmentation achieved better overall accuracy of 96% in all activities considered in the experiments compared to the existing approach. © 2015 IEEE.","Accelerometer; Activity Recognition; Decision Tree classifier; Dynamic Window; Signal Segmentation","Accelerometers; Decision trees; Industrial electronics; Pattern recognition; Activity recognition; Decision tree classifiers; Dynamic windows; Overall accuracies; Physical activity; Signal information; Signal segmentation; Triaxial accelerometer; Dynamics","","","","","","","Najafi B., Aminian K., Loew F., Blanc Y., Robert P.A., Measurement of stand-sit and sit-stand transitions using a miniature gyroscope and its application in fall risk evaluation in the elderly, IEEE Trans. Biomed. Eng, 49, 8, pp. 843-851, (2002); Gupta P., Dallas T., Feature selection and activity recognition system using a single triaxial accelerometer, IEEE Trans. Biomed. Eng, 61, 6, pp. 1780-1786, (2014); Bao L., Intille S.S., Physical Activity Recognition from Acceleration Data under Semi-naturalistic Conditions, (2003); Pirttikangas S., Fujinami K., Nakajima T., Feature selection and activity recognition from wearable sensors, Ubiquitous Computing Systems, pp. 516-527, (2006); Ermes M., Parkka J., Mantyjarvi J., Korhonen I., Detection of daily activities and sports with wearable sensors in controlled and uncontrolled conditions, IEEE Trans. Inf. Technol. Biomed, 12, 1, pp. 20-26, (2008); Ozdemir A.T., Barshan B., Detecting falls with wearable sensors using machine learning techniques, Sensors, 14, 6, pp. 10691-10708, (2014); Peeters P.H.F., Design criteria for an automatic safety-alarm system for elderly, Technol. Health Care, 8, 2, pp. 81-91, (2000); Jia R., Liu B., Human daily activity recognition by fusing accelerometer and multi-lead ECG data, 2013 IEEE International Conference on Signal Processing, Communication and Computing (ICSPCC), pp. 1-4, (2013); Adaskevicius R., Method for recognition of the physical activity of human being using a wearable accelerometer, Elektron. Ir Elektrotechnika, 20, 5, pp. 127-131, (2014); Ahanathapillai V., Amor J.D., Tadeusiak M., James C.J., Wrist-Worn accelerometer to detect postural transitions and walking patterns, XIII Mediterranean Conference on Medical and Biological Engineering and Computing 2013, pp. 1515-1518, (2014); Preece S.J., Goulermas J.Y., Kenney L.P.J., Howard D., Meijer K., Crompton R., Activity identification using body-mounted sensors - A review of classification techniques, Physiol. Meas, 30, 4, (2009); Bersch S., Azzi D., Khusainov R., Achumba I., Ries J., Sensor data acquisition and processing parameters for human activity classification, Sensors, 14, 3, pp. 4239-4270, (2014); Banos O., Galvez J.-M., Damas M., Pomares H., Rojas I., Window size impact in human activity recognition, Sensors, 14, 4, pp. 6474-6499, (2014); Gao L., Bourke A.K., Nelson J., Evaluation of accelerometer based multi-sensor versus single-sensor activity recognition systems, Med. Eng. Phys, 36, 6, pp. 779-785, (2014); Mathie M.J., Coster A.C.F., Lovell N.H., Celler B.G., Lord S.R., Tiedemann A., A pilot study of long-term monitoring of human movements in the home using accelerometry, J. Telemed. Telecare, 10, 3, pp. 144-151, (2004); Atallah L., Lo B., King R., Yang G.-Z., Sensor positioning for activity recognition using wearable accelerometers, IEEE Trans. Biomed. Circuits Syst, 5, 4, pp. 320-329, (2011); Quinlan J.R., Induction of decision trees, Mach. Learn, 1, 1, pp. 81-106, (1986); Zijlstra A., Mancini M., Lindemann U., Chiari L., Zijlstra W., Sit-stand and stand-sit transitions in older adults and patients with Parkinson's disease: Event detection based on motion sensors versus force plates, J. Neuroengineering Rehabil, 9, (2012)","","","Institute of Electrical and Electronics Engineers Inc.","","10th IEEE Conference on Industrial Electronics and Applications, ICIEA 2015","15 June 2015 through 17 June 2015","Auckland","118313","","978-146737317-3","","","English","Proc. IEEE Conf. Industrial Electron. Appl., ICIEA","Conference paper","Final","","Scopus","2-s2.0-84960909327"
"Boudville R.; Hussain Z.; Yahaya S.Z.; Noor M.H.M.","Boudville, R. (36661857300); Hussain, Z. (24724464800); Yahaya, S.Z. (38362540900); Noor, M.H.M. (36656106400)","36661857300; 24724464800; 38362540900; 36656106400","New FES-assisted knee swinging ergometer for stroke patient: A design and simulation study","2014","Elektronika ir Elektrotechnika","20","1","","63","66","3","3","10.5755/j01.eee.20.1.6168","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892394333&doi=10.5755%2fj01.eee.20.1.6168&partnerID=40&md5=99470203b023e7edafceb6d383e9cd3f","Faculty of Electrical Engineering, Universiti Teknologi MARA, 13500 Permatang Pauh, Pulau Pinang, Malaysia","Boudville R., Faculty of Electrical Engineering, Universiti Teknologi MARA, 13500 Permatang Pauh, Pulau Pinang, Malaysia; Hussain Z., Faculty of Electrical Engineering, Universiti Teknologi MARA, 13500 Permatang Pauh, Pulau Pinang, Malaysia; Yahaya S.Z., Faculty of Electrical Engineering, Universiti Teknologi MARA, 13500 Permatang Pauh, Pulau Pinang, Malaysia; Noor M.H.M., Faculty of Electrical Engineering, Universiti Teknologi MARA, 13500 Permatang Pauh, Pulau Pinang, Malaysia","This paper presents the development of a model of knee swinging ergometer for stroke patient. Knee swinging ergometer is introduced as a hybrid exercise for restoration of function of the knee for stroke patients through the application of functional electrical stimulation. The aim of the new FESassisted knee swinging ergometer is to provide high intensity exercise. This will elongate the exercise duration and avoid early muscle fatigue. The ergometer is designed to utilize the voluntary non-paretic leg movement in assisting the FESinduced paretic leg of stroke patient. A humanoid with muscle model was developed and incorporated with the ergometer to perform simulation of FES-assisted knee swinging exercise. PID controller is used to achieve full knee extension during each cycle of knee swinging exercise. Simulation results show that the ergometer is able to reduce half of the required electrical stimulation. In conclusion, the new knee swinging ergometer is able to avoid early muscle fatigue in performing high intensity knee exercise through electrical stimulation.","Functional electrical stimulation; Knee swinging ergometer; Muscle fatigue; Muscle model","","","","","","","","Kimberley T.J., Lewis S.M., Auerbach E.J., Dorsey L.L., Lojovich J.M., Carey J.R., Electrical stimulation driving functional improvements and cortical changes in subjects with stroke, Exp Brain Res, 154, 4, pp. 450-460, (2004); Ajoudani A., Erfanian A., Neuro-sliding mode control with modular models for control of knee-joint angle using quadriceps electrical stimulation, Proc. Conf. IEEE Eng. Med. Biol. Soc., pp. 2424-2427, (2007); Karu Z.Z., Durfee W.K., Barzilai A.M., Reducing muscle fatigue in FES applications by stimulating with N-let pulse trains, IEEE Trans. Biomed. Eng., 42, 8, pp. 809-817, (1995); Thrasher A., Graham G.M., Popovic M.R., Reducing muscle fatigue due to functional electrical stimulation using random modulation of stimulation parameters, Artif. Organs, 29, 6, pp. 453-458, (2005); Goldfarb M., Durfee W.K., Design of a controlled-brake orthosis for FES-aided gait, IEEE Trans. Rehabilitation Engineering, 4, 1, pp. 13-24, (1996); Greene P.J., Granat M.H., A knee and ankle flexing hybrid orthosis for paraplegic ambulation, Medical Engineering & Physics, 25, 7, pp. 539-545, (2003); McClelland M., Andrews B.J., Patrick J.H., Masri W.S.E., Augmentation of the Oswestry Parawalker orthosis by means of surface electrical stimulation: Gait analysis of three patients, Spinal Cord, 25, 1, pp. 32-38, (1987); Major R.E., Stallard J., Rose G.K., The dynamics of walking using the hip guidance orthosis (hgo) with crutches, Prosthet. Orthot. Int., 5, 1, pp. 19-22, (1981); Woldag H., Waldmann G., Heuschkel G., Hummelsheim H., Is the repetitive training of complex hand and arm movements beneficial for motor recovery in stroke patients?, Clin. Rehabil., 17, 7, pp. 723-730, (2003); Butefisch C., Hummelsheim H., Denzler P., Mauritz K.H., Repetitive training of isolated movements improves the outcome of motor rehabilitation of the centrally paretic hand, J. Neurol. Sci., 130, 1, pp. 59-68, (1995); Accessibility for the Disabled-a Design Manual for A Barrier Free Environment; Hussain Z., Tokhi M.O., Gharooni S., Jailani R., Kader Ibrahim B.S.K., Inclined ergometer to enhance FES-assisted indoor rowing exercise performance, IJSSST, 10, 6, pp. 16-25, (2009); Winter D.A., Biomechanics and Motor Control of Human Movement, (2009); Hussain Z., Tokhi M.O., Gharooni S., Dynamic simulation of indoor rowing exercise for paraplegics,  Asia Int. Conf. Modeling Simulation (AICMS 08), pp. 901-904, (2008); Boudville R., Hussain Z., Taib M.N., Yahaya S.Z., Dynamic modeling and simulation of free swinging shank for hemiplegics, 2011 IEEE Int. Conf. Control System, Computing and Engineering (ICCSCE), pp. 596-598, (2011); Ramnemark A., Nyberg L., Lorentzon R., Olsson T., Gustafson Y., Hemiosteoporosis after severe stroke, independent of changes in body composition and weight, Stroke, 30, 4, pp. 755-760, (1999); Riener R., Fuhr T., Patient-driven control of FES-supported standing up: A simulation study, IEEE Trans. Rehabilitation Engineering, 6, 2, pp. 113-124, (1998); Hussain Z., Tokhi M.O., Modelling of muscle extension and flexion for FES-assisted indoor rowing exercise, Second Asia Int. Conf. on Modeling Simulation, 2008, (AICMS 08), pp. 963-967, (2008); Massoud R., Intelligent Control Techniques for Spring Assisted FES-cycling, (2007)","","","","","","","","","13921215","","","","English","Elektron. Elektrotech.","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-84892394333"
"Hussain Z.; Yahaya S.Z.; Boudville R.; Ahmad K.A.; Noor M.H.M.","Hussain, Z. (24724464800); Yahaya, S.Z. (38362540900); Boudville, R. (36661857300); Ahmad, K.A. (35760857000); Noor, M.H. Mohd (36656106400)","24724464800; 38362540900; 36661857300; 35760857000; 36656106400","Self adaptive neuro-fuzzy control of FES-assisted paraplegics indoor rowing exercise","2011","Proceedings - 2011 IEEE International Conference on Control System, Computing and Engineering, ICCSCE 2011","","","6190486","7","11","4","4","10.1109/ICCSCE.2011.6190486","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84862075550&doi=10.1109%2fICCSCE.2011.6190486&partnerID=40&md5=b5764fd854442ebd28d4db3b490e62a7","Faculty of Electrical Engineering, Universiti Teknologi MARA, Malaysia","Hussain Z., Faculty of Electrical Engineering, Universiti Teknologi MARA, Malaysia; Yahaya S.Z., Faculty of Electrical Engineering, Universiti Teknologi MARA, Malaysia; Boudville R., Faculty of Electrical Engineering, Universiti Teknologi MARA, Malaysia; Ahmad K.A., Faculty of Electrical Engineering, Universiti Teknologi MARA, Malaysia; Noor M.H.M., Faculty of Electrical Engineering, Universiti Teknologi MARA, Malaysia","This paper describes the development of a self adaptive neuro-fuzzy control mechanism for FES-assisted indoor rowing exercise (FES-rowing). The FES-rowing is introduced as a total body exercise for rehabilitation of function of lower body through the application of functional electrical stimulation (FES). The neuro-fuzzy control technique is a control technique that combines fuzzy logic controller and a neural network, which makes the controller self tuning and adaptive. An adaptive control strategy is purposed to control the FES-rowing with the adaptation of the muscle fitness of the physiological based muscle model in the FLC. The adaptive control is able to modify the control law used by the FLC to cope with the muscle fatigue in adjusting the rowing ergometer inclination and generating the stimulation pulse width required by the system. This study indicates that the self adaptive neuro-fuzzy control developed provides an effective mechanism for automatically adjusting the ergometer inclination and regulating the stimulation pulse width for FES-rowing to overcome muscle fatigue. © 2011 IEEE.","adaptive control; FES; neuro-fuzzy; rowing; rowing exercise","Adaptive control systems; Controllers; Functional electric stimulation; Fuzzy control; Fuzzy logic; Muscle; Physiological models; Adaptive Control; FES; Neuro-Fuzzy; rowing; rowing exercise; SportS","","","","","","","Chizeck H.J., Adaptive and nonlinear control methods for neural prosthesis, Neural Prostheses: Replacing Motor Functional after Disease or Disability, pp. 298-328, (1992); Chizeck H.J., Kobetic R., Marsolais E.B., Abbas J.J., Donner I.H., Simon E., Control of functional neuromuscular stimulation systems for standing and locomotion in paraplegics, Proc. IEEE, 76, pp. 1155-1165, (1988); Davoodi R., Andrews B.J., Wheeler G.D., Manual and automatic control of FES-assisted indoor rowing exercise, Joint EMBS-BMES Conference, pp. 2377-2378, (2002); Wheeler G.D., Andrews B., Lederer R., Davoodi R., Natho K., Weiss C., Jeon J., Bhambhani Y., Steadward R.D., Functional electric stimulation-assisted rowing: Increasing cardiovascular fitness through functional electric stimulation rowing training in persons with spinal cord injury, Arch Phys Med Rehabil, 83, 8, pp. 1093-1099, (2002); Davoodi R., Andrews B.J., Wheeler G.D., Automatic finite state control of FES-assisted indoor rowing exercise after spinal cord injury, Journal of International Neuromodulation Society, 5, 4, pp. 248-255, (2002); Davoodi R., Andrews B.J., Fuzzy logic control of FES rowing exercise in paraplegia, IEEE Trans Biomed Eng, 51, 3, pp. 541-543, (2004); Veltink P.H., Control of FES-induced cyclical movements of the lower leg, Med. Biol. Eng. Comput., 29, (1991); Hatwell M.S., Oderkerk B.J., Sacher C.A., Inbar G.F., The development of a model reference adaptive controller to control the knee joint of paraplegics, IEEE Trans. Automat. Contr., 36, pp. 683-691, (1991); Chang G.C., Luh J.J., Liao G.D., Lai J.S., Cheng C.K., Kuo B.L., Kuo T.S., A neurocontrol system for the knee joint position control with quadrceps stimulation, IEEE Trans. Rehab. Eng., 5, pp. 2-11, (1997); Abbas J.J., Triolo R.J., Experimental evaluation of an adaptive feedforward controller for use in functional neuromuscular stimulation systems, IEEE Trans. Rehab. Eng., 5, pp. 12-22, (1997); Ibrahim B.S.K.K., Tokhi M.O., Huq M.S., Gharooni S.C., Fuzzy logic based cycle-to-cycle control of FES-induced swinging motion, 2011 International Conference on Electrical, Control and Computer Engineering (INECCE), pp. 60-64, (2011); Christopher M.A., Rahmat A.S., Benjamin S., Adaptive control and system identification for direct brain control of artificial limbs, American Control Conference (ACC), pp. 4787-4792, (2011); Kobravi H.R., Erfanian A., A decentralized adaptive fuzzy robust strategy for control of upright standing posture in paraplegia using functional electrical stimulation, Medical Engineering & Physics, (2011); Hussain Z., Tokhi M.O., Gharooni S., Dynamic simulation of indoor rowing exercise for paraplegics,  Asia International Conference on Modelling and Simulation, AMS2008, pp. 901-904, (2008); Riener R., Fuhr T., Patient-driven control of FES-supported standing-up: A simulation study, IEEE Trans.Rehab.Eng., 6, 2, pp. 113-124, (1998); Hussain Z., Tokhi M.O., Modelling of muscle extension and flexion for FES-assisted indoor rowing exercise,  Asia International Conference on Modelling and Simulation, AMS2008, pp. 963-967, (2008); Hussain Z., Tokhi M.O., Jailani R., Ahmad S., Kader B.S., Ibrahim K.S.M., Effect of inclined rowing machine on FES-assisted indoor rowing exercise performance, 2009 Third Asia International Conference on Modelling & Simulation, pp. 242-245, (2009)","Z. Hussain; Faculty of Electrical Engineering, Universiti Teknologi MARA, Malaysia; email: zakaria183@ppinang.uitm.edu.my","","","","2011 IEEE International Conference on Control System, Computing and Engineering, ICCSCE 2011","25 November 2011 through 27 November 2011","Penang","89794","","978-145771642-3","","","English","Proc. - IEEE Int. Conf. Control Syst., Comput. Eng., ICCSCE","Conference paper","Final","","Scopus","2-s2.0-84862075550"
"Al-Qablan T.A.; Mohd Noor M.H.; Al-Betar M.A.; Khader A.T.","Al-Qablan, Tamara Amjad (57195965457); Mohd Noor, Mohd Halim (36656106400); Al-Betar, Mohammed Azmi (57202908939); Khader, Ahamad Tajudin (24724794600)","57195965457; 36656106400; 57202908939; 24724794600","A survey on sentiment analysis and its applications","2023","Neural Computing and Applications","35","29","","21567","21601","34","1","10.1007/s00521-023-08941-y","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168392927&doi=10.1007%2fs00521-023-08941-y&partnerID=40&md5=9cca71ce11e37834da23eb1ae5927ba3","School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, 11800, Malaysia; Artificial Intelligence Research Center (AIRC), College of Engineering and Information Technology, Ajman University, Ajman, 346, United Arab Emirates; Department of Information Technology, Al-Huson University College, Al-Balqa Applied University, Irbid, 50, Jordan","Al-Qablan T.A., School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, 11800, Malaysia; Mohd Noor M.H., School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, 11800, Malaysia; Al-Betar M.A., Artificial Intelligence Research Center (AIRC), College of Engineering and Information Technology, Ajman University, Ajman, 346, United Arab Emirates, Department of Information Technology, Al-Huson University College, Al-Balqa Applied University, Irbid, 50, Jordan; Khader A.T., School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, 11800, Malaysia","Analyzing and understanding the sentiments of social media documents on Twitter, Facebook, and Instagram has become a very important task at present. Analyzing the sentiment of these documents gives meaningful knowledge about the user opinions, which will help understand the overall view on these platforms. The problem of sentiment analysis (SA) can be regarded as a classification problem in which the text is classified as positive, negative, or neutral. This paper aims to give an intensive, but not exhaustive, review of the main concepts of SA and the state-of-the-art techniques; other aims are to make a comparative study of their performances, the main applications of SA as well as the limitations and the future directions for SA. Based on our analysis, researchers have utilized three main approaches for SA, namely lexicon/rules, machine learning (ML), and deep learning (DL). The performance of lexicon/rules-based models typically falls within the range of 55–85%. ML models, on the other hand, generally exhibit performance ranging from 55% to 90%, while DL models tend to achieve higher performance, ranging from 70% to 95%. These ranges are estimated and may be higher or lower depending on various factors, including the quality of the datasets, the chosen model architecture, the preprocessing techniques employed, as well as the quality and coverage of the lexicon utilized. Moreover, to further enhance models’ performance, researchers have delved into the implementation of hybrid models and optimization techniques which have demonstrated an ability to enhance the overall performance of SA models. © 2023, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.","Deep learning; Feature selection; Machine learning; Optimization; Sentiment analysis","Deep learning; Learning systems; Social networking (online); Classifieds; Deep learning; Facebook; Features selection; ITS applications; Machine-learning; Optimisations; Performance; Sentiment analysis; Social media; Sentiment analysis","","","","","","","Pang B., Lee L., Et al., Opinion mining and sentiment analysis, Found Trends Inf Retr, 2, 1-2, pp. 1-135, (2008); Das S., Chen M., Yahoo! for amazon: Extracting market sentiment from stock message boards, Proceedings of the Asia Pacific Finance Association Annual Conference (APFA), 35, (2001); Tong R.M., An operational system for detecting and tracking opinions in on-line discussion, Working Notes of the ACM SIGIR 2001 Workshop on Operational Text Classification, 1, (2001); Turney P.D., Thumbs up or thumbs down? Semantic orientation applied to unsupervised classification of reviews, Arxiv Preprint Arxiv:Cs/0212032, (2002); Pang B., Lee L., Vaithyanathan S., Thumbs up? Sentiment classification using machine learning techniques, Arxiv Preprint Arxiv:Cs/0205070, (2002); Xu G., Meng Y., Qiu X., Yu Z., Wu X., Sentiment analysis of comment texts based on bilstm, Ieee Access, 7, pp. 51522-51532, (2019); Luo Z., Xu H., Chen F., Audio sentiment analysis by heterogeneous signal features learned from utterance-based parallel neural network, Affcon@ AAAI, (2019); Poria S., Cambria E., Hazarika D., Majumder N., Zadeh A., Morency L.-P., Context-dependent sentiment analysis in user-generated videos, Proceedings of the 55Th Annual Meeting of the Association for Computational Linguistics, 1, pp. 873-883, (2017); Alharbi A.S.M., Doncker E., Twitter sentiment analysis with a deep neural network: An enhanced approach using user behavioral information, Cogn Syst Res, 54, pp. 50-61, (2019); Wei J., Liao J., Yang Z., Wang S., Zhao Q., Bilstm with multi-polarity orthogonal attention for implicit sentiment analysis, Neurocomputing, 383, pp. 165-173, (2020); Bouazizi M., Ohtsuki T., Multi-class sentiment analysis on twitter: classification performance and challenges, Big Data Mining Anal, 2, 3, pp. 181-194, (2019); Boon-Itt S., Skunkan Y., Public perception of the covid-19 pandemic on twitter: sentiment analysis and topic modeling study, JMIR Public Health Surveill, 6, 4, (2020); Champagne-Langabeer T., Swank M.W., Manas S., Si Y., Roberts K., Dramatic increases in telehealth-related tweets during the early covid-19 pandemic: a sentiment analysis, Healthcare, 9, (2021); Biswas S., Ghosh A., Chakraborty S., Roy S., Bose R., Scope of sentiment analysis on news articles regarding stock market and gdp in struggling economic condition, Int J, 8, 7, pp. 3594-3609, (2020); Almurtadha Y., Ghaleb M., Sentiment analysis to measure public response to online education during coronavirus pandemic, 2021 National Computing Colleges Conference (NCCC), pp. 1-5, (2021); Zhang L., Wang S., Liu B., Deep learning for sentiment analysis: a survey, Wiley Interdiscip Rev Data Mining Knowl Discov, 8, 4, (2018); Shirsat V.S., Jagdale R.S., Deshmukh S., Document level sentiment analysis from news articles, In: 2017 International Conference on Computing, Communication, Control and Automation (ICCUBEA, pp. pp1-pp4, (2017); Pradhan V.M., Vala J., Balani P., A survey on sentiment analysis algorithms for opinion mining, Int J Comput Appl, 133, 9, pp. 7-11, (2016); Khoo C.S., Johnkhan S.B., Lexicon-based sentiment analysis: comparative evaluation of six sentiment lexicons, J Inf Sci, 44, 4, pp. 491-511, (2018); Naresh A., Venkata Krishna P., An efficient approach for sentiment analysis using machine learning algorithm, Evol Intel, 14, pp. 725-731, (2021); Rani S., Kumar P., Deep learning based sentiment analysis using convolution neural network, Arab J Sci Eng, 44, 4, pp. 3305-3314, (2019); Yang L., Li Y., Wang J., Sherratt R.S., Sentiment analysis for e-commerce product reviews in chinese based on sentiment lexicon and deep learning, IEEE Access, 8, pp. 23522-23530, (2020); Sravya G., Sreedevi M., Genetic optimization in hybrid level sentiment analysis for opinion classification, Int J Adv Trends Comput Sci Eng, 9, pp. 1440-1445, (2020); Tang D., Qin B., Liu T., Deep learning for sentiment analysis: successful approaches and future challenges, Wiley Interdiscip Rev Data Mining Knowl Discov, 5, 6, pp. 292-303, (2015); Liu B., Sentiment analysis and opinion mining, Synth Lect Human Lang Technol, 5, 1, pp. 1-167, (2012); Tubishat M., Idris N., Abushariah M.A., Implicit aspect extraction in sentiment analysis: review, taxonomy, oppportunities, and open challenges, Inf Process Manage, 54, 4, pp. 545-563, (2018); Angiani G., Ferrari L., Fontanini T., Fornacciari P., Iotti E., Magliani F., Manicardi S., A comparison between preprocessing techniques for sentiment analysis in twitter, In: Kdweb, (2016); Alam S., Yao N., The impact of preprocessing steps on the accuracy of machine learning algorithms in sentiment analysis, Comput Math Organ Theory, 25, 3, pp. 319-335, (2019); Pradha S., Halgamuge M.N., Vinh N.T.Q., Effective text data preprocessing technique for sentiment analysis in social media data, 2019 11Th International Conference on Knowledge and Systems Engineering (KSE), pp. 1-8, (2019); Oliveira D.N., Merschmann L.H.C., Joint evaluation of preprocessing tasks with classifiers for sentiment analysis in Brazilian portuguese language, Multimed Tools Appl, 80, pp. 15391-15412, (2021); Cirqueira D., Pinheiro M.F., Jacob A., Lobato F., Santana A., A literature review in preprocessing for sentiment analysis for Brazilian Portuguese social media, 2018 IEEE/WIC/ACM International Conference on Web Intelligence (WI), pp. 746-749, (2018); Deniz A., Kiziloz H.E., Effects of various preprocessing techniques to Turkish text categorization using n-gram features, 2017 International Conference on Computer Science and Engineering (UBMK), pp. 655-660, (2017); Ahuja R., Chug A., Kohli S., Gupta S., Ahuja P., The impact of features extraction on the sentiment analysis, Procedia Comput Sci, 152, pp. 341-348, (2019); Waykole R.N., Thakare A.D., A review of feature extraction methods for text classification, Int J Adv Eng Res Dev, 5, 4, pp. 351-354, (2018); Mikolov T., Sutskever I., Chen K., Corrado G.S., Dean J., Distributed representations of words and phrases and their compositionality, Adv Neural Inf Process Syst, 26, pp. 3111-3119, (2013); Aoumeur N.E., Li Z., Alshari E.M., Improving the polarity of text through word2vec embedding for primary classical Arabic sentiment analysis, Neural Process Lett, 55, pp. 1-16, (2023); Pennington J., Socher R., Manning C.D., Glove: global vectors for word representation, proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP), pp. 1532-1543, (2014); Xiaoyan L., Raga R.C., Xuemei S., Et al., Glove-cnn-bilstm model for sentiment analysis on text reviews, J Sens, 2022, (2022); Yanan Z., Dagang T., Research on text classification based on glove and svm, Softw Guide, 17, 6, pp. 45-48, (2018); Bojanowski P., Grave E., Joulin A., Mikolov T., Enriching word vectors with subword information, Trans Assoc Comput Linguist, 5, pp. 135-146, (2017); Kowsari K., Jafari Meimandi K., Heidarysafa M., Mendu S., Barnes L., Brown D., Text classification algorithms: a survey, Information, 10, 4, (2019); Nguyen H.N., Teerakanok S., Inomata A., Uehara T., The comparison of word embedding techniques in rnns for vulnerability detection, ICISSP, pp. 109-120, (2021); Dang N.C., Moreno-Garcia M.N., Prieta F., Sentiment analysis based on deep learning: a comparative study, Electronics, 9, 3, (2020); Sasaki S., Heinzerling B., Suzuki J., Inui K., Examining the effect of whitening on static and contextualized word embeddings, Inf Process Manage, 60, 3, (2023); Radford A., Narasimhan K., Salimans T., Sutskever I., Improving Language Understanding by Generative Pre-Training, pp. 1-12, (2018); Nath S., Marie A., Ellershaw S., Korot E., Keane P.A., New meaning for nlp: the trials and tribulations of natural language processing with gpt-3 in ophthalmology, Br J Ophthalmol, 106, 7, pp. 889-892, (2022); Lee J., Toutanova K., Pre-training of deep bidirectional transformers for language understanding, Arxiv Preprint Arxiv, 1810, (2018); Barbouch M., Verberne S., Verhoef T., Wn-bert: integrating wordnet and bert for lexical semantics in natural language understanding, Comput Linguist Neth J, 11, pp. 105-124, (2021); Lee J.-S., Hsiang J., Patent claim generation by fine-tuning openai gpt-2, World Patent Inf, 62, (2020); Mars M., From word embeddings to pre-trained language models: a state-of-the-art walkthrough, Appl Sci, 12, 17, (2022); Wang J., Yu L.-C., Lai K.R., Zhang X., Tree-structured regional cnn-lstm model for dimensional sentiment analysis, IEEE/ACM Trans Audio Speech Lang Process, 28, pp. 581-591, (2019); Gao Z., Feng A., Song X., Wu X., Target-dependent sentiment classification with bert, Ieee Access, 7, pp. 154290-154299, (2019); Li X., Fu X., Xu G., Yang Y., Wang J., Jin L., Liu Q., Xiang T., Enhancing bert representation with context-aware embedding for aspect-based sentiment analysis, IEEE Access, 8, pp. 46868-46876, (2020); Nguyen T.H., Shirai K., Velcin J., Sentiment analysis on social media for stock movement prediction, Expert Syst Appl, 42, 24, pp. 9603-9611, (2015); Panthong R., Srivihok A., Wrapper feature subset selection for dimension reduction based on ensemble learning algorithm, Procedia Comput Sci, 72, pp. 162-169, (2015); Omuya E.O., Okeyo G.O., Kimwele M.W., Feature selection for classification using principal component analysis and information gain, Expert Syst Appl, 174, (2021); Sanchez-Marono N., Alonso-Betanzos A., Calvo-Estevez R.M., A wrapper method for feature selection in multiple classes datasets, International Work-Conference on Artificial Neural Networks, pp. 456-463, (2009); Solorio-Fernandez S., Carrasco-Ochoa J.A., Martinez-Trinidad J.F., A review of unsupervised feature selection methods, Artif Intell Rev, 53, 2, pp. 907-948, (2020); Birjali M., Beni-Hssane A., Erritali M., Machine learning and semantic sentiment analysis based algorithms for suicide sentiment prediction in social networks, Procedia Comput Sci, 113, pp. 65-72, (2017); Chandrashekar G., Sahin F., A survey on feature selection methods, Comput Electr Eng, 40, 1, pp. 16-28, (2014); Jimenez-Cordero A., Morales J.M., Pineda S., A novel embedded min-max approach for feature selection in nonlinear support vector machine classification, Eur J Oper Res, 293, 1, pp. 24-35, (2021); Remeseiro B., Bolon-Canedo V., A review of feature selection methods in medical applications, Comput Biol Med, 112, (2019); Shah S., Shabbir H., Rehman S., Waqas M., A comparative study of feature selection approaches: 2016–2020, Int J Sci Eng Res, 11, 2, (2020); Liu H., Yu L., Toward integrating feature selection algorithms for classification and clustering, IEEE Trans Knowl Data Eng, 17, 4, pp. 491-502, (2005); Zhao H., Liu Z., Yao X., Yang Q., A machine learning-based sentiment analysis of online product reviews with a novel term weighting and feature selection approach, Inf Process Manage, 58, 5, (2021); Yusta S.C., Different metaheuristic strategies to solve the feature selection problem, Pattern Recogn Lett, 30, 5, pp. 525-534, (2009); Al-Qablan T.A., Noor M.H.M.M.A.A.T., Improved Binary Gray Wolf Optimizer Based on Adaptive β -Hill Climbing for Feature Selection, (2023); Tahir M., Tubaishat A., Al-Obeidat F., Shah B., Halim Z., Waqas M., A novel binary chaotic genetic algorithm for feature selection and its utility in affective computing and healthcare, Neural Comput Appl, pp. 1-22, (2020); Ahmad S.R., Rodzi M.Z.M., Nurhafizeh N., Yusop M., Ismail S., A review of feature selection and sentiment analysis technique in issues of propaganda, Int J Adv Comput Sci Appl, 10, 11, pp. 240-245, (2019); Addo-Tenkorang R., Helo P.T., Big data applications in operations/supply-chain management: a literature review, Comput Ind Eng, 101, pp. 528-543, (2016); Zaslavsky A., Perera C., Georgakopoulos D., Sensing as a Service and Big Data., (2013); Shayaa S., Jaafar N.I., Bahri S., Sulaiman A., Wai P.S., Chung Y.W., Piprani A.Z., Al-Garadi M.A., Sentiment analysis of big data: methods, applications, and open challenges, IEEE Access, 6, pp. 37807-37827, (2018); Mukhtar N., Khan M.A., Chiragh N., Lexicon-based approach outperforms supervised machine learning approach for urdu sentiment analysis in multiple domains, Telemat Inform, 35, 8, pp. 2173-2183, (2018); Catelli R., Pelosi S., Esposito M., Lexicon-based vs. bert-based sentiment analysis: a comparative study in Italian, Electronics, 11, 3, (2022); Reddy Y., Viswanath P., Reddy B.E., Semi-supervised learning: a brief review, Int J Eng Technol, 7, 1, (2018); Jasmir J., Nurmaini S., Tutuko B., Fine-grained algorithm for improving knn computational performance on clinical trials text classification, Big Data Cogn Comput, 5, 4, (2021); Didi Y., Walha A., Wali A., Covid-19 tweets classification based on a hybrid word embedding method, Big Data Cogn Comput, 6, 2, (2022); Zaks G., Katz G., Recom: a deep reinforcement learning approach for semi-supervised tabular data labeling, Inf Sci, 589, pp. 321-340, (2022); Riyadh M., Shafiq M.O., Towards multi-class sentiment analysis with limited labeled data, 2021 IEEE International Conference on Big Data (Big Data), pp. 4955-4964, (2021); Ebrahimi P., Basirat M., Yousefi A., Nekmahmud M., Gholampour A., Fekete-Farkas M., Social networks marketing and consumer purchase behavior: the combination of sem and unsupervised machine learning approaches, Big Data Cogn Comput, 6, 2, (2022); Garcia-Pablos A., Cuadros M., Rigau G., W2vlda: almost unsupervised system for aspect based sentiment analysis, Expert Syst Appl, 91, pp. 127-137, (2018); Yadav A., Jha C., Sharan A., Vaish V., Sentiment analysis of financial news using unsupervised approach, Procedia Comput Sci, 167, pp. 589-598, (2020); Pandey A.C., Rajpoot D.S., Saraswat M., Twitter sentiment analysis using hybrid cuckoo search method, Inf Process Manage, 53, 4, pp. 764-779, (2017); Kaur G., Kaushik A., Sharma S., Cooking is creating emotion: a study on hinglish sentiments of youtube cookery channels using semi-supervised approach, Big Data Cogn Comput, 3, 3, (2019); Macrohon J.J.E., Villavicencio C.N., Inbaraj X.A., Jeng J.-H., A semi-supervised approach to sentiment analysis of tweets during the 2022 philippine presidential election, Information, 13, 10, (2022); Cruz Paulino J.L., Antoja Almirol L.C., Cruz Favila J.M., Loria Aquino K.A.G., Hernandez De La Cruz A., Roxas R.E., Multilingual sentiment analysis on short text document using semi-supervised machine learning, 2021 5Th International Conference on E-Society, E-Education and E-Technology, Pp, pp. 164-170, (2021); Gupta N., Agrawal R., Application and techniques of opinion mining, Hybrid computational intelligence, pp. 1-23, (2020); Assiri A., Emam A., Al-Dossari H., Towards enhancement of a lexicon-based approach for Saudi dialect sentiment analysis, J Inf Sci, 44, 2, pp. 184-202, (2018); Zabha N.I., Ayop Z., Anawar S., Hamid E., Abidin Z.Z., Developing cross-lingual sentiment analysis of Malay twitter data using lexicon-based approach, Int J Adv Comput Sci Appl, 10, 1, pp. 346-351, (2019); YURTALAN G., Koyuncu M., TURHAN C., A polarity calculation approach for lexicon-based turkish sentiment analysis, Turk J Electr Eng Comput Sci, 27, 2, pp. 1325-1339, (2019); Wunderlich F., Memmert D., Innovative approaches in sports science-lexicon-based sentiment analysis as a tool to analyze sports-related twitter communication, Appl Sci, 10, 2, (2020); Mukhtar N., Khan M.A., Effective lexicon-based approach for Urdu sentiment analysis, Artif Intell Rev, 53, 4, pp. 2521-2548, (2020); Mehmood Y., Balakrishnan V., An enhanced lexicon-based approach for sentiment analysis: A case study on illegal immigration, Online Information Review, (2020); Aloqaily A., Alhassan M., Salah K., Elshqeirat B., Almashagbah M., Hussein Bin Abdullah P., Sentiment analysis for arabic tweets datasets: Lexicon-based and machine learning approaches, J Theor Appl Inf Technol, 98, 4, pp. 612-623, (2020); Piryani R., Piryani B., Singh V.K., Pinto D., Sentiment analysis in nepali: Exploring machine learning and lexicon-based approaches, J Intell Fuzzy Syst, pp. 1-12, (2020); Chaovalit P., Zhou L., Movie review mining: A comparison between supervised and unsupervised classification approaches, Proceedings of the 38Th Annual Hawaii International Conference on System Sciences, (2005); Liu Z., Dong X., Guan Y., Yang J., Reserved self-training: A semi-supervised sentiment classification method for chinese microblogs, Proceedings of the Sixth International Joint Conference on Natural Language Processing, pp. 455-462, (2013); Singh J., Singh G., Singh R., Optimization of sentiment analysis using machine learning classifiers, HCIS, 7, 1, pp. 1-12, (2017); Hew K.F., Hu X., Qiao C., Tang Y., What predicts student satisfaction with moocs: a gradient boosting trees supervised machine learning and sentiment analysis approach, Comput Edu, 145, (2020); Ghiassi M., Lee S., A domain transferable lexicon set for twitter sentiment analysis using a supervised machine learning approach, Expert Syst Appl, 106, pp. 197-216, (2018); Du J., Xu J., Song H., Liu X., Tao C., Optimization on machine learning based approaches for sentiment analysis on hpv vaccines related tweets, J Biomed Semant, 8, 1, pp. 1-7, (2017); Mukhtar N., Khan M.A., Urdu sentiment analysis using supervised machine learning approach, Int J Pattern Recognit Artif Intell, 32, 2, (2018); Basha C.B., Somasundaram K., A comparative study of twitter sentiment analysis using machine learning algorithms in big data, Int J Rec Technol Eng, 8, 1, pp. 591-599, (2019); Hausler J., Ruscheinsky J., Lang M., News-based sentiment analysis in real estate: a machine learning approach, J Prop Res, 35, 4, pp. 344-371, (2018); Valencia F., Gomez-Espinosa A., Valdes-Aguirre B., Price movement prediction of cryptocurrencies using sentiment analysis and machine learning, Entropy, 21, 6, (2019); Ghosh M., Sanyal G., An ensemble approach to stabilize the features for multi-domain sentiment analysis using supervised machine learning, J Big Data, 5, 1, pp. 1-25, (2018); Nandal N., Tanwar R., Pruthi J., Machine learning based aspect level sentiment analysis for amazon products, Spat Inf Res, 28, 5, pp. 601-607, (2020); Baid P., Gupta A., Chaplot N., Sentiment analysis of movie reviews using machine learning techniques, Int J Comput Appl, 179, 7, pp. 45-49, (2017); Soumya S., Pramod K., Sentiment analysis of Malayalam tweets using machine learning techniques, ICT Express, 6, 4, pp. 300-305, (2020); Al-Moslmi T., Omar N., Albared M., Alshabi A., Enhanced Malay sentiment analysis with an ensemble classification machine learning approach, J f Eng Appl Sci, 12, 20, pp. 5226-5232, (2017); Buladaco M., Buladaco J., Cantero L., Sentiments analysis on public land transport infrastructure in Davao region using machine learning algorithms, Int J Adv Trends Comput Sci Eng, 9, 1, pp. 685-690, (2020); Raza H., Faizan M., Hamza A., Mushtaq A., Akhtar N., Scientific text sentiment analysis using machine learning techniques, Int J Adv Comput Sci Appl, 10, 12, pp. 157-165, (2019); Bhargav P.S., Reddy G.N., Chand R.R., Pujitha K., Mathur A., Sentiment analysis for hotel rating using machine learning algorithms, Int J Innov Technol Explor Eng (IJITEE), 8, 6, pp. 1225-1228, (2019); Hercig T., Brychcin T., Svoboda L., Konkol M., Steinberger J., Unsupervised methods to improve aspect-based sentiment analysis in czech, Comput Sistemas, 20, 3, pp. 365-375, (2016); Azzouza N., Akli-Astouati K., Oussalah A., Bachir S.A., A real-time twitter sentiment analysis using an unsupervised method, Proceedings of the 7Th International Conference on Web Intelligence, Mining and Semantics, pp. 1-10, (2017); Odbal W.Z., A semi-supervised method for phrase-level sentiment analysis, Moshi Shibie yu Rengong Zhineng/Pattern Recognit Artif Intell, 29, 4, pp. 289-297, (2016); Socher R., Pennington J., Huang E.H., Ng A.Y., Manning C.D., Semi-supervised recursive autoencoders for predicting sentiment distributions, EMNLP 2011-Conference on Empirical Methods in Natural Language Processing, Proceedings of the Conference, pp. 151-161, (2011); Madhoushi Z., Hamdan A.R., Zainudin S., Sentiment analysis techniques in recent works, 2015 Science and Information Conference (SAI), pp. 288-291, (2015); Rehman A.U., Malik A.K., Raza B., Ali W., A hybrid cnn-lstm model for improving accuracy of movie reviews sentiment analysis, Multimed Tools Appl, 78, 18, pp. 26597-26613, (2019); Joseph J., Vineetha S., Sobhana N., A survey on deep learning based sentiment analysis, Mater Today Procee, 58, pp. 456-460, (2022); Araque O., Corcuera-Platas I., Sanchez-Rada J.F., Iglesias C.A., Enhancing deep learning sentiment analysis with ensemble techniques in social applications, Expert Syst Appl, 77, pp. 236-246, (2017); Devipriya K., Prabha D., Pirya V., Sudhakar S., Deep learning sentiment analysis for recommendations in social applications, Int J Sci Technol Res, 9, 1, pp. 3812-3815, (2020); Yadav A., Vishwakarma D.K., A deep learning architecture of ra-dlnet for visual sentiment analysis, Multimed Syst, 26, pp. 431-451, (2020); Park S., Woo J., Gender classification using sentiment analysis and deep learning in a health web forum, Appl Sci, 9, 6, (2019); Rosa R.L., Schwartz G.M., Ruggiero W.V., Rodriguez D.Z., A knowledge-based recommendation system that includes sentiment analysis and deep learning, IEEE Trans Industr Inf, 15, 4, pp. 2124-2135, (2018); Colon-Ruiz C., Segura-Bedmar I., Comparing deep learning architectures for sentiment analysis on drug reviews, J Biomed Inform, 110, (2020); Sohangir S., Wang D., Pomeranets A., Khoshgoftaar T.M., Big data: deep learning for financial sentiment analysis, J Big Data, 5, 1, pp. 1-25, (2018); Feizollah A., Ainin S., Anuar N.B., Abdullah N.A.B., Hazim M., Halal products on twitter: data extraction and sentiment analysis using stack of deep learning algorithms, IEEE Access, 7, pp. 83354-83362, (2019); Terra Vieira S., Lopes Rosa R., Zegarra Rodriguez D., Arjona Ramirez M., Saadi M., Wuttisittikulkij L., Q-meter: quality monitoring system for telecommunication services based on sentiment analysis using deep learning, Sensors, 21, 5, (2021); Li L., Goh T.-T., Jin D., How textual quality of online reviews affect classification performance: a case of deep learning sentiment analysis, Neural Comput Appl, 32, 9, pp. 4387-4415, (2020); Ghorbani M., Bahaghighat M., Xin Q., Ozen F., Convlstmconv network: a deep learning approach for sentiment analysis in cloud computing, J Cloud Comput, 9, 1, pp. 1-12, (2020); Garg A., Duhan N., Sarcasm detection on twitter data using support vector machine, ICTACT J Soft Comput, 10, 4, pp. 2165-2170, (2020); Xu F., Zhang X., Xin Z., Yang A., Investigation on the Chinese text sentiment analysis based on convolutional neural networks in deep learning, Comput Mater Contin, 58, 3, pp. 697-709, (2019); Paredes-Valverde M.A., Colomo-Palacios R., Salas-Zarate M., Valencia-Garcia R., Et al., Sentiment analysis in Spanish for improvement of products and services: A deep learning approach, Sci Program, 2017, pp. 1-6, (2017); Kapociute-Dzikiene J., Damasevicius R., Wozniak M., Sentiment analysis of Lithuanian texts using traditional and deep learning approaches, Computers, 8, 1, (2019); Ombabi A.H., Ouarda W., Alimi A.M., Deep learning cnn-lstm framework for Arabic sentiment analysis using textual information shared in social networks, Soc Netw Anal Min, 10, 1, pp. 1-13, (2020); Mohammed A., Kora R., Deep learning approaches for Arabic sentiment analysis, Soc Netw Anal Min, 9, 1, pp. 1-12, (2019); Konate A., Du R., Sentiment analysis of code-mixed Bambara-French social media text using deep learning techniques, Wuhan Univ J Nat Sci, 23, 3, pp. 237-243, (2018); Dastgheib M.B., Koleini S., Rasti F., The application of deep learning in Persian documents sentiment analysis, Int J Inf Sci Manage (IJISM), 18, 1, pp. 1-15, (2020); Nezhad Z.B., Deihimi M.A., A combined deep learning model for Persian sentiment analysis, IIUM Eng J, 20, 1, pp. 129-139, (2019); Ong J.Y., Mun'im Ahmad Zabidi M., Ramli N., Sheikh U.U., Sentiment analysis of informal Malay tweets with deep learning, IAES Int J Artif Intell, 9, 2, (2020); Tam S., Said R.B., Tanriover O.O., A convbilstm deep learning model-based approach for twitter sentiment classification, IEEE Access, 9, pp. 41283-41293, (2021); Lin Y., Li J., Yang L., Xu K., Lin H., Sentiment analysis with comparison enhanced deep neural network, IEEE Access, 8, pp. 78378-78384, (2020); Mohammadi A., Shaverizade A., Ensemble deep learning for aspect-based sentiment analysis, Int J Nonlinear Anal Appl, 12, pp. 29-38, (2021); Devlin J., Chang M.-W., Lee K., Toutanova K., Bert: Pre-training of deep bidirectional transformers for language understanding, Arxiv Preprint Arxiv, 1810, (2018); Mathew L., Bindu V., Efficient classification techniques in sentiment analysis using transformers, International Conference on Innovative Computing and Communications, pp. 849-862, (2022); Mishev K., Gjorgjevikj A., Vodenska I., Chitkushev L.T., Trajanov D., Evaluation of sentiment analysis in finance: from lexicons to transformers, IEEE Access, 8, pp. 131662-131682, (2020); Liu Y., Ott M., Goyal N., Du J., Joshi M., Chen D., Levy O., Lewis M., Zettlemoyer L., Stoyanov V., Roberta: A robustly optimized bert pretraining approach, . Arxiv Preprint Arxiv, 1907, (2019); Zeng B., Yang H., Xu R., Zhou W., Han X., Lcf: a local context focus mechanism for aspect-based sentiment classification, Appl Sci, 9, 16, (2019); Durairaj A.K., Chinnalagu A., Transformer based contextual model for sentiment analysis of customer reviews: a fine-tuned bert a sequence learning bert model for sentiment analysis, Int J Adv Comput Sci Appl, 12, 11, pp. 474-480, (2021); Iqbal F., Hashmi J.M., Fung B.C., Batool R., Khattak A.M., Aleem S., Hung P.C., A hybrid framework for sentiment analysis using genetic algorithm based feature reduction, IEEE Access, 7, pp. 14637-14652, (2019); Alqahtani A.S., Saravanan P., Maheswari M., Alshmrany S., Alsarrayrih H., Hybrid grass bee optimization-multikernal extreme learning classifier: multimodular fusion strategy and optimal feature selection for multimodal sentiment analysis in social media videos, Concurr Comput Pract Exp, 33, 16, (2021); Raviya K., Mary Vennila S., A hybrid deep learning approach for sentiment analysis using cnn and improved svm with multi objective swarm optimization for domain independent datasets, Int J Adv Trends Comput Sci Eng, 9, pp. 3200-3206, (2020); Shekhawat S.S., Shringi S., Sharma H., Twitter sentiment analysis using hybrid spider monkey optimization method, Evolut Intell, 14, pp. 1307-1316, (2021); Madani Y., Erritali M., Bengourram J., Sailhan F., A hybrid multilingual fuzzy-based approach to the sentiment analysis problem using sentiwordnet, Internat J Uncertain Fuzziness Knowl Based Syst, 28, 3, pp. 361-390, (2020); Kumar A., Khorwal R., Firefly algorithm for feature selection in sentiment analysis, Computational intelligence in data mining, pp. 693-703, (2017); Tubishat M., Abushariah M.A., Idris N., Aljarah I., Improved whale optimization algorithm for feature selection in Arabic sentiment analysis, Appl Intell, 49, 5, pp. 1688-1707, (2019); Rahab H., Haouassi H., Souidi M.E.H., Bakhouche A., Mahdaoui R., Bekhouche M., A modified binary rat swarm optimization algorithm for feature selection in Arabic sentiment analysis, Arab J Sci Eng, pp. 1-28, (2022); Mehbodniya A., Rao M.V., David L.G., Nigel K.G.J., Vennam P., Online product sentiment analysis using random evolutionary whale optimization algorithm and deep belief network, Pattern Recogn Lett, 159, pp. 1-8, (2022); Shaddeli A., Soleimanian Gharehchopogh F., Masdari M., Solouk V., An improved African vulture optimization algorithm for feature selection problems and its application of sentiment analysis on movie reviews, Big Data Cogn Comput, 6, 4, (2022); Elshakankery K., Ahmed M.F., Hilatsa: a hybrid incremental learning approach for Arabic tweets sentiment analysis, Egypt Inf J, 20, 3, pp. 163-171, (2019); ErsahIn B., Aktas O., Kilinc D., ErsahIn M., A hybrid sentiment analysis method for Turkish, Turk J Electr Eng Comput Sci, 27, 3, pp. 1780-1793, (2019); Sinha S., Saxena K., Joshi N., Sentiment analysis of facebook posts using hybrid method, Int J Recent Technol Eng, 8, pp. 2421-2428, (2019); Mendon S., Dutta P., Behl A., Lessmann S., A hybrid approach of machine learning and lexicons to sentiment analysis: enhanced insights from twitter data of natural disasters, Inf Syst Front, (2021); Learning S.M., Hybrid model for twitter data sentiment analysis based on ensemble of dictionary based classifier and stacked machine learning classifiers-svm, knn and c50, J Theor Appl Inf Technol, 98, 4, pp. 624-635, (2020); Dashtipour K., Gogate M., Li J., Jiang F., Kong B., Hussain A., A hybrid Persian sentiment analysis framework: integrating dependency grammar based rules and deep neural networks, Neurocomputing, 380, pp. 1-10, (2020); Wu C., Wu F., Wu S., Yuan Z., Huang Y., A hybrid unsupervised method for aspect term and opinion target extraction, Knowl-Based Syst, 148, pp. 66-73, (2018); Ray P., Chakrabarti A., A mixed approach of deep learning method and rule-based method to improve aspect level sentiment analysis, Appl Comput Inf, (2020); Srinidhi H., Siddesh G., Srinivasa K., A hybrid model using Malstm based on recurrent neural networks with support vector machines for sentiment analysis, Eng Appl Sci Res, 47, 3, pp. 232-240, (2020); Kumar A., Srinivasan K., Cheng W.-H., Zomaya A.Y., Hybrid context enriched deep learning model for fine-grained sentiment analysis in textual and visual semiotic modality social data, Inf Process Manage, 57, 1, (2020); Raviya K., Mary Vennila S., An implementation of hybrid enhanced sentiment analysis system using spark ml pipeline: a big data analytics framework, Int J Adv Comput Sci Appl, 12, pp. 323-329, (2021); Hassonah M.A., Al-Sayyed R., Rodan A., Ala'M A.-Z., Aljarah I., Faris H., An efficient hybrid filter and evolutionary wrapper approach for sentiment analysis of various topics on twitter, Knowl Based Syst, 192, (2020); Omar A., Hamouda W.I., A sentiment analysis of Egypt’s new real estate registration law on facebook, Int J Adv Comput Sci Appl, 12, 4, pp. 656-663, (2021); Bashir S., Bano S., Shueb S., Gul S., Mir A.A., Ashraf R., Noor N., Et al., Twitter chirps for syrian people: sentiment analysis of tweets related to syria chemical attack, Int J Disaster Risk Red, 62, (2021); Villavicencio C., Macrohon J.J., Inbaraj X.A., Jeng J.-H., Hsieh J.-G., Twitter sentiment analysis towards covid-19 vaccines in the Philippines using naïve bayes, Information, 12, 5, (2021); Sailunaz K., Alhajj R., Emotion and sentiment analysis from twitter text, J Comput Sci, 36, (2019); Wang L., Niu J., Yu S., Sentidiff: combining textual information and sentiment diffusion patterns for twitter sentiment analysis, IEEE Trans Knowl Data Eng, 32, 10, pp. 2026-2039, (2019); Gabarron E., Dorronzoro E., Rivera-Romero O., Wynn R., Diabetes on twitter: a sentiment analysis, J Diabetes Sci Technol, 13, 3, pp. 439-444, (2019); Ozturk N., Ayvaz S., Sentiment analysis on twitter: a text mining approach to the Syrian refugee crisis, Telematics Inform, 35, 1, pp. 136-147, (2018); Bouazizi M., Ohtsuki T., A pattern-based approach for multi-class sentiment analysis in twitter, IEEE Access, 5, pp. 20617-20639, (2017); Daniel M., Neves R.F., Horta N., Company event popularity for financial markets using twitter and sentiment analysis, Expert Syst Appl, 71, pp. 111-124, (2017); Zafra S.M.J., Valdivia M.T.M., Camara E.M., Lopez L.A.U., Studying the scope of negation for Spanish sentiment analysis on twitter, IEEE Trans Affect Comput, 10, 1, pp. 129-141, (2017); Prabha V.D., Rathipriya R., Competitive capsule network based sentiment analysis on twitter covid’19 vaccines, J Web Eng, 21, pp. 1583-1602, (2022); Musleh D.A., Alkhales T.A., Almakki R.A., Alnajim S.E., Almarshad S.K., Alhasaniah R.S., Aljameel S.S., Almuqhim A.A., Twitter Arabic sentiment analysis to detect depression using machine learning, Comput Mater Contin, 71, pp. 3463-3477, (2022); Nezhad Z.B., Deihimi M.A., Twitter sentiment analysis from Iran about covid 19 vaccine, Diabetes Metab Syndr Clin Res Rev, 16, 1, (2022); Hassan M.K., Hudaefi F.A., Caraka R.E., Mining netizen’s opinion on cryptocurrency: sentiment analysis of twitter data, Stud Econ Financ, 39, 3, pp. 365-385, (2022); Ribeiro L.A., Cinalli D., Garcia A.C.B., Discovering adverse drug reactions from twitter: A sentiment analysis perspective, 2021 IEEE 24Th International Conference on Computer Supported Cooperative Work in Design (CSCWD), pp. 1172-1177, (2021)","T.A. Al-Qablan; School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, 11800, Malaysia; email: tqablan@student.usm.my","","Springer Science and Business Media Deutschland GmbH","","","","","","09410643","","","","English","Neural Comput. Appl.","Review","Final","","Scopus","2-s2.0-85168392927"
"Baraka A.M.A.; Mohd Noor M.H.","Baraka, Abdulrahman M. A. (58574878000); Mohd Noor, Mohd Halim (36656106400)","58574878000; 36656106400","Similarity Segmentation Approach for Sensor-Based Activity Recognition","2023","IEEE Sensors Journal","23","17","","19704","19716","12","0","10.1109/JSEN.2023.3295778","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165293712&doi=10.1109%2fJSEN.2023.3295778&partnerID=40&md5=f91132775fbe8ec32175da38f89870d8","Al-Quds Open University (QOU), Faculty of Technology and Applied Sciences, Strip, Gaza, 970, Palestine; Universiti Sains Malaysia, School of Computer Sciences, Pulau Pinang, 11800, Malaysia","Baraka A.M.A., Al-Quds Open University (QOU), Faculty of Technology and Applied Sciences, Strip, Gaza, 970, Palestine, Universiti Sains Malaysia, School of Computer Sciences, Pulau Pinang, 11800, Malaysia; Mohd Noor M.H., Universiti Sains Malaysia, School of Computer Sciences, Pulau Pinang, 11800, Malaysia","The fixed sliding window is the commonly used technique for signal segmentation in human activity recognition (HAR). However, the fixed sliding window may not produce optimal segmentation because human activities have varying durations, especially for transitional activities (TAs). This is because a large window size may contain activity signals belonging to different activities, and a small window size may split the activity signal into multiple windows. Furthermore, the fixed sliding window does not consider the relationship between adjacent windows, which may affect the performance of the HAR model. In this study, we propose a similarity segmentation approach (SSA) that exploits the temporal structure of the activity signal within the window segmentation process. Specifically, the proposed approach segments each window into subwindows and extracts the inner features by measuring the similarity between them. The inner features are used to measure the dissimilarity between the adjacent windows. The proposed approach is able to distinguish between transitional and nontransitional windows, which achieves more effective segmentation and classification processes. Two public datasets are used for the evaluation. The experimental results show that the proposed approach can distinguish TAs from basic activities (BAs) at 97.65% accuracy, which enhanced the accuracy of TAs recognition compared to the fixed sliding window by 33.41%. Also, our approach achieved accuracy for activity recognition of 92.71% and 86.65% for both datasets, respectively, which exceeds the fixed sliding window by 2.29% and 3.93% for both datasets, respectively. These results are significant and exceed the accuracy of the state-of-the-art models.  © 2001-2012 IEEE.","Human activity recognition (HAR); signal segmentation; transitional activity (TA)","Activity recognition; Human activities; Human activity recognition; Multiple windows; Optimal segmentation; Segmentation process; Signal segmentation; Sliding Window; Transitional activity; Window Size; Pattern recognition","","","","","","","Benhaili Z., Balouki Y., Moumoun L., A hybrid deep neural network for human activity recognition based on IoT sensors, Int. J. Adv. Comput. Sci. Appl., 12, 11, pp. 250-257, (2021); Alhammad N., Al-Dossari H., Dynamic segmentation for physical activity recognition using a single wearable sensor, Appl. Sci., 11, 6, (2021); Ghazali N.F., As'ari M.A., Shahar N., Latip H.F.M., Investigation on the effect of different window size in segmentation for common sport activity, Proc. Int. Conf. Smart Comput. Electron. Enterprise (ICSCEE), pp. 1-7, (2018); Bermejo U., Almeida A., Bilbao-Jayo A., Azkune G., Embeddingbased real-time change point detection with application to activity segmentation in smart home time series data, Expert Syst. Appl., 185, (2021); Chen L., Fan S., Kumar V., Jia Y., A method of human activity recognition in transitional period, Information, 11, 9, pp. 1-17, (2020); Li J.-H., Tian L., Wang H., An Y., Wang K., Yu L., Segmentation and recognition of basic and transitional activities for continuous physical human activity, IEEE Access, 7, pp. 42565-42576, (2019); Reyes-Ortiz J.-L., Oneto L., Sama A., Parra X., Anguita D., Transition-aware human activity recognition using smartphones, Neurocomputing, 171, pp. 754-767, (2016); Wairagkar M., Et al., A novel approach for modelling and classifying sit-to-stand kinematics using inertial sensors, (2021); Pilario K.E., Et al., Wearables-based multi-task gait and activity segmentation using recurrent neural networks, Sensors, 8, 1, pp. 1-11, (2020); Kumar P., Chauhan S., Human activity recognition with deep learning: Overview, challenges and possibilities, CCF Trans. Pervasive Comput. Interact., (2021); Noor M.H.M., Salcic Z., Wang K.I.-K., Adaptive sliding window segmentation for physical activity recognition using a single tri-axial accelerometer, Pervas. Mobile Comput., 38, pp. 41-59, (2017); Jimale A.O., Noor M.H.M., Subject variability in sensor-based activity recognition, J. Ambient Intell. Humanized Comput., 14, 4, pp. 3261-3274, (2021); Zhang S., Et al., Deep learning in human activity recognition with wearable sensors: A review on advances, Sensors, 22, 4, (2022); Atalaa B.A., Alenany A., Helmi A., Ziedan I., Effect of data segmentation on the quality of human activity recognition, East Afr. Scholars J. Eng. Comput. Sci., 4480, 7, pp. 133-145, (2020); Whitlock J., Krand O., Jain S., Understanding activity segmentation for multi-sport competitions, Proc. 4th ACM Workshop Wearable Syst. Appl., pp. 16-20, (2018); Martindale C.F., Christlein V., Klumpp P., Eskofier B.M., Wearables-based multi-task gait and activity segmentation using recurrent neural networks, Neurocomputing, 432, pp. 250-261, (2021); Fida B., Bernabucci I., Bibbo D., Conforto S., Schmid M., Varying behavior of different window sizes on the classification of static and dynamic physical activities from a single accelerometer, Med. Eng. Phys., 37, 7, pp. 705-711, (2015); Banos O., Galvez J.-M., Damas M., Pomares H., Rojas I., Window size impact in human activity recognition, Sensors, 14, 4, pp. 6474-6499, (2014); Akbari A., Wu J., Grimsley R., Jafari R., Hierarchical signal segmentation and classification for accurate activity recognition, Proc. ACM Int. Joint Conf. Int. Symp. Pervasive Ubiquitous Comput. Wearable Comput., pp. 1596-1605, (2018); Xiao C., Lei Y., Ma Y., Zhou F., Qin Z., DeepSeg: Deep-learningbased activity segmentation framework for activity recognition using WiFi, IEEE Internet Things J., 8, 7, pp. 5669-5681, (2021); He J., Zhang Q., Wang L., Pei L., Weakly supervised human activity recognition from wearable sensors by recurrent attention learning, IEEE Sensors J., 19, 6, pp. 2287-2297, (2019); Lone K.J., Hussain L., Saeed S., Aslam A., Maqbool A., Butt F.M., Detecting basic human activities and postural transition using robust machine learning techniques by applying dimensionality reduction methods, Waves Random Complex Media, 2021, pp. 1-26, (2021); Shi J., Zuo D., Zhang Z., Transition activity recognition system based on standard deviation trend analysis, Sensors, 20, 11, pp. 1-11, (2020); Irfan S., Anjum N., Masood N., Khattak A.S., Ramzan N., A novel hybrid deep learning model for human activity recognition based on transitional activities, Sensors, 21, 24, pp. 1-20, (2021); Noor M.H.M., Feature learning using convolutional denoising autoencoder for activity recognition, Neural Comput. Appl., 2021, pp. 1-12, (2021); Xia K., Huang J., Wang H., LSTM-CNN architecture for human activity recognition, IEEE Access, 8, pp. 56855-56866, (2020); Noor M.H.M., Tan S.Y., Wahab M.N.A., Deep temporal conv-lstm for activity recognition, Neural Process. Lett., 54, 5, pp. 4027-4049, (2022); Rizwan M., Anderson D.V., Comparison of Distance Metrics for Phoneme Classification Based On Deep Neural Network Features and Weighted K-NN Classifier, (2016); Ferrari A., Micucci D., Mobilio M., Napoletano P., Trends in human activity recognition using smartphones, J. Reliable Intell. Environments, 7, 3, pp. 189-213, (2021); Xu Y., Qiu T.T., Human activity recognition and embedded application based on convolutional neural network, J. Artif. Intell. Technol., 1, 1, pp. 51-60, (2020); Karagiannaki K., Panousopoulou A., Tsakalides P., A benchmark study on feature selection for human activity recognition, Proc. ACM Int. Joint Conf. Pervasive Ubiquitous Computing: Adjunct, pp. 105-108, (2016); Anguita D., Et al., A public domain dataset for human activity recognition using smartphones, Proc. Eur. Symp. Artif. Neural Netw., (2013); Luptakova I.D., Kubovcik M., Pospichal J., Wearable sensorbased human activity recognition with transformer model, Sensors, 22, 5, (2022); Kljun M., Tersek M., Strumbelj E., A review and comparison of time series similarity measures, Proc. 29th Int. Electrotech. Comput. Sci. Conf., pp. 21-22, (2020); Kavitha K., Sandhya B., Thirumala B., Evaluation of distance measures for feature based image registration using AlexNet, Int. J. Adv. Comput. Sci. Appl., 9, 10, pp. 284-290, (2018); Labib K., Uznanski P., Wolleb-Graf D., Hamming distance completeness, Proc. Annu. Symp. Combinat. Pattern Matching, 128, 14, pp. 1-14, (2019); Choi S.S., Cha S.H., Tappert C.C., A survey of binary similarity and distance measures, Proc. 13th World Multi-Conf. Syst. Cybern. Inform., 3, 1, pp. 80-85, (2009); Yulita I.N., Saori S., Human activities and postural transitions classification using support vector machine and k-nearest neighbor methods, IOP Conf. Ser. Earth Environ. Sci., 248, 1, (2019)","M.H. Mohd Noor; Universiti Sains Malaysia, School of Computer Sciences, Pulau Pinang, 11800, Malaysia; email: halimnoor@usm.my","","Institute of Electrical and Electronics Engineers Inc.","","","","","","1530437X","","","","English","IEEE Sensors J.","Article","Final","","Scopus","2-s2.0-85165293712"
"Ahmad F.; Isa N.A.M.; Noor M.H.M.; Hussain Z.","Ahmad, Fadzil (36350716900); Isa, Nor Ashidi Mat (6603297760); Noor, Mohd Halim Mohd (36656106400); Hussain, Zakaria (24724464800)","36350716900; 6603297760; 36656106400; 24724464800","Intelligent breast cancer diagnosis using hybrid GA-ANN","2013","Proceedings - 5th International Conference on Computational Intelligence, Communication Systems, and Networks, CICSyN 2013","","","6571334","9","12","3","24","10.1109/CICSYN.2013.67","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883367681&doi=10.1109%2fCICSYN.2013.67&partnerID=40&md5=38d23079923e39319338a758dea437c3","Faculty of Electrical Engineering, Universiti Teknologi MARA, Pulau Pinang, Malaysia; Imaging and Intelligent System Research Team, School of Electrical and Electronic Engineering, Universiti Sains Malaysia, Pulau Pinang, Malaysia","Ahmad F., Faculty of Electrical Engineering, Universiti Teknologi MARA, Pulau Pinang, Malaysia, Imaging and Intelligent System Research Team, School of Electrical and Electronic Engineering, Universiti Sains Malaysia, Pulau Pinang, Malaysia; Isa N.A.M., Imaging and Intelligent System Research Team, School of Electrical and Electronic Engineering, Universiti Sains Malaysia, Pulau Pinang, Malaysia; Noor M.H.M., Faculty of Electrical Engineering, Universiti Teknologi MARA, Pulau Pinang, Malaysia; Hussain Z., Faculty of Electrical Engineering, Universiti Teknologi MARA, Pulau Pinang, Malaysia","Breast cancer prevails as one of the infamous deathly diseases among women worldwide. Early detection and treatment of breast cancer can increase the survival rate of patients. Presently, the method of diagnosis depends on the human experiences. The method is time-consuming, subjected to human error and cause unnecessary burden to radiologists. This paper introduces an automatic breast cancer diagnosis technique using a genetic algorithm (GA) for simultaneous feature selection and parameter optimization of artificial neural networks (ANN). The performances of the proposed algorithm employing three different variations of the backpropagation technique for the fine tuning of the weight of ANN are compared. The algorithm is called the GAANN-XX where the XX refers to the back-propagation training variation used. The proposed algorithms called GAANN-RP produces the best and average, 99.43% and 98.29% correct classification respectively on the Wiscinson Breast Cancer Dataset. © 2013 IEEE.","Artificial Neural Network; Back-propagation; Classification Accuracy; Feature Selection; Genetic Algorithm","Backpropagation algorithms; Classification (of information); Communication systems; Diagnosis; Diseases; Feature extraction; Neural networks; Patient treatment; Backpropagation techniques; Breast Cancer; Breast cancer diagnosis; Classification accuracy; Fine tuning; Human errors; Parameter optimization; Survival rate; Genetic algorithms","","","","","","","Ubeyli E.D., Implementing automated diagnostic systems for breast cancer detection, Expert Syst. Appl., 33, 4, pp. 1054-1062, (2007); Karabatak M., Ince M.C., An expert system for detection of breast cancer based on association rules and neural network, Expert Syst. Appl., 36, 2, pp. 3465-3469, (2009); Furundzic D., Djordjevic M., Jovicevic Bekic A., Neural networks approach to early breast cancer detection, J. Syst. Arch., 44, 8, pp. 617-633, (1998); Paliwal M., Kumar U.A., Neural networks and statistical techniques: A review of applications, Expert Syst. Appl., 36, 1, pp. 2-17, (2009); Walczak S., Cerpa N., Heuristic principles for the design of artificial neural networks, Inf. Softw. Technol., 41, 2, pp. 107-117, (1999); Setiono R., Liu H., Neural-network feature selector, Ieee Trans. Neural Networks, 8, 3, pp. 654-662, (1997); Huang C.-L., Wang C.-J., A GA-based feature selection and parameters optimizationfor support vector machines, Expert Syst. Appl., 31, 2, pp. 231-240, (2006); Ferentinos K.P., Biological engineering applications of feedforward neural networks designed and parameterized by genetic algorithms, Neural Networks Off. J. Int. Neural Netw. Soc., 18, 7, pp. 934-950, (2005); Almeida L.M., Ludermir T.B., A multi-objective memetic and hybrid methodology for optimizing the parameters and performance of artificial neural networks, Neurocomputing, 73, 7-9, pp. 1438-1450, (2010); Yao X., Evolving artificial neural networks, Proc. Ieee, 87, 9, pp. 1423-1447, (1999); Goldberg D.E., Genetic Algorithms in Search, Optimization, and Machine Learning, (1989); Prechelt L., PROBEN1-A Set of Neural Network Benchmark Problems and Benchmarking Rules, (1994); Castillo P.A., Merelo J.J., Prieto A., Rivas V., Romero G., GProp: Global optimization of multilayer perceptrons using GAs, Neurocomputing, 35, 1-4, pp. 149-163, (2000); Esugasini S., Mashor M.Y., Isa N.A.M., Othman N.H., Performance comparison for mlp networks using various back propagation algorithms for breast cancer diagnosis, Knowledge-Based Intelligent Information and Engineering Systems, pp. 123-130, (2005); Riedmiller M., Braun H., RPROP - A fast adaptive learning algorithm, Proc. of ISCIS VII, (1992)","","","","","5th International Conference on Computational Intelligence, Communication Systems, and Networks, CICSyN 2013","5 June 2013 through 7 June 2013","Madrid","99042","","978-076955042-8","","","English","Proc. - Int. Conf. Comput. Intell., Commun. Syst., Networks, CICSyN","Conference paper","Final","","Scopus","2-s2.0-84883367681"
"Al-Qablan T.A.; Noor M.H.M.; Al-Betar M.A.; Khader A.T.","Al-Qablan, Tamara Amjad (57195965457); Noor, Mohd Halim Mohd (36656106400); Al-Betar, Mohammed Azmi (57202908939); Khader, Ahamad Tajudin (24724794600)","57195965457; 36656106400; 57202908939; 24724794600","Improved Binary Gray Wolf Optimizer Based on Adaptive β-Hill Climbing for Feature Selection","2023","IEEE Access","11","","","59866","59881","15","0","10.1109/ACCESS.2023.3285815","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162640256&doi=10.1109%2fACCESS.2023.3285815&partnerID=40&md5=4c3064ac559c45e005bda7d02388360b","Universiti Sains Malaysia, School of Computer Sciences, Pulau Pinang, 11800, Malaysia; Ajman University, Artificial Intelligence Research Center (AIRC), College of Engineering and Information Technology, Ajman, United Arab Emirates; Al-Huson University College, Al-Balqa Applied University, Department of Information Technology, Irbid, 19117, Jordan","Al-Qablan T.A., Universiti Sains Malaysia, School of Computer Sciences, Pulau Pinang, 11800, Malaysia; Noor M.H.M., Universiti Sains Malaysia, School of Computer Sciences, Pulau Pinang, 11800, Malaysia; Al-Betar M.A., Ajman University, Artificial Intelligence Research Center (AIRC), College of Engineering and Information Technology, Ajman, United Arab Emirates, Al-Huson University College, Al-Balqa Applied University, Department of Information Technology, Irbid, 19117, Jordan; Khader A.T., Universiti Sains Malaysia, School of Computer Sciences, Pulau Pinang, 11800, Malaysia","According to the literature reviews, the Gray Wolf Optimization (GWO) algorithm has been applied to various optimization problems, including feature selection. It is important to consider two opposing ideas while using the metaheuristic technique, exploring the search field, and exploiting the best possible solutions. Despite the increased performance of the GWO, stagnation in local optima areas could still be a concern. This paper proposes a hybridized version of Binary GWO (BGWO) and another recent metaheuristic algorithm, namely adaptive β -hill climbing (A β CH), to enhance the performance of a wrapper-based feature selection approach. The sigmoid transfer function is used to transfer the continuous search space into a binary version to meet the feature selection nature requirement. The K-Nearest Neighbor (KNN) classifier is used to evaluate the goodness of the selected features. To validate the performance of the proposed hybrid approach, 18 standard feature selection UCI benchmark datasets were used. The performance of the proposed hybrid approach was also compared with the Binary hybrid Gray Wolf Optimization Particle Swarm Optimization (BGWOPSO), BGWO (bGWO1,bGWO2), Binary Particle Swarm Optimization (BPSO), Binary Genetic Algorithm (BGA), Whale Optimization Algorithm with Simulated Annealing (WOASAT-2), A β HC with Binary Sailfish (A β BSF), Binary β -Hill Climbing ( β HC), Binary JAYA with Adaptive Mutation (BJAM), and Binary Horse herd Optimization Algorithm(BHOA). The findings revealed that the proposed hybrid algorithm was effective in improving the performance of the normal BGWO algorithm, also the proposed hybrid approach outperforms the two approaches of the BGWO algorithm in terms of accuracy and selected feature size. Similarly, compared with BGWOPSO, BPSO, BGA, WOASAT-2, A β BSF, β HC, BJAM, and BHOA feature selection approaches, the proposed approach surpassed them and yielded better accuracy and smaller size of feature selection.  © 2013 IEEE.","adaptive β-hill climbing; Binary Grey wolf Optimizer; feature selection; local search; optimization","Ball grid arrays; Benchmarking; Classification (of information); Genetic algorithms; Nearest neighbor search; Particle swarm optimization (PSO); Simulated annealing; Adaptive β-hill climbing; Binary gray wolf optimizer; Classification algorithm; Features extraction; Features selection; Gray wolves; Hill climbing; Local search; Metaheuristic; Optimisations; Optimizers; Particle swarm; Particle swarm optimization; Prediction algorithms; Search problem; Swarm optimization; Feature Selection","","","","","","","Hira Z.M., Gillies D.F., A review of feature selection and feature extraction methods applied on microarray data, Adv. Bioinf, 2015, pp. 1-13, (2015); Hoque N., Ahmed H.A., Bhattacharyya D.K., Kalita J.K., A fuzzy mutual information-based feature selection method for classification, Fuzzy Inf. Eng, 8, 3, pp. 355-384, (2016); Guyon I., Elisseeff A., An introduction to variable and feature selection, J. Mach. Learn. Res, 3, pp. 1157-1182, (2003); Hassonah M.A., Al-Sayyed R., Rodan A., Al-Zoubi A.M., Aljarah I., Faris H., An efficient hybrid filter and evolutionary wrapper approach for sentiment analysis of various topics on Twitter, Knowl.-Based Syst, 192, (2020); Kumar A., Khorwal R., Firefly algorithm for feature selection in sentiment analysis, Computational Intelligence in Data Mining: Proceedings of the International Conference on CIDM, 10.11 December 2016. Springer, pp. 693-703, (2017); Labani M., Moradi P., Ahmadizar F., Jalili M., A novel multivariate filter method for feature selection in text classification problems, Eng. Appl. Artif. Intell, 70, pp. 25-37, (2018); Alweshah M., Alkhalaileh S., Al-Betar M.A., Bakar A.A., Coronavirus herd immunity optimizer with greedy crossover for feature selection in medical diagnosis, Knowl.-Based Syst, 235, (2022); Liu H., Zhou M., Liu Q., An embedded feature selection method for imbalanced data classification, IEEE/CAA J. Autom. Sinica, 6, 3, pp. 703-715, (2019); Urbanowicz R.J., Meeker M., Cava W.L., Olson R.S., Moore J.H., Relief-based feature selection: Introduction and review, J. Biomed. Informat, 85, pp. 189-203, (2018); Brezonik L., Fister I., Podgorelec V., Swarm intelligence algorithms for feature selection: A review, Appl. Sci, 8, 9, (2018); Fonseca C.M., Fleming P.J., An overview of evolutionary algorithms in multiobjective optimization, Evol. Comput, 3, 1, pp. 1-16, (1995); Iqbal F., Hashmi J.M., Fung B.C.M., Batool R., Khattak A.M., Aleem S., Hung P.C.K., A hybrid framework for sentiment analysis using genetic algorithm based feature reduction, IEEE Access, 7, pp. 14637-14652, (2019); Aggarwal S., Chhabra B., Sentimental analysis of tweets using ant colony optimizations, Proc. Int. Conf. Intell. Sustain. Syst. (ICISS), pp. 1219-1223, (2017); Tubishat M., Abushariah M.A.M., Idris N., Aljarah I., Improved whale optimization algorithm for feature selection in Arabic sentiment analysis, Appl. Intell, 49, 5, pp. 1688-1707, (2019); Mirjalili S., Mirjalili S.M., Lewis A., Grey wolf optimizer, Adv. Eng. Softw, 69, pp. 46-61, (2014); Faris H., Aljarah I., Al-Betar M.A., Mirjalili S., Grey wolf optimizer: A review of recent variants and applications, Neural Comput. Appl, 30, 2, pp. 413-435, (2018); Abdel-Basset M., Sallam K.M., Mohamed R., Elgendi I., Munasinghe K., Elkomy O.M., An improved binary grey-wolf optimizer with simulated annealing for feature selection, IEEE Access, 9, pp. 139792-139822, (2021); Rajammal R.R., Mirjalili S., Ekambaram G., Palanisamy N., Binary grey wolf optimizer with mutation and adaptive K-nearest neighbour for feature selection in Parkinson's disease diagnosis, Knowl.-Based Syst, 246, (2022); Elgamal Z.M., Yasin N.M., Sabri A.Q.M., Sihwail R., Tubishat M., Jarrah H., Improved equilibrium optimization algorithm using elite opposition-based learning and new local search strategy for feature selection in medical datasets, Computation, 9, 6, (2021); Al-Betar M.A., Aljarah I., Awadallah M.A., Faris H., Mirjalili S., Adaptive .hill climbing for optimization, Soft Comput, 23, 24, pp. 13489-13512, (2019); Kushwaha N., Pant M., Link based BPSO for feature selection in big data text clustering, Future Gener. Comput. Syst, 82, pp. 190-199, (2018); Wang H., Yu H., Zhang Q., Cang S., Liao W., Zhu F., Parameters optimization of classifier and feature selection based on improved artificial bee colony algorithm, Proc. Int. Conf. Adv. Mech. Syst. (ICAMechS), pp. 242-247, (2016); Ahmad S.R., Bakar A.A., Yaakub M.R., Ant colony optimization for text feature selection in sentiment analysis, Intell. Data Anal, 23, 1, pp. 133-158, (2019); Awadallah M.A., Al-Betar M.A., Hammouri A.I., Alomari O.A., Binary Jaya algorithm with adaptive mutation for feature selection, Arabian J. Sci. Eng, 45, 12, pp. 10875-10890, (2020); Al-Betar M.A., Hammouri A.I., Awadallah M.A., Doush I.A., Binary -hill climbing optimizer with s-shape transfer function for feature selection, J. Ambient Intell. Hum. Comput, 12, 7, pp. 7637-7665, (2021); Awadallah M.A., Hammouri A.I., Al-Betar M.A., Braik M.S., Elaziz M.A., Binary horse herd optimization algorithm with crossover operators for feature selection, Comput. Biol. Med, 141, (2022); Ahmad S.R., Zakwan M., Syafira N., Moziyana N., Ismail S., A review of feature selection and sentiment analysis technique in issues of propaganda, Int. J. Adv. Comput. Sci. Appl, 10, 11, pp. 1-6, (2019); Zhao H., Liu Z., Yao X., Yang Q., A machine learning-based sentiment analysis of online product reviews with a novel term weighting and feature selection approach, Inf. Process. Manage, 58, 5, (2021); Moldovan D., Slowik A., Energy consumption prediction of appliances using machine learning and multi-objective binary grey wolf optimization for feature selection, Appl. Soft Comput, 111, (2021); Dudi B.P., Rajesh V., The plant leaf classification system using an optimum feature selection by grey wolf optimization, Turkish J. Physiotherapy Rehabil, 32, pp. 138-142, (2021); Nimbiwal M., Vashishtha J., A novel hybrid grey wolf optimization algorithm using two-phase crossover approach for feature selection and classification, Computacion Sistemas, 25, 4, pp. 793-801, (2021); El-Kenawy E.-S.M., Eid M., Hybrid gray wolf and particle swarm optimization for feature selection, Int. J. Innov. Comput. Inf. Control, 16, 3, pp. 831-844, (2020); Sankhwar S., Gupta D., Ramya K.C., Rani S.S., Shankar K., Lakshmanaprabu S.K., Improved grey wolf optimization-based feature subset selection with fuzzy neural classifier for financial crisis prediction, Soft Comput, 24, 1, pp. 101-110, (2020); Almazini H., Ku-Mahamud K., Grey wolf optimization parameter control for feature selection in anomaly detection, Int. J. Intell. Eng. Syst, 14, 2, pp. 474-483, (2021); Zhang C., Wang W., Pan Y., Enhancing electronic nose performance by feature selection using an improved grey wolf optimization based algorithm, Sensors, 20, 15, (2020); Alzubi Q.M., Anbar M., Alqattan Z.N.M., Al-Betar M.A., Abdullah R., Intrusion detection system based on a modified binary grey wolf optimisation, Neural Comput. Appl, 32, 10, pp. 6125-6137, (2020); Al-Tashi Q., Kadir S.J.A., Rais H.M., Mirjalili S., Alhussian H., Binary optimization using hybrid grey wolf optimization for feature selection, IEEE Access, 7, pp. 39496-39508, (2019); Tu Q., Chen X., Liu X., Multi-strategy ensemble grey wolf optimizer and its application to feature selection, Appl. Soft Comput, 76, pp. 16-30, (2019); Zhao X., Zhang X., Cai Z., Tian X., Wang X., Huang Y., Chen H., Hu L., Chaos enhanced grey wolf optimization wrapped ELM for diagnosis of paraquat-poisoned patients, Comput. Biol. Chem, 78, pp. 481-490, (2019); Sharma P., Sundaram S., Sharma M., Sharma A., Gupta D., Diagnosis of Parkinson's disease using modified grey wolf optimization, Cogn. Syst. Res, 54, pp. 100-115, (2019); Nirmala Sreedharan N.P., Ganesan B., Raveendran R., Sarala P., Dennis B., Boothalingam R., Grey wolf optimisation-based feature selection and classification for facial emotion recognition, IET Biometrics, 7, 5, pp. 490-499, (2018); Too J., Abdullah A., Saad N.M., Ali N.M., Tee W., A new competitive binary grey wolf optimizer to solve the feature selection problem in EMG signals classification, Computers, 7, 4, (2018); Wang J.-S., Li S.-X., An improved grey wolf optimizer based on differential evolution and elimination mechanism, Sci. Rep, 9, 1, pp. 1-21, (2019); Wolpert D.H., MacReady W.G., No free lunch theorems for optimization, IEEE Trans. Evol. Comput, 1, 1, pp. 67-82, (1997); Al-Tashi Q., Md Rais H., Abdulkadir S.J., Mirjalili S., Alhussian H., A review of grey wolf optimizer-base feature selection methods for classification, Evolutionary Machine Learning Techniques: Algorithms and Applications, pp. 273-286, (2020); Imandoust S.B., Bolandraftar M., Application of k-nearest neighbor (KNN) approach for predicting economic events: Theoretical background, Int. J. Eng. Res. Appl, 3, pp. 605-610, (2013); Suganthan P.N., Hansen N., Liang J.J., Deb K., Chen Y.-P., Auger A., Tiwari S., Problem definitions and evaluation criteria for the CEC 2005 special session on realparameter optimization, KanGAL, Tech. Rep. 2005005, 2005, (2005); Mirjalili S., Mirjalili S.M., Hatamlou A., Multi-verse optimizer: A nature-inspired algorithm for global optimization, Neural Comput. Appl, 27, 2, pp. 495-513, (2016); Mahdavi M., Fesanghary M., Damangir E., An improved harmony search algorithm for solving optimization problems, Appl. Math. Comput, 188, 2, pp. 1567-1579, (2007); Emary E., Zawbaa H.M., Hassanien A.E., Binary grey wolf optimization approaches for feature selection, Neurocomputing, 172, pp. 371-381, (2016); Mafarja M.M., Mirjalili S., Hybrid whale optimization algorithm with simulated annealing for feature selection, Neurocomputing, 260, pp. 302-312, (2017); Emary E., Zawbaa H.M., Hassanien A.E., Binary ant lion approaches for feature selection, Neurocomputing, 213, pp. 54-65, (2016); Ghosh K.K., Ahmed S., Singh P.K., Geem Z.W., Sarkar R., Improved binary sailfish optimizer based on adaptive β-hill climbing for feature selection, IEEE Access, 8, pp. 83548-83560, (2020)","T.A. Al-Qablan; Universiti Sains Malaysia, School of Computer Sciences, Pulau Pinang, 11800, Malaysia; email: tqablan@student.usm.my; M.H.M. Noor; Universiti Sains Malaysia, School of Computer Sciences, Pulau Pinang, 11800, Malaysia; email: halimnoor@usm.my","","Institute of Electrical and Electronics Engineers Inc.","","","","","","21693536","","","","English","IEEE Access","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85162640256"
"Ab Wahab M.N.; Nazir A.; Ren A.T.Z.; Noor M.H.M.; Akbar M.F.; Mohamed A.S.A.","Ab Wahab, Mohd Nadhir (57223397087); Nazir, Amril (24723004500); Ren, Anthony Tan Zhen (57290466200); Noor, Mohd Halim Mohd (36656106400); Akbar, Muhammad Firdaus (57195979493); Mohamed, Ahmad Sufril Azlan (57190968285)","57223397087; 24723004500; 57290466200; 36656106400; 57195979493; 57190968285","Efficientnet-Lite and Hybrid CNN-KNN Implementation for Facial Expression Recognition on Raspberry Pi","2021","IEEE Access","9","","","134065","134080","15","36","10.1109/ACCESS.2021.3113337","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115174722&doi=10.1109%2fACCESS.2021.3113337&partnerID=40&md5=92c9705ca03f0589b4a0244d4eecce85","School of Computer Sciences, Universiti Sains Malaysia, Penang, Minden, 11800, Malaysia; Department of Information Systems and Technology Management, College of Technological Innovation, Zayed University, Abu Dhabi, United Arab Emirates; School of Electrical and Electronic Engineering, Engineering Campus, Universiti Sains Malaysia, Nibong Tebal, Penang, 14300, Malaysia","Ab Wahab M.N., School of Computer Sciences, Universiti Sains Malaysia, Penang, Minden, 11800, Malaysia; Nazir A., Department of Information Systems and Technology Management, College of Technological Innovation, Zayed University, Abu Dhabi, United Arab Emirates; Ren A.T.Z., School of Computer Sciences, Universiti Sains Malaysia, Penang, Minden, 11800, Malaysia; Noor M.H.M., School of Computer Sciences, Universiti Sains Malaysia, Penang, Minden, 11800, Malaysia; Akbar M.F., School of Electrical and Electronic Engineering, Engineering Campus, Universiti Sains Malaysia, Nibong Tebal, Penang, 14300, Malaysia; Mohamed A.S.A., School of Computer Sciences, Universiti Sains Malaysia, Penang, Minden, 11800, Malaysia","Facial expression recognition (FER) is the task of determining a person's current emotion. It plays an important role in healthcare, marketing, and counselling. With the advancement in deep learning algorithms like Convolutional Neural Network (CNN), the system's accuracy is improving. A hybrid CNN and k-Nearest Neighbour (KNN) model can improve FER's accuracy. This paper presents a hybrid CNN-KNN model for FER on the Raspberry Pi 4, where we use CNN for feature extraction. Subsequently, the KNN performs expression recognition. We use the transfer learning technique to build our system with an EfficientNet-Lite model. The hybrid model we propose replaces the Softmax layer in the EfficientNet with the KNN. We train our model using the FER-2013 dataset and compare its performance with different architectures trained on the same dataset. We perform optimization on the Fully Connected layer, loss function, loss optimizer, optimizer learning rate, class weights, and KNN distance function with the k-value. Despite running on the Raspberry Pi hardware with very limited processing power, low memory capacity, and small storage capacity, our proposed model achieves a similar accuracy of 75.26% (with a slight improvement of 0.06%) to the state-of-the-art's Ensemble of 8 CNN model. © 2013 IEEE.","EfficientNet-Lite; emotion recognition; facial expression recognition; hybrid CNN-KNN; Raspberry Pi","Convolutional neural networks; Deep learning; Face recognition; Learning systems; Nearest neighbor search; Transfer learning; Distance functions; Expression recognition; Facial expression recognition; K nearest neighbours (k-NN); Learning techniques; Processing power; State of the art; Storage capacity; Learning algorithms","","","","","","","Panksepp J., Affective Neuroscience: The Foundations of Human and Animal Emotions, (2004); Izard C., The Psychology of Emotions, (1991); Ekman P., Friesen W., Facial Action Coding System, 1, (1978); Carlson N., Physiology of Behavior, (2012); Yu J., Bhanu B., Evolutionary feature synthesis for facial expression recognition, Pattern Recognit. Lett., 27, 11, pp. 1289-1298, (2006); Jabid T., Kabir M.H., Chae O., Robust facial expression recognition based on local directional pattern, Etri J., 32, 5, pp. 784-794, (2010); Shima Y., Omori Y., Image augmentation for classifying facial expression images by using deep neural network pre-trained with object image database, Proc. 3rd Int. Conf. Robot., Control Autom., pp. 140-146, (2018); Shan C., Gong S., McOwan P.W., Facial expression recognition based on local binary patterns: A comprehensive study, Image Vis. Com-put, 27, 6, pp. 803-816, (2009); Mehendale N., Facial emotion recognition using convolutional neural networks (FERC), Social Netw. Appl. Sci., 2, 3, pp. 1-8, (2020); Breuer R., Kimmel R., A Deep Learning Perspective on the Origin of Facial Expressions, (2017); Saeed S., Baber J., Bakhtyar M., Ullah I., Sheikh N., Dad I., Ali A., Empirical evaluation of SVM for facial expression recognition, Int. J. Adv. Comput. Sci. Appl., 9, 11, pp. 670-673, (2018); Goodfellow I.J., Erhan D., Carrier P.L., Courville A., Mirza M., Hamner B., Cukierski W., Tang Y., Thaler D., Lee D.H., Zhou Y., Challenges in representation learning: A report on three machine learning contests, Proc. Int. Conf. Neural Inf. Process, pp. 117-124, (2013); Pramerdorfer C., Kampel M., Facial Expression Recognition Using Convolutional Neural Networks: State of the Art, (2016); Sun Y., An Y., Research on the embedded system of facial expression recognition based on HMM, Proc. 2nd Ieee Int. Conf. Inf. Manage. Eng, pp. 727-731, (2010); Turabzadeh S., Meng H., Swash R.M., Pleva M., Juhar J., Real-time emotional state detection from facial expression on embedded devices, Proc. 7th Int. Conf. Innov. Comput. Technol. (INTECH), pp. 46-51, (2017); Loza-Alvarez A., Monroy-Meza A., Suarez-Rivera R.A., Perez-Soto G.I., Morales-Hernandez L.A., Camarillo-Gomez K.A., Facial expressions recognition with CNN and its application in an assistant humanoid robot, Proc. COMRob, pp. 1-6, (2018); Gallego A.-J., Pertusa A., Calvo-Zaragoza J., Improving convolu-tional neural networks' accuracy in noisy environments using k-nearest neighbors, Appl. Sci., 8, 11, (2018); Tan M., Le Q., EfficientNet: Rethinking model scaling for convolu-tional neural networks, Proc. 36th Int. Conf. Mach. Learn, pp. 6105-6114, (2019); FER-2013 Dataset, (2020); Srinivas B., Rao G., A hybrid CNN-KNN model for MRI brain tumor classification, Int. J. Recent Technol. Eng., 8, 2, pp. 20-25, (2019); Raheem K.R., Ali I.H., Facial expression recognition using hybrid CNN-SVM technique, Int. J. Adv. Sci. Technol., 29, 4, pp. 5528-5534, (2020); Gallego A.-J., Calvo-Zaragoza J., Rico-Juan J.R., Insights into efficient k-nearest neighbor classification with convolutional neural codes, Ieee Access, 8, pp. 99312-99326, (2020); Sun X., Park J., Kang K., Hur J., Novel hybrid CNN-SVM model for recognition of functional magnetic resonance images, Proc. Ieee Int. Conf. Syst., Man, Cybern. (SMC), pp. 1001-1006, (2017); Mohamed A.E., Comparative study of four supervised machine learning techniques for classification, Int. J. Appl. Sci. Technol., 7, 2, pp. 5-18, (2017); Miao S., Xu H., Han Z., Zhu Y., Recognizing facial expressions using a shallow convolutional neural network, Ieee Access, 7, pp. 78000-78011, (2019); Zahara L., Musa P., Prasetyo Wibowo E., Karim I., Bahri Musa S., The facial emotion recognition (FER-2013) dataset for prediction system of micro-expressions face using the convolutional neural network (CNN) algorithm based raspberry pi, Proc. 5th Int. Conf. Informat. Comput. (ICIC), pp. 1-9, (2020); Shirisha K., Buddha M., Facial emotion detection using convolutional neural network, Int. J. Sci. Eng. Res., 11, 3, pp. 51-54, (2020)","M.H.M. Noor; School of Computer Sciences, Universiti Sains Malaysia, Minden, Penang, 11800, Malaysia; email: halimnoor@usm.my; M.F. Akbar; School of Electrical and Electronic Engineering, Engineering Campus, Universiti Sains Malaysia, Penang, Nibong Tebal, 14300, Malaysia; email: firdaus.akbar@usm.my","","Institute of Electrical and Electronics Engineers Inc.","","","","","","21693536","","","","English","IEEE Access","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85115174722"
"Ahmad K.A.; Noor M.H.M.; Hussain Z.; Idin M.A.M.; Abdullah N.","Ahmad, K.A. (35760857000); Noor, M.H Mohd (36656106400); Hussain, Z. (24724464800); Idin, M.A. Mohd (55247148600); Abdullah, Noramalina (57208570673)","35760857000; 36656106400; 24724464800; 55247148600; 57208570673","Improvement moving vehicle detection using RGB removal shadow segmentation","2011","Proceedings - 2011 IEEE International Conference on Control System, Computing and Engineering, ICCSCE 2011","","","6190489","22","26","4","4","10.1109/ICCSCE.2011.6190489","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84862084005&doi=10.1109%2fICCSCE.2011.6190489&partnerID=40&md5=aec5eb9a99c7099216b7b9f23cbda515","Faculty of Electrical, Universiti Teknologi MARA, 40450 Shah Alam, Malaysia; School of Electrical and Electronic Engineering, Universiti Sains Malaysia, 14300 Nibong Tebal, Seberang Perai Selatan, Pulau Pinang, Malaysia","Ahmad K.A., Faculty of Electrical, Universiti Teknologi MARA, 40450 Shah Alam, Malaysia; Noor M.H.M., Faculty of Electrical, Universiti Teknologi MARA, 40450 Shah Alam, Malaysia; Hussain Z., Faculty of Electrical, Universiti Teknologi MARA, 40450 Shah Alam, Malaysia; Idin M.A.M., Faculty of Electrical, Universiti Teknologi MARA, 40450 Shah Alam, Malaysia; Abdullah N., School of Electrical and Electronic Engineering, Universiti Sains Malaysia, 14300 Nibong Tebal, Seberang Perai Selatan, Pulau Pinang, Malaysia","The detection of moving object in dynamic case especially outdoor case is very challenging for computer vision. One of the problems in dynamic case is detection of shadow in moving object. This paper presents the improvement of moving vehicle detection using removal shadow technique in RGB color space and frame difference technique. In RGB color space, the luminance and chrominance value are being tuned to remove shadow. The result shows about 75% of shadow can be removed from image moving object detection. The result also shows the improvement of moving object detection. © 2011 IEEE.","Frame Differencing; Moving object detection; RGB color space; Shadow Removal","Computer vision; Control systems; Object recognition; Detection of moving object; Frame differences; Frame differencing; Moving objects; Moving vehicles; Moving-object detection; RGB color space; Shadow removal; Shadow segmentation; Color","","","","","","","Cao J., Wang W., Liang Y., An Improved Detection Algorithm of Moving Vehicles Based on Computer Vision, (2009); Hafiz F., Khalifa O., Shafie A.A., Ali M.H., Foreground segmentation-based human detection with shadow removal, International Conference on Computer and Communication Engineering (ICCCE 2010), IEEE, (2010); Saravanakumar S., Vadiel A., Saneem Ahmed C.G., Multiple human object tracking and shadow removal techniques, IEEE International Conference on Signal and Image Processing, (2010); Chen C.-T., Su C.-Y., Kao W.-C., An Enhanced Segmentation on Vision-based Shadow Removal for Vehicle Detection, (2010); Zhu Z., Lu X., An accurate shadow removal method for vehicle tracking, IEEE International Conference on Artificial Intelligence and Computational Intelligent, (2010); Li P., Ma H., Huang C., Xu B., Dynamic vehicle detection algorithm based on background updating and suppressing, IEEE International Conference of Information Science and Management Engineering, (2010); Kanhere N.K., Birchfield S.T., Rela-time incremental segmentation and tracking of vehicles at low camera angles using stable features, IEEE Transaction on Intelligent Transportation System, 9, 1, (2008); Lin S., Tang J., Zhang X., Lv Y., Research on traffic moving object detection, tracking and track-generating, IEEE Proceedings International Conference on Automation and Logistics Shenyang, (2009); Jaijang K., Kaewtrakulpong P., Siddhichai S., Object Detection and Modeling Algorithm for Automatic Visual People Counting System, (2009); Yang W., Real-time moving vehicle detection with cast shadow removal in video based on conditional random field, IEEE Transactions on Circuit and Systems for Video Technology, 19, 3, (2009); Song X., Ding Y., Gen J., Chen Y., Shadow removal of vehicle in a video system based on RGB chroma model, IEEE International Conference on Computer Science and Software Engineering, (2008); Wang C., Zhang W., A robust algorithm for shadow of foreground detection in video surveillance, IEEE Asia-Pasific Conference on Information Processing, (2009); Xu L., Qi F., Jiang R., Shadow removal from a single image, IEEE International Conference on Intelligent System Design and Applications (ISDA'06), (2006); Hamdy A., Hamdy S., Visual surveillance in dynamic scene, IEEE Proceedings on WSEAS International Conference on Computational Intelligent, Man-Machine Systems and Cybernatics, (2008); Hu H., Li Z., Qu Z., Wang D., Vision-based moving objects detction with background modeling, IEEE International Conference on Measuring Technology and Mechatronics Automation, (2009); Mohana H.S., Ashwatakumar M., Shivakumar G., Vehicle detection and counting by using real time traffic flux throungh differential technique and performance evaluation, IEEE International Conference on Advanced Computer Control, (2008); Zhang W., Wu Q.M.J., Yin H.B., Moving Vehicles Detection Based on Adaptive Motion Histogram","K.A. Ahmad; Faculty of Electrical, Universiti Teknologi MARA, 40450 Shah Alam, Malaysia; email: Azman062@ppinang.uitm.edu.my","","","","2011 IEEE International Conference on Control System, Computing and Engineering, ICCSCE 2011","25 November 2011 through 27 November 2011","Penang","89794","","978-145771642-3","","","English","Proc. - IEEE Int. Conf. Control Syst., Comput. Eng., ICCSCE","Conference paper","Final","","Scopus","2-s2.0-84862084005"
"Nordin N.; Zainol Z.; Mohd Noor M.H.; Lai Fong C.","Nordin, Noratikah (57222566751); Zainol, Zurinahni (12144032400); Mohd Noor, Mohd Halim (36656106400); Lai Fong, Chan (57222566956)","57222566751; 12144032400; 36656106400; 57222566956","A comparative study of machine learning techniques for suicide attempts predictive model","2021","Health Informatics Journal","27","1","","","","","14","10.1177/1460458221989395","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103230376&doi=10.1177%2f1460458221989395&partnerID=40&md5=b958b8cc1c08beb7042078d845464d24","Universiti Sains Malaysia, Malaysia; National University of Malaysia Medical Centre, Malaysia","Nordin N., Universiti Sains Malaysia, Malaysia; Zainol Z., Universiti Sains Malaysia, Malaysia; Mohd Noor M.H., Universiti Sains Malaysia, Malaysia; Lai Fong C., National University of Malaysia Medical Centre, Malaysia","Current suicide risk assessments for predicting suicide attempts are time consuming, of low predictive value and have inadequate reliability. This paper aims to develop a predictive model for suicide attempts among patients with depression using machine learning algorithms as well as presents a comparative study on single predictive models with ensemble predictive models for differentiating depressed patients with suicide attempts from non-suicide attempters. We applied and trained eight different machine learning algorithms using a dataset that consists of 75 patients diagnosed with a depressive disorder. A recursive feature elimination was used to reduce the features via three-fold cross validation. An ensemble predictive models outperformed the single predictive models. Voting and bagging revealed the highest accuracy of 92% compared to other machine learning algorithms. Our findings indicate that history of suicide attempt, religion, race, suicide ideation and severity of clinical depression are useful factors for prediction of suicide attempts. © The Author(s) 2021.","data mining; depressive disorder; machine learning; predictive model; suicidal behaviour","Algorithms; Humans; Machine Learning; Reproducibility of Results; Risk Factors; Suicidal Ideation; Suicide, Attempted; algorithm; human; machine learning; reproducibility; risk factor; suicidal ideation; suicide attempt","","","","","Institute of Postgraduate Studies, Universiti Sains Malaysia, IPS, (USM Bridging Grant [304.PKOM.6316284]); Universiti Sains Malaysia","","Saxena S., Krug E.G., Chestnov O., Preventing suicide: a global imperative, (2014); Barros J., Morales S., Echavarri O., Et al., Suicide detection in Chile: proposing a predictive model for suicide risk in a clinical sample of patients with mood disorders, Rev Bras Psiquiatr, 39, 1, pp. 1-11, (2016); Ribeiro J.D., Franklin J.C., Fox K.R., Et al., Self-injurious thoughts and behaviors as risk factors for future suicide ideation, attempts, and death: a meta-analysis of longitudinal studies, Psychol Med, 46, 2, pp. 225-236, (2016); Melhem N.M., Porta G., Oquendo M.A., Et al., Severity and variability of depression symptoms predicting suicide attempt in high-risk individuals, JAMA Psychiatry, 76, 6, (2019); Ahmed H., Hossain M., Aftab A., Et al., Suicide and depression in the World Health Organization South-East Asia Region: a systematic review, WHO South-East Asia J Public Health, 6, 1, (2017); Mars B., Heron J., Klonsky E.D., Et al., Predictors of future suicide attempt among adolescents with suicidal thoughts or non-suicidal self-harm: a population-based birth cohort study, Lancet Psychiatry, 6, 4, pp. 327-337, (2019); Sinniah A., Maniam T., Oei T.P., Et al., Suicide attempts in Malaysia from the year 1969 to 2011, Sci World J, 2014, pp. 1-13, (2014); National Health and Morbidity Survey (NHMS) 2017: key findings from the adolescent health and nutrition surveys, (2018); Chan L.F., Maniam T., Shamsul A.S., Suicide attempts among depressed inpatients with depressive disorder in a Malaysian sample: psychosocial and clinical risk factors, Crisis, 32, 5, pp. 283-287, (2011); Delgado-Gomez D., Blasco-Fontecilla H., Sukno F., Et al., Suicide attempters classification: toward predictive models of suicidal behavior, Neurocomputing, 92, pp. 3-8, (2012); Chan L.F., Shamsul A.S., Maniam T., Are predictors of future suicide attempts and the transition from suicidal ideation to suicide attempts shared or distinct: a 12-month prospective study among patients with depressive disorders, Psychiatry Res, 220, 3, pp. 867-873, (2014); Velupillai S., Hadlaczky G., Baca-Garcia E., Et al., Risk assessment tools and data-driven approaches for predicting and preventing suicidal behavior, Front Psychiatry, 10, (2019); Le D.V., Montgomery J., Kirkby K.C., Et al., Risk prediction using natural language processing of electronic mental health records in an inpatient forensic psychiatry setting, J Biomed Inform, 86, pp. 49-58, (2018); Walsh C.G., Ribeiro J.D., Franklin J.C., Predicting suicide attempts in adolescents with longitudinal clinical data and machine learning, J Child Psychol Psychiatry, 59, 12, pp. 1261-1270, (2018); Belsher B.E., Smolenski D.J., Pruitt L.D., Et al., Prediction models for suicide attempts and deaths: a systematic review and simulation, JAMA Psychiatry, 76, 6, (2019); Hettige N.C., Nguyen T.B., Yuan C., Et al., Classification of suicide attempters in schizophrenia using sociocultural and clinical features: a machine learning approach, Gen Hosp Psychiatry, 47, pp. 20-28, (2017); Bae S.-M., Lee S.-H., Lee S.A., Prediction by data mining, of suicide attempts in Korean adolescents: a national study, Neuropsychiatr Dis Treat, 11, pp. 2367-2375, (2015); Oh J., Yun K., Hwang J.-H., Et al., Classification of suicide attempts through a machine learning algorithm based on multiple systemic psychiatric scales, Front Psychiatry, 8, (2017); Passos I.C., Mwangi B., Cao B., Et al., Identifying a clinical signature of suicidality among patients with mood disorders: a pilot study using a machine learning approach, J Affect Disord, 193, pp. 109-116, (2016); Ryu S., Lee H., Lee D.-K., Et al., Use of a machine learning algorithm to predict individuals with suicide ideation in the general population, Psychiatry Investig, 15, 11, pp. 1030-1036, (2018); Franklin J.C., Ribeiro J.D., Fox K.R., Et al., Risk factors for suicidal thoughts and behaviors: a meta-analysis of 50 years of research, Psychol Bull, 143, 2, pp. 187-232, (2017); Jain D., Singh V., Feature selection and classification systems for chronic disease prediction: a review, Egypt Inform J, 19, 3, pp. 179-189, (2018); Sanchez-Pinto L.N., Venable L.R., Fahrenbach J., Et al., Comparison of variable selection methods for clinical predictive modeling, Int J Med Inf, 116, pp. 10-17, (2018); Richter A.N., Khoshgoftaar T.M., A review of statistical and machine learning methods for modeling cancer risk using structured clinical data, Artif Intell Med, 90, pp. 1-14, (2018); Zhou Z.-H., Ensemble methods: foundations and algorithms, (2012); Alpaydin E., Introduction to machine learning, (2010); Indrawan G., Sudiarsa I.K.P., Agustini K., Et al., Smooth support vector machine for suicide-related behaviours prediction, Int J Electr Comput Eng, 8, 5, (2018); Kantardzic M., Data mining: concepts, models, methods, and algorithms, (2019); Xu Y., Goodacre R., On splitting training and validation set: a comparative study of cross-validation, bootstrap and systematic sampling for estimating the generalization performance of supervised learning, J Anal Test, 2, 3, pp. 249-262, (2018); Korjus K., Hebart M.N., Vicente R., An efficient data partitioning to improve classification performance while keeping parameters interpretable, PLoS One, 11, 8, (2016); Saeb S., Lonini L., Jayaraman A., Et al., The need to approximate the use-case in clinical machine learning, Gigascience, 6, 5, (2017); Trevethan R., Sensitivity, specificity, and predictive values: foundations, pliabilities, and pitfalls in research and practice, Front Public Health, 5, (2017); Fangyu L., Hua H., Assessing the accuracy of diagnostic tests, Shanghai Arch Psychiatry, 30, 3, pp. 207-212, (2018)","M.H. Mohd Noor; Universiti Sains Malaysia, Malaysia; email: halimnoor@usm.my","","SAGE Publications Ltd","","","","","","14604582","","HIJEA","33745355","English","Health Informatics J.","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85103230376"
"Hussain Z.; Mohd Noor M.H.; Ahmad K.A.; Ahmad F.","Hussain, Z. (24724464800); Mohd Noor, M.H. (36656106400); Ahmad, K.A. (35760857000); Ahmad, F. (36350716900)","24724464800; 36656106400; 35760857000; 36350716900","Evaluation of spreading factor inertial weight PSO for FLC of FES-assisted paraplegic indoor rowing exercise","2011","Proceedings - 2011 IEEE 7th International Colloquium on Signal Processing and Its Applications, CSPA 2011","","","5759916","430","434","4","1","10.1109/CSPA.2011.5759916","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79957517037&doi=10.1109%2fCSPA.2011.5759916&partnerID=40&md5=3f93207b8be4f3e0a50f3ce5e9ad7564","Faculty of Electrical Engineering, Universiti Teknologi MARA, Malaysia","Hussain Z., Faculty of Electrical Engineering, Universiti Teknologi MARA, Malaysia; Mohd Noor M.H., Faculty of Electrical Engineering, Universiti Teknologi MARA, Malaysia; Ahmad K.A., Faculty of Electrical Engineering, Universiti Teknologi MARA, Malaysia; Ahmad F., Faculty of Electrical Engineering, Universiti Teknologi MARA, Malaysia","This paper describes the evaluation of the spreading factor inertia weight Particle Swarm Optimization (PSO) for the fuzzy logic control (FLC) of FES-assisted paraplegic indoor rowing exercise (FES-rowing). The FES-rowing is introduced as a total body exercise for rehabilitation of lower extremities through the application of functional electrical stimulation (FES). FLC is used to control the knee trajectories for smooth rowing manoeuvre and minimize the total electrical stimulation required by the muscles. PSO is implemented to optimize the parameter of the FLC. The objective function specified is to minimize the mean squared error of knee angle trajectory. The inertia weight of the PSO is updated using spreading factor technique and it performance is compared to the performance of PSO with time variant inertia weight. In view of good results obtained, it is concluded that Spreading Factor Inertia weight PSO is able to obtain the optimal parameter for FLC of FES-rowing. © 2011 IEEE.","FES-Rowing Exercise; Fuzzy logic control; PSO; Spreading Factor Inertia Weight","Fuzzy logic; Fuzzy systems; Signal processing; Electrical stimulations; FES-Rowing Exercise; Functional electrical stimulation; Fuzzy logic control; Inertia weight; IT performance; Lower extremity; Mean squared error; Objective functions; Optimal parameter; PSO; Spreading factor; Spreading Factor Inertia Weight; Time variant; Particle swarm optimization (PSO)","","","","","","","Elbeltagi E., Hegazy T., Grierson D., Comparison among five evolutionary-based optimization algorithms, Advanced Engineering Informatics, 19, pp. 43-53, (2005); Kennedy J., Eberhart R., Particle Swarm Optimization, Proceedings of the IEEE International Conference on Neural Networks. Perth, Australia, 1995, 4, pp. 1942-1945; Panda G., Mohanty D., Majhi B., Sahoo G., Identification of nonlinear systems using particle swarm optimization technique, Proceedings of IEEE Congress on Evolutionary Computation (CEC 2007), Singapore, 25-28 September 2007, pp. 3253-3257; Medeiros J.A.C.C., Schirru R., Identification of nuclear power plant transients using the particle swarm optimization algorithm, Journal of Annals of Nuclear Energy, 35, pp. 576-582, (2008); Mansouri R., Bettayeb M., Djamah T., Djennoune S., Vector fitting fractional system identification using particle swarm optimization, Journal of Applied Mathematics and Computation, (2008); Liu L., Liu W., Cartes D.A., Particle swarm optimization-based parameter identification applied to permanent magnet synchronous motor, Journal of Engineering Applications of Artificial Intelligence, (2007); Wheeler G.D., Andrews B., Lederer R., Davoodi R., Natho K., Weiss C., Jeon J., Bhambhani Y., Steadward R.D., Functional electric stimulation-assisted rowing: Increasing cardiovascular fitness through functional electric stimulation rowing training in persons with spinal cord injury, Arch Phys Med Rehabil, 83, 8, pp. 1093-1099, (2002); Davoodi R., Andrews B.J., Wheeler G.D., Modified concept 2™ rowing machine with manual FES controller for total body exercise in paraplegia, Proceedings of International FES Society, pp. 114-116, (2001); Davoodi R., Andrews B.J., Fuzzy Logic Control of FES Rowing Exercise in Paraplegia, IEEE Transactions on Biomedical Engineering, 51, 3, pp. 541-543, (2004); Halliday S.E., Zavatsky A.B., Hase K., Can functional electric stimulation-assisted rowing reproduce a race-winning rowing stroke?, Archives of Physical Medicine and Rehabilitation, 85, 8, pp. 1265-1272, (2004); Andrew B.J., Hase K., Halliday S.E., Zavatsk A.B., Biomechanical Study of FES Rowing and Inclined Bench Sliding Systems Using Simulation Models, 7th Annual Conference of the International FES Society, Slovenia, 2002; Huq M.S., Alam M.S., Gharooni S.C., Tokhi M.O., Genetic optimisation of spring brake orthosis parameters: Spring properties, The 10th Annual Conference on of International Functional Electrical Stimulation Society (IFESS), Montreal, Canada, pp. 279-281, (2005); Panda S., Padhy N.P., Comparison of Particle Swarm Optimization and Genetic Algorithm for TCSC-based Controller Design, International Journal of Computer Science and Engineering, pp. 41-49, (2007); Latiff I.A., Tokhi M.O., Fast convergence strategy for particle swarm optimization usig spreading factor, Proceedings of IEEE Congress on Evolutionary Computing, Norway, 2009; Ratnaweera A., Halgamuge S.K., Watson H.C., Self-organizing hierarchical particle swarm optimizer with timevarying accelerartion coefficients, IEEE Transactions on Evolutionary Computation, 8, pp. 240-255, (2004); Winter D.A., Biomechanics and Motor Control of Human Movement, (2005); Hussain Z., Tokhi M.O., Gharooni S., Dynamic simulation of indoor rowing exercise for paraplegics,  Asia International Conference on Modelling and Simulation, AMS2008, pp. 901-904, (2008); Riener R., Fuhr T., Patient-driven control of FES-supported standing-up: A simulation study, IEEE Trans.Rehab.Eng., 6, 2, pp. 113-124, (1998); Hussain Z., Tokhi M.O., Modelling of muscle extension and flexion for FES-assisted indoor rowing exercise,  Asia International Conference on Modelling and Simulation, AMS2008, pp. 963-967, (2008)","Z. Hussain; Faculty of Electrical Engineering, Universiti Teknologi MARA, Malaysia; email: zakaria183@ppinang.uitm.edu.my","","","","2011 IEEE 7th International Colloquium on Signal Processing and Its Applications, CSPA 2011","4 March 2011 through 6 March 2011","Penang","84971","","978-161284414-5","","","English","Proc. - IEEE Int. Colloq. Signal Process. Its Appl., CSPA","Conference paper","Final","","Scopus","2-s2.0-79957517037"
"Noor M.H.M.; Salcic Z.; Wang K.I.-K.","Noor, Mohd Halim Mohd (36656106400); Salcic, Zoran (7003306034); Wang, Kevin I-Kai (7501398184)","36656106400; 7003306034; 7501398184","Enhancing ontological reasoning with uncertainty handling for activity recognition","2016","Knowledge-Based Systems","114","","","47","60","13","39","10.1016/j.knosys.2016.09.028","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994779131&doi=10.1016%2fj.knosys.2016.09.028&partnerID=40&md5=9c2277c1978282a1b8f17418b2291a22","The University of Auckland, Auckland, New Zealand; Faculty of Electrical Engineering, Universiti Teknologi MARA, Penang, Malaysia","Noor M.H.M., The University of Auckland, Auckland, New Zealand, Faculty of Electrical Engineering, Universiti Teknologi MARA, Penang, Malaysia; Salcic Z., The University of Auckland, Auckland, New Zealand; Wang K.I.-K., The University of Auckland, Auckland, New Zealand","Ontology-based activity recognition is gaining interest due to its expressiveness and comprehensive reasoning mechanism. An obstacle to its wider use is that the imperfect observations result in failure of recognizing activities. This paper proposes a novel reasoning algorithm for activity recognition in smart environments. The algorithm integrates OWL ontological reasoning mechanism with Dempster–Shafer theory of evidence to provide support for handling uncertainty in activity recognition. It quantifies uncertainty while aggregating contextual information and provides a degree of belief that facilitates more robust decision making in activity recognition. The presented approach has been implemented and evaluated on an internal and public datasets and compared with a data-driven approach that is using hidden Markov model. Results have shown that the proposed reasoning approach can accommodate uncertainties and subsequently infer the activities more accurately in comparison with existing ontology-based recognition and perform comparably well to the data-driven approach. © 2016 Elsevier B.V.","Activity recognition; Dempster–Shafer theory; Missing sensor data; Ontological reasoning; Uncertainty reasoning","Decision making; Formal logic; Hidden Markov models; Pattern recognition; Activity recognition; Ontological reasoning; Sensor data; Shafer theory; Uncertainty reasoning; Ontology","","","","","","","Alam M.R., Reaz M.B.I., Ali M.A.M., A review of smart homes—past, present, and future, IEEE Trans. Syst. Man Cybern. Part C Appl. Rev., 42, pp. 1190-1203, (2012); Chan M., Esteve D., Escriba C., Campo E., A review of smart homes—present state and future challenges, Comput. Methods Programs Biomed., 91, pp. 55-81, (2008); Ramos C., Augusto J.C., Shapiro D., Ambient intelligence —the next step for artificial intelligence, IEEE Intell. Syst., 23, pp. 15-18, (2008); Chen L., Hoey J., Nugent C.D., Cook D.J., Yu Z., Sensor-based activity recognition, IEEE Trans. Syst. Man Cybern. C Appl. Rev., 42, pp. 790-808, (2012); Ye J., Dobson S., McKeever S., Situation identification techniques in pervasive computing: a review, Pervasive Mob. Comput., 8, pp. 36-66, (2012); Brdiczka O., Crowley J.L., Reignier P., Learning situation models in a smart home, IEEE Trans. Syst. Man Cybern. B Cybern., 39, pp. 56-63, (2009); Cook D.J., Schmitter-Edgecombe M., Assessing the quality of activities in a smart environment, Methods Inf. Med., 48, 5, pp. 480-485, (2009); Kim E., Helal S., Cook D., Human activity recognition and pattern discovery, IEEE Pervasive Comput., 9, 1, pp. 48-53, (2010); Rashidi P., Cook D.J., Holder L.B., Schmitter-Edgecombe M., Discovering activities to recognize and track in a smart environment, IEEE Trans. Knowl. Data Eng., 23, pp. 527-539, (2011); Cook D.J., Krishnan N.C., Rashidi P., Activity discovery and activity recognition: a new partnership, IEEE Trans. Cybern., 43, pp. 820-828, (2013); Ordonez F.J., Iglesias J.A., de Toledo P., Ledezma A., Sanchis A., Online activity recognition using evolving classifiers, Expert Syst. Appl., 40, pp. 1248-1255, (2013); Wen J., Zhong M., Wang Z., Activity recognition with weighted frequent patterns mining in smart environments, Expert Syst. Appl., 42, pp. 6423-6432, (2015); Wang K.I.-K., Abdulla W.H., Salcic Z., Multi-agent system with hybrid intelligence using neural network and fuzzy inference techniques, New Trends in Applied Artificial Intelligence, pp. 473-482, (2007); Liu L., Peng Y., Liu M., Huang Z., Sensor-based human activity recognition system with a multilayered model using time series shapelets, Knowl.-Based Syst., 90, pp. 138-152, (2015); Turaga P., Chellappa R., Subrahmanian V.S., Udrea O., Machine recognition of human activities: a survey, IEEE Trans. Circuits Syst. Video Technol., 18, pp. 1473-1488, (2008); Witten I.H., Frank E., Data Mining: Practical Machine Learning Tools and Techniques, (2005); Chen L., Nugent C., Okeyo G., An ontology-based hybrid approach to activity modeling for smart homes, IEEE Trans. Hum.-Mach. Syst., 44, pp. 92-105, (2014); Chen L., Nugent C., Ontology‐based activity recognition in intelligent pervasive environments, Int. J. Web Inf. Syst., 5, pp. 410-430, (2009); Rodriguez N.D., Cuellar M.P., Lilius J., Calvo-Flores M.D., A survey on ontologies for human behavior recognition, ACM Comput. Surv., 46, (2014); Klyne G., “Composite capability/preference profiles (CC/PP) : structure and vocabularies,” Httpwwww3orgTR2001WD-CCPP-Struct-Vocab-20010315, (2001); Henricksen K., Indulska J., Developing context-aware pervasive computing applications: Models and approach, Pervasive Mob. Comput., 2, pp. 37-64, (2006); Gu T., Pung H.K., Zhang D.Q., A service‐oriented middleware for building context‐aware services, J. Netw. Comput. Appl., 28, pp. 1-18, (2005); Perera C., Zaslavsky A., Christen P., Georgakopoulos D., Context aware computing for the internet of things: a survey, IEEE Commun. Surv. Tutor., 16, 1, pp. 414-454, (2014); Bettini C., Brdiczka O., Henricksen K., Indulska J., Nicklas D., Ranganathan A., Riboni D., A survey of context modelling and reasoning techniques, Pervasive Mob. Comput., 6, pp. 161-180, (2010); Endsley M., Jones D., Confidence and uncertainty in sa and decision making, Designing for Situation Awareness, pp. 113-130, (2011); Henricksen K., Indulska J., Modelling and using imperfect context information, Proceedings of the Second IEEE Annual Conference on Pervasive Computing and Communications Workshops, 2004, pp. 33-37, (2004); Dempster A.P., Upper and Lower Probabilities Induced by a Multivalued Mapping, Ann. Math. Stat., 38, pp. 325-339, (1967); Shafer G., A Mathematical Theory of Evidence, 1, (1976); Murphy R.R., Introduction to AI Robotics, (2000); Baader F., Calvanese D., McGuinness D.L., Nardi D., Patel-Schneider P.F., The Description Logic Handbook: Theory, Implementation, and Applications, (2003); Chen L., Nugent C.D., Wang H., A knowledge-driven approach to activity recognition in smart homes, IEEE Trans. Knowl. Data Eng., 24, pp. 961-974, (2012); Bae I.-H., An ontology-based approach to ADL recognition in smart homes, Future Gener. Comput. Syst., 33, pp. 32-41, (2014); Okeyo G., Chen L., Wang H., Sterritt R., Dynamic sensor data segmentation for real-time knowledge-driven activity recognition, Pervasive Mob. Comput., 10, pp. 155-172, (2014); Ye J., Stevenson G., Dobson S., KCAR: a knowledge-driven approach for concurrent activity recognition, Pervasive Mob. Comput., 19, pp. 47-70, (2015); Meditskos G., Dasiopoulou S., Kompatsiaris I., MetaQ: a knowledge-driven framework for context-aware activity recognition combining SPARQL and OWL 2 activity patterns, Pervasive Mob. Comput., 25, pp. 104-124, (2016); Khattak A.M., Khan W.A., Pervez Z., Iqbal F., Lee S., Towards a self adaptive system for social wellness, Sensors, 16, (2016); Ahmadi-Karvigh S., Becerik-Gerber B., Soibelman L., A framework for allocating personalized appliance-level disaggregated electricity consumption to daily activities, Energy Build., 111, pp. 337-350, (2016); Riboni D., Bettini C., COSAR: hybrid reasoning for context-aware activity recognition, Pers. Ubiquitous Comput., 15, pp. 271-289, (2011); Ye J., Stevenson G., Dobson S., USMART: an unsupervised semantic mining activity recognition technique, ACM Trans. Interact Intell. Syst., 4, (2014); Ranganathan A., Al-Muhtadi J., Campbell R.H., Reasoning about uncertain contexts in pervasive computing environments, IEEE Pervasive Comput., 3, pp. 62-70, (2004); Helaoui R., Riboni D., Stuckenschmidt H., A probabilistic ontological framework for the recognition of multilevel human activities, Proceedings of the 2013 ACM International Joint Conference on Pervasive and Ubiquitous Computing, pp. 345-354, (2013); Ding Z., Peng Y., Pan R., Ding Z., Peng Y., Pan R., BayesOWL: uncertainty modeling in semantic web ontologies, Soft Computing in Ontologies and Semantic Web, volume 204 of Studies in Fuzziness and Soft Computing, (2005); Yang Y., Calmet J., OntoBayes: an ontology-driven uncertainty model, International Conference on Computational Intelligence for Modelling, Control and Automation, 2005 and International Conference on Intelligent Agents, Web Technologies and Internet Commerce, 1, pp. 457-463, (2005); Ausin D., Lopez-de-Ipina D., Castanedo F., A probabilistic OWL reasoner for intelligent environments, 10th International Workshop on Uncertainty Reasoning for the Semantic Web (URSW 2014), (2014); Wu H., Grimm W., Corporation R.B., Wu C.H., “Sensor Data Fusion for Context-Aware Computing Using Dempster-Shafer Theory,”, (2003); Hong X., Nugent C., Mulvenna M., McClean S., Scotney B., Devlin S., Evidential fusion of sensor data for activity recognition in smart homes, Pervasive Mob. Comput., 5, pp. 236-252, (2009); Zhang D., Guo M., Zhou J., Kang D., Cao J., Context reasoning using extended evidence theory in pervasive computing environments, Future Gener. Comput. Syst., 26, pp. 207-216, (2010); McKeever S., Ye J., Coyle L., Dobson S., Bleakley C., Activity recognition using temporal evidence theory, Articles, (2010); Kushwah A., Kumar S., Hegde R.M., Multi-sensor data fusion methods for indoor activity recognition using temporal evidence theory, Pervasive Mob. Comput., (2014); Sebbak F., Benhammadi F., Chibani A., Amirat Y., Mokhtari A., Dempster–Shafer theory-based human activity recognition in smart home environments, Ann. Telecommun., 69, pp. 171-184, (2013); Liao J., Bi Y., Nugent C., Using the Dempster–Shafer theory of evidence with a revised lattice structure for activity recognition, IEEE Trans. Inf. Technol. Biomed., 15, pp. 74-82, (2011); Chen C., Jafari R., Kehtarnavaz N., Improving human action recognition using fusion of depth camera and inertial sensors, IEEE Trans. Hum.-Mach. Syst., 45, pp. 51-61, (2015); Aloulou H., Mokhtari M., Tiberghien T., Endelin R., Biswas J., Uncertainty handling in semantic reasoning for accurate context understanding, Knowl.-Based Syst., 77, pp. 16-28, (2015); Yuan K., Xiao F., Fei L., Kang B., Deng Y., Modeling sensor reliability in fault diagnosis based on evidence theory, Sensors, 16, (2016); Azkune G., Almeida A., Lopez-de-Ipina D., Chen L., Extending knowledge-driven activity models through data-driven learning techniques, Expert Syst. Appl., 42, pp. 3115-3128, (2015); Diaz Rodriguez N., Cuellar M.P., Lilius J., Delgado Calvo-Flores M., A fuzzy ontology for semantic modelling and recognition of human behaviour, Knowl.-Based Syst., 66, pp. 46-60, (2014); Dai P., Ho S.-S., Rudzicz F., Sequential behavior prediction based on hybrid similarity and cross-user activity transfer, Knowl.-Based Syst., 77, pp. 29-39, (2015); Scalmato A., Sgorbissa A., Zaccaria R., Describing and recognizing patterns of events in smart environments with description logic, IEEE Trans. Cybern., 43, pp. 1882-1897, (2013); Lowrance J.D., Garvey T.D., Strat T.M., A framework for evidential-reasoning systems, Classic Works of the Dempster-Shafer Theory of Belief Functions, pp. 419-434, (2008); Liu W., Hong J., McTear M.F., An extended framework for evidential reasoning systems, Proceedings of the 2nd International IEEE Conference on Tools for Artificial Intelligence, 1990, pp. 731-737, (1990); Zadeh L.A., A simple view of the dempster-shafer theory of evidence and its implication for the rule of combination, AI Mag, 7, pp. 85-90, (1986); Smarandache F., Dezert J., “A simple proportional conflict redistribution rule,” Multispace & Multistructure, Neutrosophic Transdisciplinarity (100 Collected Papers of Science), 4, (2010); Murphy C.K., Combining belief functions when evidence conflicts, Decis. Support Syst., 29, pp. 1-9, (2000); Rashidi P., Cook D.J., Keeping the resident in the loop: adapting the smart home to the user, IEEE Trans. Syst. Man Cybern. Part Syst. Hum., 39, pp. 949-959, (2009); (2016); Kabir M.H., Hoque M.R., Thapa K., Yang S.-H., Kabir M.H., Hoque M.R., Thapa K., Yang S.-H., Two-layer hidden markov model for human activity recognition in home environments, two-layer hidden markov model for human activity recognition in home environments, Int. J. Distrib. Sens. Netw. Int. J. Distrib. Sens. Netw., 2016, (2016); Raman N., Maybank S.J., Activity recognition using a supervised non-parametric hierarchical HMM, Neurocomputing, 199, pp. 163-177, (2016); Zhang Y., Zhang Y., Swears E., Larios N., Wang Z., Ji Q., Modeling temporal interactions with interval temporal bayesian networks for complex activity recognition, IEEE Trans. Pattern Anal. Mach. Intell., 35, pp. 2468-2483, (2013); Liu L., Cheng L., Liu Y., Jia Y., Rosenblum D.S., Recognizing complex activities by a probabilistic interval-based model, Thirtieth AAAI Conference on Artificial Intelligence, (2016); Nazerfard E., Cook D.J., CRAFFT: an activity prediction model based on Bayesian networks, J. Ambient Intell. Humaniz. Comput., 6, 2, pp. 193-205, (2015)","M.H.M. Noor; The University of Auckland, Auckland, New Zealand; email: mmoh626@aucklanduni.ac.nz","","Elsevier B.V.","","","","","","09507051","","KNSYE","","English","Knowl Based Syst","Article","Final","","Scopus","2-s2.0-84994779131"
"Ige A.O.; Mohd Noor M.H.","Ige, Ayokunle Olalekan (57828337400); Mohd Noor, Mohd Halim (36656106400)","57828337400; 36656106400","Unsupervised Feature Learning in Activity Recognition using Convolutional Denoising Autoencoders with Squeeze and Excitation Networks","2022","ICOIACT 2022 - 5th International Conference on Information and Communications Technology: A New Way to Make AI Useful for Everyone in the New Normal Era, Proceeding","","","","435","440","5","1","10.1109/ICOIACT55506.2022.9972095","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145359273&doi=10.1109%2fICOIACT55506.2022.9972095&partnerID=40&md5=532da8abbc8cfd025a00ff5595709cf7","School of Computer Science, Universiti Sains Malaysia Pulau, Pinang, Malaysia","Ige A.O., School of Computer Science, Universiti Sains Malaysia Pulau, Pinang, Malaysia; Mohd Noor M.H., School of Computer Science, Universiti Sains Malaysia Pulau, Pinang, Malaysia","Sensor modalities have recently been used to acquire activity recognition data, especially wearable sensors, due to their relative advantages over other modalities. Datasets obtained using wearable sensors are often in time-series format; therefore, there is a need to segment and extract only salient features from the raw sensor data. Generally, the overall performance of activity recognition relies heavily on the quality of these extracted features. For this reason, various feature extraction approaches have been proposed in the literature, ranging from manual to automatic feature extraction methods. However, most of the existing feature extraction methods are time-consuming and supervised. Since wearable sensor data is quite tedious and time-consuming to label, there is a need to propose unsupervised feature extraction methods capable of extracting features from fully unlabelled wearable sensor datasets. Several autoencoder models have been proposed for unsupervised feature learning using fully connected and convolutional neural networks. However, these methods cannot effectively learn discriminative features since they treat all features as equally important. To tackle this, this research introduced a feature weighting mechanism based on squeeze and excitation networks in a convolutional denoising autoencoder to act as channel-wise attention to reweigh feature channels accordingly. This allowed more discriminative activity features to be extracted from fully unlabelled activity data. The proposed model was benchmarked on two publicly available datasets, including a dataset which consists of transitional activities (WISDM and HAPT). Results showed that the proposed method exploited more discriminative features while learning inherent features of unlabelled activity recognition data and outperformed the existing methods with improved recognition performance on the two benchmark datasets.  © 2022 IEEE.","activity; autoencoder; convolutional; features; learning; recognition","Benchmarking; Convolution; Convolutional neural networks; Data mining; Extraction; Feature extraction; Learning systems; Activity; Activity recognition; Auto encoders; Convolutional; De-noising; Feature; Feature extraction methods; Learning; Recognition; Unsupervised feature learning; Wearable sensors","","","","","","","Khare S., Sarkar S., Totaro M., Comparison of Sensor-Based Datasets for Human Activity Recognition in Wearable IoT, IEEE World Forum Internet Things, WF-IoT 2020-Symp. Proc., pp. 1-6, (2020); Wang C., Gao Y., Mathur A., Amanda A.C., Lane N.D., Bianchi-Berthouze N., Leveraging Activity Recognition to Enable Protective Behavior Detection in Continuous Data, Proc. ACM Interactive, Mobile, Wearable Ubiquitous Technol., 5, 2, pp. 1-24, (2021); Liu J., Convolutional Neural Network-Based Human Movement Recognition Algorithm in Sports Analysis, Front. Psychol., 12, (2021); Manjarres J., Narvaez P., Gasser K., Percybrooks W., Pardo M., Physical workload tracking using human activity recognition with wearable devices, Sensors (Switzerland), 20, 1, (2020); Noor M.H.M., Nazir A., Wahab M.N.A., Ling J.O.Y., Detection of Freezing of Gait Using Unsupervised Convolutional Denoising Autoencoder, IEEE Access, 9, pp. 115700-115709, (2021); Ige A.O., Mohd Noor M.H., A survey on unsupervised learning for wearable sensor-based activity recognition, Appl. Soft Comput., (2022); Mohd Noor M.H., Feature learning using convolutional denoising autoencoder for activity recognition, Neural Comput. Appl., 33, 17, pp. 10909-10922, (2021); Ferrari A., Micucci D., Mobilio M., Napoletano P., Handcrafted Features vs Residual Networks for Human Activities Recognition using Accelerometer, 2019 IEEE 23rd International Symposium on Consumer Technologies, ISCT 2019, pp. 153-156, (2019); Hu J., Shen L., Sun G., Squeeze-and-Excitation Networks, Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit., pp. 7132-7141, (2018); Iantsen A., Visvikis D., Hatt M., Squeeze-and-Excitation Normalization for Automated Delineation of Head and Neck Primary Tumors in Combined PET and CT Images, Lect. Notes Comput. Sci. (including Subser. Lect. Notes Artif. Intell. Lect. Notes Bioinformatics), pp. 37-43, (2021); Chen L., Et al., SCA-CNN: Spatial and channel-wise attention in convolutional networks for image captioning, Proceedings-30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017, 2017, pp. 6298-6306, (2017); Zhao W., Meng Q.H., Zeng M., Qi P.F., Stacked sparse autoencoders (SSAE) based electronic nose for chinese liquors classification, Sensors (Switzerland), 17, 12, (2017); Vincent P., Larochelle H., Lajoie I., Bengio Y., Manzagol P.A., Stacked denoising autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion, J. Mach. Learn. Res., 11, pp. 3371-3408, (2010); Hinton G.E., Salakhutdinov R.R., Reducing the dimensionality of data with neural networks, Science (80-.)., 313, 5786, pp. 504-507, (2006); Gao X., Luo H., Wang Q., Zhao F., Ye L., Zhang Y., A human activity recognition algorithm based on stacking denoising autoencoder and lightGBM, Sensors (Switzerland), 19, 4, pp. 1-20, (2019); Li Y., Shi D., Ding B., Liu D., Unsupervised feature learning for human activity recognition using smartphone sensors, Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), 8891, pp. 99-107, (2014); Gu F., Khoshelham K., Valaee S., Shang J., Zhang R., Locomotion Activity Recognition Using Stacked Denoising Autoencoders, Ieee Internet Things J., 5, 3, pp. 2085-2093, (2018); Mohd Noor M.H., Ahmadon M.A., Osman M.K., Activity Recognition using Deep Denoising Autoencoder, Proc.-9th IEEE Int. Conf. Control Syst. Comput. Eng. ICCSCE 2019, pp. 188-192, (2019); Roy A.G., Navab N., Wachinger C., Concurrent spatial and channel 'squeeze & excitation' in fully convolutional networks, Lect. Notes Comput. Sci. (including Subser. Lect. Notes Artif. Intell. Lect. Notes Bioinformatics), pp. 421-429, (2018); Gong L., Jiang S., Yang Z., Zhang G., Wang L., Automated pulmonary nodule detection in CT images using 3D deep squeezeand-excitation networks, Int. J. Comput. Assist. Radiol. Surg., 14, 11, pp. 1969-1979, (2019); Han Y., Wei C., Zhou R., Hong Z., Zhang Y., Yang S., Combining 3D-CNN and Squeeze-and-Excitation Networks for Remote Sensing Sea Ice Image Classification, Math. Probl. Eng., 2020, (2020); Han W., Et al., ContextNet: Improving convolutional neural networks for automatic speech recognition with global context, Proc. Annu. Conf. Int. Speech Commun. Assoc. INTERSPEECH, 2020, pp. 3610-3614, (2020); Zhang B., Et al., A spatiotemporal multi-feature extraction framework with space and channel based squeeze-and-excitation blocks for human activity recognition, J. Ambient Intell. Humaniz. Comput., (2020); Ismail Fawaz H., Forestier G., Weber J., Idoumghar L., Muller P.A., Deep learning for time series classification: A review, Data Min. Knowl. Discov., 33, 4, pp. 917-963, (2019); Gu F., Et al., Locomotion Activity Recognition Using Stacked Denoising Autoencoders, IEEE Internet Things J., 5, 3, pp. 2085-2093, (2018); Kwapisz J.R., Weiss G.M., Moore S.A., Activity recognition using cell phone accelerometers, ACM SIGKDD Explor. Newsl., 12, 2, pp. 74-82, (2011); Anguita D., Ghio A., Oneto L., Parra Perez X., Reyes Ortiz J.L., A public domain dataset for human activity recognition using smartphones, Proceedings of the 21th international European symposium on artificial neural networks, computational intelligence and machine learning, pp. 437-442, (2013); Ni Q., Et al., Leveraging wearable sensors for human daily activity recognition with stacked denoising autoencoders, Sensors (Switzerland), 20, 18, pp. 1-22, (2020)","","","Institute of Electrical and Electronics Engineers Inc.","","5th International Conference on Information and Communications Technology, ICOIACT 2022","24 August 2022 through 25 August 2022","Yogyakarta","185076","","978-166545140-6","","","English","ICOIACT - Int. Conf. Inf. Commun. Technol.: A New Way Make AI Useful Everyone New Norm. Era, Proceeding","Conference paper","Final","","Scopus","2-s2.0-85145359273"
"Mohd Noor M.H.; Tan S.Y.; Ab Wahab M.N.","Mohd Noor, Mohd Halim (36656106400); Tan, Sen Yan (57555812800); Ab Wahab, Mohd Nadhir (57223397087)","36656106400; 57555812800; 57223397087","Deep Temporal Conv-LSTM for Activity Recognition","2022","Neural Processing Letters","54","5","","4027","4049","22","8","10.1007/s11063-022-10799-5","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127360552&doi=10.1007%2fs11063-022-10799-5&partnerID=40&md5=51918fbebc70f0fbb83ee169deb268a4","School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, 11800, Malaysia","Mohd Noor M.H., School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, 11800, Malaysia; Tan S.Y., School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, 11800, Malaysia; Ab Wahab M.N., School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, 11800, Malaysia","Human activity recognition has gained interest from the research community due to the advancements in sensor technology and the improved machine learning algorithm. Wearable sensors have become more ubiquitous, and most of the wearable sensor data contain rich temporal structural information that describes the distinct underlying patterns and relationships of various activity types. The nature of those activities is typically sequential, with each subsequent activity window being the result of the preceding activity window. However, the state-of-the-art methods usually model the temporal characteristic of the sensor data and ignore the relationship of the sliding window. This research proposes a novel deep temporal Conv-LSTM architecture to enhance activity recognition performance by utilizing both temporal characteristics from sensor data and the relationship of sliding windows. The proposed architecture is evaluated based on the dataset consisting of transition activities—Smartphone-Based Recognition of Human Activities and Postural Transitions dataset. The proposed hybrid architecture with parallel features learning pipelines has demonstrated the ability to model the temporal relationship of the activity windows where the transition of activities is captured accurately. Besides that, the size of sliding windows is studied, and it has shown that the selection of window size is affecting the accuracy of the activity recognition. The proposed deep temporal Conv-LSTM architecture can achieve an accuracy score of 0.916, which outperformed the state-of-the-art accuracy. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.","Activity recognition; Deep learning; LSTM; Temporal model","Decoding; Learning algorithms; Learning systems; Long short-term memory; Pattern recognition; Wearable sensors; Activity recognition; Deep learning; Human activity recognition; LSTM; Research communities; Sensor technologies; Sensors data; Sliding Window; Temporal characteristics; Temporal models; Smartphones","","","","","Ministry of Higher Education, Malaysia, MOHE, (FRGS/1/2019/ICT02/USM/02/1)","This work has been supported in part by the Ministry of Higher Education Malaysia for Fundamental Research Grant Scheme with Project Code: FRGS/1/2019/ICT02/USM/02/1. ","Abidine B.M., Fergani L., Fergani B., Oussalah M., The joint use of sequence features combination and modified weighted SVM for improving daily activity recognition, Pattern Anal Appl, 21, pp. 119-138, (2018); Tian Y., Zhang J., Wang J., Et al., Robust human activity recognition using single accelerometer via wavelet energy spectrum features and ensemble feature selection, Syst Sci Control Eng, 8, pp. 83-96, (2020); Vanrell S.R., Milone D.H., Rufiner H.L., Et al., Assessment of homomorphic analysis for human activity recognition from acceleration signals, IEEE J Biomed Health Inform, 22, pp. 1001-1010, (2018); Ertugrul O.F., Kaya Y., Determining the optimal number of body-worn sensors for human activity recognition, Soft Comput, 21, pp. 5053-5060, (2017); Kanjilal R., Uysal I., The future of human activity recognition: deep learning or feature engineering?, Neural Process Lett, 53, pp. 561-579, (2021); Wang J., Chen Y., Hao S., Et al., Deep learning for sensor-based activity recognition: a survey, Pattern Recognit Lett, 119, pp. 3-11, (2019); Xu W., Pang Y., Yang Y., Liu Y., Human activity recognition based on convolutional neural network, 2018 24Th International Conference on Pattern Recognition (ICPR), pp. 165-170, (2018); Bevilacqua A., MacDonald K., Rangarej A., Et al., Human activity recognition with convolutional neural networks, Machine learning and knowledge discovery in databases, pp. 541-552, (2019); Lawal I.A., Bano S., Deep human activity recognition using wearable sensors, Proceedings of the 12Th ACM International Conference on Pervasive Technologies Related to Assistive Environments, pp. 45-48, (2019); Gil-Martin M., San-Segundo R., Fernandez-Martinez F., Ferreiros-Lopez J., Time analysis in human activity recognition, Neural Process Lett, 53, pp. 4507-4525, (2021); Zhu R., Xiao Z., Cheng M., Et al., Deep ensemble learning for human activity recognition using smartphone, 2018 IEEE 23Rd International Conference on Digital Signal Processing (DSP), pp. 1-5, (2018); Zehra N., Azeem S.H., Farhan M., Human activity recognition through ensemble learning of multiple convolutional neural networks, 2021 55Th Annual Conference on Information Sciences and Systems (CISS), pp. 1-5, (2021); Sikder N., Chowdhury M., Arif A.S.M., Nahid A.-A., Human activity recognition using multichannel convolutional neural network, 2019 5Th International Conference on Advances in Electrical Engineering (ICAEE), pp. 560-565, (2019); Zhang H., Xiao Z., Wang J., Et al., A novel IoT-perceptive Human Activity Recognition (HAR) approach using multihead convolutional attention, IEEE Internet Things J, 7, pp. 1072-1080, (2020); Chen Y., Zhong K., Zhang J., Et al., LSTM networks for mobile human activity recognition, pp. 50-53, (2016); Zebin T., Sperrin M., Peek N., Casson A.J., Human activity recognition from inertial sensor time-series using batch normalized deep LSTM recurrent networks, 2018 40Th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), pp. 1-4, (2018); Guan Y., Plotz T., Ensembles of deep LSTM learners for activity recognition using wearables, Proc ACM Interact Mob Wearable Ubiquitous Technol, 1, pp. 1-28, (2017); Li S., Li C., Li W., Et al., Smartphone-sensors based activity recognition using IndRNN, Proceedings of the 2018 ACM International Joint Conference and 2018 International Symposium on Pervasive and Ubiquitous Computing and Wearable Computers, pp. 1541-1547, (2018); Mahmud T., Akash S.S., Fattah S.A., Et al., Human activity recognition from multi-modal wearable sensor data using deep multi-stage LSTM architecture based on temporal feature aggregation, 2020 IEEE 63Rd International Midwest Symposium on Circuits and Systems (MWSCAS), pp. 249-252, (2020); Ordonez F.J., Roggen D., Deep convolutional and LSTM recurrent neural networks for multimodal wearable activity recognition, Sensors, (2016); Mekruksavanich S., Jitpattanakul A., Smartwatch-based human activity recognition using hybrid LSTM network, In: 2020 IEEE SENSORS, pp. 1-4, (2020); Mutegeki R., Han D.S., A CNN-LSTM approach to human activity recognition, In: 2020 International Conference on Artificial Intelligence in Information and Communication (ICAIIC, pp. 362-366, (2020); Li Z., Liu Y., Guo X., Zhang J., Multi-convLSTM neural network for sensor-based human activity recognition, J Phys Conf Ser, 1682, (2020); Wang H., Zhao J., Li J., Et al., Wearable sensor-based human activity recognition using hybrid deep learning techniques, Secur Commun Netw, 2020, (2020); Singh S.P., Sharma M.K., Lay-Ekuakille A., Et al., Deep ConvLSTM with self-attention for human activity decoding using wearable sensors, IEEE Sens J, 21, pp. 8575-8582, (2021); Abdel-Basset M., Hawash H., Chakrabortty R.K., Et al., ST-DeepHAR: deep learning model for human activity recognition in IoHT applications, IEEE Internet Things J, 8, pp. 4969-4979, (2021); Xia K., Huang J., Wang H., LSTM-CNN architecture for human activity recognition, IEEE Access, 8, pp. 56855-56866, (2020); Nafea O., Abdul W., Muhammad G., Alsulaiman M., Sensor-based human activity recognition with spatio-temporal deep learning, Sensors, (2021); Xiao Z., Xu X., Xing H., Et al., A federated learning system with enhanced feature extraction for human activity recognition, Knowl -Based Syst, 229, (2021); Gao W., Zhang L., Teng Q., Et al., DanHAR: dual attention network for multimodal human activity recognition using wearable sensors, Appl Soft Comput, 111, (2021); Reyes-Ortiz J.-L., Oneto L., Sama A., Et al., Transition-aware human activity recognition using smartphones, Neurocomputing, 171, pp. 754-767, (2016); Janidarmian M., Roshan Fekr A., Radecka K., Zilic Z., A Comprehensive analysis on wearable acceleration sensors in human activity recognition, Sensors, (2017); Banos O., Galvez J.-M., Damas M., Et al., Window size impact in human activity recognition, Sensors, 14, pp. 6474-6499, (2014); Hogg R.V., Tanis E.A., Zimmerman D.L., Probability and statistical inference, (2010)","M.H. Mohd Noor; School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, 11800, Malaysia; email: halimnoor@usm.my","","Springer","","","","","","13704621","","NPLEF","","English","Neural Process Letters","Article","Final","","Scopus","2-s2.0-85127360552"
"Ige A.O.; Mohd Noor M.H.","Ige, Ayokunle Olalekan (57828337400); Mohd Noor, Mohd Halim (36656106400)","57828337400; 36656106400","A deep local-temporal architecture with attention for lightweight human activity recognition","2023","Applied Soft Computing","149","","110954","","","","1","10.1016/j.asoc.2023.110954","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175034665&doi=10.1016%2fj.asoc.2023.110954&partnerID=40&md5=8788df6155b78e8ff281d1583347002c","School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, 11800, Malaysia","Ige A.O., School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, 11800, Malaysia; Mohd Noor M.H., School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, 11800, Malaysia","Human Activity Recognition (HAR) is an essential area of pervasive computing deployed in numerous fields. In order to seamlessly capture human activities, various inertial sensors embedded in wearable devices have been used to generate enormous amounts of signals, which are multidimensional time series of state changes. Therefore, the signals must be divided into windows for feature extraction. Deep learning (DL) methods have recently been used to automatically extract local and temporal features from signals obtained using wearable sensors. Likewise, multiple input deep learning architectures have been proposed to improve the quality of learned features in wearable sensor HAR. However, these architectures are often designed to extract local and temporal features on a single pipeline, which affects feature representation quality. Also, such models are always parameter-heavy due to the number of weights involved in the architecture. Since resources (CPU, battery, and memory) of end devices are limited, it is crucial to propose lightweight deep architectures for easy deployment of activity recognition models on end devices. To contribute, this paper presents a new deep parallel architecture named DLT, based on pipeline concatenation. Each pipeline consists of two sub-pipelines, where the first sub-pipeline learns local features in the current window using 1D-CNN, and the second sub-pipeline learns temporal features using Bi-LSTM and LSTMs before concatenating the feature maps and integrating channel attention. By doing this, the proposed DLT model fully harnessed the capabilities of CNN and RNN equally in capturing more discriminative features from wearable sensor signals while increasing responsiveness to essential features. Also, the size of the model is reduced by adding a lightweight module to the top of the architecture, thereby ensuring the proposed DLT architecture is lightweight. Experiments on two publicly available datasets showed that the proposed architecture achieved an accuracy of 98.52% on PAMAP2 and 97.90% on WISDM datasets, outperforming existing models with few model parameters. © 2023 Elsevier B.V.","Deep learning; Lightweight; Local features; Temporal features; Wearable sensors","Long short-term memory; Parallel architectures; Pattern recognition; Pipelines; Ubiquitous computing; Deep learning; End-devices; Human activities; Human activity recognition; Inertial sensor; Learn+; Lightweight; Local feature; Temporal features; Wearable devices; Wearable sensors","","","","","","","(2023); Webber M., Rojas R.F., Human activity recognition with accelerometer and gyroscope: a data fusion approach, IEEE Sens. J., 21, pp. 16979-16989, (2021); Lara O.D., Labrador M.A., A survey on human activity recognition using wearable sensors, IEEE Commun. Surv. Tutor., pp. 1192-1209, (2013); Ige A.O., Mohd Noor M.H., A survey on unsupervised learning for wearable sensor-based activity recognition, Appl. Soft Comput., (2022); Abdel-Basset M., Hawash H., Chakrabortty R.K., Ryan M., Elhoseny M., Song H., ST-DeepHAR: Deep Learning Model for Human Activity Recognition in IoHT Applications, IEEE Internet Things J., 8, pp. 4969-4979, (2021); Mohd Noor M.H., Feature learning using convolutional denoising autoencoder for activity recognition, Neural Comput. Appl., 33, pp. 10909-10922, (2021); Chen K., Zhang D., Yao L., Guo B., Yu Z., Liu Y., Deep learning for sensor-based human activity recognition: Overview, challenges, and opportunities, ACM Comput. Surv., 54, pp. 1-40, (2021); Mim T.R., Amatullah M., Afreen S., Yousuf M.A., Uddin S., Alyami S.A., Hasan K.F., Moni M.A., GRU-INC: An inception-attention based approach using GRU for human activity recognition, Expert Syst. Appl., 216, (2023); Rueda F.M., Grzeszick R., Fink G.A., Feldhorst S., Ten Hompel M., Convolutional neural networks for human activity recognition using body-worn sensors, Informatics, 5, pp. 1-17, (2018); Qi W., Su H., Yang C., Ferrigno G., De Momi E., Aliverti A., A fast and robust deep convolutional neural networks for complex human activity recognition using smartphone, Sens. Switz., 19, (2019); Bai L., Yao L., Wang X., Kanhere S.S., Xiao Y., Prototype similarity learning for activity recognition, Pac. -Asia Conf. Knowl. Discov. Data Min., pp. 649-661, (2020); Chen Y., Zhong K., Zhang J., Sun Q., Zhao X., LSTM Networks for Mobile Human Activity Recognition, : Int. Conf. Artif. Intell. Technol. Appl., pp. 50-53, (2016); Guan Y., Plotz T., Ensembles of deep LSTM learners for activity recognition using wearables, Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., 1, pp. 1-28, (2017); Saha S.S., Sandha S.S., Srivastava M., Deep Convolutional Bidirectional LSTM for Complex Activity Recognition with Missing Data, (2021); Donahue J., Hendricks L.A., Rohrbach M., Venugopalan S., Guadarrama S., Saenko K., Darrell T., Long-term recurrent convolutional networks for visual recognition and description, IEEE Trans. Pattern Anal. Mach. Intell., 39, pp. 677-691, (2017); Xia K., Huang J., Wang H., LSTM-CNN architecture for human activity recognition, IEEE Access, 8, pp. 56855-56866, (2020); Mohd Noor M.H., Tan S.Y., Ab Wahab M.N., Deep Temporal Conv-LSTM for Activity Recognition, Neural Process. Lett., (2022); Park H., Kim N., Lee G.H., Choi J.K., MultiCNN-FilterLSTM: Resource-efficient sensor-based human activity recognition in IoT applications, Future Gener. Comput. Syst., 139, pp. 196-209, (2023); Ige A.O., Mohd Noor M.H., Unsupervised feature learning in activity recognition using convolutional denoising autoencoders with squeeze and excitation networks, ICOIACT 2022 - 5th Int. Conf. Inf. Commun. Technol. N. Way Make AI Useful Everyone N. Norm. Era Proc., pp. 435-440, (2022); Gao W., Zhang L., Teng Q., He J., Wu H., DanHAR: Dual Attention Network for multimodal human activity recognition using wearable sensors, Appl. Soft Comput., 111, (2021); Khan Z.N., Ahmad J., Attention induced multi-head convolutional neural network for human activity recognition, Appl. Soft Comput., 110, (2021); Ma H., Li W., Zhang X., Gao S., Lu S., Attnsense: Multi-level attention mechanism for multimodal human activity recognition, IJCAI Int. Jt. Conf. Artif. Intell. 2019-Augus, pp. 3109-3115, (2019); Essa E., Abdelmaksoud I.R., Temporal-channel convolution with self-attention network for human activity recognition using wearable sensors, Knowl. -Based Syst., 278, (2023); Zhou Y., Zhao H., Huang Y., Hefenbrock M., Riedel T., Beigl M., TinyHAR: A Lightweight Deep Learning Model Designed for Human Activity Recognition, Assoc. Comput. Mach., (2022); Bhattacharya S., Nurmi P., Hammerla N., Plotz T., Using unlabeled data in a sparse-coding framework for human activity recognition, Pervasive Mob. Comput., 15, pp. 242-262, (2014); Javed A.R., Faheem R., Asim M., Baker T., Beg M.O., A smartphone sensors-based personalized human activity recognition system for sustainable smart cities, Sustain. Cities Soc., 71, (2021); Rasul M.G., Khan M.H., Lota L.N., Nurse care activity recognition based on convolution neural network for accelerometer data, UbiCompISWC 2020 Adjun. - Proc. 2020 ACM Int. Jt. Conf. Pervasive Ubiquitous Comput. Proc. 2020 ACM Int. Symp. Wearable Comput, pp. 425-430, (2020); Babiker M., Khalifa O.O., Htike K.K., Hassan A., Zaharadeen M., Automated daily human activity recognition for video surveillance using neural network, 2017 IEEE Int. Conf. Smart Instrum. Meas. Appl. ICSIMA, 2018, pp. 1-5, (2017); Mitsis K., Zarkogianni K., Kalafatis E., Dalakleidi K., Jaafar A., Mourkousis G., Nikita K.S., A multimodal approach for real time recognition of engagement towards adaptive serious games for health, Sensors, 22, (2022); Khare S., Sarkar S., Totaro M., Comparison of sensor-based datasets for human activity recognition in wearable IoT, IEEE World Forum Internet Things WF-IoT 2020 - Symp. Proc, pp. 1-6, (2020); Wang C., Gao Y., Mathur A., Amanda A.C., Lane N.D., Bianchi-Berthouze N., Leveraging activity recognition to enable protective behavior detection in continuous data, Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., 5, pp. 1-24, (2021); Liu J., Convolutional neural network-based human movement recognition algorithm in sports analysis, Front. Psychol., 12, (2021); Manjarres J., Narvaez P., Gasser K., Percybrooks W., Pardo M., Physical workload tracking using human activity recognition with wearable devices, Sens. Switz., 20, (2020); Noor M.H.M., Nazir A., Wahab M.N.A., Ling J.O.Y., Detection of freezing of gait using unsupervised convolutional denoising autoencoder, IEEE Access, 9, pp. 115700-115709, (2021); Wang S., Zhou G., A review on radio based activity recognition, Digit. Commun. Netw., 1, pp. 20-29, (2015); Qi W., Su H., Chen F., Zhou X., Shi Y., Ferrigno G., De Momi E., Depth vision guided human activity recognition in surgical procedure using wearable multisensor, ICARM 2020 - 2020 5th IEEE Int. Conf. Adv. Robot. Mechatron, pp. 431-436, (2020); Yadav S.K., Tiwari K., Pandey H.M., Akbar S.A., A review of multimodal human activity recognition with special emphasis on classification, applications, challenges and future directions, Knowl. -Based Syst., 223, (2021); Demrozi F., Pravadelli G., Bihorac A., Rashidi P., Human activity recognition using inertial, physiological and environmental sensors: a comprehensive survey, IEEE Access, 8, pp. 210816-210836, (2020); Ferrari A., Micucci D., Mobilio M., Napoletano P., Hand-crafted Features vs Residual Networks for Human Activities Recognition using accelerometer, 2019 IEEE 23rd Int. Symp. Consum. Technol, 2019, pp. 153-156, (2019); Sani S., Wiratunga N., Massie S., Cooper K., kNN sampling for personalised human activity recognition, Lect. Notes Comput. Sci. Subser. Lect. Notes Artif. Intell. Lect. Notes Bioinforma., pp. 330-344, (2017); Manosha Chathuramali K.G., Rodrigo R., Faster human activity recognition with SVM, Int. Conf. Adv. ICT Emerg. Reg. ICTer 2012 - Conf. Proc., pp. 197-203, (2012); Lecun Y., Bengio Y., Hinton G., Deep learning, Nature, 521, pp. 436-444, (2015); Zeng M., Nguyen L.T., Yu B., Mengshoel O.J., Zhu J., Wu P., Zhang J., Convolutional Neural Networks for human activity recognition using mobile sensors, Proc. 2014 6th Int. Conf. Mob. Comput. Appl. Serv, pp. 197-205, (2014); Zheng Y., Liu Q., Chen E., Ge Y., Zhao J.L., Time series classification using multi-channels deep convolutional neural networks, Lect. Notes Comput. Sci. Subser. Lect. Notes Artif. Intell. Lect. Notes Bioinforma., 8485 LNCS, pp. 298-310, (2014); Ronao C.A., Cho S.B., Human activity recognition with smartphone sensors using deep learning neural networks, Expert Syst. Appl., 59, pp. 235-244, (2016); Huang J., Lin S., Wang N., Dai G., Xie Y., Zhou J., TSE-CNN: A Two-Stage End-to-End CNN for Human Activity Recognition, IEEE J. Biomed. Health Inform., 24, pp. 292-299, (2020); Ahmad Z., Khan N., CNN-Based Multistage Gated Average Fusion (MGAF) for Human Action Recognition Using Depth and Inertial Sensors, IEEE Sens. J., 21, pp. 3623-3634, (2021); Dua N., Singh S.N., Semwal V.B., Multi-input CNN-GRU based human activity recognition using wearable sensors, Computing, 103, pp. 1461-1478, (2021); Agarwal P., Alam M., A lightweight deep learning model for human activity recognition on edge devices, Procedia Comput. Sci., 167, pp. 2364-2373, (2020); Edel M., Koppe E., Binarized-BLSTM-RNN based Human Activity Recognition, 2016 Int. Conf. Indoor Position. Indoor Navig., IPIN 2016, pp. 4-7, (2016); Barut O., Zhou L., Luo Y., Multitask LSTM model for human activity recognition and intensity estimation using wearable sensor data, IEEE Internet Things J., 7, pp. 8760-8768, (2020); Xu C., Chai D., He J., Zhang X., Duan S., InnoHAR: A deep neural network for complex human activity recognition, IEEE Access, 7, pp. 9893-9902, (2019); Gumaei A., Hassan M.M., Alelaiwi A., Alsalman H., A hybrid deep learning model for human activity recognition using multimodal body sensing data, IEEE Access, 7, pp. 99152-99160, (2019); Challa S.K., Kumar A., Semwal V.B., A multibranch CNN-BiLSTM model for human activity recognition using wearable sensor data, Vis. Comput., (2021); Nafea O., Abdul W., Muhammad G., Alsulaiman M., Sensor-based human activity recognition with spatio-temporal deep learning, Sensors, 21, pp. 1-20, (2021); Li Y., Wang L., Human activity recognition based on residual network and BiLSTM, Sensors, 22, pp. 1-18, (2022); Lu L., Zhang C., Cao K., Deng T., Yang Q., A Multi-channel CNN-GRU Model for Human Activity Recognition, IEEE Access, 10, pp. 66797-66810, (2022); Bhattacharya D., Sharma D., Kim W., Ijaz M.F., Singh P.K., Ensem-HAR: An Ensemble Deep Learning Model for Smartphone Sensor-Based Human Activity Recognition for Measurement of Elderly Health Monitoring, Biosensors, 12, (2022); Hu J., Shen L., Sun G., Squeeze-and-excitation networks, Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit, pp. 7132-7141, (2018); Murahari V.S., Plotz T., On attention models for human activity recognition, Proc. - Int. Symp. Wearable Comput. Iswc., pp. 100-103, (2018); Zhang H., Xiao Z., Wang J., Li F., Szczerbicki E., A Novel IoT-Perceptive Human Activity Recognition (HAR) Approach Using Multihead Convolutional Attention, IEEE Internet Things J., 7, pp. 1072-1080, (2020); Zhang W., Zhu T., Yang C., Xiao J., Ning H., Sensors-based Human Activity Recognition with Convolutional Neural Network and Attention Mechanism, Proc. IEEE Int. Conf. Softw. Eng. Serv. Sci, pp. 158-162, (2020); Ige A.O., Mohd Noor M.H., A lightweight deep learning with feature weighting for activity recognition, Comput. Intell., 39, pp. 315-343, (2023); Xiao Z., Xu X., Xing H., Song F., Wang X., Zhao B., A federated learning system with enhanced feature extraction for human activity recognition, Knowl. -Based Syst., 229, (2021); Ige A.O., Noor M.H.M., WSense: a robust feature learning module for lightweight human activity recognition, ArXiv Prepr. ArXiv230317845, (2023); Reiss A., Stricker D., Introducing a new benchmarked dataset for activity monitoring, Proc. - Int. Symp. Wearable Comput. Iswc., pp. 108-109, (2012); Kwapisz J.R., Weiss G.M., Moore S.A., Activity recognition using cell phone accelerometers, ACM SIGKDD Explor. Newsl., 12, pp. 74-82, (2011); Gil-Martin M., San-Segundo R., Fernandez-Martinez F., Ferreiros-Lopez J., Time analysis in human activity recognition, Neural Process. Lett., 53, pp. 4507-4525, (2021); Han C., Zhang L., Tang Y., Huang W., Min F., He J., Human activity recognition using wearable sensors by heterogeneous convolutional neural networks, Expert Syst. Appl., 198, (2022); Xiao S., Wang S., Huang Z., Wang Y., Jiang H., Two-stream transformer network for sensor-based human activity recognition, Neurocomputing, 512, pp. 253-268, (2022)","M.H. Mohd Noor; School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, 11800, Malaysia; email: halimnoor@usm.my","","Elsevier Ltd","","","","","","15684946","","","","English","Appl. Soft Comput.","Article","Final","","Scopus","2-s2.0-85175034665"
"Mohd Noor M.H.","Mohd Noor, Mohd Halim (36656106400)","36656106400","Feature learning using convolutional denoising autoencoder for activity recognition","2021","Neural Computing and Applications","33","17","","10909","10922","13","9","10.1007/s00521-020-05638-4","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098509400&doi=10.1007%2fs00521-020-05638-4&partnerID=40&md5=44911fc6494bdad39ab48d078e4d56c2","School of Computer Sciences, Universiti Sains Malaysia, USM, Pulau Pinang, 11800, Malaysia","Mohd Noor M.H., School of Computer Sciences, Universiti Sains Malaysia, USM, Pulau Pinang, 11800, Malaysia","Wearable technology offers a prospective solution to the increasing demand for activity monitoring in pervasive healthcare. Feature extraction and selection are crucial steps in activity recognition since it determines the accuracy of activity classification. However, existing feature extraction and selection methods involve manual feature engineering, which is time-consuming, laborious and prone to error. Therefore, this paper proposes an unsupervised feature learning method that automatically extracts and selects the features without human intervention. Specifically, the proposed method jointly trains a convolutional denoising autoencoder with a convolutional neural network to learn the underlying features and produces a compact feature representation of the data. This allows not only more accurate and discriminative features to be extracted but also reduces the computational cost and improves generalization of the classification models. The proposed method was evaluated and compared with deep learning convolutional neural networks on a public dataset. Results have shown that the proposed method can learn a salient feature representation and subsequently recognize the activities with an accuracy of 0.934 and perform comparably well to the convolutional neural networks. © 2021, The Author(s), under exclusive licence to Springer-Verlag London Ltd. part of Springer Nature.","Activity recognition; Deep learning; Denoising autoencoder; Feature learning","Convolution; Convolutional neural networks; Deep learning; Deep neural networks; Extraction; Learning systems; Wearable technology; Activity classifications; Activity recognition; Classification models; Discriminative features; Feature engineerings; Feature extraction and selection; Pervasive healthcare; Unsupervised feature learning; Feature extraction","","","","","Universiti Sains Malaysia, (304/PKOMP/6315206)","This work has been supported in part by the Universiti Sains Malaysia under Short-Term Grant 304/PKOMP/6315206. ","Landi F., Onder G., Carpenter I., Et al., Physical activity prevented functional decline among frail community-living elderly subjects in an international observational study, J Clin Epidemiol, 60, pp. 518-524, (2007); Jansen F.M., Prins R.G., Etman A., Et al., Physical activity in non-frail and frail older adults, PLoS ONE, 10, (2015); Durstine J.L., Gordon B., Wang Z., Luo X., Chronic disease and the link to physical activity, J Sport Health Sci, 2, pp. 3-11, (2013); Naci H., Ioannidis J.P.A., Comparative effectiveness of exercise and drug interventions on mortality outcomes: metaepidemiological study, BMJ, 347, (2013); Lara O.D., Labrador M.A., A survey on human activity recognition using wearable sensors, IEEE Commun Surv Tutor, 15, pp. 1192-1209, (2013); Suto J., Oniga S., Lung C., Orha I., Comparison of offline and real-time human activity recognition results using machine learning techniques, Neural Comput Appl, (2018); Rosati S., Balestra G., Knaflitz M., Comparison of different sets of features for human activity recognition by wearable sensors, Sensors, 18, (2018); Parkka J., Ermes M., Korpipaa P., Et al., Activity classification using realistic data from wearable sensors, IEEE Trans Inf Technol Biomed, 10, pp. 119-128, (2006); Kwon M.-C., Choi S., Recognition of daily human activity using an artificial neural network and smartwatch, Wirel Commun Mob Comput, 2018, (2018); Fuentes D., Gonzalez-Abril L., Angulo C., Ortega J.A., Online motion recognition using an accelerometer in a mobile device, Expert Syst Appl, 39, pp. 2461-2465, (2012); Catal C., Tufekci S., Pirmit E., Kocabag G., On the use of ensemble of classifiers for accelerometer-based activity recognition, Appl Soft Comput, 37, pp. 1018-1022, (2015); Xu S., Tang Q., Jin L., Pan Z., A cascade ensemble learning model for human activity recognition with smartphones, Sensors, (2019); Ronao C.A., Cho S.-B., Recognizing human activities from smartphone sensors using hierarchical continuous hidden Markov models, Int J Distrib Sens Netw, 13, (2017); Preece S.J., Goulermas J.Y., Kenney L.P.J., Howard D., A comparison of feature extraction methods for the classification of dynamic activities from accelerometer data, IEEE Trans Biomed Eng, 56, pp. 871-879, (2009); Balli S., Sagbas E.A., Peker M., Human activity recognition from smart watch sensor data using a hybrid of principal component analysis and random forest algorithm, Meas Control., (2018); Vanrell S.R., Milone D.H., Rufiner H.L., Assessment of homomorphic analysis for human activity recognition from acceleration signals, IEEE J Biomed Health Inform, 22, pp. 1001-1010, (2018); Wang Z., Wu D., Chen J., Et al., A triaxial accelerometer-based human activity recognition via EEMD-based features and game-theory-based feature selection, IEEE Sens J, 16, pp. 3198-3207, (2016); Ker J., Wang L., Rao J., Lim T., Deep learning applications in medical image analysis, IEEE Access, 6, pp. 9375-9389, (2018); Justesen N., Bontrager P., Togelius J., Risi S., Deep learning for video game playing, IEEE Trans Games, (2019); Xin Y., Kong L., Liu Z., Et al., Machine learning and deep learning methods for cybersecurity, IEEE Access, 6, pp. 35365-35381, (2018); Ronao C.A., Cho S.-B., Human activity recognition with smartphone sensors using deep learning neural networks, Expert Syst Appl, 59, pp. 235-244, (2016); Almaslukh B., Al Muhtadi J., Artoli A.M., A robust convolutional neural network for online smartphone-based human activity recognition, J Intell Fuzzy Syst, 35, pp. 1609-1620, (2018); Ignatov A., Real-time human activity recognition from accelerometer data using convolutional neural networks, Appl Soft Comput, 62, pp. 915-922, (2018); Huang J., Lin S., Wang N., Et al., TSE-CNN: a two-stage end-to-end CNN for human activity recognition, IEEE J Biomed Health Inform, (2019); Ordonez F.J., Roggen D., Deep convolutional and LSTM recurrent neural networks for multimodal wearable activity recognition, Sensors, 16, (2016); Wang L., Recognition of human activities using continuous autoencoders with wearable sensors, Sensors, 16, (2016); Gao X., Luo H., Wang Q., Et al., A human activity recognition algorithm based on stacking denoising autoencoder and lightGBM, Sensors, 19, (2019); Gu F., Khoshelham K., Valaee S., Et al., Locomotion activity recognition using stacked denoising autoencoders, IEEE Internet Things J, 5, pp. 2085-2093, (2018); Mohd Noor M.H., Ahmadon M.A., Osman M.K., Activity Recognition using Deep Denoising Autoencoder, 2019 9Th IEEE International Conference on Control System, Computing and Engineering (ICCSCE), pp. 188-192, (2019); Gao L., Bourke A.K., Nelson J., Evaluation of accelerometer based multi-sensor versus single-sensor activity recognition systems, Med Eng Phys, 36, pp. 779-785, (2014); Banos O., Galvez J.-M., Damas M., Et al., Window size impact in human activity recognition, Sensors, 14, pp. 6474-6499, (2014); Fida B., Bernabucci I., Bibbo D., Et al., Varying behavior of different window sizes on the classification of static and dynamic physical activities from a single accelerometer, Med Eng Phys, 37, pp. 705-711, (2015); Noor M.H.M., Salcic Z., Wang K.I.-K., Adaptive sliding window segmentation for physical activity recognition using a single tri-axial accelerometer, Pervasive Mob Comput, 38, pp. 41-59, (2017); Vincent P., Larochelle H., Bengio Y., Manzagol P.-A., Extracting and composing robust features with denoising autoencoders, Proceedings of the 25Th International Conference on Machine Learning, pp. 1096-1103, (2008); Ismail Fawaz H., Forestier G., Weber J., Et al., Deep learning for time series classification: a review, Data Min Knowl Discov, 33, pp. 917-963, (2019); LeCun Y., Bengio Y., Hinton G., Deep learning, Nature, 521, pp. 436-444, (2015); Goodfellow I., Pouget-Abadie J., Mirza M., Et al., Generative Adversarial Nets, Advances in neural information processing systems 27, pp. 2672-2680, (2014); Reyes-Ortiz J.-L., Oneto L., Sama A., Et al., Transition-aware human activity recognition using smartphones, Neurocomputing, 171, pp. 754-767, (2016)","M.H. Mohd Noor; School of Computer Sciences, Universiti Sains Malaysia, USM, Pulau Pinang, 11800, Malaysia; email: halimnoor@usm.my","","Springer Science and Business Media Deutschland GmbH","","","","","","09410643","","","","English","Neural Comput. Appl.","Article","Final","","Scopus","2-s2.0-85098509400"
"Jimale A.O.; Mohd Noor M.H.","Jimale, Ali Olow (57918294100); Mohd Noor, Mohd Halim (36656106400)","57918294100; 36656106400","Fully Connected Generative Adversarial Network for Human Activity Recognition","2022","IEEE Access","10","","","100257","100266","9","5","10.1109/ACCESS.2022.3206952","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139391264&doi=10.1109%2fACCESS.2022.3206952&partnerID=40&md5=1cac3ac72de581e3cc292d2a9f43261b","Universiti Sains Malaysia, School of Computer Sciences, Pulau Pinang, 11800, Malaysia; Simad University, Faculty of Computing, Mogadishu, 252, Somalia","Jimale A.O., Universiti Sains Malaysia, School of Computer Sciences, Pulau Pinang, 11800, Malaysia, Simad University, Faculty of Computing, Mogadishu, 252, Somalia; Mohd Noor M.H., Universiti Sains Malaysia, School of Computer Sciences, Pulau Pinang, 11800, Malaysia","Conditional Generative Adversarial Networks (CGAN) have shown great promise in generating synthetic data for sensor-based activity recognition. However, one key issue concerning existing CGAN is the design of the network architecture that affects sample quality. This study proposes an effective CGAN architecture that synthesizes higher quality samples than state-of-the-art CGAN architectures. This is achieved by combining convolutional layers with multiple fully connected networks in the generator's input and discriminator's output of the CGAN. We show the effectiveness of the proposed approach using elderly data for sensor-based activity recognition. Visual evaluation, similarity measure, and usability evaluation are used to assess the quality of generated samples by the proposed approach and validate its performance in activity recognition. In comparison to the state-of-the-art CGAN, the visual evaluation and similarity measure demonstrate that the proposed models' synthetic data more accurately represents actual data and creates more variations in each synthetic data than the state-of-the-art approach respectively. The experimental stages of the usability evaluation, on the other hand, show a performance gain of 2.5%, 2.5%, 3.1%, and 4.4% over the state-of-the-art CGAN when using synthetic samples by the proposed architecture.  © 2013 IEEE.","Activity recognition; deep learning; generative adversarial network","Deep learning; Network architecture; Pattern recognition; Quality control; Activity recognition; Deep learning; Features extraction; Generator; State of the art; Synthetic data; Training data; Visual evaluation; Generative adversarial networks","","","","","","","Wang A., Zhao S., Zheng C., Chen H., Liu L., Chen G., Hier-HAR: Sensor-based data-driven hierarchical human activity recogni-tion, IEEE Sensors J, 21, 3, pp. 3353-3365, (2021); Noor M.H.M., Salcic Z., Wang K.I.-K., Ontology-based sensor fusion activity recognition, J. Ambient Intell. Hum. Comput, 11, 8, pp. 3073-3087, (2020); Farias G., Dormido-Canto S., Vega J., Ratta G., Vargas H., Hermosilla G., Alfaro L., Valencia A., Automatic feature extraction in large fusion databases by using deep learning approach, Fusion Eng. Des, 112, pp. 979-983, (2016); Wang J., Chen Y., Hao S., Peng X., Hu L., Deep learning for sensor-based activity recognition: A survey, Pattern Recognit. Lett, 119, pp. 3-11, (2019); Nweke H.F., Teh Y.W., Al-Garadi M.A., Alo U.R., Deep learning algorithms for human activity recognition using mobile and wearable sensor networks: State of the art and research challenges, Expert Syst. Appl, 105, pp. 233-261, (2018); Yang J.B., Nguyen M.N., San P.P., Li X.L., Krishnaswamy S., Deep convolutional neural networks on multichannel time series for human activity recognition, Proc. Int. Joint Conf. Artif. Intell. (IJCAI), pp. 3995-4001, (2015); Hasan M., Roy-Chowdhury K.A., A continuous learning frame-work for activity recognition using deep hybrid feature models, IEEE Trans. Multimedia, 17, 11, pp. 1909-1922, (2015); Yang Q., Activity recognition: Linking low-level sensors to high-level intelligence, Proc. Int. Joint Conf. Artif. Intell. (IJCAI), pp. 20-25, (2009); Ronao C.A., Cho S.-B., Human activity recognition with smartphone sensors using deep learning neural networks, Expert Syst. Appl, 59, pp. 235-244, (2016); Shi D., Li Y., Ding B., Unsupervised feature learning for human activity recognition, Guofang Keji Daxue Xuebao/J. Nat. Univ. Defence Technol, 37, 5, pp. 128-134, (2015); Shaheen F., Verma B., Asafuddoula M., Impact of automatic feature extraction in deep learning architecture, Proc. Int. Conf. Digit. Image Comput., Techn. Appl. (DICTA), pp. 1-8, (2016); Alawneh L., Alsarhan T., Al-Zinati M., Al-Ayyoub M., Jararweh Y., Lu H., Enhancing human activity recognition using deep learning and time series augmented data, J. Ambient Intell. Hum. Comput, 12, 12, pp. 10565-10580, (2021); Rashid K.M., Louis J., Times-series data augmentation and deep learning for construction equipment activity recognition, Adv. Eng. Informat, 42, (2019); Zhang S., Alshurafa N., Deep generative cross-modal on-body accelerometer data synthesis from videos, Proc. Adjunct Proc. ACM Int. Joint Conf. Pervasive Ubiquitous Comput. Proc. ACM Int. Symp. Wearable Comput, pp. 223-227, (2020); Kim M., Jeong C.Y., Label-preserving data augmentation for mobile sensor data, Multidimensional Syst. Signal Process, 32, 1, pp. 115-129, (2021); Tran S.N., Nguyen T.D., Ngo T.-S., Vu X.-S., Hoang L., Zhang Q., Karunanithi M., Deep learning for multi-resident activity recogni-tion in ambient sensing smart homes, Artif. Intell. Rev, 53, 3, pp. 340-341, (2019); Leite C.F.S., Xiao Y., Improving cross-subject activity recognition via adversarial learning, IEEE Access, 8, pp. 90542-90554, (2020); Antoniou A., Storkey A., Edwards H., Data augmentation gen-629 erative adversarial networks, (2017); Chen K., Zhang D., Yao L., Guo B., Yu Z., Liu Y., Deep learning for sensor-based human activity recognition: Overview, challenges, and opportunities, ACM Comput. Surv, 54, 4, pp. 1-40, (2022); DeVries T., Taylor G.W., Dataset augmentation in feature space, Proc. 5th Int. Conf. Learn. Represent. (ICLR), pp. 1-12, (2019); Hsu W.-N., Zhang Y., Glass J., Unsupervised domain adaptation for robust speech recognition via variational autoencoder-based data augmentation, Proc. IEEE Autom. Speech Recognit. Understand. Workshop (ASRU), pp. 16-23, (2017); Boquet G., Vicario J., Morell A., Serrano J., Missing data in traffic estimation: A variational autoencoder imputation method, Proc. IEEE Int. Conf. Acoust., Speech Signal Process. (ICASSP), Barcelona, U.K, pp. 2882-2886, (2019); Ko H., Lee J., Kim J., Lee J., Shim H., Diversity regularized autoencoders for text generation, Proc. 35th Annu. ACMSymp. Appl. Comput, pp. 883-891, (2020); Mesbah S., Yang J., Sips R.-J., Torre M.V., Lofi C., Bozzon A., Houben G.-J., Training data augmentation for detecting adverse drug reactions in user-generated content, Proc. Conf. Empirical Meth-ods Natural Lang. Process. 9th Int. Joint Conf. Natural Lang. Process. (EMNLP-IJCNLP), pp. 2349-2359, (2020); Shorten C., Khoshgoftaar T.M., A survey on image data augmentation for deep learning, J. Big Data, 6, 1, pp. 1-48, (2019); Chan M.H., Noor M.H.M., A unified generative model using generative adversarial network for activity recognition, J. Ambient Intell. Hum. Comput, 12, 7, pp. 8119-8128, (2021); Li X., Luo J., Younes R., ActivityGAN: Generative adversarial networks for data augmentation in sensor-based human activity recognition, Proc. Adjunct ACM Int. Joint Conf. Pervasive Ubiquitous Com-put., ACM Int. Symp. Wearable Comput, pp. 249-254, (2020); Abdu-Aguye M., Gomaa W., Robust human activity recognition based on deepmetric learning, Proc. 16th Int. Conf. Informat. Control, Autom. Robot, pp. 656-663, (2019); Bulling A., Blanke U., Schiele B., A tutorial on human activity recognition using body-worn inertial sensors, ACM Comput. Surv, 46, 3, pp. 1-33, (2014); Chiang T.-C., Bruno B., Menicatti R., Recchiuto C.T., Sgorbissa A., Culture as a sensor? A novel perspective on human activity recognition, Int. J. Social Robot, 11, 5, pp. 797-814, (2019); Campbell A.T., Eisenman S.B., Lane N.D., Miluzzo E., Peterson R.A., Lu H., Zheng X., Musolesi M., Fodor K., Ahn G.-S., The rise of people-centric sensing, IEEE Internet Comput, 12, 4, pp. 12-21, (2008); Li J.-H., Tian L., Wang H., An Y., Wang K., Yu L., Segmentation and recognition of basic and transitional activities for continuous physical human activity, IEEE Access, 7, pp. 42565-42576, (2019); Liu J., Liu H., Chen Y., Wang Y., Wang C., Wireless sensing for human activity: A survey, IEEE Commun. Surveys Tuts, 22, 3, pp. 1629-1645, (2020); Cook D., Feuz K.D.F., Krishnan N.C., Transfer learning for activity recognition: A survey diane, Bone, 23, 1, pp. 1-7, (2008); Chen L., Hoey J., Nugent C.D., Cook D.J., Yu Z., Sensor-based activity recognition, IEEE Trans. Syst., Man, Cybern. C, Appl. Rev, 42, 6, pp. 790-808, (2012); Ali S., Shah M., Human action recognition in videos using kinematic features and multiple instance learning, IEEE Trans. Pat-tern Anal. Mach. Intell, 32, 2, pp. 288-303, (2010); Hussain Z., Sheng M., Zhang W.E., Different approaches for human activity recognition: A survey, (2019); Ramamurthy S.R., Roy N., Recent trends in machine learning for human activity recognition-A survey, Wiley Interdiscipl. Rev., Data Mining Knowl. Discovery, 8, 4, pp. 1-11, (2018); Zdravevski E., Lameski P., Trajkovik V., Kulakov A., Chorbev I., Goleva R., Pombo N., Garcia N., Improving activity recogni-tion accuracy in ambient-assisted living systems by automated fea-ture engineering, IEEE Access, 5, pp. 5262-5280, (2017); Ono H., Suzuki S., Data augmentation for gross motor-activity recog-nition using DCGAN, Proc. IEEE/SICE Int. Symp. Syst. Integr. (SII), pp. 440-443, (2020); Almaslukh B., Al Muhtadi J., Artoli A.M., A robust convolutional neural network for online smartphone-based human activity recognition, J. Intell. Fuzzy Syst, 35, 2, pp. 1609-1620, (2018); Mahdizadehaghdam S., Panahi A., Krim H., Generative adversarial nets, Proc. IEEE/CVF Int. Conf. Comput. Vis. Workshop (ICCVW), pp. 3063-3071, (2014); Xiao C., Han D., Ma Y., Qin Z., CsiGAN: Robust chan-nel state information-based activity recognition with GANs, IEEE Internet Things J, 6, 6, pp. 10191-10204, (2019); Palipana S., Rojas D., Agrawal P., Pesch D., FallDeFi: Ubiquitous fall detection using commodity Wi-Fi devices, Proc. ACM Interact., Mobile, Wearable Ubiquitous Technol, 1, 4, pp. 1-25, (2018); Wang J., Chen Y., Gu Y., Xiao Y., Pan H., SensoryGANs: An effective generative adversarial framework for sensor-based human activity recognition, Proc. Int. Joint Conf. Neural Netw. (IJCNN), pp. 1-8, (2018); Shi J., Zuo D., Zhang Z., A GAN-based data augmentation method for human activity recognition via the caching ability, Internet Technol. Lett, 4, 5, pp. 4-9, (2021); Barua S., Erfani S.M., Bailey J., FCC-GAN: A fully connected and convolutional net architecture for GANs, (2019); Jimale A.O., Noor M.H.M., Subject variability in sensor-based activ-ity recognition, J. Ambient Intell. Hum. Comput, pp. 1-14, (2021); Liu L., Peng Y., Liu M., Huang Z., Sensor-based human activ-ity recognition system with a multilayered model using time series shapelets, Knowl.-Based Syst, 90, pp. 138-152, (2015)","M.H. Mohd Noor; Universiti Sains Malaysia, School of Computer Sciences, Pulau Pinang, 11800, Malaysia; email: halimnoor@usm.my","","Institute of Electrical and Electronics Engineers Inc.","","","","","","21693536","","","","English","IEEE Access","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85139391264"
"Yusof N.A.M.; Ibrahim A.; Noor M.H.M.; Tahir N.M.; Yusof N.M.; Abidin N.Z.; Osman M.K.","Yusof, N.A.M. (57207308210); Ibrahim, A. (57198461652); Noor, M.H.M. (36656106400); Tahir, N.M. (56168849900); Yusof, N.M. (58422899800); Abidin, N.Z. (55602740300); Osman, M.K. (7201930443)","57207308210; 57198461652; 36656106400; 56168849900; 58422899800; 55602740300; 7201930443","Deep convolution neural network for crack detection on asphalt pavement","2019","Journal of Physics: Conference Series","1349","1","012020","","","","23","10.1088/1742-6596/1349/1/012020","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077790231&doi=10.1088%2f1742-6596%2f1349%2f1%2f012020&partnerID=40&md5=11428d0b6342f1588cc0ef49bf5be589","Electrical Engineering Department, Politeknik Tuanku Sultanah Bahiyah, Kedah, Malaysia; Faculty of Electrical Engineering, Universiti Teknologi MARA, Cawangan Pulau Pinang, Malaysia; School of Computer Science, Universiti Sains Malaysia, Pulau Pinang, Malaysia; Faculty of Civil Engineering, Universiti Teknologi MARA, Cawangan Pulau Pinang, Malaysia; Faculty of Electrical Engineering, Universiti Teknologi MARA, Selangor, Malaysia; PLUS Berhad, Persada PLUS, Selangor, Malaysia; Keysight Technologies Malaysia Sdn Bhd, Pulau Pinang, Malaysia","Yusof N.A.M., Electrical Engineering Department, Politeknik Tuanku Sultanah Bahiyah, Kedah, Malaysia; Ibrahim A., Faculty of Electrical Engineering, Universiti Teknologi MARA, Cawangan Pulau Pinang, Malaysia; Noor M.H.M., School of Computer Science, Universiti Sains Malaysia, Pulau Pinang, Malaysia; Tahir N.M., Faculty of Civil Engineering, Universiti Teknologi MARA, Cawangan Pulau Pinang, Malaysia; Yusof N.M., Faculty of Electrical Engineering, Universiti Teknologi MARA, Selangor, Malaysia; Abidin N.Z., PLUS Berhad, Persada PLUS, Selangor, Malaysia; Osman M.K., Keysight Technologies Malaysia Sdn Bhd, Pulau Pinang, Malaysia","Asphalt cracks are one of the major road damage problems in civil field as it may potentially threaten the road and highway safety. Crack detection and classification is a challenging task because complicated pavement conditions due to the presence of shadows, oil stains and water spot will result in poor visual and low contrast between cracks and the surrounding pavement. In this paper, the network proposed a fully automated crack detection and classification using deep convolution neural network (DCNN) architecture. First, the image of pavement cracks manually prepared in RGB format with dimension of 1024x768 pixels, captured using NIKON digital camera. Next, the image will segmented into patches (32x32 pixels) as a training dataset from the original pavement cracks and trained DCNN with two different filter sizes: 3x3 and 5x5. The proposed method has successfully detected the presence of crack in the images with 98%, 99% and 99% of recall, precision and accuracy respectively. The network was also able to automatically classify the pavement cracks into no cracks, transverse, longitudinal and alligator with acceptable classification accuracy for both filter sizes. There was no significant different in classification accuracy between the two different filters. However, smaller filter size need more processing training time compared to the larger filter size. Overall, the proposed method has successfully achieved accuracy of 94.5% in classifying different types of crack. © Published under licence by IOP Publishing Ltd.","","Asphalt mixtures; Convolution; Deep neural networks; Highway engineering; Nanostructured materials; Pixels; Roads and streets; Classification accuracy; Convolution neural network; Fully automated; Pavement condition; Pavement cracks; Road and highways; Training dataset; Training time; Crack detection","","","","","Foundation for Fundamental Research on Matter, FOM, (FRGS/1/2019/TK04/UITM/02/30)","The authors would like to thank to all parties that support and involve directly or indirectly into this research especially Universiti Teknologi MARA, Pulau Pinang. This research is supported by the Fundamental Research Grant Scheme (FRGS), Grant No: FRGS/1/2019/TK04/UITM/02/30. Also, appreciation goes to the Ministry of Higher Education (MOHE) for giving great privilege in providing scholarship as inspiring encouragement for the success of this research.","Guan H., Li J., Yu Y., Chapman M., Wang C., Automated Road Information Extraction from Mobile Laser Scanning Data, IEEE Trans. Intell. Transp. Syst., 16, 1, pp. 194-205, (2015); Salman M., Mathavan S., Kamal S., Rahman M., Pavement Crack Detection Using the Gabor Filter, 16th International IEEE Conference on Intelligent Transportation Systems (ITSC 2013), pp. 2039-2044, (2013); Radopoulou I., Jog S.G.M., Brilakis, Patch Distress Detection in Asphalt Pavement Images, Proc. 30th Int. Symp. Autom. Robot. Constr. (ISARC 2013), pp. 1572-1580, (2013); Sun L., Qian Z., Multi-Scale Wavelet Transform Filtering of Non-Uniform Pavement Surface Image Background for Automated Pavement Distress Identification Meas, J. Int. Meas. Confed., 86, pp. 26-40, (2016); Cubero-Fernandez A., Rodriguez-Lozano F.J., Villatoro R., Olivares J., Palomares J.M., Efficient Pavement Crack Detection and Classification Eurasip, J. Image Video Process., 2017, 1, (2017); Talab A.M.A., Huang Z., Xi F., Haiming L., Detection Crack in Image Using Otsu Method and Multiple Filtering, Image Processing Techniques Optik (Stuttg), 127, 3, pp. 1030-1033, (2016); Sun Y., Automated Pavement Distress Detection Using Advanced Image Processing Techniques, pp. 29-47, (2016); Qingbo Z., Pavement Crack Detection Algorithm Based on Image Processing Analysis, 2016 8th Int. Conf. Intell. Human-Machine Syst. Cybern., pp. 15-18, (2016); Mathavan S., Rahman M., Kama K., Use of a Self-Organizing Map for Crack Detection in Highly Textured Pavement Images, J. Infrastruct. Syst., 21, 3, (2015); Fan Z., Wu Y., Lu J., Li W., Automatic Pavement Crack Detection Based on Structured Prediction with the Convolutional Neural Network, pp. 1-9, (2018); Yadav P.P.S., Crack Detection Using Image Processing : Review, 7, pp. 121-124, (2018); Hoang N., Nguyen Q., Tran V., Automation in Construction Automatic Recognition of Asphalt Pavement Cracks Using Metaheuristic Optimized Edge Detection Algorithms and Convolution Neural Network, 94, pp. 203-213, (2018); Pauly L., Peel H., Luo S., Hogg D., Fuentes R., Deeper Networks for Pavement Crack Detection, Proc. 34th ISARC. 34th Int. Symp. Autom. Robot. Constr., Isarc, pp. 479-485, (2017); Lins R.G., Givigi S.N., Automatic Crack Detection and Measurement Based on Image Analysis, IEEE Trans. Instrum. Meas., 65, 3, pp. 583-590, (2016); Madli R., Hebbar S., Pattar P., Golla V., Automatic detection and notification of potholes and humps on roads to aid drivers, IEEE Sens. J., 15, 8, pp. 4313-4318, (2015); Adu-Gyamfi Y., Kambhamettu C., Okine N.A., Performance Assessment of Flexible Pavements Using Active Contour Models, Airf. Highw. Pavement 2013 Sustain. Effic. Pavements, pp. 887-902, (2013); Wang X., Feng X., Pavement Distress Detection and Classification with Automated Image Processing, Proceedings 2011 International Conference on Transportation, Mechanical, and Electrical Engineering, TMEE, 2011, pp. 1345-1350, (2011); Broberg P., Surface Crack Detection in Welds Using Thermography NDT, E Int., 57, pp. 69-73, (2013); Zou Q., Cao Y., Li Q., Mao Q., Wang S., Cracktree: Automatic Crack Detection from Pavement Images Pattern, Recognit. Lett., 33, 3, pp. 227-238, (2012); Li B., Wang K.C.P., Zhang A., Yang E., Wang G., Automatic Classification of Pavement Crack Using Deep Convolutional Neural Network, Int. J. Pavement Eng., pp. 1-7, (2018); Gao F., Huang T., Wang J., Sun J., Hussain A., Yang E., Applied Sciences Dual-Branch Deep Convolution Neural Network for Polarimetric SAR Image Classification, (2003); Behnke S., Hierarchical Neural Networks for Image Interpretation, 2766, (2003); Simard P.Y., Steinkraus D., Platt J.C., Best Practices for Convolutional Neural Networks Applied to Visual Document Analysis Doc. Anal. Recognition, 2003, Proceedings. Seventh Int. Conf, pp. 958-963, (2003); Zhang X., Sun S., Li C., DeepGait : A Learning Deep Convolutional Representation for Gait Recognition, Chinese Conference on Biometric Recognition CCBR 2017: Biometric Recognition, pp. 447-456, (2017); Yu S., Jia S., Xu C., Convolutional Neural Networks for Hyperspectral Image Classification, Neurocomputing, 219, pp. 88-98, (2017); Cha Y.J., Choi W., Deep Learning - Based Crack Damage Detection Using Convolutional Neural Networks, Comput. - Aided Civ. Infrastruct. Eng., pp. 1-18, (2017); Zhang L., Yang F., Daniel Zhang Y., Zhu Y.J., Road Crack Detection Using Deep Convolutional Neural Network, 2016 IEEE International Conference on Image Processing (ICIP), pp. 3708-3712, (2016); Krizhevsky A., Sutskever I., Hinton G.E., ImageNet Classification with Deep Convolutional Neural Networks, Adv. Neural Inf. Process. Syst., pp. 1-9, (2012); Zeiler M.D., Fergus R., Visualizing and Understanding Convolutional Networks, Comput. Vision-ECCV, 2014, pp. 818-833, (2013); Simonyan K., Zisserman A., Very Deep Convolutional Networks for Large-Scale Image Recognition, pp. 1-12, (2014); Gopalakrishnan K., Khaitan S.K., Choudhary A., Agrawal A., Deep Convolutional Neural Networks with Transfer Learning for Computer Vision-Based Data-Driven Pavement Distress Detection, Constr. Build. Mater., 157, pp. 322-330, (2017); Nair V., Hinton G.E., Rectified Linear Units Improve Restricted Boltzmann Machines, Proc. 27th Int. Conf. Mach. Learn., 3, pp. 807-814, (2010); Pauly L., Peel H., Luo S., Hogg D., Fuentes R., Deeper Networks for Pavement Crack Detection, pp. 479-485, (2017); Cha Y.J., Choi W., Buyukozturk O., Deep Learning-Based Crack Damage Detection Using Convolutional Neural Networks, Comput. Civ. Infrastruct. Eng., 32, 5, pp. 361-378, (2017); Wang W., Hu Z., Grid-Based Pavement Crack Analysis Using Deep Learning, 2017 4th International Conference on Transportation Information and Safety, ICTIS 2017 - Proceedings, pp. 917-924, (2017); Chen F.C., Jahanshahi M.R., NB-CNN: Deep Learning-Based Crack Detection Using Convolutional Neural Network and Naïve Bayes Data Fusion, IEEE Trans. Ind. Electron., 65, 5, pp. 4392-4400, (2018)","","","Institute of Physics Publishing","","International Conference on Nanomaterials: Science, Engineering and Technology 2019, ICoNSET 2019","5 August 2019 through 6 August 2019","Penang Island","156302","17426588","","","","English","J. Phys. Conf. Ser.","Conference paper","Final","All Open Access; Bronze Open Access","Scopus","2-s2.0-85077790231"
"Ahmad K.A.; Saad Z.; Abdullah N.; Hussain Z.; Mohd Noor M.H.","Ahmad, K.A. (35760857000); Saad, Z. (35093131900); Abdullah, Noramalina (57208570673); Hussain, Z. (24724464800); Mohd Noor, M.H. (36656106400)","35760857000; 35093131900; 57208570673; 24724464800; 36656106400","Moving vehicle segmentation in a dynamic background using self-adaptive Kalman background method","2011","Proceedings - 2011 IEEE 7th International Colloquium on Signal Processing and Its Applications, CSPA 2011","","","5759918","439","442","3","6","10.1109/CSPA.2011.5759918","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79957480068&doi=10.1109%2fCSPA.2011.5759918&partnerID=40&md5=1f7f4c63cd0a39ed147af2e03275fe97","Faculty of Electrical Engineering, University of Technology MARA, Malaysia; School of Electrical and Electronic Engineering, University of Science Malaysia, Malaysia","Ahmad K.A., Faculty of Electrical Engineering, University of Technology MARA, Malaysia; Saad Z., Faculty of Electrical Engineering, University of Technology MARA, Malaysia; Abdullah N., School of Electrical and Electronic Engineering, University of Science Malaysia, Malaysia; Hussain Z., Faculty of Electrical Engineering, University of Technology MARA, Malaysia; Mohd Noor M.H., Faculty of Electrical Engineering, University of Technology MARA, Malaysia","This paper introduce the adaptive kalman filter to modeling dynamic background for background subtraction. Background subtraction is a method to identify object and famous used in moving object segmentation. In this paper we also investigate a comparison study on Gaussian subtraction method, frame differencing method and approximate median method. The detection of object will be shown in the result. © 2011 IEEE.","Adaptive Kalman Background Subtraction Method; Frame Differencing Method; Mixture of Gaussian Method","Signal processing; Speech recognition; Adaptive kalman filter; Background subtraction; Background subtraction method; Comparison study; Dynamic background; Frame differencing method; Gaussians; Mixture of Gaussian Method; Moving object segmentation; Moving vehicles; Self-adaptive; Subtraction method; Image segmentation","","","","","","","Conaire C.O., O'Connnor N., Cooke E., Smeaton A., Detection Thresholding Using Mutual Information, International Conference on Computer Vision Theory and Applications, 25-28 February 2006, Setubal, Portugal; Hu W., Tan T., Wang L., Maybank S., A Survey on Visual Surveillance of Object Motion and Behaviors, IEEE Transactions on Systems, Man, and Cybernatics, 3, (2004); Kun A.J., Vamossy Z., Traffic Monitoring with Computer Vision, 7th International Symposium on Applied Machine Intelligence and Informatics, 2009. SAMI 2009. Date:30-31 Jan. 2009; Wu J., Liu Z., Li J., Gu C., Si M., Tan F., An Algorithm for Automatic Vehicle Speed Detection using Video Camera,  International Conference on Computer Science & Education; Kim H., Sakamoto R., Kitahara I., Toriyama T., Kogure K., Background Subtraction using Generalized Gaussian Family Model, Electronics Letters, 44, 3, (2008); Tavakkoli A., Nicolescu M., Bebis G., A Novelty Detection Approach for Foreground Region Detection in Videos with Quasi-Stationary Backgrounds, Proceedings of the 2nd International Symposium on Visual Computing, 2006; Pornpanomchai C., Liamsanguan T., Vannakosit V., Vehicle Detection and Counting from a Video Frame, Proceeding of the 2008 International Conference on Wavelet Analysis and Pattern Recognition, Hong Kong, 30-31 August 2008; Hou Y.-L., Pang G.K.H., People Counting and Human Detection in a Challenging Situation, IEEE Transaction on Systems, Man, and Cybernatics, 41, (2011); Somasundaram G., Morellas V., Papanikolopoulos N., Counting Pedestrians and Bicycles in Traffic Scenes, Proceedings of the 12th International IEEE Conference on Intelligent Transportaion Systems, St. Louis, MO, USA, 3-7 October 2009; Jaijing K., Kaewtrakulpong P., Siddhichai S., Object Detection and Modelling Algorithm for Automatic Visual People Counting System,  International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology, 2009. ECTI-CON 2009; Shao J., Jia Z., Li Z., Liu F., Zhao J., Peng P.-Y., Robust Visual Surveilllance based Traffic Information Analysis and Forewarning in Urban Dynamic Scenes, IEEE Intellligent Vehicles Symposium University of California, San Diego, Ca, USA 21-24 June, 2010; Culibrk D., Marques O., Socek D., Kalva H., Furht B., A Neural Network Approach to Bayesian Background Modeling for Video Object Segmentation, Dissertation Abstracts International, 67, 6, (2006); Dubravko, Marques O., Socek D., Kalva H., Furht B., Neural Network Approach to Background Modelling for Video Object Segmentation, IEEE Transactions on Neural Networks, 6, (2007); Maddalena L., Petrosino A., A Self-Organizing Approach to Detection of Moving Patterns for Real-Time Applications, LNCS 2007, 4729, (2007); Lin H.-H., Liu T.-L., Chuang J.-H., A Probabilistic SVM Approach for Background Scene Initialization, Proceedings on 2002 Conference on Image Proceesing, 2002, 3, pp. 893-896; Wang J., Bebis G., Miller R., Robust Video-Based Surveilllance by Integrating Target Detection with Tracking, Proceedings of the 2006 Conference on Computer Vision and Pattern Recognition Workshop, 2006; Tang W., Gong C., Zhou H., A Novel Background Modeling Approach for Accurate and Real-Time Motion Segmentation, ICSP2006 Proceedings; Lei M., Lefloch D., Gouton P., Madani K., A Video-Based Real-Time Vehicle Counting System using Adaptive Background Method, 2008 IEEE International Conference on Signal Image Technology and Internet Based Systems","K. A. Ahmad; Faculty of Electrical Engineering, University of Technology MARA, Malaysia; email: azman062@ppinang.uitm.edu.my","","","","2011 IEEE 7th International Colloquium on Signal Processing and Its Applications, CSPA 2011","4 March 2011 through 6 March 2011","Penang","84971","","978-161284414-5","","","English","Proc. - IEEE Int. Colloq. Signal Process. Its Appl., CSPA","Conference paper","Final","","Scopus","2-s2.0-79957480068"
"Ige A.O.; Mohd Noor M.H.","Ige, Ayokunle Olalekan (57828337400); Mohd Noor, Mohd Halim (36656106400)","57828337400; 36656106400","A lightweight deep learning with feature weighting for activity recognition","2023","Computational Intelligence","39","2","","315","343","28","1","10.1111/coin.12565","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144131183&doi=10.1111%2fcoin.12565&partnerID=40&md5=8a4e07e87305c372e1c7157265ee3f69","School of Computer Sciences, Universiti Sains Malaysia, George Town, Malaysia","Ige A.O., School of Computer Sciences, Universiti Sains Malaysia, George Town, Malaysia; Mohd Noor M.H., School of Computer Sciences, Universiti Sains Malaysia, George Town, Malaysia","With the development of deep learning, numerous models have been proposed for human activity recognition to achieve state-of-the-art recognition on wearable sensor data. Despite the improved accuracy achieved by previous deep learning models, activity recognition remains a challenge. This challenge is often attributed to the complexity of some specific activity patterns. Existing deep learning models proposed to address this have often recorded high overall recognition accuracy, while low recall and precision are often recorded on some individual activities due to the complexity of their patterns. Some existing models that have focused on tackling these issues are always bulky and complex. Since most embedded systems have resource constraints in terms of their processor, memory and battery capacity, it is paramount to propose efficient lightweight activity recognition models that require limited resources consumption, and still capable of achieving state-of-the-art recognition of activities, with high individual recall and precision. This research proposes a high performance, low footprint deep learning model with a squeeze and excitation block to address this challenge. The squeeze and excitation block consist of a global average-pooling layer and two fully connected layers, which were placed to extract the flattened features in the model, with best-fit reduction ratios in the squeeze and excitation block. The squeeze and excitation block served as channel-wise attention, which adjusted the weight of each channel to build more robust representations, which enabled our network to become more responsive to essential features while suppressing less important ones. By using the best-fit reduction ratio in the squeeze and excitation block, the parameters of the fully connected layer were reduced, which helped the model increase responsiveness to essential features. Experiments on three publicly available datasets (PAMAP2, WISDM, and UCI-HAR) showed that the proposed model outperformed existing state-of-the-art with fewer parameters and increased the recall and precision of some individual activities compared to the baseline, and the existing models. © 2022 Wiley Periodicals LLC.","activity recognition; deep learning; wearable","Complex networks; Deep learning; Learning systems; Pattern recognition; Wearable sensors; Activity recognition; Best fit; Deep learning; Essential features; Feature weighting; Learning models; Recall and precision; Reduction ratios; State of the art; Wearable; Embedded systems","","","","","","","Tan J.S., Beheshti B.K., Binnie T., Et al., Human activity recognition for people with knee osteoarthritis—a proof-of-concept, Sensors, 21, 10, (2021); Kasahara Y., Nishiyama Y., Sezaki K., Detecting childcare activities using an off-the-shelf smartwatch. Paper presented at: 2022 IEEE International Conference on Smart Computing (SMARTCOMP), pp. 159-161, (2022); Askari M.R., Rashid M., Sun X., Et al., Meal and physical activity detection from free-living data for discovering disturbance patterns of glucose levels in people with diabetes, BioMedInform, 2, 2, pp. 297-317, (2022); Ertugrul O.F., Kaya Y., Determining the optimal number of body-worn sensors for human activity recognition, Soft Comput, 21, 17, pp. 5053-5060, (2017); Casale P., Pujol O., Radeva P., Human activity recognition from accelerometer data using a wearable device. Paper presented at: Lect Notes Comput Sci Subser Lect Notes Artif Intell Lect Notes Bioinforma, 6669 LNCS, pp. 289-296, (2011); Ige A.O., Mohd Noor M.H., A survey on unsupervised learning for wearable sensor-based activity recognition, Appl Soft Comput, 127, (2022); Mahmud S., Tanjid Hasan Tonmoy M., Kumar Bhaumik K., Et al., Human activity recognition fromwearable sensor data using self-attention, Front Artif Intell Appl, 325, pp. 1332-1339, (2020); Jimale A.O., Mohd Noor M.H., Subject variability in sensor-based activity recognition, J Ambient Intell Humaniz Comput, (2021); Sani S., Wiratunga N., Massie S., Cooper K., kNN sampling for personalised human activity recognition. Paper presented at: Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), 10339 LNAI, pp. 330-344, (2017); Uddin M.T., Uddiny M.A., A guided random forest based feature selection approach for activity recognition. Paper presented at: 2nd International Conference on Electrical Engineering and Information and Communication Technology, ICEEiCT 2015, pp. 1-6, (2015); Manosha Chathuramali K.G., Rodrigo R., Faster human activity recognition with SVM. Paper presented at: Int Conf Adv ICT Emerg Reg ICTer 2012 - Conf Proc, pp. 197-203, (2012); Fan L., Wang Z., Wang H., Human activity recognition model based on decision tree. Paper presented at: 2013 International Conference on Advanced Cloud and Big Data, CBD 2013, pp. 64-68, (2013); Mohd Noor M.H., Feature learning using convolutional denoising autoencoder for activity recognition, Neural Comput Appl, 33, 17, pp. 10909-10922, (2021); Wang J., Chen Y., Hao S., Peng X., Hu L., Deep learning for sensor-based activity recognition: a survey, Pattern Recognit Lett, 119, pp. 3-11, (2019); Huang J., Lin S., Wang N., Dai G., Xie Y., Zhou J., TSE-CNN: a two-stage end-to-end CNN for human activity recognition, IEEE J Biomed Health Inform, 24, 1, pp. 292-299, (2020); Ma H., Li W., Zhang X., Gao S., Lu S., Attnsense: multi-level attention mechanism for multimodal human activity recognition, Int Jt Conf Artif Intell, pp. 3109-3115, (2019); Zeng M., Gao H., Yu T., Et al., Understanding and improving recurrent networks for human activity recognition by continuous attention. Paper presented at: Proc - Int Symp Wearable Comput ISWC, pp. 56-63, (2018); Gao W., Zhang L., Teng Q., He J., Wu H., DanHAR: dual attention network for multimodal human activity recognition using wearable sensors, Appl Soft Comput, 111, (2021); Hu J., Shen L., Sun G., Squeeze-and-excitation networks, Proc IEEE Comput Soc Conf Comput Vis Pattern Recognit, pp. 7132-7141, (2018); Ismail Fawaz H., Forestier G., Weber J., Idoumghar L., Muller P.A., Deep learning for time series classification: a review, Data Min Knowl Discov, 33, 4, pp. 917-963, (2019); Lecun Y., Bengio Y., Hinton G., Deep learning, Nature, 521, 7553, pp. 436-444, (2015); Murahari V.S., Plotz T., On attention models for human activity recognition. Paper presented at: International Symposium on Wearable Computers, ISWC, pp. 100-103, (2018); Pascanu R., Mikolov T., Bengio Y., On the difficulty of training recurrent neural networks. Paper presented at: PMLR, ed. 30th International Conference on Machine Learning, ICML 2013, PMLR, pp. 2347-2355, (2013); Banos O., Galvez J.M., Damas M., Pomares H., Rojas I., Window size impact in human activity recognition, Sens Switz, 14, 4, pp. 6474-6499, (2014); Scheurer S., Tedesco S., Brown K.N., O'flynn B., Using domain knowledge for interpretable and competitive multi-class human activity recognition, Sens Switz., 20, 4, pp. 1-25, (2020); Zhu Q., Chen Z., Soh Y.C., A novel semisupervised deep learning method for human activity recognition, IEEE Trans Ind Inform, 15, 7, pp. 3821-3830, (2019); Lara O.D., Labrador M.A., A survey on human activity recognition using wearable sensors, IEEE Commun Surv Tutor, 15, 3, pp. 1192-1209, (2013); Ronao C.A., Cho S.B., Human activity recognition with smartphone sensors using deep learning neural networks, Expert Syst Appl., 59, pp. 235-244, (2016); Trost S.G., Zheng Y., Wong W.K., Machine learning for activity recognition: hip versus wrist data, Physiol Meas, 35, 11, pp. 2183-2189, (2014); Ragb H.K., Dover I.T., Ali R., Deep convolutional neural network ensemble for improved malaria parasite detection, Proc - Appl Imag Pattern Recognit Workshop, pp. 1-10, (2020); Prabha P.A., Priya M.D., Jeba Malar A.C., Karthik S., Dakshin G.K.S.D., Improved ResNet-based image classification technique for malaria detection springer, Singapore, Proceedings of 6th International Conference on Recent Trends in Computing. Lecture Notes in Networks and Systems, 177, (2021); Joy Rakesh Y., Kavitha R., Julian J., Human activity recognition using wearable sensors, Adv Intell Syst Comput, 1177, 3, pp. 527-538, (2021); Delgado-Ortet M., Molina A., Alferez S., Rodellar J., Merino A., A deep learning approach for segmentation of red blood cell images and malaria detection, Entropy, 22, 6, pp. 1-16, (2020); Li W., Shao W., Ji S., Cambria E., BiERU: bidirectional emotional recurrent unit for conversational sentiment analysis, Neurocomput, 467, pp. 73-82, (2022); Jantawong P., Jitpattanakul A., Mekruksavanich S., Enhancement of human complex activity recognition using wearable sensors data with inception time network. Paper presented at: 2021 2nd International Conference on Big Data Analytics and Practices, IBDAP 2021, pp. 12-16, (2021); Chernbumroong S., Atkins A.S., Yu H., Activity classification using a single wrist-worn accelerometer. Paper presented at: SKIMA 2011 - 5th International Conference on Software, Knowledge Information, Industrial Management and Applications, pp. 21-25, (2011); Catal C., Tufekci S., Pirmit E., Kocabag G., On the use of ensemble of classifiers for accelerometer-based activity recognition, Appl Soft Comput J, 37, pp. 1018-1022, (2015); Gomathi V., Kalaiselvi S., Thamarai S.D., Sensor-based human activity recognition using fuzzified deep CNN architecture with λmax method, Sens Rev, 42, pp. 250-262, (2022); Rueda F.M., Grzeszick R., Fink G.A., Feldhorst S., Ten Hompel M., Convolutional neural networks for human activity recognition using body-worn sensors, Informatics, 5, 2, pp. 1-17, (2018); Qi W., Su H., Yang C., Ferrigno G., De Momi E., Aliverti A., A fast and robust deep convolutional neural networks for complex human activity recognition using smartphone, Sens Switz., 19, 17, (2019); Li Y., Wang L., Human activity recognition based on residual network and BiLSTM, Sensors., 22, 2, pp. 1-18, (2022); Dua N., Singh S.N., Semwal V.B., Multi-input CNN-GRU based human activity recognition using wearable sensors, Comput Secur, 103, 7, pp. 1461-1478, (2021); Challa S.K., Kumar A., Semwal V.B., A multibranch CNN-BiLSTM model for human activity recognition using wearable sensor data, Vis Comput, (2021); Mohd Noor M.H., Tan S.Y., Ab Wahab M.N., Deep temporal conv-LSTM for activity recognition, Neural Process Lett, 54, pp. 4027-4049, (2022); Ullah M., Ullah H., Khan S.D., Cheikh F.A., Stacked Lstm network for human activity recognition using smartphone data, Proc - Eur Workshop Vis Inf Process EUVIP, pp. 175-180, (2019); Nafea O., Abdul W., Muhammad G., Alsulaiman M., Sensor-based human activity recognition with spatio-temporal deep learning, Sensors., 21, 6, pp. 1-20, (2021); Ordonez F.J., Roggen D., Deep convolutional and LSTM recurrent neural networks for multimodal wearable activity recognition, Sens Switz., 16, 1, (2016); Wang K., He J., Zhang L., Attention-based convolutional neural network for weakly labeled human activities' recognition with wearable sensors, IEEE Sens J., 19, 17, pp. 7598-7604, (2019); Abdel-Basset M., Hawash H., Chakrabortty R.K., Ryan M., Elhoseny M., Song H., ST-DeepHAR: deep learning model for human activity recognition in IoHT applications, IEEE Internet Things J, 8, 6, pp. 4969-4979, (2021); Liu L., He J., Ren K., Lungu J., Hou Y., Dong R., An information gain-based model and an attention-based RNN for wearable human activity recognition, Entropy., 23, 12, (2021); Ioffe S., Szegedy C., Batch normalization: accelerating deep network training by reducing internal covariate shift. Paper presented at: 32nd Int Conf Mach Learn ICML 2015, 1, pp. 448-456, (2015); Reiss A., Stricker D., Introducing a new benchmarked dataset for activity monitoring. Paper presented at: Proc - Int Symp Wearable Comput ISWC 2012, pp. 108-109, (2012); Kwapisz J.R., Weiss G.M., Moore S.A., Activity recognition using cell phone accelerometers, ACM SIGKDD Explorations Newsletter, 12, pp. 74-82, (2011); Garcia-Gonzalez D., Rivero D., Fernandez-Blanco E., Luaces M.R., A public domain dataset for real-life human activity recognition using smartphone sensors, Sensors (Switzerland), 20, pp. 24-26, (2020); Teng Q., Wang K., Zhang L., He J., The layer-wise training convolutional neural networks using local loss for sensor-based human activity recognition, IEEE Sens J., 20, 13, pp. 7265-7274, (2020); Han C., Zhang L., Tang Y., Huang W., Min F., He J., Human activity recognition using wearable sensors by heterogeneous convolutional neural networks, Expert Syst Appl, 198, 2, (2022); Lu L., Zhang C., Cao K., Deng T., Yang Q., A multichannel CNN-GRU model for human activity recognition, IEEE Access., 10, pp. 66797-66810, (2022); Li X., Nie L., Si X., Ding R., Zhan D., Enhancing representation of deep features for sensor-based activity recognition, Mob Netw Appl, 26, 1, pp. 130-145, (2021); Gil-Martin M., San-Segundo R., Fernandez-Martinez F., Ferreiros-Lopez J., Time analysis in human activity recognition, Neural Process Lett., 53, 6, pp. 4507-4525, (2021); Bhattacharya D., Sharma D., Kim W., Ijaz M.F., Singh P.K., Ensem-HAR: an ensemble deep learning model for smartphone sensor-based human activity recognition for measurement of elderly health monitoring, Biosensors, 12, 6, (2022); Li X., Wang Y., Zhang B., Ma J., PSDRNN: an efficient and effective HAR scheme based on feature extraction and deep learning, IEEE Trans Ind Inform., 16, 10, pp. 6703-6713, (2020); Xia K., Huang J., Wang H., LSTM-CNN architecture for human activity recognition, IEEE Access, 8, pp. 56855-56866, (2020); Zhang H., Xiao Z., Wang J., Li F., Szczerbicki E., A novel IoT-perceptive human activity recognition (HAR) approach using multihead convolutional attention, IEEE Internet Things J, 7, 2, pp. 1072-1080, (2020); Khan Z.N., Ahmad J., Attention induced multi-head convolutional neural network for human activity recognition, Appl Soft Comput, 110, (2021); Li H., Shrestha A., Heidari H., Le Kernec J., Fioranelli F., Bi-LSTM network for multimodal continuous human activity recognition and fall detection, IEEE Sens J, 20, 3, pp. 1191-1201, (2020); Xu C., Chai D., He J., Zhang X., Duan S., InnoHAR: a deep neural network for complex human activity recognition, IEEE Access, 7, pp. 9893-9902, (2019); MstA K., Yousuf M.A., Ahmed S., Et al., Deep CNN-LSTM with self-attention model for human activity recognition using wearable sensor, IEEE J Transl Eng Health Med, 10, pp. 1-16, (2022)","M.H. Mohd Noor; School of Computer Sciences, Universiti Sains Malaysia, George Town, Pulau Pinang, 11800, Malaysia; email: halimnoor@usm.my","","John Wiley and Sons Inc","","","","","","08247935","","COMIE","","English","Comput Intell","Article","Final","","Scopus","2-s2.0-85144131183"
"Nordin N.; Zainol Z.; Mohd Noor M.H.; Chan L.F.","Nordin, Noratikah (57222566751); Zainol, Zurinahni (12144032400); Mohd Noor, Mohd Halim (36656106400); Chan, Lai Fong (54884505400)","57222566751; 12144032400; 36656106400; 54884505400","An explainable predictive model for suicide attempt risk using an ensemble learning and Shapley Additive Explanations (SHAP) approach","2023","Asian Journal of Psychiatry","79","","103316","","","","16","10.1016/j.ajp.2022.103316","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141997941&doi=10.1016%2fj.ajp.2022.103316&partnerID=40&md5=7f430989a49ecce90da81f9d6a77024d","School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, 11800 USM, Malaysia; Department of Psychiatry, Faculty of Medicine, National University of Malaysia (UKM), 56000 Cheras, Wilayah Persekutuan Kuala Lumpur, Malaysia","Nordin N., School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, 11800 USM, Malaysia; Zainol Z., School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, 11800 USM, Malaysia; Mohd Noor M.H., School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, 11800 USM, Malaysia; Chan L.F., Department of Psychiatry, Faculty of Medicine, National University of Malaysia (UKM), 56000 Cheras, Wilayah Persekutuan Kuala Lumpur, Malaysia","Machine learning approaches have been used to develop suicide attempt predictive models recently and have been shown to have a good performance. However, those proposed models have difficulty interpreting and understanding why an individual has suicidal attempts. To overcome this issue, the identification of features such as risk factors in predicting suicide attempts is important for clinicians to make decisions. Therefore, the aim of this study is to propose an explainable predictive model to predict and analyse the importance of features for suicide attempts. This model can also provide explanations to improve the clinical understanding of suicide attempts. Two complex ensemble learning models, namely Random Forest and Gradient Boosting with an explanatory model (SHapley Additive exPlanations (SHAP)) have been constructed. The models are used for predictive interpretation and understanding of the importance of the features. The experiment shows that both models with SHAP are able to interpret and understand the nature of an individual's predictions with suicide attempts. However, compared with Random Forest, the results show that Gradient Boosting with SHAP achieves higher accuracy and the analyses found that history of suicide attempts, suicidal ideation, and ethnicity as the main predictors for suicide attempts. © 2022 Elsevier B.V.","Ensemble learning; Explainable AI; Predictive model; SHAP; Suicide attempt risk","Ethnicity; Humans; Machine Learning; Risk Factors; Suicidal Ideation; Suicide, Attempted; adult; aged; alcoholism; anxiety; anxiety disorder; area under the curve; Article; Beck Depression Inventory; clinician; controlled study; cross validation; decision making; depression; diagnostic accuracy; diagnostic test accuracy study; disease severity; drug dependence; DSM-IV; female; hospitalization; human; machine learning; major clinical study; male; mental disease assessment; prediction; predictive model; probability; random forest; recall; risk factor; Scale for Suicidal Ideation; sensitivity and specificity; shapley additive explanations approach; suicidal ideation; suicide attempt; ethnicity; machine learning","","","","","Ministry of Higher Education, Malaysia, MOHE, (FRGS/1/2020/ICT02/USM/02/5)","This work has been supported by Ministry of Higher Education Malaysia for Fundamental Research Grant Scheme (FRGS) with Project Code: FRGS/1/2020/ICT02/USM/02/5 . ","Abdullah T.A.A., Zahid M.S.M., Ali W., A review of interpretable ML in healthcare: taxonomy, applications, challenges, and future directions, Symmetry, 13, 12, (2021); Ahmed H., Hossain M., Aftab A., Soron T., Alam M., Chowdhury M.A., Uddin A., Suicide and depression in the World Health Organization South-East Asia Region: A systematic review, WHO South-East Asia J. Public Health, 6, 1, (2017); Alpaydin E., Introduction to Machine Learning, (2010); Amann J., Blasimme A., Vayena E., Frey D., Madai V.I., Explainability for artificial intelligence in healthcare: a multidisciplinary perspective, BMC Med. Inform. Decis. Mak., 20, 1, (2020); Barredo Arrieta A., Diaz-Rodriguez N., Del Ser J., Bennetot A., Tabik S., Barbado A., Garcia S., Gil-Lopez S., Molina D., Benjamins R., Chatila R., Herrera F., Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI, Inf. Fusion, 58, pp. 82-115, (2020); Belle V., Papantonis I., Principles and practice of explainable machine learning, Front. Big Data, 4, (2021); Bernert R.A., Hilberg A.M., Melia R., Kim J.P., Shah N.H., Abnousi F., Artificial intelligence and suicide prevention: a systematic review of machine learning investigations, Int. J. Environ. Res. Public Health, 17, 16, (2020); Boudreaux E.D., Rundensteiner E., Liu F., Wang B., Larkin C., Agu E., Ghosh S., Semeter J., Simon G., Davis-Martin R.E., Applying machine learning approaches to suicide prediction using healthcare data: overview and future directions, Front. Psychiatry, 12, (2021); Burke T.A., Ammerman B.A., Jacobucci R., The use of machine learning in the study of suicidal and non-suicidal self-injurious thoughts and behaviors: a systematic review, J. Affect. Disord., 245, pp. 869-884, (2019); Burke T.A., Jacobucci R., Ammerman B.A., Alloy L.B., Diamond G., Using machine learning to classify suicide attempt history among youth in medical care settings, J. Affect. Disord., 268, pp. 206-214, (2020); Chan L.F., Maniam T., Shamsul A.S., Suicide attempts among depressed inpatients with depressive disorder in a Malaysian sample: psychosocial and clinical risk factors, Crisis, 32, 5, pp. 283-287, (2011); Cho S.-E., Geem Z.W., Na K.-S., Development of a suicide prediction model for the elderly using health screening data, Int. J. Environ. Res. Public Health, 18, 19, (2021); Dwyer D.B., Falkai P., Koutsouleris N., Machine learning approaches for clinical psychology and psychiatry, Annu. Rev. Clin. Psychol., 14, 1, pp. 91-118, (2018); Edgcomb J.B., Shaddox T., Hellemann G., Brooks J.O., Predicting suicidal behavior and self-harm after general hospitalization of adults with serious mental illness, J. Psychiatr. Res., 136, pp. 515-521, (2021); Fonseka T.M., Bhat V., Kennedy S.H., The utility of artificial intelligence in suicide risk prediction and the management of suicidal behaviors, Aust. N. Z. J. Psychiatry, 53, 10, pp. 954-964, (2019); Franklin J.C., Ribeiro J.D., Fox K.R., Bentley K.H., Kleiman E.M., Huang X., Musacchio K.M., Jaroszewski A.C., Chang B.P., Nock M.K., Risk factors for suicidal thoughts and behaviors: a meta-analysis of 50 years of research, Psychol. Bull., 143, 2, pp. 187-232, (2017); Ibrahim N., Amit N., Che Din N., Ong H.C., Gender differences and psychological factors associated with suicidal ideation among youth in Malaysia, Psychol. Res. Behav. Manag., 10, pp. 129-135, (2017); Jung J.S., Park S.J., Kim E.Y., Na K.-S., Kim Y.J., Kim K.G., Prediction models for high risk of suicide in Korean adolescents using machine learning techniques, PLOS ONE, 14, 6, (2019); Kantardzic M., DATA MINING: Concepts, models, methods, and algorithms, (2019); Kessler R.C., Bossarte R.M., Luedtke A., Zaslavsky A.M., Zubizarreta J.R., Suicide prediction models: a critical review of recent research with recommendations for the way forward, Mol. Psychiatry, 25, 1, pp. 168-179, (2020); Kim S., Lee H.-K., Lee K., Detecting suicidal risk using MMPI-2 based on machine learning algorithm, Sci. Rep., 11, 1, (2021); Knapic S., Malhi A., Saluja R., Framling K., Explainable artificial intelligence for human decision support system in the medical domain, Mach. Learn. Knowl. Extr., 3, 3, pp. 740-770, (2021); Linardatos P., Papastefanopoulos V., Kotsiantis S., Explainable AI: a review of machine learning interpretability methods, Entropy, 23, 1, (2020); Lundberg S., Lee S.-I., A unified approach to interpreting model predictions, Artif. Itell., (2017); Mars B., Heron J., Klonsky E.D., Moran P., O'Connor R.C., Tilling K., Wilkinson P., Gunnell D., Predictors of future suicide attempt among adolescents with suicidal thoughts or non-suicidal self-harm: a population-based birth cohort study, Lancet Psychiatry, 6, 4, pp. 327-337, (2019); Navarro M.C., Ouellet-Morin I., Geoffroy M.-C., Boivin M., Tremblay R.E., Cote S.M., Orri M., Machine learning assessment of early life factors predicting suicide attempt in adolescence or young adulthood, JAMA Netw. Open, 4, 3, (2021); Nordin N., Zainol Z., Mohd Noor M.H., Lai Fong C., A comparative study of machine learning techniques for suicide attempts predictive model, Health Inform. J., 27, 1, (2021); O'Connor R.C., Nock M.K., The psychology of suicidal behaviour, Lancet Psychiatry, 1, 1, pp. 73-85, (2014); Peng J., Zou K., Zhou M., Teng Y., Zhu X., Zhang F., Xu J., An explainable artificial intelligence framework for the deterioration risk prediction of hepatitis patients, J. Med. Syst., 45, 5, (2021); Ribeiro M.T., Singh S., Guestrin C., (2016); Ribeiro M.T., Sameer S., Carlos G., Anchors: high-precision model-agnostic explanations, Proc. AAAI Conf. Artif. Intell., 32, 1, pp. 1-9, (2018); Ryu S., Lee H., Lee D.-K., Park K., Use of a machine learning algorithm to predict individuals with suicide ideation in the general population, Psychiatry Investig., 15, 11, pp. 1030-1036, (2018); Sahakyan M., Aung Z., Rahwan T., Explainable artificial intelligence for tabular data: a survey, IEEE Access, 9, pp. 135392-135422, (2021); Shen Y., Zhang W., Chan B.S.M., Zhang Y., Meng F., Kennon E.A., Wu H.E., Luo X., Zhang X., Detecting risk of suicide attempts among Chinese medical college students using a machine learning algorithm, J. Affect. Disord., 273, pp. 18-23, (2020); Velupillai S., Hadlaczky G., Baca-Garcia E., Gorrell G.M., Werbeloff N., Nguyen D., Patel R., Leightley D., Downs J., Hotopf M., Dutta R., Risk assessment tools and data-driven approaches for predicting and preventing suicidal behavior, Front. Psychiatry, 10, (2019); Walsh C.G., Ribeiro J.D., Franklin J.C., Predicting risk of suicide attempts over time through machine learning, Clin. Psychol. Sci., 5, 3, pp. 457-469, (2017); Walsh C.G., Ribeiro J.D., Franklin J.C., Predicting suicide attempts in adolescents with longitudinal clinical data and machine learning, J. Child Psychol. Psychiatry, 59, 12, pp. 1261-1270, (2018); Ward I.R., Wang L., Lu J., Bennamoun M., Dwivedi G., Sanfilippo F.M., Explainable artificial intelligence for pharmacovigilance: what features are important when predicting adverse outcomes, Comput. Methods Prog. Biomed., 212, (2021); Zafar M.R., Khan N., Deterministic local interpretable model-agnostic explanations for stable explainability, Mach. Learn. Knowl. Extr., 3, 3, pp. 525-541, (2021); Zhou Z.-H., Ensemble Methods: Foundations and Algorithms, (2012)","N. Nordin; School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, 11800 USM, Malaysia; email: noratikahnordin@student.usm.my","","Elsevier B.V.","","","","","","18762018","","","36395702","English","Asian J. Psychiatry","Article","Final","","Scopus","2-s2.0-85141997941"
"Zhonglin T.; Wahab M.N.A.; Akbar M.F.; Mohamed A.S.A.; Noor M.H.M.; Rosdi B.A.","Zhonglin, Tian (57222069782); Wahab, Mohd Nadhir Ab (36471236100); Akbar, Muhammad Firdaus (57195979493); Mohamed, Ahmad Sufril Azlan (57190968285); Noor, Mohd Halim Mohd (36656106400); Rosdi, Bakhtiar Affendi (14525363000)","57222069782; 36471236100; 57195979493; 57190968285; 36656106400; 14525363000","SFFSORT Multi-Object Tracking by Shallow Feature Fusion for Vehicle Counting","2023","IEEE Access","11","","","76827","76841","14","0","10.1109/ACCESS.2023.3297190","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165387856&doi=10.1109%2fACCESS.2023.3297190&partnerID=40&md5=29ad760996cb557ed5beed6e2c931a0d","Universiti Sains Malaysia, School of Computer Sciences, Minden, 11800, Malaysia; Universiti Sains Malaysia, Engineering Campus, Nibong Tebal, School of Electrical and Electronic Engineering, Penang, 14300, Malaysia","Zhonglin T., Universiti Sains Malaysia, School of Computer Sciences, Minden, 11800, Malaysia; Wahab M.N.A., Universiti Sains Malaysia, School of Computer Sciences, Minden, 11800, Malaysia; Akbar M.F., Universiti Sains Malaysia, Engineering Campus, Nibong Tebal, School of Electrical and Electronic Engineering, Penang, 14300, Malaysia; Mohamed A.S.A., Universiti Sains Malaysia, School of Computer Sciences, Minden, 11800, Malaysia; Noor M.H.M., Universiti Sains Malaysia, School of Computer Sciences, Minden, 11800, Malaysia; Rosdi B.A., Universiti Sains Malaysia, Engineering Campus, Nibong Tebal, School of Electrical and Electronic Engineering, Penang, 14300, Malaysia","Standard Multi-Object Tracking (MOT) frameworks are currently categorised into three categories: tracking-by-detection, joint detection, and tracking and attention mechanisms. Infrequently, the latter two frameworks require substantial computing resources. The difficulty of implementing real-time tracking does not apply to vehicle detection at traffic crossings. Not only is it essential to meet real-time requirements for vehicle tracking and detection at traffic intersections, but it is also necessary to address common MOT issues such as target occlusion, repetition technology, error detection, etc. Detection-based tracking has a great deal of potential. This study proposed a shallow feature fusion algorithm based on SORT, called SFFSORT and developed an innovative architecture for vehicle monitoring and counting based on detection tracking. This tracking method is more efficient than both SORT and DeepSORT. It achieved 60.9% MOTA and 65.5% IDF1 in MOT16 while MOTA achieved 60.1% and 64.7% IDF1 in MOT17. Utilizing this tracking method as a foundation, we have developed a vehicle counting framework and successfully implemented it on road traffic videos sourced from the Malaysian transportation department. The tracking algorithm presented here effectively addresses the tracking challenges arising from both detection errors and inaccuracies, providing a robust solution. The experimental findings demonstrate that the deep learning framework is capable of achieving lane-level vehicle counting even in scenarios with limited labelled data.  © 2013 IEEE.","deep learning; Intelligent transportation; multi-object tracking; transfer learning; video tracking","Deep learning; Feature extraction; Intelligent systems; Interactive computer systems; Multiobjective optimization; Object detection; Pareto principle; Target tracking; Vehicles; Deep learning; Intelligent transportation; Intelligent transportation systems; Multi-object tracking; Pareto-optimization; Real - Time system; Targets tracking; Transfer learning; Vehicles detection; Video-tracking; Real time systems","","","","","","","Mandellos N.A., Keramitsoglou I., Kiranoudis C.T., A background subtraction algorithm for detecting and tracking vehicles, Expert Syst. Appl., 38, 3, pp. 1619-1631, (2011); Lin H., Yuan Z., He B., Kuai X., Li X., Guo R., A deep learning framework for video-based vehicle counting, Frontiers Phys, 10; Kasturi R., Goldgof D., Soundararajan P., Manohar V., Garofolo J., Bowers R., Boonstra M., Korzhova V., Zhang J., Framework for performance evaluation of face, text, and vehicle detection and tracking in video: Data, metrics, and protocol, IEEE Trans. Pattern Anal. Mach. Intell., 31, 2, pp. 319-336, (2009); Wang W., Gee T., Price J., Qi H., Real time multi-vehicle tracking and counting at intersections from a fisheye camera, Proc. IEEE Winter Conf. Appl. Comput. Vis., pp. 17-24, (2015); Dai Z., Song H., Wang X., Fang Y., Yun X., Zhang Z., Li H., Video-based vehicle counting framework, IEEE Access, 7, pp. 64460-64470, (2019); Rosin P., Ellis T., Image difference threshold strategies and shadow detection, Proc. Brit. Mach. Vis. Conf., (1995); Chen Z., Cao J., Tang Y., Tang L., Tracking of moving object based on optical flow detection, Proc. Int. Conf. Comput. Sci. Netw. Technol., 2, pp. 1096-1099, (2011); Redmon J., Divvala S., Girshick R., Farhadi A., You only look once: Unified, real-time object detection, Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 779-788, (2016); Redmon J., Farhadi A., YOLOv3: An incremental improvement, (2018); Bochkovskiy A., Wang C.-Y., Mark Liao H.-Y., YOLOv4: Optimal speed and accuracy of object detection; Liu W., Anguelov D., Erhan D., Szegedy C., Reed S., Fu C.-Y., Berg A.C., SSD: Single shot MultiBox detector, Proc. Eur. Conf. Comput. Vis., pp. 21-37, (2016); Ren S., He K., Girshick R., Sun J., Faster R-CNN: Towards realtime object detection with region proposal networks, IEEE Trans. Pattern Anal. Mach. Intell., 39, 6, pp. 1137-1149, (2017); Bewley A., Ge Z., Ott L., Ramos F., Upcroft B., Simple online and realtime tracking, Proc. IEEE Int. Conf. Image Process. (ICIP), pp. 3464-3468, (2016); Wojke N., Bewley A., Paulus D., Simple online and realtime tracking with a deep association metric, (2017); Zhou X., Koltun V., Krahenbuhl P., Tracking objects as points; Zhang Y., Wang C., Wang X., Zeng W., Liu W., FairMOT: On the fairness of detection and re-identification in multiple object tracking, Int. J. Comput. Vis., 129, 11, pp. 3069-3087; Peng J., Wang C., Wan F., Wu Y., Wang Y., Tai Y., Wang C., Li J., Huang F., Fu Y., Chained-tracker: Chaining paired attentive regression results for end-to-end joint multiple-object detection and tracking; Meinhardt T., Kirillov A., Leal-Taixe L., Feichtenhofer C., Track-Former: Multi-object tracking with transformers, Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 8834-8844, (2022); Sun P., Cao J., Jiang Y., Zhang R., Xie E., Yuan Z., Wang C., Luo P., TransTrack: Multiple object tracking with transformer,; Yang T., Liang R., Huang L., Vehicle counting method based on attention mechanism SSD and state detection, Vis. Comput., 38, 8, pp. 2871-2881, (2022); Liang H., Song H., Li H., Dai Z., Vehicle counting system using deep learning and multi-object tracking methods, Transp. Res. Rec., J. Transp. Res. Board, 2674, 4, pp. 114-128; Bui K.N., Yi H., Cho J., A vehicle counts by class framework using distinguished regions tracking at multiple intersections, Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. Workshops (CVPRW), pp. 2466-2474, (2020); Milan A., Leal-Taixe L., Reid I., Roth S., Schindler K., MOT16: A benchmark for multi-object tracking, (2016); Benjumea A., Teeti I., Cuzzolin F., Bradley A., YOLO-Z: Improving small object detection in YOLOv5 for autonomous vehicles; Girshick R., Donahue J., Darrell T., Malik J., Rich feature hierarchies for accurate object detection and semantic segmentation, Proc. IEEE Conf. Comput. Vis. Pattern Recognit., pp. 580-587, (2014); Wang H., Yu Y., Cai Y., Chen X., Chen L., Liu Q., A comparative study of state-of-the-art deep learning algorithms for vehicle detection, IEEE Intell. Transp. Syst. Mag., 11, 2, pp. 82-95, (2019); Chen X., Fang H., Lin T.-Y., Vedantam R., Gupta S., Dollar P., Zitnick C.L., Microsoft COCO captions: Data collection and evaluation server, (2015); Yu J., Jiang Y., Wang Z., Cao Z., Huang T., UnitBox: An advanced object detection network, Proc. 24th ACM Int. Conf. Multimedia, pp. 516-520, (2016); Zheng Z., Wang P., Liu W., Li J., Ye R., Ren D., Distance-IoU loss: Faster and better learning for bounding box regression, (2019); Zheng Z., Wang P., Ren D., Liu W., Ye R., Hu Q., Zuo W., Enhancing geometric factors in model learning and inference for object detection and instance segmentation; Rezatofighi H., Tsoi N., Gwak J., Sadeghian A., Reid I., Savarese S., Generalized intersection over union: A metric and a loss for bounding box regression, Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 658-666, (2019); Zhang Y., Sun P., Jiang Y., Yu D., Weng F., Yuan Z., Luo P., Liu W., Wang X., ByteTrack: Multi-object tracking by associating every detection box; Leal-Taixe L., Milan A., Reid I., Roth S., Schindler K., MOTChallenge 2015: Towards a benchmark for multi-target tracking, (2015); Dendorfer P., Rezatofighi H., Milan A., Shi J., Cremers D., Reid I., Roth S., Schindler K., Leal-Taixe L., MOT20: A benchmark for multi object tracking in crowded scenes; Bergmann P., Meinhardt T., Leal-Taixe L., Tracking without bells and whistles, Proc. IEEE/CVF Int. Conf. Comput. Vis. (ICCV), pp. 941-951, (2019); Dai P., Weng R., Choi W., Zhang C., He Z., Ding W., Learning a proposal classifier for multiple object tracking, Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 2443-2452, (2021); Yang J., Ge H., Yang J., Tong Y., Su S., Online multi-object tracking using multi-function integration and tracking simulation training, Appl. Intell., 52, 2, pp. 1268-1288, (2022); Kim C., Fuxin L., Alotaibi M., Rehg J.M., Discriminative appearance modeling with multi-track pooling for real-time multi-object tracking, Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. (CVPR), pp. 9548-9557, (2021); He Y., Wei X., Hong X., Ke W., Gong Y., Identity-quantity harmonic multi-object tracking, IEEE Trans. Image Process., 31, pp. 2201-2215; Kalman R.E., A new approach to linear filtering and prediction problems, J. Basic Eng., 82, 1, pp. 35-45, (1960); Jagannathan P., Rajkumar S., Frnda J., Divakarachari P.B., Subramani P., Moving vehicle detection and classification using Gaussian mixture model and ensemble deep learning technique, Wireless Commun. Mobile Comput., 2021, pp. 1-15, (2021); Zhou A., Xie W., Pei J., Background modeling combined with multiple features in the Fourier domain for maritime infrared target detection, IEEE Trans. Geosci. Remote Sens., 60; Yin G., Yu M., Wang M., Hu Y., Zhang Y., Research on highway vehicle detection based on faster R-CNN and domain adaptation, Int. J. Speech Technol., 52, 4, pp. 3483-3498; Lin C.-J., Jhang J.-Y., Intelligent traffic-monitoring system based on YOLO and convolutional fuzzy neural networks, IEEE Access, 10, pp. 14120-14133; Khalkhali M.B., Vahedian A., Yazdi H.S., Situation assessment-augmented interactive Kalman filter for multi-vehicle tracking, IEEE Trans. Intell. Transp. Syst., 23, 4, pp. 3766-3776, (2022); Hassaballah M., Kenk M.A., Muhammad K., Minaee S., Vehicle detection and tracking in adverse weather using a deep learning framework, IEEE Trans. Intell. Transp. Syst., 22, 7, pp. 4230-4242; Hou X., Wang Y., Chau L.-P., Vehicle tracking using deep SORT with low confidence track filtering, Proc. 16th IEEE Int. Conf. Adv. Video Signal Based Surveill. (AVSS), pp. 1-6, (2019); Valdivieso Tituana D.E., Yoo S.G., Andrade R.O., Vehicle counting using computer vision: A survey, Proc. IEEE 7th Int. Conf. Converg. Technol. (I2CT), pp. 1-8, (2022); Najm M., Ali Y.H., Automatic vehicles detection, classification and counting techniques/survey, Iraqi J. Sci., 61, 7, pp. 1811-1822; Mandal V., Adu-Gyamfi Y., Object detection and tracking algorithms for vehicle counting: A comparative analysis, J. Big Data Anal. Transp., 2, 3, pp. 251-261; Li H., Wang P., Huang C., Comparison of deep learning methods for detecting and counting sorghum heads in UAV imagery, Remote Sens, 14, 13, (2022); Berwo M.A., Khan A., Fang Y., Fahim H., Javaid S., Mahmood J., Abideen Z.U., Deep learning techniques for vehicle detection and classification from images/videos: A survey, Sensors, 23, 10, (2023)","M.N.A. Wahab; Universiti Sains Malaysia, School of Computer Sciences, Minden, 11800, Malaysia; email: mohdnadhir@usm.my; M.F. Akbar; Universiti Sains Malaysia, Engineering Campus, Nibong Tebal, School of Electrical and Electronic Engineering, Penang, 14300, Malaysia; email: firdaus.akbar@usm.my","","Institute of Electrical and Electronics Engineers Inc.","","","","","","21693536","","","","English","IEEE Access","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85165387856"
"Noor M.H.M.; Nazir A.; Wahab M.N.A.; Ling J.O.Y.","Noor, Mohd Halim Mohd (36656106400); Nazir, Amril (24723004500); Wahab, Mohd Nadhir Ab (36471236100); Ling, Jodene Ooi Yen (57197825708)","36656106400; 24723004500; 36471236100; 57197825708","Detection of Freezing of Gait Using Unsupervised Convolutional Denoising Autoencoder","2021","IEEE Access","9","","9514558","115700","115709","9","10","10.1109/ACCESS.2021.3104975","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113206158&doi=10.1109%2fACCESS.2021.3104975&partnerID=40&md5=21021290b3c5713ec097d424d246ee18","School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, 11800, Malaysia; Department of Information Systems, College of Technological Innovation, Zayed University, Abu Dhabi, United Arab Emirates","Noor M.H.M., School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, 11800, Malaysia; Nazir A., Department of Information Systems, College of Technological Innovation, Zayed University, Abu Dhabi, United Arab Emirates; Wahab M.N.A., School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, 11800, Malaysia; Ling J.O.Y., School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, 11800, Malaysia","At the advanced stage of Parkinson's disease, patients may suffer from 'freezing of gait' episodes: a debilitating condition wherein a patient's 'feet feel as though they are glued to the floor.' The objective, continuous monitoring of the gait of Parkinson's disease patients with wearable devices has led to the development of many freezing of gait detection models involving the automatic cueing of a rhythmic auditory stimulus to shorten or prevent episodes. The use of thresholding and manually extracted features or feature engineering returned promising results. However, these approaches are subjective, time-consuming, and prone to error. Furthermore, their performance varied when faced with the different walking styles of Parkinson's disease patients. Inspired by state-of-art deep learning techniques, this research aims to improve the detection model by proposing a feature learning deep denoising autoencoder to learn the salient characteristics of Parkinsonian gait data that is applicable to different walking styles for the elimination of manually handcrafted features. Even with the elimination of manually handcrafted features, a reduction in half of the data window sizes to 2s, and a significant dimensionality reduction of learned features, the detection model still managed to achieve 90.94% sensitivity and 67.04% specificity, which is comparable to the original Daphnet dataset research.  © 2013 IEEE.","denoising autoencoder; freezing of gait; Parkinson's disease; unsupervised learning","Deep learning; Dimensionality reduction; Freezing; Learning systems; Auditory stimuli; Continuous monitoring; Detection models; Feature engineerings; Feature learning; Freezing of gaits; Learning techniques; Wearable devices; Feature extraction","","","","","Ministry of Higher Education, Malaysia, MOHE; Universiti Sains Malaysia","This work was supported by the Universiti Sains Malaysia and the Ministry of Higher Education Malaysia under the Fundamental Research Grant Scheme 203.PKOMP.6711798.","Sveinbjornsdottir S., The clinical symptoms of Parkinson's disease, J. Neurochem., 139, pp. 318-324, (2016); Heremans E., Nieuwboer A., Vercruysse S., Freezing of gait in Parkinson's disease: Where are we now?, Current Neurol. Neurosci. Rep., 13, 6, (2013); Rodriguez-Martin D., Home detection of freezing of gait using support vector machines through a single waist-worn triaxial accelerometer, PLoS One, 12, 2, (2017); Channa A., Popescu N., Ciobanu V., Wearable solutions for patients with Parkinson's disease and neurocognitive disorder: A systematic review, Sensors, 20, 9, (2020); Sklerov M., Shih C.-H., Browner N., Palma J.-A., Styner M., Dayan E., Longitudinal change in autonomic symptoms predicts activities of daily living and depression in Parkinson's disease, Clin. Autonomic Res., 30, 3, pp. 223-230, (2020); Khorasani A., Daliri M.R., HMM for classification of Parkinson's disease based on the raw gait data, J. Med. Syst., 38, 12, (2014); Bachlin M., Plotnik M., Roggen D., Maidan I., Hausdorff J.M., Giladi N., Troster G., Wearable assistant for Parkinson's disease patients with the freezing of gait symptom, IEEE Trans. Inf. Technol. Biomed., 14, 2, pp. 436-446, (2010); Pardoel S., Kofman J., Nantel J., Lemaire E.D., Wearablesensor-based detection and prediction of freezing of gait in Parkinson's disease: A review, Sensors, 19, 23, (2019); Camps J., Sama A., Martin M., Deep learning for detecting freezing of gait episodes in Parkinson's disease based on accelerometers, Advances in Computational Intelligence, pp. 344-355, (2017); Moore S.T., MacDougall H.G., Ondo W.G., Ambulatory monitoring of freezing of gait in Parkinson's disease, J. Neurosci. Meth-ods, 167, 2, pp. 340-348, (2008); Mazilu S., Hardegger M., Zhu Z., Roggen D., Troester G., Plotnik M., Hausdorff J., Online detection of freezing of gait with smartphones and machine learning techniques, Proc. 6th Int. Conf. Pervas. Comput. Technol. For Healthcare, pp. 123-130, (2012); Kleanthous N., Hussain A.J., Khan W., Liatsis P., A new machine learning based approach to predict freezing of gait, Pattern Recognit. Lett., 140, pp. 119-126, (2020); Demrozi F., Bacchin R., Tamburin S., Cristani M., Pravadelli G., Toward a wearable system for predicting freezing of gait in people affected by Parkinson's disease, IEEE J. Biomed. Health Informat., 24, 9, pp. 2444-2451, (2020); Ahlrichs C., Sama A., Lawo M., Cabestany J., Rodriguez-Martin D., Perez-Lopez C., Sweeney D., Quinlan L.R., Laighin G.O., Detecting freezing of gait with a tri-axial accelerometer in Parkinson's disease patients, Med. Biol. Eng. Comput., 54, 1, pp. 223-233, (2016); Sama A., Rodriguez-Martina D., Perez-Lopez C., Catala A., Alcaine S., Mestre B., Prats A., CruzCrespo M., Bayes A., Determining the optimal features in freezing of gait detection through a single waist accelerometer in home environments, Pattern Recognit. Lett., 105, pp. 135-143, (2018); Borzi L., Mazzetta I., Zampogna A., Suppa A., Olmo G., Irrera F., Prediction of freezing of gait in Parkinson's disease using wearables and machine learning, Sensors, 21, 2, (2021); Ashour A.S., El-Attar A., Dey N., Long short term memory based patient-dependent model for FOG detection in Parkinson's disease, Pattern Recognit. Lett., 131, pp. 23-29, (2020); Torvi V.G., Bhattacharya A., Chakraborty S., Deep domain adaptation to predict freezing of gait in patients with Parkinson's disease, Proc. 17th IEEE Int. Conf. Mach. Learn. Appl. (ICMLA), pp. 1001-1006, (2018); Xia Y., Zhang J., Ye Q., Cheng N., Lu Y., Zhang D., Evaluation of deep convolutional neural networks for detection of freezing of gait in Parkinson's disease patients, Biomed. Signal Process. Control, 46, pp. 221-230, (2018); Li B., Yao Z., Wang J., Wang S., Yang X., Sun Y., Improved deep learning technique to detect freezing of gait in Parkinson's disease based on wearable sensors, Electronics, 9, 11, (2020); Vincent P., Larochelle H., Bengio Y., Extracting and composing robust features with denoising autoencoders, Proc. 25th Int. Conf. Mach. Learn. Assoc. Comput. Machinery, pp. 1096-1103, (2008); Mazilu S., Calatroni A., Gazit E., Feature learning for detection and prediction of freezing of gait in Parkinson's disease, Machine Learning and Data Mining in Pattern Recognition, pp. 144-158, (2013)","M.H.M. Noor; School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, 11800, Malaysia; email: halimnoor@usm.my; M.N.A. Wahab; School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, 11800, Malaysia; email: mohdnadhir@usm.my","","Institute of Electrical and Electronics Engineers Inc.","","","","","","21693536","","","","English","IEEE Access","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85113206158"
"Nordin N.; Zainol Z.; Mohd Noor M.H.; Chan L.F.","Nordin, Noratikah (57222566751); Zainol, Zurinahni (12144032400); Mohd Noor, Mohd Halim (36656106400); Chan, Lai Fong (54884505400)","57222566751; 12144032400; 36656106400; 54884505400","An Ontology-based Modeling for Classifying Risk of Suicidal Behavior","2023","ACM International Conference Proceeding Series","","","","71","76","5","0","10.1145/3587828.3587840","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163896898&doi=10.1145%2f3587828.3587840&partnerID=40&md5=34a363cd073277d04931dacbc0c3699b","School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, 11800, Malaysia; Department of Psychiatry, Faculty of Medicine, National University of Malaysia (UKM), Cheras, Wilayah Persekutuan, Kuala Lumpur, 56000, Malaysia","Nordin N., School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, 11800, Malaysia; Zainol Z., School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, 11800, Malaysia; Mohd Noor M.H., School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, 11800, Malaysia; Chan L.F., Department of Psychiatry, Faculty of Medicine, National University of Malaysia (UKM), Cheras, Wilayah Persekutuan, Kuala Lumpur, 56000, Malaysia","Classifying an individual with suicidal behavior is a complex problem. A clinical decision support system (CDSS) helps medical experts in their daily work and supports them in effective decision-making. The huge amount of medical information and the complex correlation between the risk factors and the level of risk for suicidal behavior makes the representation of data is challenging. Therefore, this paper proposes an ontology-based modeling to classify an individual with at-risk of suicidal behavior for effective clinical decision support system. The case study is conducted to evaluate the ontology model and provides a general approach to knowledge sharing and reusing knowledge for suicide risk prevention and management. The finding shows that the ontology model can be used as a knowledge base for classification, and it is suitable to capture medical knowledge, detailed concepts, and relationships in a formal way using Web Ontology Language (OWL). The results of the proposed ontology model in terms of accuracy, specificity, and sensitivity are 83%, 84%, and 82% respectively. © 2023 Copyright held by the owner/author(s).","Clinical Decision Support System; Data Mining; Knowledge Base; Ontological Model; Suicidal Behavior","Decision making; Decision support systems; Knowledge based systems; Ontology; Clinical decision support systems; Complex problems; Decisions makings; Knowledge base; Medical experts; Medical information; Ontological modeling; Ontology based modeling; Ontology model; Suicidal behavior; Data mining","","","","","Ministry of Higher Education, Malaysia, MOHE, (FRGS/1/2020/ICT02/USM/02/5); Universiti Sains Malaysia, USM","The authors would like to thank all parties that support and involve directly or indirectly into this research, especially Universiti Sains Malaysia, Pulau Pinang and Universiti Kebangsaan Malaysia Medical Centre, Kuala Lumpur. This research is supported by the Ministry of Higher Education Malaysia for Fundamental Research Grant Scheme (FRGS) with Project Code: FRGS/1/2020/ICT02/USM/02/5.","Preventing suicide: a global imperative, (2014); Turecki G., Et al., Suicide and suicide risk, Nat. Rev. Dis. Primer, 5, 1, (2019); Franklin J.C., Et al., Risk factors for suicidal thoughts and behaviors: A meta-analysis of 50 years of research, Psychol. Bull., 143, 2, pp. 187-232, (2017); Chan L.F., Maniam T., Shamsul A.S., Suicide Attempts Among Depressed Inpatients with Depressive Disorder in a Malaysian Sample: Psychosocial and Clinical Risk Factors, Crisis, 32, 5, pp. 283-287, (2011); Velupillai S., Et al., Risk Assessment Tools and Data-Driven Approaches for Predicting and Preventing Suicidal Behavior, Front. Psychiatry, 10, (2019); Runeson B., Odeberg J., Pettersson A., Edbom T., Jildevik Adamsson I., Waern M., Instruments for the assessment of suicide risk: A systematic review evaluating the certainty of the evidence, PLOS ONE, 12, 7, (2017); O'Connor R.C., Portzky G., Looking to the Future: A Synthesis of New Developments and Challenges in Suicide Research and Prevention, Front. Psychol., 9, (2018); Boudreaux E.D., Et al., Applying Machine Learning Approaches to Suicide Prediction Using Healthcare Data: Overview and Future Directions, Front. Psychiatry, 12, (2021); Burke T.A., Ammerman B.A., Jacobucci R., The use of machine learning in the study of suicidal and non-suicidal self-injurious thoughts and behaviors: A systematic review, J. Affect. Disord., 245, pp. 869-884, (2019); Sutton R.T., Pincock D., Baumgart D.C., Sadowski D.C., Fedorak R.N., Kroeker K.I., An overview of clinical decision support systems: benefits, risks, and strategies for success, Npj Digit. Med., 3, 1, (2020); Cheung C.F., Wang W.M., Leung Z.C.S., A pilot study on a knowledge-based case library to support suicide risk assessment, Int. Soc. Work, 56, 2, pp. 208-227, (2013); Middleton B., Sittig D.F., Wright A., Clinical Decision Support: a 25 Year Retrospective and a 25 Year Vision, Yearb. Med. Inform., 25, pp. S103-S116, (2016); Moreira M.W.L., Rodrigues J.J.P.C., Korotaev V., Al-Muhtadi J., Kumar N., A Comprehensive Review on Smart Decision Support Systems for Health Care, IEEE Syst. J., 13, 3, pp. 3536-3545, (2019); Gruber T.R., Toward principles for the design of ontologies used for knowledge sharing?, Int. J. Hum.-Comput. Stud., 43, 5-6, pp. 907-928, (1995); Fung K.W., Bodenreider O., Knowledge Representation and Ontologies, Clinical Research Informatics, pp. 313-339, (2019); Noy N.F., McGuinness D.L., Ontology development 101: A guide to creating your first ontology, Stanf. Knowl. Syst. Lab. Tech. Rep. KSL-01-05 Stanf. Med. Inform. Tech. Rep. SMI-2001-0880, 15, 2, (2001); Scalmato A., Sgorbissa A., Zaccaria R., Describing and Recognizing Patterns of Events in Smart Environments With Description Logic, IEEE Trans. Cybern., 43, 6, pp. 1882-1897, (2013); Noor M.H.M., Salcic Z., Wang K.I.-K., Ontology-based sensor fusion activity recognition, J. Ambient Intell. Humaniz. Comput., 11, 8, pp. 3073-3087, (2020); McDaniel M., Storey V.C., Evaluating Domain Ontologies: Clarification, Classification, and Challenges, ACM Comput. Surv., 52, 4, pp. 1-44, (2019); Nordin N., Zainol Z., Mohd Noor M.H., Lai Fong C., A comparative study of machine learning techniques for suicide attempts predictive model, Health Informatics J, 27, 1, (2021); Nordin N., Zainol Z., Mohd Noor M.H., Chan L.F., Suicidal behaviour prediction models using machine learning techniques: A systematic review, Artif. Intell. Med., 132, (2022)","N. Nordin; School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, 11800, Malaysia; email: noratikahnordin@student.usm.my; Z. Zainol; School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, 11800, Malaysia; email: zuri@usm.my; M.H. Mohd Noor; School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, 11800, Malaysia; email: halimnoor@usm.my","","Association for Computing Machinery","","12th International Conference on Software and Computer Applications, ICSCA 2023","23 February 2023 through 25 February 2023","Kuantan","189662","","978-145039858-9","","","English","ACM Int. Conf. Proc. Ser.","Conference paper","Final","","Scopus","2-s2.0-85163896898"
"Jimale A.O.; Mohd Noor M.H.","Jimale, Ali Olow (57203986629); Mohd Noor, Mohd Halim (36656106400)","57203986629; 36656106400","Subject variability in sensor-based activity recognition","2023","Journal of Ambient Intelligence and Humanized Computing","14","4","","3261","3274","13","6","10.1007/s12652-021-03465-6","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114285038&doi=10.1007%2fs12652-021-03465-6&partnerID=40&md5=900933d1d2d92267709fa6c56762e4e3","School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, 11800, Malaysia; Faculty of Computing, SIMAD University, Mogadishu, Somalia","Jimale A.O., School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, 11800, Malaysia, Faculty of Computing, SIMAD University, Mogadishu, Somalia; Mohd Noor M.H., School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, 11800, Malaysia","Building classification models in activity recognition is based on the concept of exchangeability. While splitting the dataset into training and test sets, we assume that the training set is exchangeable with the test set and expect good classification performance. However, this assumption is invalid due to subject variability of the training and test sets due to age differences. This happens when the classification models are trained with adult dataset and tested it with elderly dataset. This study investigates the effects of subject variability on activity recognition using inertial sensor. Two different datasets—one locally collected from 15 elders and another public from 30 adults with eight types of activities—were used to evaluate the assessment techniques using ten-fold cross-validation. Three sets of experiments have been conducted: experiments on the public dataset only, experiments on the local dataset only, and experiments on public (as training) and local (as test) datasets using machine learning and deep learning classifiers including single classifiers (Support Vector Machine, Decision Tree, K-Nearest Neighbors), ensemble classifiers (Adaboost, Random Forest, and XGBoost), and Convolutional Neural Network. The experimental results show that there is a significant performance drop in activity recognition on different subjects with different age groups. It demonstrates that on average the drop in recognition accuracy is 9.75 and 12% for machine learning and deep learning models respectively. This confirms that subject variability concerning age is a valid problem that degrades the performance of activity recognition models. © 2021, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.","Activity recognition; Deep learning; Machine learning; Subject variability","Adaptive boosting; Classification (of information); Convolutional neural networks; Deep learning; Drops; Learning systems; Nearest neighbor search; Pattern recognition; Statistical tests; Support vector machines; Activity recognition; Classification models; Classification performance; Deep learning; Machine-learning; Performance; Splittings; Subject variability; Test sets; Training sets; Decision trees","","","","","Ministry of Higher Education, Malaysia, MOHE; Universiti Sains Malaysia, USM","This work was supported by the Universiti Sains Malaysia and Ministry of Higher Education Malaysia under Fundamental Research Grant Scheme (Grant No. 203.PKOMP.6711798). ","Akbari A., Jafari R., Personalizing activity recognition models with quantifying different types of uncertainty using wearable sensors, IEEE Trans Biomed Eng, (2020); Anguita D., Ghio A., Oneto L., Parra X., Reyes-Ortiz J.L., A public domain dataset for human activity recognition using smartphones, ESANN 2013 Proceedings, 21St European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning (April, pp. 437-442, (2013); Attal F., Mohammed S., Dedabrishvili M., Chamroukhi F., Oukhellou L., Amirat Y., Physical human activity recognition using wearable sensors, Sensors (Switzerland), 15, 12, pp. 31314-31338, (2015); Banos O., Garcia R., Holgado-terriza J.A., Damas M., mHealthDroid: a novel framework for agile development of mobile health applications, (2014); Campbell A.T., Lane N.D., Miluzzo E., Peterson R.A., Lu H., Zheng X., Musoles M., Fodor K., Ahn G.-S., Eisenman S.B., The rise of people-centric sensing, IEEE Internet Comput, 12, 4, pp. 12-21, (2008); Chang A.Y., Skirbekk V.F., Tyrovolas S., Kassebaum N.J., Dieleman J.L., Measuring population ageing: an analysis of the global burden of disease study 2017, Lancet Public Health, 4, 3, pp. e159-e167, (2019); Chiang T.C., Bruno B., Menicatti R., Recchiuto C.T., Sgorbissa A., Culture as a sensor? A novel perspective on human activity recognition, Int J Soc Robot, (2019); Cornacchia M., Ozcan K., Zheng Y., Velipasalar S., A survey on activity detection and classification using wearable sensors, IEEE Sens J, 17, 2, pp. 386-403, (2017); Dinarevic E.C., Husic J.B., Barakovic S., Issues of human activity recognition in healthcare, In: 2019 18Th International Symposium INFOTEH-JAHORINA, INFOTEH 2019-Proceedings (March, pp. 20-22, (2019); Gani M.O., Fayezeen T., Povinelli R.J., Smith R.O., Arif M., Kattan A.J., Ahamed S.I., A light weight smartphone based human activity recognition system with high accuracy, J Netw Comput Appl, 141, pp. 59-72, (2019); Gil-Martin M., San-Segundo R., Fernandez-Martinez F., Ferreiros-Lopez J., Improving physical activity recognition using a new deep learning architecture and post-processing techniques, Eng Appl Artif Intell, 92, (2020); Hammerla N.Y., Halloran S., Plotz T., Deep, convolutional, and recurrent models for human activity recognition using wearables, In: IJCAI International Joint Conference on Artificial Intelligence 2016-Janua, pp. 1533-1540, (2016); Howdon D., Rice N., Health care expenditures, age, proximity to death and morbidity: implications for an ageing population, J Health Econ, 57, pp. 60-74, (2018); Hussain Z., Sheng M., Zhang W.E., Different approaches for human activity recognition: A survey., pp. 1-28, (2019); Khatun S., Morshed B.I., Fully-automated human activity recognition with transition awareness from wearable sensor data for mHealth, pp. 934-938, (2018); Khusainov R., Azzi D., Achumba I.E., Bersch S.D., Real-time human ambulation, activity, and physiological monitoring: taxonomy of issues, techniques, applications, challenges and limitations, Sensors (Switzerland), 13, 10, pp. 12852-12902, (2013); Kim Y., Toomajian B., Hand gesture recognition using micro-doppler signatures with convolutional neural network, IEEE Access, 4, pp. 7125-7130, (2016); Kwapisz J.R., Weiss G.M., Moore S.A., Activity recognition using cell phone accelerometers, ACM SIGKDD Explor Newsl, 12, 2, (2011); Labrador M.A., Yejas O.D.L., Human activity recognition using wearable sensors and smartphones, (2011); Lara O.D., Labrador M.A., A survey on human activity recognition using wearable sensors, IEEE Commun Surv Tutor, 15, 3, pp. 1192-1209, (2013); Lee G., Choi B., Jebelli H., Ahn C.R., Lee S.H., Wearable biosensor and collective sensing-based approach for detecting older adults’ environmental barriers, J Comput Civ Eng, 34, 2, pp. 1-12, (2020); Lv T., Wang X., Jin L., Xiao Y., Song M., Margin-based deep learning networks for human activity recognition, Sensors (Switzerland), (2020); Mannini A., Intille S.S., Classifier personalization for activity recognition using wrist accelerometers, IEEE J Biomed Health Inform, 23, 4, pp. 1585-1594, (2019); Mohammed Hashim B.A., Amutha R., Human activity recognition based on smartphone using fast feature dimensionality reduction technique, J Ambient Intell Humaniz Comput, (2020); Nambu M., Nakajima K., Kawarada A., Tamura T., The automatic health monitoring system for home health care., pp. 79-82, (2000); Nweke H.F., Teh Y.W., Al-garadi M.A., Alo U.R., Deep learning algorithms for human activity recognition using mobile and wearable sensor networks: State of the art and research challenges, Expert Syst Appl, 105, pp. 233-261, (2018); Piyathilaka L., Kodagoda S., Human activity recognition for domestic robots, (2015); Reiss A., Stricker D., Introducing a new benchmarked dataset for activity monitoring, pp. 108-109, (2012); Reyes-Ortiz J.L., Oneto L., Sama A., Parra X., Anguita D., Transition-aware human activity recognition using smartphones, Neurocomputing, 171, pp. 754-767, (2016); Rezaie H., Ghassemian M., Comparison analysis of Radio_Based and Sensor_Based wearable human activity recognition systems, Wirel Pers Commun, 101, 2, pp. 775-797, (2018); Richter J., Wiede C., Dayangac E., Shahenshah A., Hirtz G., Activity recognition for elderly care by evaluating proximity to objects and human skeleton data, . In: Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) 10163 LNCS, pp. 139-155, (2017); Roggen D., Calatroni A., Rossi M., Holleczek T., Forster K., Troster G., Lukowicz P., Bannach D., Pirkl G., Ferscha A., Doppler J., Holzmann C., Kurz M., Holl G., Chavarriaga R., Sagha H., Bayati H., Creaturamillan M.R., Collecting complex activity datasets in highly rich networked sensor environments, In: INSS 2010–7th International Conference on Networked Sensing Systems, pp. 233-240, (2010); Sajjad Hossain H.M., Roy N., Active deep learning for activity recognition with context aware annotator selection, In: Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pp. 1862-1870, (2019); Sakuma Y., Kleisarchaki S., Gurgen L., Nishi H., Exploring variability in IoT data for human activity recognition, IECON Proceedings, pp. 5312-5318, (2019); Satapathy S.C., Das S., PCA based optimal ANN classifiers for human activity recognition using mobile sensors data, (2016); Straczkiewicz M., Onnela J., A systematic review of human activity recognition using smartphones, Arxiv E-Prints Arxiv, 1910, (2019); Subasi A., Khateeb K., Brahimi T., Sarirete A., Human activity recognition using machine learning methods in a smart healthcare environment, (2020); Nations U., World population prospects 2019, Ten Key Findings, (2019); Van Kasteren T.L.M., Englebienne G., Krose B.J.A., An activity monitoring system for elderly care using generative and discriminative models, Pers Ubiquit Comput, 14, 6, pp. 489-498, (2010); Vepakomma P., De D., Das S.K., Bhansali S., A-Wristocracy: Deep learning on wrist-worn sensing for recognition of user complex activities. In: 2015 IEEE 12th international conference on wearable and implantable body sensor networks, BSN, 2015, pp. 1-6, (2015); Vijayaprabakaran K., Sathiyamurthy K., Ponniamma M., Video-based human activity recognition for elderly using convolutional neural network, Int J Secur Priv Pervasive Comput, (2020); Xia K., Huang J., Wang H., LSTM-CNN architecture for human activity recognition, IEEE Access, 8, pp. 56855-56866, (2020); Xu L.I., He F.X., Tian Z., Liu W.E.I., Harmonic loss function for sensor-based human activity recognition based on LSTM recurrent neural networks, IEEE Access, (2020); Yao L., Sheng Q.Z., Li X., Gu T., Tan M., Wang X., Wang S., Ruan W., Compressive representation for device-free activity recognition with passive RFID signal strength, IEEE Trans Mob Comput, 17, 2, pp. 293-306, (2018); Zahin A., Tan L.T., Hu R.Q., Sensor-based human activity recognition for smart healthcare: a semi-supervised machine learning, (2019); Zhang H., Xiao Z., Wang J., Li F., Szczerbicki E., A novel IoT-perceptive human activity recognition (HAR) approach using multihead convolutional attention, IEEE Internet Things J, 7, 2, pp. 1072-1080, (2020)","M.H. Mohd Noor; School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, 11800, Malaysia; email: halimnoor@usm.my","","Springer Science and Business Media Deutschland GmbH","","","","","","18685137","","","","English","J. Ambient Intell. Humanized Comput.","Article","Final","","Scopus","2-s2.0-85114285038"
"Abdu H.; Mohd Noor M.H.","Abdu, Haruna (57201667366); Mohd Noor, Mohd Halim (36656106400)","57201667366; 36656106400","A Survey on Waste Detection and Classification Using Deep Learning","2022","IEEE Access","10","","","128151","128165","14","7","10.1109/ACCESS.2022.3226682","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144784175&doi=10.1109%2fACCESS.2022.3226682&partnerID=40&md5=d00ba08acfb49a4114487f60dffebfba","Universiti Sains Malaysia, School of Computer Sciences, Pulau Pinang, 11800, Malaysia","Abdu H., Universiti Sains Malaysia, School of Computer Sciences, Pulau Pinang, 11800, Malaysia; Mohd Noor M.H., Universiti Sains Malaysia, School of Computer Sciences, Pulau Pinang, 11800, Malaysia","Waste or trash management is receiving increased attention for intelligent and sustainable development, particularly in developed and developing countries. The waste or trash management system comprises several related processes that carry out various complex functions. Recently, interest in deep learning (DL) has increased in providing alternative computational techniques for determining the solution to various waste or trash management problems. Researchers have concentrated on this domain, and as a result, significant research has been published, particularly in recent years. According to the literature, a few comprehensive surveys have been done on waste detection and classification. However, no study has investigated the application of DL to solve waste or trash management problems in various domains and highlight the available datasets for waste detection and classification in different domains. To this end, this survey contributes by reviewing various image classification and object detection models, and their applications in waste detection and classification problems, providing an analysis of waste detection and classification techniques with precise and organized representation and compiling over twenty benchmarked trash datasets. Also, we backed up the study with the challenges of existing methods and the future potential in this field. This will give researchers in this area a solid background and knowledge of the state-of-the-art deep learning models and insight into the research areas that can still be explored.  © 2013 IEEE.","Deep learning survey; trash datasets; waste classification; waste detection","Classification (of information); Deep learning; Developing countries; Object detection; Object recognition; Waste management; Deep learning; Deep learning survey; Images classification; Neural-networks; Objects detection; Residual neural network; Training data; Trash dataset; Waste classification; Waste detection; Image classification","","","","","","","Sami K.N., Amin Z.M.A., Hassan R., Waste management using machine learning and deep learning algorithms, Int. J. Per-ceptive Cogn. Comput, 6, 2, pp. 97-106, (2020); Shahab S., Anjum M., Umar M.S., Deep learning applications in solid waste management: A deep literature review, Int. J. Adv. Comput. Sci. Appl, 13, 3, pp. 381-395, (2022); Triassi M., Alfano R., Illario M., Nardone A., Caporale O., Montuori P., Environmental pollution from illegal waste disposal and health effects: A review on the `triangle of death, Int. J. Environ. Res. Public Health, 12, 2, pp. 1216-1236, (2015); Namen A.A., Da Costa Brasil F., Abrunhosa J.J.G., Abrunhosa G.G.S., Tarre R.M., Marques F.J.G., RFID technology for hazardous waste management and tracking, Waste Manage. Res., J. Sus-Tain. Circular Economy, 32, 9, pp. 59-66, (2014); Chandra S.S., Kulshreshtha M., Randhawa P., Garbage detection and path-planning in autonomous robots, Proc. 9th Int. Conf. Rel., Infocom Technol. Optim. Trends Future Directions (ICRITO), pp. 1-4, (2021); Sarker N., Chaki S., Das A., Forhad M.S.A., Illegal trash thrower detection based on HOGSVM for a real-Time monitoring system, Proc. 2nd Int. Conf. Robot., Electr. Signal Process. Techn. (ICREST), pp. 483-487, (2021); Didelija M., Kulo N., Mulahusi A., Tuno N., Topoljak J., Segmentation scale parameter influence on the accuracy of detecting illegal landfills on satellite imagery. A case study for Novo Sarajevo, Ecol. Informat, 70, (2022); Morin E., Herrault P.-A., Guinard Y., Grandjean F., Bech N., The promising combination of a remote sensing approach and landscape connectivity modelling at a fine scale in urban planning, Ecological Indicators, 139, (2022); Bhandari S., Automatic waste sorting in industrial environments via machine learning approaches, Tampere Univ. Tampere Finland, (2020); White P., Franke M., Hindle P., Lifecycle inventory: A part of lifecycle assessment, Integrated Solid Waste Management: A Lifecycle Inventory, pp. 25-36, (1999); Demirbas A., Waste management, waste resource facilities and waste conversion processes, Energy Convers. Manage, 52, 2, pp. 1280-1287, (2011); Wang J., Zhang T., Cheng Y., Al-Nabhan N., Deep learning for object detection: A survey, Comput. Syst. Sci. Eng, 38, 2, pp. 165-182, (2021); Swetha M.S., Veena M.S., Muneshwara M.S., Thungamani M., Survey of object detection using deep neural networks, Int. J. Adv. Res. Comput. Commun. Eng, 7, 11, pp. 19-24, (2018); Yewange M., Gaikwad K., Kamble R., Maske S., Shahu R., Real-Time Object Detection by Using Deep Learning: A Survey, (2022); Ahmed M., Hashmi K.A., Pagani A., Liwicki M., Stricker D., Afzal M.Z., Survey and performance analysis of deep learning based object detection in challenging environments, Sensors, 21, 15; Rekha B.S., Marium A., Srinivasan G.N., Shetty S.A., Literature survey on object detection using YOLO, Int. Res. J. Eng. Technol, 7, 6, pp. 3082-3088, (2020); Wang W., Lai Q., Fu H., Shen J., Ling H., Yang R., Salient object detection in the deep learning era: An in-depth survey, IEEE Trans. Pattern Anal. Mach. Intell, 44, 6, pp. 3239-3259; Ferrara L., Iannace M., Patelli A.M., Arienzo M., Geochemical survey of an illegal waste disposal site under a waste emergency scenario (Northwest Naples, Italy), Environ. Monit. Assessment, 185, 3, pp. 2671-2682, (2013); Prasanna M A., Kaushal S.V., Mahalakshmi P., Survey onidenti fication and classification of waste for efficient disposal and recycling, Int. J. Eng. Technol, 7, 2-8, (2018); Yang T., Xu J., Zhao Y., Gong T., Zhao R., Sun M., Xi B., Classification technology of domestic waste from 2000 to 2019: A bibliometrics-based review, Environ. Sci. Pollut. Res, 28, 21, pp. 26313-26324; Wang Y., Wang Q., Jin S., Long W., Hu L., A Literature Review of Underwater Image Frontiers in Artificial Intelligence and Applica-Tions, 347, pp. 42-51, (2022); Zhang F., Cao C., Li C., Liu Y., Huisingh D., A systematic review of recent developments in disaster waste management, J. Cleaner Prod, 235, pp. 822-840, (2019); Dalal N., Triggs B., Histograms of oriented gradients for human detection, Proc. CVPR, pp. 886-893, (2005); Lowe D.G., Distinctive image features from scale-invariant keypoints, Int. J. Comput. Vis, 60, 2, pp. 91-110, (2004); Viola P., Jones M., Rapid object detection using a boosted cascade of simple features, Proc IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit, pp. 511-518, (2001); Krizhevsky A., Sutskever I., Hinton G.E., ImageNet Classifica-Tion with Deep Convolutional Neural Networks; Simonyan K., Zisserman A., Very deep convolutional networks for large-scale image recognition, arXiv:1409.1556, (2014); Szegedy C., Ioffe S., Vanhoucke V., Alemi A., Inception-v4, inception-ResNet and the impact of residual connections on learning, arXiv:1602.07261, (2016); Howard A.G., Zhu M., Chen B., Kalenichenko D., Wang W., Weyand T., Andreetto M., Adam H., MobileNets: Efficient convolutional neural networks for mobile vision applications, arXiv:1704.04861, (2017); He K., Zhang X., Ren S., Sun J., Deep Residual Learning for Image Recognition; He K., Zhang X., Ren S., Sun J., Deep residual learning for image recognition, Proc IEEE Conf. Comput. Vis. Pattern Recognit. CVPR, pp. 770-778, (2016); Bircanoglu C., Atay M., Beser F., Genc O., Kizrak M.A., RecycleNet: Intelligent waste sorting using deep neural networks, Proc. Innov. Intell. Syst. Appl. (INISTA, pp. 1-7, (2018); Lin T.-Y., Maire M., Belongie S., Hays J., Perona P., Ramanan D., Dollar P., Zitnick C.L., Microsoft COCO: Common objects in context, Proc. Eur. Conf. Comput. Vis., in Lecture Notes in Computer Science, 8693, pp. 740-755, (2014); Girshick R., Donahue J., Darrell T., Malik J., Rich feature hierarchies for accurate object detection and semantic segmentation, arXiv:1311.2524, (2013); Wang C.-Y., Yeh I.-H., Mark Liao H.-Y., You only learn one representation: Unified network for multiple tasks, arXiv:2105.04206; Redmon J., Farhadi A., YOLOv3: An Incremental Improvement; Bochkovskiy A., Wang C.-Y., Mark Liao H.-Y., YOLOv4: Optimal speed and accuracy of object detection, arXiv:2004.10934, (2020); YOLOv7: The Fastest Object Detection Algorithm, (2022); Wang C.-Y., Bochkovskiy A., Liao H.-Y.M., YOLOv7: Trainable bag-of-freebies sets new state-of-The-Art for real-Time object detectors, arXiv:2207.02696; Redmon J., Divvala S., Girshick R., Farhadi A., You only look once: Unified, real-Time object detection, arXiv:1506.02640, (2015); Duan K., Bai S., Xie L., Qi H., Huang Q., Tian Q., CenterNet: Keypoint triplets for object detection, arXiv:1904.08189, (2019); Duan K., Bai S., Xie L., Qi H., Huang Q., Tian Q., CenterNet: Keypoint triplets for object detection, Proc IEEE/CVF Int. Conf. Comput. Vis. ICCV, pp. 6568-6577, (2019); Tan M., Pang R., Le Q.V., EfficientDet: Scalable and efficient object detection, arXiv:1911.09070, (2019); Zhou X., Zhuo J., Krahenbohl P., Bottom-up object detection by grouping extreme and center points, arXiv:1901.08043, (2019); He K., Gkioxari G., Dollar P., Girshick R., Mask R-CNN, arXiv:1703.06870, (2017); Carolis B.D., Ladogana F., Macchiarulo N., YOLO TrashNet: Garbage detection in video streams, Proc IEEE Conf. Evolving Adapt. Intell. Syst. EAIS, pp. 1-7, (2020); Fulton M., Hong J., Islam M.J., Sattar J., Robotic detection of marine litter using deep visual detection models, Proc. Int. Conf. Robot. Autom. (ICRA, pp. 5752-5758, (2019); Liu Y., Ge Z., Lv G., Wang S., Research on automatic garbage detection system based on deep learning and narrowband Internet of Things, J. Phys., Conf. ser, 1069, (2018); Wang Y., Zhang X., Autonomous garbage detection for intelligent urban management, Proc. MATEC Web Conf, 232, (2018); Mengistu O.A., Smart Trash Net:Waste Localization and Classification, pp. 1-6, (2017); Mittal G., Yagnik K.B., Garg M., Krishnan N.C., SpotGarbage: Smartphone app to detect garbage using deep learning, Proc ACM Int. Joint Conf. Pervasive Ubiquitous Comput, pp. 940-945, (2016); Tharani M., Amin A.W., Maaz M., Taj M., Attention neural network for trash detection on water channels, arXiv:2007.04639, (2020); Panwar H., Gupta P.K., Siddiqui M.K., Morales-Menendez R., Bhardwaj P., Sharma S., Sarker I.H., AquaVision: Automating the detection of waste in water bodies using deep transfer learning, Case Stud. Chem. Environ. Eng, 2, (2020); Wu C., Sun Y., Wang T., Liu Y., Underwater trash detection algorithm based on improved YOLOv5s, J. Real-Time Image Process, 19, 5, pp. 911-920; Yu Y., A computer vision based detection system for trash bins identifi-cation during trash classification, J. Phys., Conf. ser, 1617, 1, (2020); Conley G., Zinn S.C., Hanson T., McDonald K., Beck N., Wen H., Using a deep learning model to quantify trash accumulation for cleaner urban stormwater, Comput., Environ. Urban Syst, 93, (2022); Ma W., Wang X., Yu J., A lightweight feature fusion single shot multibox detector for garbage detection, IEEE Access, 8, pp. 188577-188586, (2020); Alzyoud F., Maqableh W., Al Shrouf F., A semi smart adaptive approach for trash classification, Int. J. Comput. Commun. CONTROL, 16, 4, pp. 1-13; Zhou P., Zhu Z., Xu X., Liu X., He B., Zhang J., Towards the urban future: A novel trash segregation algorithm based on improved YOLOV4, Proc IEEE Int. Conf. Robot. Biomimetics (ROBIO), pp. 1526-1531, (2021); Hossain S., Debnath B., Anika A., Junaed-Al-Hossain M., Biswas S., Shahnaz C., Autonomous trash collector based on object detection using deep neural network, Proc IEEE Region 10 Conf. (TENCON, pp. 1406-1410, (2019); Lin W., YOLO-green: A real-Time classification and object detection model optimized for waste management, Proc IEEE Int. Conf. Big Data (Big Data), pp. 51-57, (2021); Yu Z., Liu J., Li X., LTDTS: A lightweight trash detecting and tracking system, Proc. Int. Conf. Adapt. Intell. Syst., in Lecture Notes in Computer Science: Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics, 13338, pp. 240-250, (2022); Yu C., Xu J., Zhao A., Xiao P., Tai J., Bi Z., Li G., The generation and effects for recyclable waste from households in a megapolis: A case study in Shanghai, Sustainability, 14, 13; Yang M., Thung G., Classification of Trash for Recyclability Status, 3, (2016); Chu Y., Huang C., Xie X., Tan B., Kamal S., Xiong X., Multilayer hybrid deep-learning method for waste classification and recycling, Comput. Intell. Neurosci, 2018, pp. 1-9, (2018); Zhou H., Yu X., Alhaskawi A., Dong Y., Wang Z., Jin Q., Hu X., Liu Z., Kota V.G., Abdulla M.H.A.H., Ezzi S.H.A., Qi B., Li J., Wang B., Fang J., Lu H., A deep learning approach for medical waste classification, Sci. Rep, 12, 1, pp. 1-9; Song F., Zhang Y., Zhang J., Optimization of CNN-based garbage classification model, Proc. 4th Int. Conf. Comput. Sci. Appl. Eng, pp. 1-5, (2020); Meng S., Chu W.-T., A study of garbage classification with convolutional neural networks, Proc. Indo Taiwan 2nd Int. Conf. Com-put., Anal. Netw. Indo-Taiwan ICAN, pp. 152-157, (2020); Bobulski J., Kubanek M., Deep learning for plastic waste classifi-cation system, Appl. Comput. Intell. Soft Comput, pp. 1-7, (2021); Azis F.A., Suhaimi H., Abas E., Waste classification using convolutional neural network, Proc. 2nd Int. Conf. Inf. Technol. Comput. Commun, pp. 9-13, (2020); Wu Y., Shen X., Liu Q., Xiao F., Li C., A garbage detection and classification method based on visual scene understanding in the home environment, Complexity, 2021, 2021, pp. 1-14; Chen Y., Han W., Jin J., Wang H., Xing Q., Zhang Y., Clean our city: An automatic urban garbage classification algorithm using computer vision and transfer learning technologies, J. Phys., Conf. ser, 1994, 1; Liu W., Ouyang H., Liu Q., Cai S., Wang C., Xie J., Hu W., Image recognition for garbage classification based on transfer learning and model fusion, Math. Problems Eng, 2022, 2022, pp. 1-12; Liu F., Xu H., Qi M., Liu D., Wang J., Kong J., Depth-wise separable convolution attention module for garbage image classification, Sustainability, 14, 5; Vo A.H., Son L.H., Vo M.T., Le T., A novel framework for trash classification using deep transfer learning, IEEE Access, 7, pp. 178631-178639, (2019); Tiyajamorn P., Lorprasertkul P., Assabumrungrat R., Poomarin W., Chancharoen R., Automatic trash classification using convolutional neural network machine learning, Proc IEEE Int. Conf. Cybern. Intell. Syst. (CIS) IEEE Conf. Robot., Autom. Mechatronics (RAM, pp. 71-76, (2019); Hong J., Fulton M., Sattar J., A generative approach towards improved robotic detection of marine litter, Proc IEEE Int. Conf. Robot. Autom. (ICRA, pp. 10525-10531, (2020); Sun A., Xiao H., ThanosNet: A novel trash classification method using metadata, Proc IEEE Int. Conf. Big Data (Big Data, pp. 1394-1401, (2020); Dong X., Research and design of marine trash classification robot based on color recognition, IOP Conf. Ser., Earth Environ. Sci, 514, 3, (2020); Liu H., Guo Z., Bao J., Xie L., Research on trash classification based on artificial intelligence and sensor, Proc. 2nd Int. Conf. Intell. Comput. Hum.-Comput. Interact. (ICHCI), pp. 274-279, (2021); Patil A., Tatke A., Vachhani N., Patil M., Gulhane P., Garbage classifying application using deep learning techniques, Proc. Int. Conf. Recent Trends Electron., Inf., Commun. Technol. (RTEICT), pp. 122-130, (2021); Proenca P.F., Simoes P., TACO: Trash annotations in context for litter detection, arXiv:2003.06975, (2020); Kraft M., Piechocki M., Ptak B., Walas K., Autonomous, onboard vision-based trash and litter detection in low altitude aerial images collected by an unmanned aerial vehicle, Remote Sens, 13, 5, pp. 1-17; Bobulski J., Piatkowski J., PETwaste classification method and plastic waste database-WaDaBa, Advances in Intelligent Systems and Computing, 681, pp. 57-64, (2018); Glassense-Vision Dataset; Wang T., Cai Y., Liang L., Ye D., A multi-level approach to waste object segmentation, Sensors, 20, 14, pp. 1-22, (2020); Lynch S., OpenLitterMap.com-Open data on plastic pollution with blockchain rewards (littercoin), Open Geospatial Data, Softw. Stan-dards, 3, 1, (2018); Waste-Pictures | Kaggle; Waste Classification Data | Kaggle; Waste Images from Sushi Restaurant | Kaggle; OpenLitterMap; Litter Dataset; Drinking Waste Classification | Kaggle; Garbage | Kaggle; DeepSeaWaste | Kaggle; Datacluster-Labs/Domestic-Trash-Dataset; Cigarette Butt Dataset-Immersive Limit; Kumsetty N.V., Nekkare A.B., Kamath S.S.K., Kumar M.A., TrashBox: Trash detection and classification using quantum transfer learning, Proc. 31st Conf. Open Innov. Assoc. (FRUCT), pp. 125-130, (2022); Letsdoitworld/Wade-AI: An AI Algorithm for Detecting Trash in Geolocated Images; Zhang Q., Yang Q., Zhang X., Bao Q., Su J., Liu X., Waste image classification based on transfer learning and convolutional neural network, Waste Manag, 135, pp. 150-157, (2021); Majchrowska S., Mikoajczyk A., Ferlin M., Klawikowska Z., Plantykow M.A., Kwasigroch A., Majek K., Deep learning-based waste detection in natural and urban environments, Waste Manag, 138, pp. 274-284, (2022); Ren S., He K., Girshick R., Sun J., Faster R-CNN: Towards real-Time object detection with region proposal networks, arXiv:1506.01497, (2015)","M.H. Mohd Noor; Universiti Sains Malaysia, School of Computer Sciences, Pulau Pinang, 11800, Malaysia; email: halimnoor@usm.my","","Institute of Electrical and Electronics Engineers Inc.","","","","","","21693536","","","","English","IEEE Access","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85144784175"
"Mohd Noor M.H.; Ahmad A.R.; Hussain Z.; Ahmad K.A.; Ainihayati A.R.","Mohd Noor, M.H. (36656106400); Ahmad, A.R. (55843287500); Hussain, Z. (24724464800); Ahmad, K.A. (35760857000); Ainihayati, A.R. (38360991000)","36656106400; 55843287500; 24724464800; 35760857000; 38360991000","Multilevel thresholding of gel electrophoresis images using firefly algorithm","2011","Proceedings - 2011 IEEE International Conference on Control System, Computing and Engineering, ICCSCE 2011","","","6190488","18","21","3","7","10.1109/ICCSCE.2011.6190488","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84862078017&doi=10.1109%2fICCSCE.2011.6190488&partnerID=40&md5=a0a38caac69d12c15145a582773db725","Faculty of Electrical Engineering, Universiti Teknologi MARA, Pulau Pinang, Malaysia; School of Biological Sciences, Universiti Sains Malaysia, Malaysia","Mohd Noor M.H., Faculty of Electrical Engineering, Universiti Teknologi MARA, Pulau Pinang, Malaysia; Ahmad A.R., Faculty of Electrical Engineering, Universiti Teknologi MARA, Pulau Pinang, Malaysia; Hussain Z., Faculty of Electrical Engineering, Universiti Teknologi MARA, Pulau Pinang, Malaysia; Ahmad K.A., Faculty of Electrical Engineering, Universiti Teknologi MARA, Pulau Pinang, Malaysia; Ainihayati A.R., School of Biological Sciences, Universiti Sains Malaysia, Malaysia","Gel electrophoresis (GE) is a process of DNA, RNA and protein molecules separation using electric field applied to a gel matrix. This paper describes the image processing techniques applied on GE image to segment the bands from their background. A few pre-processing steps are applied on the image prior to the segmentation technique for the purpose of removing noise in the image. Multilevel thresholding using Otsu method based on Firefly Algorithm is developed. The experimental results show that the Otsu-FA produced good separation of DNA bands and its background. © 2011 IEEE.","DNA bands image; Firefly Algorithm (FA); Gel electrophoresis image (GE); multilevel thresholding; Otsu method","Algorithms; Bioluminescence; Control systems; DNA; Electric fields; Electrophoresis; RNA; Separation; DNA bands; Firefly algorithms; Gel electrophoresis images; Multilevel thresholding; Otsu method; Image segmentation","","","","","","","Maramis C., Delopoulos A., Efficient quantitative information extraction from PCR-RFLP gel electrophoresis images, Proceedings - International Conference on Pattern Recognition, pp. 2560-2563, (2010); Akbari A., Albregtsen F., Jakobsen K.S., Automatic lane detection and separation in one dimensional gel images using continuous wavelet transform, Analytical Methods, 2, 9, pp. 1360-1371, (2010); Labyed Y., Kaabouch N., Schultz R.R., Singh B.B., Automatic segmentation and band detection of protein images based on the standard deviation profile and its derivative, 2007 IEEE International Conference on Electro/Information Technology, EIT 2007, pp. 577-582, (2007); Lin C.-Y., Ching Y.-T., Yang Y.-L., Automatic method to compare the lanes in gel electrophoresis images, IEEE Transactions on Information Technology in Biomedicine, 11, 2, pp. 179-189, (2007); Kaabouch N., Schultz R.R., A 2-D gel electrophoresis DNA image analysis algorithm with automatic thresholding, Proceedings of SPIE, (2007); Caridade C.M.R., Marcal A.R.S., Mendonca T., Pessoa A.M., Pereira S., Automatic information extraction from gel electrophoresis images using GEIAS, Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), 6112, pp. 185-194, (2010); Otsu N., Threshold selection method from gray-level histograms, IEEE Transactions on Systems, Man and Cybernetics, 9, 1, pp. 62-66, (1979); Yang X.-S., Firefly algorithms for multimodal optimization, 5th Symposium on Stochastic Algorithms, Foundations and Applications, SAGA 2009, October 26, 2009 - October 28, 2009, 5792, pp. 169-178, (2009); Lukasik S., Zak S., Firefly algorithm for continuous constrained optimization tasks, 1st International Conference on Computational Collective Intelligence, ICCCI 2009, October 5, 2009 - October 7, 2009, 5796, pp. 97-106, (2009)","M.H. Mohd Noor; Faculty of Electrical Engineering, Universiti Teknologi MARA, Pulau Pinang, Malaysia; email: halim5381@ppinang.uitm.edu.my","","","","2011 IEEE International Conference on Control System, Computing and Engineering, ICCSCE 2011","25 November 2011 through 27 November 2011","Penang","89794","","978-145771642-3","","","English","Proc. - IEEE Int. Conf. Control Syst., Comput. Eng., ICCSCE","Conference paper","Final","","Scopus","2-s2.0-84862078017"
"Nordin N.; Zainol Z.; Mohd Noor M.H.; Fong C.L.","Nordin, Noratikah (57222566751); Zainol, Zurinahni (12144032400); Mohd Noor, Mohd Halim (36656106400); Fong, Chan Lai (57930802000)","57222566751; 12144032400; 36656106400; 57930802000","Explainable Machine Learning Models for Suicidal Behavior Prediction","2022","ACM International Conference Proceeding Series","","","","118","123","5","0","10.1145/3545729.3545754","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140015081&doi=10.1145%2f3545729.3545754&partnerID=40&md5=82e72fd3f1c51a774a82a8a640215c86","School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, 11800, Malaysia; Department of Psychiatry, Universiti Kebangsaan, Malaysia Medical Centre, Jalan Yaacob Latif, Bandar Tun Razak, Kuala Lumpur, Cheras, 56000, Malaysia","Nordin N., School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, 11800, Malaysia; Zainol Z., School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, 11800, Malaysia; Mohd Noor M.H., School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, 11800, Malaysia; Fong C.L., Department of Psychiatry, Universiti Kebangsaan, Malaysia Medical Centre, Jalan Yaacob Latif, Bandar Tun Razak, Kuala Lumpur, Cheras, 56000, Malaysia","In the healthcare setting, suicidal behavior prediction plays an important role in clinical decision making due to the suicide rate increasing day by day contributes to a decrease in productivity and increase in national expenditure. Several machine learning models are being developed to generate accurate predictions in a suicide attempt. However, there is a lack of interpretability, explainability and transparency with these predictive models. Therefore, the aim of this study is to improve explanations of machine learning models for predicting suicidal behavior based on clinical data using the Shapley Additive exPlanations (SHAP) approach. The experiment shows that machine learning models with SHAP are able to interpret and understand the nature of an individual's predictions of suicidal behavior.  © 2022 ACM.","Data Mining; Explainable AI; Machine Learning; Prediction Model; Suicidal Behavior","Data mining; Decision making; Forecasting; Accurate prediction; Behavior prediction; Clinical decision making; Explainable AI; Interpretability; Machine learning models; Machine-learning; Prediction modelling; Shapley; Suicidal behavior; Machine learning","","","","","Ministry of Higher Education, Malaysia, MOHE, (FRGS/1/2020/ICT02/USM/02/5)","The authors would like to thank all parties that support and involve directly or indirectly into this research, especially Universiti Sains Malaysia, Pulau Pinang and Universiti Kebangsaan Malaysia Medical Centre, Kuala Lumpur. This research is supported by the Ministry of Higher Education Malaysia for Fundamental Research Grant Scheme (FRGS) with Project Code: FRGS/1/2020/ICT02/USM/02/5.","Suicide; O'Connor R.C., Nock M.K., The psychology of suicidal behaviour, Lancet Psychiatry., 1, 1, pp. 73-85, (2014); Jung J.S., Park S.J., Kim E.Y., Na K.-S., Kim Y.J., Kim K.G., Prediction models for high risk of suicide in Korean adolescents using machine learning techniques, PLOS ONE., 14, 6, (2019); Oh B., Yun J.-Y., Yeo E.C., Kim D.-H., Kim J., Cho B.-J., Prediction of suicidal ideation among korean adults using machine learning: A cross-sectional study, Psychiatry Investig., 17, 4, pp. 331-340, (2020); Burke T.A., Ammerman B.A., Jacobucci R., The use of machine learning in the study of suicidal and non-suicidal self-injurious thoughts and behaviors: A systematic review, J. Afect. Disord., 245, pp. 869-884, (2019); Franklin J.C., Ribeiro J.D., Et al., Risk factors for suicidal thoughts and behaviors: A meta-analysis of 50 years of research, Psychol. Bull., 143, 2, pp. 187-232, (2017); Abdullah T.A.A., Mohd Zahid M.S., Ali W., A review of interpretable ml in healthcare: taxonomy, applications, challenges, and future directions, Symmetry., 13, 12, (2021); Velupillai S., Hadlaczky G., Et al., Risk assessment tools and data-driven approaches for predicting and preventing suicidal behavior, Front. Psychiatry., 10, 36, pp. 1-8, (2019); Amini P., Ahmadinia H., Poorolajal J., Moqaddasi Amiri M., Evaluating the high-risk groups for suicide: A comparison of logistic regression, support vector machine, decision tree and artifcial neural network, Iran. J. Public Health., 45, 9, pp. 1179-1187, (2016); Edgcomb J.B., Shaddox T., Hellemann G., Brooks J.O., Predicting suicidal behavior and self-harm after general hospitalization of adults with serious mental illness, J. Psychiatr. Res., 136, pp. 515-521, (2021); Su C., Aseltine R., Doshi R., Chen K., Rogers S.C., Wang F., Machine learning for suicide risk prediction in children and adolescents with electronic health records, Transl. Psychiatry., 10, 1, pp. 1-10, (2020); Horvath A., Dras M., Lai C.C.W., Boag S., Predicting suicidal behavior without asking about suicidal ideation: machine learning and the role of borderline personality disorder criteria, Suicide Life. Threat. Behav., 51, 3, pp. 455-466, (2021); Belle V., Papantonis I., Principles and practice of explainable machine learning, Front. Big Data., 4, (2021); De Leo D., Goodfellow B., Et al., International study of defnitions of English-language terms for suicidal behaviours: A survey exploring preferred terminology, BMJ Open., 11, 2, (2021); Chan L.F., Maniam T., Shamsul A.S., Suicide attempts among depressed inpatients with depressive disorder in a Malaysian sample: Psychosocial and clinical risk factors, Crisis., 32, 5, pp. 283-287, (2011); Iorfno F., Ho N., Et al., Predicting self-harm within six months after initial presentation to youth mental health services: A machine learning study, PLOS ONE., 15, 12, (2020); Barros J., Morales S., Et al., Suicide detection in Chile: proposing a predictive model for suicide risk in a clinical sample of patients with mood disorders, Rev. Bras. Psiquiatr., 39, 1, pp. 1-11, (2016); Ribeiro M.T., Singh S., Guestrin C., Model-agnostic interpretability of machine learning, Proceedings of 2016 ICML Workshop on Human Interpretability in Machine Learning, New York, USA, pp. 91-95, (2016); Lundberg S.M., Lee S.-I., A unifed approach to interpreting model predictions, Proceedings of 31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA, pp. 1-10, (2017); Nordin N., Zainol Z., Halim M., Noor M., Lai Fong C., A comparative study of machine learning techniques for suicide attempts predictive model, Health Informatics J., 27, 1, (2021); Kuhn M., Johnson K., Applied Predictive Modeling, (2013)","N. Nordin; School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, 11800, Malaysia; email: noratikahnordin@student.usm.my; Z. Zainol; School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, 11800, Malaysia; email: zuri@usm.my; M.H. Mohd Noor; School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, 11800, Malaysia; email: halimnoor@usm.my","","Association for Computing Machinery","","6th International Conference on Medical and Health Informatics, ICMHI 2022","12 May 2022 through 15 May 2022","Virtual, Online","183360","","978-145039630-1","","","English","ACM Int. Conf. Proc. Ser.","Conference paper","Final","","Scopus","2-s2.0-85140015081"
"Nordin N.; Zainol Z.; Mohd Noor M.H.; Chan L.F.","Nordin, Noratikah (57222566751); Zainol, Zurinahni (12144032400); Mohd Noor, Mohd Halim (36656106400); Chan, Lai Fong (54884505400)","57222566751; 12144032400; 36656106400; 54884505400","Suicidal behaviour prediction models using machine learning techniques: A systematic review","2022","Artificial Intelligence in Medicine","132","","102395","","","","9","10.1016/j.artmed.2022.102395","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138803583&doi=10.1016%2fj.artmed.2022.102395&partnerID=40&md5=4deba43ee5d77fa7be164066c87a48c4","School of Computer Sciences, Universiti Sains Malaysia, USM, Pulau Pinang, 11800, Malaysia; Department of Psychiatry, Faculty of Medicine, National University of Malaysia (UKM), Wilayah Persekutuan Kuala Lumpur, Cheras, 56000, Malaysia","Nordin N., School of Computer Sciences, Universiti Sains Malaysia, USM, Pulau Pinang, 11800, Malaysia; Zainol Z., School of Computer Sciences, Universiti Sains Malaysia, USM, Pulau Pinang, 11800, Malaysia; Mohd Noor M.H., School of Computer Sciences, Universiti Sains Malaysia, USM, Pulau Pinang, 11800, Malaysia; Chan L.F., Department of Psychiatry, Faculty of Medicine, National University of Malaysia (UKM), Wilayah Persekutuan Kuala Lumpur, Cheras, 56000, Malaysia","Background: Early detection and prediction of suicidal behaviour are key factors in suicide control. In conjunction with recent advances in the field of artificial intelligence, there is increasing research into how machine learning can assist in the detection, prediction and treatment of suicidal behaviour. Therefore, this study aims to provide a comprehensive review of the literature exploring machine learning techniques in the study of suicidal behaviour prediction. Methods: A search of four databases was conducted: Web of Science, PubMed, Dimensions, and Scopus for research papers dated between January 2016 and September 2021. The search keywords are ‘data mining’, ‘machine learning’ in combination with ‘suicidal behaviour’, ‘suicide’, ‘suicide attempt’, ‘suicidal ideation’, ‘suicide plan’ and ‘self-harm’. The studies that used machine learning techniques were synthesized according to the countries of the articles, sample description, sample size, classification tasks, number of features used to develop the models, types of machine learning techniques, and evaluation of performance metrics. Results: Thirty-five empirical articles met the criteria to be included in the current review. We provide a general overview of machine learning techniques, examine the feature categories, describe methodological challenges, and suggest areas for improvement and research directions. Ensemble prediction models have been shown to be more accurate and useful than single prediction models. Conclusions: Machine learning has great potential for improving estimates of future suicidal behaviour and monitoring changes in risk over time. Further research can address important challenges and potential opportunities that may contribute to significant advances in suicide prediction. © 2022 Elsevier B.V.","Data mining; Machine learning; Prediction model; Suicidal behaviour","Artificial Intelligence; Data Mining; Humans; Machine Learning; Suicidal Ideation; Forecasting; Learning algorithms; Machine learning; neuroleptic agent; Behavior prediction; Key factors; Machine learning techniques; Machine-learning; Prediction modelling; Research papers; Search keyword; Suicidal behavior; Systematic Review; Web of Science; alcoholism; artificial neural network; automutilation; Bayes theorem; Bayesian learning; Bayesian network; bootstrapping; computer prediction; data mining; decision tree; deep neural network; educational status; employment status; externalizing disorder; family history; female; groups by age; human; internalizing disorder; k nearest neighbor; learning algorithm; least absolute shrinkage and selection operator; leave one out cross validation; logistic regression analysis; machine learning; male; physical disease; postnatal depression; predictive model; probability theory; random forest; relevance vector machine; Review; ridge regression; risk factor; schizophrenia; sex difference; suicidal behavior; suicidal ideation; suicide; suicide attempt; support vector machine; systematic review; artificial intelligence; machine learning; suicidal ideation; Data mining","","","","","Ministry of Higher Education, Malaysia, MOHE, (FRGS/1/2020/ICT02/USM/02/5); Universiti Sains Malaysia","Funding text 1: The authors would like to thank all parties that support and involve directly or indirectly into this research, especially Universiti Sains Malaysia, Pulau Pinang and Universiti Kebangsaan Malaysia Medical Centre, Kuala Lumpur. This research is supported by the Ministry of Higher Education, Malaysia for Fundamental Research Grant Scheme (FRGS) with Project Code: FRGS/1/2020/ICT02/USM/02/5 .; Funding text 2: The authors would like to thank all parties that support and involve directly or indirectly into this research, especially Universiti Sains Malaysia, Pulau Pinang and Universiti Kebangsaan Malaysia Medical Centre, Kuala Lumpur. This research is supported by the Ministry of Higher Education, Malaysia for Fundamental Research Grant Scheme (FRGS) with Project Code: FRGS/1/2020/ICT02/USM/02/5.","Suicide, (2021); Franklin J.C., Et al., Risk factors for suicidal thoughts and behaviors: a meta-analysis of 50 years of research, Psychol Bull, 143, 2, pp. 187-232, (2017); O'Connor R.C., Nock M.K., The psychology of suicidal behaviour, Lancet Psychiatry, 1, 1, pp. 73-85, (2014); Turecki G., Et al., Suicide and suicide risk, Nat Rev Dis Primers, 5, 1, (2019); Walsh C.G., Ribeiro J.D., Franklin J.C., Predicting risk of suicide attempts over time through machine learning, Clin Psychol Sci, 5, 3, pp. 457-469, (2017); Velupillai S., Et al., Risk assessment tools and data-driven approaches for predicting and preventing suicidal behavior, Front Psychiatry, 10, (2019); Ribeiro J.D., Et al., Self-injurious thoughts and behaviors as risk factors for future suicide ideation, attempts, and death: a meta-analysis of longitudinal studies, Psychol Med, 46, 2, pp. 225-236, (2016); Walsh C.G., Ribeiro J.D., Franklin J.C., Predicting suicide attempts in adolescents with longitudinal clinical data and machine learning, J Child Psychol Psychiatry, 59, 12, pp. 1261-1270, (2018); Dwyer D.B., Falkai P., Koutsouleris N., Machine learning approaches for clinical psychology and psychiatry, Annu Rev Clin Psychol, 14, 1, pp. 91-118, (2018); Bernert R.A., Hilberg A.M., Melia R., Kim J.P., Shah N.H., Abnousi F., Artificial intelligence and suicide prevention: a systematic review of machine learning investigations, Int J Environ Res Public Health, 17, 16, (2020); Fonseka T.M., Bhat V., Kennedy S.H., The utility of artificial intelligence in suicide risk prediction and the management of suicidal behaviors, Aust N Z J Psychiatry, 53, 10, pp. 954-964, (2019); Alpaydin E., Introduction to machine learning, (2010); Boudreaux E.D., Et al., Applying machine learning approaches to suicide prediction using healthcare data: overview and future directions, Front Psychiatry, 12, (2021); Burke T.A., Ammerman B.A., Jacobucci R., The use of machine learning in the study of suicidal and non-suicidal self-injurious thoughts and behaviors: a systematic review, J Affect Disord, 245, pp. 869-884, (2019); Alonso S.G., Et al., Data mining algorithms and techniques in mental health: a systematic review, J Med Syst, 42, 9, (2018); Shatte A.B.R., Hutchinson D.M., Teague S.J., Machine learning in mental health: a scoping review of methods and applications, Psychol Med, 49, 9, pp. 1426-1448, (2019); Thieme A., Belgrave D., Doherty G., Machine learning in mental health: a systematic review of the HCI literature to support the development of effective and implementable ML systems, ACM Trans Comput-Hum Interact, 27, 5, pp. 1-53, (2020); Kessler R.C., Bossarte R.M., Luedtke A., Zaslavsky A.M., Zubizarreta J.R., Suicide prediction models: a critical review of recent research with recommendations for the way forward, Mol Psychiatry, 25, 1, pp. 168-179, (2020); Moher D., Liberati A., Tetzlaff J., Altman D.G., Preferred reporting items for systematic reviews and meta-analyses: the PRISMA statement, PLoS Med, 6, 7, (2009); Hutton B., Catala-Lopez F., Moher D., The PRISMA statement extension for systematic reviews incorporating network meta-analysis: PRISMA-NMA, Med Clín Engl Ed, 147, 6, pp. 262-266, (2016); Leucht S., Kissling W., Davis J.M., How to read and understand and use systematic reviews and meta-analyses, Acta Psychiatr Scand, 119, 6, pp. 443-450, (2009); PRISMA-P Group, Preferred reporting items for systematic review and meta-analysis protocols (PRISMA-P) 2015 statement, Syst Rev, 4, 1, (2015); Bramer W.M., Rethlefsen M.L., Kleijnen J., Franco O.H., Optimal database combinations for literature searches in systematic reviews: a prospective exploratory study, Syst Rev, 6, 1, (2017); De Leo D., Et al., International study of definitions of english-language terms for suicidal behaviours: a survey exploring preferred terminology, BMJ Open, 11, 2, (2021); Amini P., Ahmadinia H., Poorolajal J., Amiri M.M., Evaluating the high risk groups for suicide: a comparison of logistic regression, support vector machine, decision tree and artificial neural network, Iran J Public Health, 45, 9, pp. 1179-1187, (2016); Passos I.C., Et al., Identifying a clinical signature of suicidality among patients with mood disorders: a pilot study using a machine learning approach, J Affect Disord, 193, pp. 109-116, (2016); Barros J., Et al., Suicide detection in Chile: proposing a predictive model for suicide risk in a clinical sample of patients with mood disorders, Rev Bras Psiquiatr, 39, 1, pp. 1-11, (2016); Barak-Corren Y., Et al., Predicting suicidal behavior from longitudinal electronic health records, Am J Psychiatry, 174, 2, pp. 154-162, (2017); Gradus J.L., King M.W., Galatzer-Levy I., Street A.E., Gender differences in machine learning models of trauma and suicidal ideation in veterans of the Iraq and Afghanistan wars: gender differences in trauma and suicidal ideation, J Trauma Stress, 30, 4, pp. 362-371, (2017); Hettige N.C., Et al., Classification of suicide attempters in schizophrenia using sociocultural and clinical features: a machine learning approach, Gen Hosp Psychiatry, 47, pp. 20-28, (2017); Kessler R.C., Et al., Developing a practical suicide risk prediction model for targeting high-risk patients in the veterans health administration, Int J Methods Psychiatr Res, 26, 3, (2017); Oh J., Yun K., Hwang J.-H., Chae J.-H., Classification of suicide attempts through a machine learning algorithm based on multiple systemic psychiatric scales, Front Psychiatry, 8, (2017); Choi S.B., Lee W., Yoon J.-H., Won J.-U., Kim D.W., Ten-year prediction of suicide death using cox regression and machine learning in a nationwide retrospective cohort study in South Korea, J Affect Disord, 231, pp. 8-14, (2018); Ryu S., Lee H., Lee D.-K., Park K., Use of a machine learning algorithm to predict individuals with suicide ideation in the general population, Psychiatry Investig, 15, 11, pp. 1030-1036, (2018); Simon G.E., Et al., Predicting suicide attempts and suicide deaths following outpatient visits using electronic health records, Am J Psychiatry, 175, 10, pp. 951-960, (2018); Jung J.S., Park S.J., Kim E.Y., Na K.-S., Kim Y.J., Kim K.G., Prediction models for high risk of suicide in korean adolescents using machine learning techniques, PLOS ONE, 14, 6, (2019); Ribeiro J.D., Huang X., Fox K.R., Walsh C.G., Linthicum K.P., Predicting imminent suicidal thoughts and nonfatal attempts: the role of complexity, Clin Psychol Sci, 7, 5, pp. 941-957, (2019); Su C., Aseltine R., Doshi R., Chen K., Rogers S.C., Wang F., Machine learning for suicide risk prediction in children and adolescents with electronic health records, Transl Psychiatry, 10, 1, (2020); Shen Y., Et al., Detecting risk of suicide attempts among chinese medical college students using a machine learning algorithm, J Affect Disord, 273, pp. 18-23, (2020); Oh B., Yun J.-Y., Yeo E.C., Kim D.-H., Kim J., Cho B.-J., Prediction of suicidal ideation among korean adults using machine learning: a cross-sectional study, Psychiatry Investig, 17, 4, pp. 331-340, (2020); Miche M., Et al., Prospective prediction of suicide attempts in community adolescents and young adults, using regression methods and machine learning, J Affect Disord, 265, pp. 570-578, (2020); van Mens K., Et al., Predicting future suicidal behaviour in young adults, with different machine learning techniques: a population-based longitudinal study, J Affect Disord, 271, pp. 169-177, (2020); Lin G.-M., Nagamine M., Yang S.-N., Tai Y.-M., Lin C., Sato H., Machine learning based suicide ideation prediction for military personnel, IEEE J Biomed Health Inform, 24, 7, pp. 1907-1916, (2020); Burke T.A., Jacobucci R., Ammerman B.A., Alloy L.B., Diamond G., Using machine learning to classify suicide attempt history among youth in medical care settings, J Affect Disord, 268, pp. 206-214, (2020); Chen Q., Et al., Predicting suicide attempt or suicide death following a visit to psychiatric specialty care: a machine learning study using swedish national registry data, PLoS Med, 17, 11, (2020); Horvath A., Dras M., Lai C.C.W., Boag S., Predicting suicidal behavior without asking about suicidal ideation: machine learning and the role of borderline personality disorder criteria, Suicide Life Threat Behav, 51, 3, pp. 455-466, (2021); Iorfino F., Et al., Predicting self-harm within six months after initial presentation to youth mental health services: a machine learning study, PLOS ONE, 15, 12, (2020); van Mens K., Et al., Applying machine learning on health record data from general practitioners to predict suicidality, Internet Interv, 21, (2020); Edgcomb J.B., Shaddox T., Hellemann G., Brooks J.O., Predicting suicidal behavior and self-harm after general hospitalization of adults with serious mental illness, J Psychiatr Res, 136, pp. 515-521, (2021); Nordin N., Zainol Z., Noor M.H.M., Fong C.L., A comparative study of machine learning techniques for suicide attempts predictive model, Health Informatics J, 27, 1, (2021); Kirlic N., A machine learning analysis of risk and protective factors of suicidal thoughts and behaviors in college students, J Am Coll Health, pp. 1-10, (2021); Macalli M., Et al., A machine learning approach for predicting suicidal thoughts and behaviours among college students, Sci Rep, 11, 1, (2021); McMullen L., Parghi N., Rogers M.L., Yao H., Bloch-Elkouby S., Galynker I., The role of suicide ideation in assessing near-term suicide risk: a machine learning approach, Psychiatry Res, 304, (2021); van Vuuren C.L., Et al., Comparing machine learning to a rule-based approach for predicting suicidal behavior among adolescents: results from a longitudinal population-based survey, J Affect Disord, 295, pp. 1415-1420, (2021); Cho S.-E., Geem Z.W., Na K.-S., Development of a suicide prediction model for the elderly using health screening data, Int J Environ Res Public Health, 18, 19, (2021); Navarro M.C., Et al., Machine learning assessment of early life factors predicting suicide attempt in adolescence or young adulthood, JAMA Netw Open, 4, 3, (2021); Kim S., Lee H.-K., Lee K., Detecting suicidal risk using MMPI-2 based on machine learning algorithm, Sci Rep, 11, 1, (2021); Faul A.C., A concise introduction to machine learning, (2019); Woldaregay A.Z., Et al., Data-driven modeling and prediction of blood glucose dynamics: machine learning applications in type 1 diabetes, Artif Intell Med, 98, pp. 109-134, (2019); Parimbelli E., Et al., A review of AI and data science support for cancer management, Artif Intell Med, 117, (2021); Zhou Z.-H., Ensemble methods: foundations and algorithms, (2012); Kantardzic M., DATA MINING: concepts, models, methods, and algorithms. Place of publication not identified, (2019); Zhang Z., Zhao Y., Canes A., Steinberg D., Lyashevska O., Predictive analytics with gradient boosting in clinical medicine, Ann Transl Med, 7, 7, (2019); Krueger R.F., Markon K.E., Understanding psychopathology: melding behavior genetics, personality, and quantitative psychology to develop an empirically based model, Curr Dir Psychol Sci, 15, 3, pp. 113-117, (2006); Amann J., Blasimme A., Vayena E., Frey D., Madai V.I., Explainability for artificial intelligence in healthcare: a multidisciplinary perspective, BMC Med Inform Decis Mak, 20, 1, (2020); Stiglic G., Kocbek P., Fijacko N., Zitnik M., Verbert K., Cilar L., Interpretability of machine learning-based prediction models in healthcare, WIREs Data Min Knowl Discovery, 10, 5, (2020); Belle V., Papantonis I., Principles and practice of explainable machine learning, Front Big Data, 4, (2021); Roy A., Nikolitch K., McGinn R., Jinah S., Klement W., Kaminsky Z.A., A machine learning approach predicts future risk to suicidal ideation from social media data, Npj Digit Med, 3, 1, (2020); Fernandes A.C., Dutta R., Velupillai S., Sanyal J., Stewart R., Chandran D., Identifying suicide ideation and suicidal attempts in a psychiatric clinical research database using natural language processing, Sci Rep, 8, 1, (2018); Cusick M., Et al., Using weak supervision and deep learning to classify clinical notes for identification of current suicidal ideation, J Psychiatr Res, 136, pp. 95-102, (2021)","N. Nordin; School of Computer Sciences, Universiti Sains Malaysia, USM, Pulau Pinang, 11800, Malaysia; email: noratikahnordin@student.usm.my","","Elsevier B.V.","","","","","","09333657","","AIMEE","36207078","English","Artif. Intell. Med.","Review","Final","","Scopus","2-s2.0-85138803583"
"Ige A.O.; Mohd Noor M.H.","Ige, Ayokunle Olalekan (57828337400); Mohd Noor, Mohd Halim (36656106400)","57828337400; 36656106400","A survey on unsupervised learning for wearable sensor-based activity recognition","2022","Applied Soft Computing","127","","109363","","","","21","10.1016/j.asoc.2022.109363","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135340081&doi=10.1016%2fj.asoc.2022.109363&partnerID=40&md5=7d40c79abb937753c86c6477424982b3","School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, USM, 11800, Malaysia","Ige A.O., School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, USM, 11800, Malaysia; Mohd Noor M.H., School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, USM, 11800, Malaysia","Human Activity Recognition (HAR) is an essential task in various applications such as pervasive healthcare, smart environment, and security and surveillance. The need to develop accurate HAR systems has motivated researchers to propose various recognition models, feature extraction methods, and datasets. A lot of comprehensive surveys have been done on vision-based HAR, while few surveys have been done on sensor-based HAR. The few existing surveys on sensor-based HAR have focused on reviewing various feature extraction methods, the adoption of deep learning in activity recognition, and existing wearable acceleration sensors, among other areas. In recent times, state-of-the-art HAR models have been developed using wearable sensors due to the numerous advantages it offers over other modalities. However, one limitation of wearable sensors is the difficulty of annotating datasets during or after collection, as it tends to be laborious, time-consuming, and expensive. For this reason, recent state-of-the-art activity recognition models are being proposed using fully unlabelled datasets, an approach which is described as unsupervised learning. However, no existing sensor-based HAR surveys have focused on reviewing this recent adoption. To this end, this survey contributes by reviewing the evolution of activity recognition models, collating various types of activities, compiling over thirty activity recognition datasets, and reviewing the existing state-of-the-art models to leveraging fully unlabelled datasets in activity recognition. Also, this survey is the first attempt at a comprehensive review on the adoption of unsupervised learning in wearable sensor-based activity recognition. This will give researchers in this area a solid background and knowledge of the existing state-of-the-art models and an insight into the grand research areas that can still be explored. © 2022 Elsevier B.V.","Clustering; Data augmentation; Human Activity Recognition; Unsupervised learning; Wearable sensor","Deep learning; Extraction; Feature extraction; Surveys; Unsupervised learning; Activity recognition; ART model; Clusterings; Data augmentation; Feature extraction methods; Human activity recognition; Pervasive healthcare; Recognition models; Smart environment; State of the art; Wearable sensors","","","","","","","Ferrari A., Micucci D., Mobilio M., Napoletano P., On the personalization of classification models for human activity recognition, IEEE Access, 8, pp. 32066-32079, (2020); Lara O.D., Labrador M.A., A survey on human activity recognition using wearable sensors, IEEE Commun. Surv. Tutor., 15, 3, pp. 1192-1209, (2013); Qi W., Et al., Depth vision guided human activity recognition in surgical procedure using wearable multisensor, 2020 5th International Conference on Advanced Robotics and Mechatronics, pp. 431-436, (2020); Ben-Arie J., Wang Z., Pandit P., Rajaram S., Human activity recognition using multidimensional indexing, IEEE Trans. Pattern Anal. Mach. Intell., 24, 8, pp. 1091-1104, (2002); Tan H.C., De Silva L.C., pp. 320-326, (2003); Ramasso E., Panagiotakis C., Rombaut M., Pellerin D., Tziritas G., Human shape-motion analysis in athletics videos for coarse to fine action/activity recognition using transferable BeliefModel, ELCVIA: Electronic Letters on Computer Vision and Image Analysis, pp. 32-50, (2008); Chen L., Hoey J., Nugent C.D., Cook D.J., Yu Z., Sensor-based activity recognition, IEEE Trans. Syst. Man Cybern. C, 42, 6, pp. 790-808, (2012); Zhang M., Sawchuk A.A., USc-HAD: A daily activity dataset for ubiquitous activity recognition using wearable sensors, UbiComp12 - Proc. 2012 ACM Conf. Ubiquitous Comput, pp. 1036-1043, (2012); Kwapisz J.R., Weiss G.M., Moore S.A., Activity recognition using cell phone accelerometers, SIGKDD Explor Newsl., 12, 2, pp. 74-82, (2011); Zhu Q., Chen Z., Soh Y.C., A novel semisupervised deep learning method for human activity recognition, IEEE Trans. Ind. Inf., 15, 7, pp. 3821-3830, (2019); Ward J.A., Lukowicz P., Troster G., Starner T.E., Activity recognition of assembly tasks using body-worn microphones and accelerometers, IEEE Trans. Pattern Anal. Mach. Intell., 28, 10, (2006); Van Kasteren T., Noulas A., Englebienne G., Krose B., Accurate activity recognition in a home setting, UbiComp 2008 - Proc. 10th Int. Conf. Ubiquitous Comput, pp. 1-9, (2008); Sunny J.T., George S.M., Kizhakkethottam J.J., Applications and challenges of human activity recognition using sensors in a smart environment, IJIRST –Int. J. Innov. Res. Sci. Technol., 2, 4, pp. 50-57, (2015); Palumbo F., Gallicchio C., Pucci R., Micheli A., Human activity recognition using multisensor data fusion based on reservoir computing, J. Ambient Intell. Smart Environ., 8, 2, pp. 87-107, (2016); Liu L., Peng Y., Liu M., Huang Z., Sensor-based human activity recognition system with a multilayered model using time series shapelets, Knowl.-Based Syst., 90, pp. 138-152, (2015); Chen C., Jafari R., Kehtarnavaz N., UTD-MHAD: A multimodal dataset for human action recognition utilizing a depth camera and a wearable inertial sensor, Proc. - Int. Conf. Image Process. ICIP, 2015-Decem, pp. 168-172, (2015); Choudhury T., Consolvo S., Harrison B., The mobile sensing platform: An embedded activity recognition system, IEEE Pervasive Comput., 7, 2, pp. 32-41, (2008); Bhattacharya S., Nurmi P., Hammerla N., Plotz T., Using unlabeled data in a sparse-coding framework for human activity recognition, Pervasive Mob. Comput., 15, pp. 242-262, (2014); Stikic M., Schiele B., Activity recognition from sparsely labeled data using multi-instance learning, Proc. Locat. Context Aware., 5561, pp. 156-173, (2009); Khalifa S., Hassan M., Seneviratne A., Pervasive self-powered human activity recognition without the accelerometer, IEEE International Conference on Pervasive Computing and Communications (PerCom), pp. 79-86, (2015); Chen L., Nugent C.D., Ontology-based activity ecognition in intelligent pervasive environments, Int. J. Web. Inf. Syst., 5, 4, pp. 410-430, (2009); Rasul M.G., Khan M.H., Lota L.N., Nurse care activity recognition based on convolution neural network for accelerometer data, UbiComp/ISWC 2020 Adjunct - Proceedings of the 2020 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2020 ACM International Symposium on Wearable Computers, pp. 425-430, (2020); Taghanaki S.R., Etemad A., Self-supervised wearable-based activity recognition by learning to forecast motion, (2020); Alemdar H., Ersoy C., Wireless sensor networks for healthcare: A survey, Comput. Netw., 54, 15, pp. 2688-2710, (2010); Babiker M., Khalifa O.O., Htike K.K., Hassan A., Zaharadeen M., Automated daily human activity recognition for video surveillance using neural network, IEEE 4th International Conference on Smart Instrumentation, Measurement and Application (ICSIMA), pp. 1-5, (2017); Lin W., Sun M.T., Poovandran R., Zhang Z., Human activity recognition for video surveillance, IEEE International Symposium on Circuits and Systems, pp. 2737-2740, (2008); De Maria E., L'Yvonnet T., Moisan S., Rigault J.P., Probabilistic activity recognition for serious games with applications in medicine, Communications in Computer and Information Science, Vol. 1165, pp. 106-124, (2020); Khare S., Sarkar S., Totaro M., Comparison of sensor-based datasets for human activity recognition in wearable IoT, IEEE World Forum Internet Things WF-IoT 2020 - Symp. Proc, pp. 1-6, (2020); Wang C., Williams A.C.D.C., Lane N.D., Bianchi-berthouze N., Leveraging activity recognition to enable protective behavior detection in continuous data, Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., 5, 2, pp. 1-24, (2021); Liu J., Convolutional neural network-based human movement recognition algorithm in sports analysis, Front. Psychol., 12, (2021); Manjarres J., Narvaez P., Gasser K., Percybrooks W., Pardo M., Physical workload tracking using human activity recognition with wearable devices, Sensors, 20, 1, (2020); Paragliola G., Coronato A., Gait anomaly detection of subjects with parkinson's disease using a deep time series-based approach, IEEE Access, 6, pp. 73280-73292, (2018); Noor M.H.M., Nazir A., Wahab M.N.A., Ling J.O.Y., Detection of freezing of gait using unsupervised convolutional denoising autoencoder, IEEE Access, 9, pp. 115700-115709, (2021); Ma C.Y., Chen M.H., Kira Z., AlRegib G., TS-LSTM and temporal-inception: Exploiting spatiotemporal dynamics for activity recognition, Signal Process., Image Commun., 71, pp. 76-87, (2019); Ye J., Stevenson G., Dobson S., A top-level ontology for smart environments, Pervasive Mob. Comput., 7, pp. 359-378, (2011); Colpas P.A., Vicario E., De-La-Hoz-Franco E., Pineres-Melo M., Oviedo-Carrascal A., Patara F., Unsupervised human activity recognition using the clustering approach: A review, Sens. Switz., 20, 9, (2020); Chen K., Zhang D., Yao L., Guo B., Yu Z., Liu Y., Deep learning for sensor-based human activity recognition, ACM Comput. Surv., 54, 4, pp. 1-40, (2021); Wang J., Chen Y., Hao S., Peng X., Hu L., Deep learning for sensor-based activity recognition: A survey, Pattern Recognit. Lett., 119, pp. 3-11, (2019); Mao H.H., A survey on self-supervised pre-training for sequential transfer learning in neural networks, pp. 1-25, (2020); Jing L., Tian Y., Self-supervised visual feature learning with deep neural networks: A survey, IEEE Trans. Pattern Anal. Mach. Intell., (2020); Patel A., Shah J., Sensor-based activity recognition in the context of ambient assisted living systems: A review, J. Ambient Intell. Smart Environ., 11, 4, pp. 301-322, (2019); Nweke H.F., Teh Y.W., Al-garadi M.A., Alo U.R., Deep learning algorithms for human activity recognition using mobile and wearable sensor networks: State of the art and research challenges, Expert Syst. Appl., 105, pp. 233-261, (2018); De-La-Hoz-Franco E., Ariza-Colpas P., Quero J.M., Espinilla M., Sensor-based datasets for human activity recognition - A systematic review of literature, IEEE Access, 6, 100, pp. 59192-59210, (2018); Prati A., Shan C., Wang K.I., Sensors, vision and networks : From video surveillance to activity recognition and health monitoring, J. Ambient Intell. Smart Environ., 11, pp. 5-22, (2019); Hussain Z., Sheng M., Zhang W.E., Different approaches for human activity recognition- A survey, pp. 1-28, (2019); Suresha M., Kuppa S., Raghukumar D.S., A study on deep learning spatiotemporal models and feature extraction techniques for video understanding, Int. J. Multimed. Inf. Retr., 9, 2, pp. 81-101, (2020); Minh Dang L., Min K., Wang H., Jalil Piran M., Hee Lee C., Moon H., Sensor-based and vision-based human activity recognition: A comprehensive survey, Pattern Recognit., 108, (2020); Kumar P., Chauhan S., Human activity recognition with deep learning : Overview, challenges & possibilities, CCF Transactions on Pervasive Computing and Interaction, pp. 1-21, (2021); Liu R., Ramli A.A., Zhang H., Henricson E., Liu X., An overview of human activity recognition using wearable sensors: Healthcare and artificial intelligence, pp. 1-14, (2021); Ferrari A., Micucci D., Mobilio M., Napoletano P., Trends in human activity recognition using smartphones, J. Reliab. Intell. Environ., 7, 3, pp. 189-213, (2021); Schlmilch O.X., Witzschel B., Cantor M., Kahl E., Mehmke R., Runge C., Detection of posture and motion by accelerometry: a validation study in ambulatory monitoring, Comput. Hum. Behav., 15, 5, pp. 571-583, (1999); Goddard N.H., Shah M., Jain R., Human activity recognition, motion based recognit, Comput. Imaging Vis. - Springer, Vol. 9, (1997); Bao L., Intille S.S., Activity recognition from user-annotated acceleration data, Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), Vol. 3001, pp. 1-17, (2004); Pham C., Olivier P., Slice & Dice: Recognizing food preparation activities using embedded accelerometers, Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), Vol. 5859, pp. 34-43, (2009); Sigurdsson G.A., Varol G., Wang X., Farhadi A., Laptev I., Gupta A., Hollywood in homes: Crowdsourcing data collection for activity understanding, Lecture Notes in Computer Science, Vol. 9905, LNCS, pp. 510-526, (2016); Boraston Z., Blakemore S.J., The application of eye-tracking technology in the study of autism, J. Physiol., 581, 3, pp. 893-898, (2007); Ball L., Et al., Eye-gaze access to AAC technology for people with amyotrophic lateral scelerosis, J. Med. Speech - Lang. Pathol., 18, 3, pp. 11-23, (2010); Ke S.R., Thuc H.L.U., Lee Y.J., Hwang J.N., Yoo J.H., Choi K.H., (2013); Zhang H.B., Et al., A comprehensive survey of vision-based human action recognition methods, Sensors (Switzerland), 19, 5, pp. 1-20, (2019); Poppe R., A survey on vision-based human action recognition, Image Vis. Comput., 28, 6, pp. 976-990, (2010); Philipose M., Large-scale human activity recognition using ultra-dense sensing, Bridge Natl. Acad. Eng., 35, 4, (2005); Wilson D.H., Atkeson C., Simultaneous tracking and activity recognition (STAR) using many anonymous, binary sensors, International Conference on Pervasive Computing, pp. 62-79, (2005); Mozer M.C., The neural network house: An environment that adapts to its inhabitants, pp. 110-114; Roy N., Misra A., Cook D., Ambient and smartphone sensor assisted ADL recognition in multi-inhabitant smart environments, J. Ambient. Intell. Humaniz. Comput., 7, 1, pp. 1-19, (2016); Byrom B., McCarthy M., Schueler P., Muehlhausen W., Brain monitoring devices in neuroscience clinical research: The potential of remote monitoring using sensors, wearables, and mobile devices, Clin. Pharmacol. Ther., 104, 1, pp. 59-71, (2018); Tricoli A., Nasiri N., De S., Wearable and miniaturized sensor technologies for personalized and preventive medicine, Adv. Funct. Mater., 27, 15, (2017); Wang C., Xia K., Wang H., Liang X., Yin Z., Zhang Y., Advanced carbon for flexible and wearable electronics, Adv. Mater., 31, 9, (2019); Banos O., Et al., MHealthDroid: A novel framework for agile development of mobile health applications, Ambient Assisted Living and Daily Activities, pp. 91-98, (2014); Scheurer S., Tedesco S., Brown K.N., O'Flynn B., Using domain knowledge for interpretable and competitive multi-class human activity recognition, Sensors, pp. 1-25, (2020); Qin Z., Zhang Y., Meng S., Choo K.R., Imaging and fusing time series for wearable sensor-based human activity recognition, Inf. Fusion, 53, pp. 80-87, (2020); Reyes-Ortiz J.L., Oneto L., Ghio A., Sama A., Anguita D., Parra X., Human activity recognition on smartphones with awareness of basic activities and postural transitions, Lect. Notes Comput. Sci. Subser. Lect. Notes Artif. Intell. Lect. Notes Bioinforma, Vol. 8681, LNCS, pp. 177-184, (2014); Taghanaki S.R., Etemad A., Self-supervised wearable-based activity recognition by learning to forecast motion, (2020); Ronao C.A., Cho S.B., Human activity recognition with smartphone sensors using deep learning neural networks, Expert Syst. Appl., 59, pp. 235-244, (2016); Yu H., Cang S., Wang Y., selection A.R.R.R., A review of sensor selection sensor devices and sensor deployment for wearable sensor-based human activity recognition systems, Ski. 2016-2016 10th Int. Conf. Softw. Knowl. Inf. Manag. Appl, pp. 250-257, (2017); Ignatov A., Real-time human activity recognition from accelerometer data using Convolutional Neural Networks, Appl. Soft Comput., 62, pp. 915-922, (2018); Banos O., Damas M., Pomares H., Rojas I., Toth M.A., Amft O., A benchmark dataset to evaluate sensor displacement in activity recognition, UbiComp, pp. 1026-1035, (2012); Catal C., Tufekci S., Pirmit E., Kocabag G., On the use of ensemble of classifiers for accelerometer-based activity recognition, Appl. Soft Comput., 37, pp. 1018-1022, (2015); Delporte B., Perroton L., Grandpierre T., Trichet J., Accelerometer and magnetometer based gyroscope emulation on smart sensor for a virtual reality application, Sens. Transducers. J, 14, pp. 32-47, (2012); Gjoreski H., Gams M., Activity/posture recognition using wearable sensors placed on different body locations, Proceedings of the IASTED International Conference on Artificial Intelligence and Soft Computing, ASC 2011, pp. 340-347, (2011); Parkka J., Ermes M., Korpipaa P., Mantyjarvi J., Peltola J., Korhonen I., Activity classification using realistic data from wearable sensors, Inf. Technol. Biomed. IEEE Trans., 10, 1, pp. 119-128, (2006); Chernbumroong S., Cang S., Atkins A., Yu H., Elderly activities recognition and classification for applications in assisted living, Expert. Syst. Appl., 40, 5, (2013); Cook A.J., Gargiulo G.D., Lehmann T., Hamilton T.J., Open platform, eight-channel, portable bio- potential and activity data logger for wearable medical device development, Electr. Lett., 51, 21, pp. 1641-1643, (2015); Nakamura M., Nakamura J., Shuzo M., Warisawa S., Yamada I., Collaborative processing of wearable and ambient sensor system for health monitoring application, 2010 3rd International Symposium on Applied Sciences in Biomedical and Communication Technologies (ISABEL 2010), pp. 1-5, (2010); Georgi M., Amma C., Schultz T., Recognizing hand and finger gestures with IMU based motion and EMG based muscle activity sensing, BIOSIGNALS 2015-8th Int. Conf. Bio-Inspired Syst. Signal Process. Proc. Part 8th Int. Jt. Conf. Biomed. Eng. Syst. Technol. BIOSTEC 2015, pp. 99-108, (2015); Jia Y., Diatetic and exercise therapy against diabetes mellitus, Second International Conference on Intelligent Networks and Intelligent Systems, pp. 693-696, (2009); Yin J., Yang Q., Pan J., Sensor based abnormal human activity detection, IEEE Trans. Knowl. Data Eng., 20, 8, pp. 1082-1090, (2008); Gayathri K.S., Elias S., Ravindran B., Hierarchical activity recognition for dementia care using Markov Logic, Netw. Ubiquit Comput., 19, pp. 271-285, (2015); Tripathi A.M., Baruah R.D., Subbiah S., Oil well drilling activities recognition using a hierarchical classifier, J. Pet. Sci. Eng., (2020); Oguntala G.A., Et al., SmartWall: Novel RFID-enabled ambient human activity recognition using machine learning for unobtrusive health monitoring, IEEE Access, 7, pp. 68022-68033, (2019); Schrader L., Et al., Advanced sensing and human activity recognition in early intervention and rehabilitation of elderly people, J. Popul. Ageing., 13, 2, pp. 139-165, (2020); Siirtola P., Koskimaki H., Roning J., Personalizing human activity recognition models using incremental learning, ESANN 2018 - Proceedings, European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning, pp. 627-632, (2018); Ishimaru S., Kensuke H., Kai K., Koichi K., Andreas D., pp. 704-711, (2017); Rene G., Et al., pp. 1-6, (2017); Gaikwad N.B., Tiwari V., Keskar A., Shivaprakash N.C., Efficient FPGA implementation of multilayer perceptron for real-time human activity classification, IEEE Access, 7, pp. 26696-26706, (2019); Yang Y., Hou C., Lang Y., Guan D., Huang D., Xu J., Open-set human activity recognition based on micro-Doppler signatures, Pattern Recognit., 85, pp. 60-69, (2019); Wang A., Zhao S., Zheng C., Yang J., Chen G., Chang C.Y., Activities of daily living recognition with binary environment sensors using deep learning: A comparative study, IEEE Sens. J., 21, 4, pp. 5423-5433, (2021); Bharti P., De D., Chellappan S., Das S.K., HuMAn: complex activity recognition with multi-modal multi-positional body sensing, IEEE Trans. Mob. Comput., 18, 4, pp. 857-870, (2019); Lago P., Matsuki M., Inoue S., Achieving single-sensor complex activity recognition from multi-sensor training data, pp. 1-17, (2020); He Z., Activity recognition from accelerometer signals based on wavelet-AR model, 2010 IEEE International Conference on Progress in Informatics and Computing, pp. 499-502, (2010); Xiao W., Lu Y., Daily human physical activity recognition based on kernel discriminant analysis and extreme learning machine, Mathematical Problems in Engineering, (2015); Wang A., Chen G., Yang J., Zhao S., Chang C.-Y., A comparative study on human activity recognition using inertial sensors in a smartphone, IEEE Sens. J., 16, 11, pp. 4566-4578, (2016); Wijekoon A., Wirantunga N., Personalised meta-learning for human activity recognition with few-data, 40th British Computer Society's Specialist Group on Artificial Intelligence (SGAI) Artificial Intelligence International Conference, Vol. 2020, No. December, (2020); Ho C., Robinson A., Miller D., Davis M., Overview of sensors and needs for environmental monitoring, Sensors, 5, 1, pp. 4-37, (2008); Ravi N., Nikhil D., Mysore P., Littman M.L., Activity recognition from accelerometer data, pp. 1541-1546, (2005); Allen F.R., Ambikairajah E., Lovell N.H., Celler B.G., Classification of a known sequence of motions and postures from accelerometry data using adapted Gaussian mixture models, Physiol. Meas., 27, 10, (2006); Ermes M., Parkka J., Mantyjarvi J., Korhonen I., Detection of daily activities and sports with wearable sensors in controlled and uncontrolled conditions, IEEE Trans. Inf. Technol. Biomed., 12, 1, pp. 20-26, (2008); Mannini A., Sabatini A.M., Machine learning methods for classifying human physical activity from on-body accelerometers, Sensors, 10, 2, pp. 1154-1175, (2010); Aziz O., Park E.J., Mori G., Robinovitch S.N., Distinguishing the causes of falls in humans using an array of wearable tri-axial accelerometers, Gait Posture, 39, 1, pp. 506-512, (2014); Jia R., Liu B., Human daily activity recognition by fusing accelerometer and multi-lead ECG data, 2013 IEEE International Conference on Signal Processing, Communica- Tion and Computing (ICSPCC 2013), pp. 1-4, (2013); Noor M.H.M., Salcic Z., Wang K.I.K., Ontology-based sensor fusion activity recognition, J. Ambient Intell. Humaniz. Comput., 11, 8, pp. 3073-3087, (2018); Shaikh M.F., Salcic Z., Wang K.I.-K., Hu A.P., Bipedal gait model for precise gait recognition and optimal triggering in foot drop stimulator: A proof of concept, Med. Biol. Eng. Comput., (2018); Anguita D., Ghio A., Oneto L., Parra X., Reyes-Ortiz J., A public domain dataset for human activity recognition using smartphones, 21th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning, ESANN, pp. 24-26, (2013); Chavarriaga R., Et al., The opportunity challenge: A benchmark database for on-body sensor-based activity recognition, Pattern Recognit. Lett., 34, 15, pp. 2033-2042, (2013); Micucci D., Mobilio M., Napoletano P., UniMiB SHAR: A Dataset for human activity recognition using acceleration data from smartphones, Appl. Sci. Switz., 7, 10, (2017); Reiss A., Stricker D., Introducing a new benchmarked dataset for activity monitoring, Proc. - Int. Symp. Wearable Comput. ISWC, pp. 108-109, (2012); Xue Y., Jin L., A naturalistic 3D acceleration-based activity dataset amp; benchmark evaluations, 2010 IEEE International Conference on Systems, Man and Cybernetics, pp. 4081-4085, (2010); Kawaguchi N., Et al., HASC Challenge: Gathering large scale human activity corpus for the real-world activity understandings, ACM Int. Conf. Proceeding Ser, pp. 1-5, (2011); Kaluza B., Kozina S., Lustrek M., pp. 44-47, (2012); Tapia E., Intille S., Lopez L., Larson K., The design of a portable kit of wireless sensors for naturalistic data collection, International Conference on Pervasive Computing, pp. 117-134, (2006); Hodgins F., Macey J., (2009); Casale P., Pujol O., Radeva P., Personalization and user verification in wearable systems using biometric walking patterns, Pers. Ubiquitous Comput., pp. 563-580, (2012); Bachlin M., Et al., Wearable assistant for Parkinson's disease patients with the freezing of gait symptom, IEEE Trans. Inf. Technol. Biomed. Publ. IEEE Eng. Med. Biol. Soc., 14, 2, pp. 436-444, (2010); Bulling A., Blanke U., Schiele B., A tutorial on human activity recognition using body-worn inertial sensors, Comput. Surv., 46, 3, pp. 1-33, (2014); Inoue S., Ueda N., Nohara Y., Nakashima N., Recognizing and understanding nursing activities for a whole day with a big dataset, J. Inf. Process., pp. 853-866, (2016); Hasc2010 corpus, (2021); Cook D., Learning setting-generalized activity models for smart spaces, IEEE Intell. Syst., 27, pp. 32-38, (2012); Singla G., Cook D.J., Schmitter-Edgecombe M., Recognizing independent and joint activities among multiple residents in smart environments, J. Ambient Intell. Hum. Comput., 1, pp. 57-63, (2010); Hasc_Bdd, (2021); Predicting parkinson's disease progression with smartphone data, (2021); Stiefmeier T., Roggen D., Troster G., Fusion of string-matched templates for continuous activity recognition, Wearable Computers, 2007 11th IEEE International Symposium on IEEE, pp. 41-44, (2007); Wirz M., Roggen D., Troster G., Decentralized detection of group formations from wearable acceleration sensors, (2009); Forster K., Roggen D., Troster G., Unsupervised classifier self- calibration through repeated context occurences: Is there robustness against sensor displacement to gain?, Wearable Computers ISWC'09. International Symposium on, pp. 77-84, (2009); Zhang S., McCullagh P., Nugent C., Zheng H., Activity monitoring using a smart phone's accelerometer with hierarchical classification, pp. 158-163, (2010); Espinilla M., Martinez L., Medina J., Nugent C., The experience of developing the UJAmI smart lab, IEEE Access, 6, pp. 34631-34642, (2018); Sussex-huawei locomotion dataset, (2020); Bruno B., Mastrogiovanni F., Sgorbissa A., Wearable inertial sensors: Applications, challenges, and public test benches, IEEE Robot. Autom. Mag., 22, 3, pp. 116-124, (2015); Sikder N., Al Nahid A., KU-HAR: AN open dataset for heterogeneous human activity recognition, Pattern Recognit. Lett., 146, pp. 46-54, (2021); Triboan D., Chen L., Chen F., Wang Z., A semantics-based approach to sensor data segmentation in real-time activity recognition, Future Gener. Comput., 93, pp. 224-236, (2019); Quigley B., Donnelly M., Moore G., Galway L., A comparative analysis of windowing approaches in dense sensing environments, Multidiscip. Digit. Publ. Inst. Proc., 2, (2018); Banos O., Galvez J., Damas M., Pomares H., Rojas I., Window size impact in human activity recognition, Sensors, 14, 4, pp. 6474-6499, (2014); Noor M.H.M., Salcic Z., Wang K.I.-K., Adaptive sliding window segmentation for physical activity recognition using a single tri-axial accelerometer, Pervasive Mob. Comput., pp. 1-19, (2016); Chen K., Zhang D., Yao L., Guo B., Yu Z., Liu Y., Deep learning for sensor-based human activity recognition: overview, challenges and opportunities, (2020); Ferrari A., Micucci D., Marco M., Napoletano P., Handcrafted features vs residual networks for human activities recognition using accelerometer, (2019); Olszewski R.T., Faloutsos C., Dot D.B., Generalized feature extraction for structural pattern recognition in time-series data, (2001); Castro H., Et al., All-inkjet-printed low-pass filters with adjustable cutoff frequency consisting of resistors, inductors and transistors for sensor applications, Org. Electron., 38, pp. 205-212, (2016); Ma C., Wang A., Chen G., Xu C., Hand joints-based gesture recognition for noisy dataset using nested interval unscented Kalman filter with LSTM network, Vis. Comput., 34, 6-8, pp. 1053-1063, (2018); Gu F., Khoshelham K., Valaee S., Shang J., Zhang R., Locomotion activity recognition using stacked denoising autoencoders, IEEE Internet Things J., 5, 3, pp. 2085-2093, (2018); Hong H., Tan Y., Zhang W., A wavelet tensor fuzzy clustering scheme for multi-sensor human activity recognition, Eng. Appl. Artif. Intell., 70, pp. 109-122, (2018); Rafiee J., Rafiee M.A., Yavari F., Schoen M.P., Feature extraction of forearm EMG signals for prosthetics, Expert Syst. Appl., 38, 4, pp. 4058-4067, (2011); Xiao F., Et al., A deep learning method for complex human activity recognition using virtual wearable sensors, Lect. Notes Comput. Sci. Subser. Lect. Notes Artif. Intell. Lect. Notes Bioinforma, LNCS, 12567, pp. 261-270, (2021); Shirahama K., Grzegorzek M., On the generality of codebook approach for sensor-based human activity recognition, Electronics, 6, 2, (2017); Abdi H., Williams L.J., Principal component analysis, Wiley Interdiscip. Rev. Comput. Stat., 2, 4, (2010); Zhang L., Wu X., Luo D., Human activity recognition with HMM-DNN model, 2015 IEEE 14th International Conference on Cognitive Informatics & Cognitive Computing (ICCI*CC), pp. 192-197, (2015); Fridriksdottir E., Bonomi A.G., Accelerometer-based human activity recognition for patient monitoring using a deep neural network, Sensors, 20, 22, (2020); Ronao C.A., Cho S.B., Human activity recognition with smartphone sensors using deep learning neural networks, Expert Syst. Appl., 59, pp. 235-244, (2016); Gao W., Zhang L., Teng Q., He J., Wu H., DanHAR: DUal attention network for multimodal human activity recognition using wearable sensors, Appl. Soft Comput., 111, (2021); Khaled H., Abu-Elnasr O., Elmougy S., Tolba A.S., Intelligent system for human activity recognition in IoT environment, Complex Intell. Syst., pp. 1-12, (2021); Saha S.S., Sandha S.S., Srivastava M., Deep Convolutional Bidirectional LSTM for Complex Activity Recognition with Missing Data, 199, No. November, (2021); Haque M.N., Mahbub M., Tarek M.H., Lota L.N., Ali A.A., Nurse care activity recognition: A GRU-based approach with attention mechanism, Adjunct Proceedings of the 2019 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2019 ACM International Symposium on Wearable Computers, pp. 719-723, (2019); Pan J., Hu Z., Yin S., Li M., GRU With dual attentions for sensor-based human activity recognition, Electronics, 11, 11, (2022); Arifoglu D., Bouchachia A., Activity recognition and abnormal behaviour detection with recurrent neural networks, Procedia Comput. Sci., 110, pp. 86-93, (2017); Nair H., Tan C., Zeng M., Mengshoel O.J., Shen J.P., AttriNet: LEarning mid-level features for human activity recognition with deep belief networks, Adjunct Proceedings of the 2019 Acm International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2019 ACM International Symposium on Wearable Computers, pp. 510-517, (2019); Hassan M.M., Huda S., Uddin M.Z., Almogren A., Alrubaian M., Human activity recognition from body sensor data using deep learning, J. Med. Syst., 42, 6, (2018); Noor M.H.M., Feature learning using convolutional denoising autoencoder for activity recognition, Neural Comput. Appl., 33, 17, pp. 10909-10922, (2021); Noor M.H.M., Ahmadon M.A., Osman M.K., Activity recognition using deep denoising autoencoder, Proc. - 9th IEEE Int. Conf. Control Syst. Comput. Eng. ICCSCE 2019, pp. 188-192, (2019); Gao X., Luo H., Wang Q., Zhao F., Ye L., Zhang Y., A human activity recognition algorithm based on stacking denoising autoencoder and lightGBM, Sensors, 19, 4, (2019); Kwon Y., Kang K., Bae C., Unsupervised learning for human activity recognition using smartphone sensors, Expert Syst. Appl., 41, 14, pp. 6067-6074, (2014); Nafea O., Abdul W., Muhammad G., Multi-sensor human activity recognition using CNN and GRU, Int. J. Multimedia Inf. Retr., 11, 2, pp. 135-147, (2022); Mohd Noor M.H., Tan S.Y., Ab Wahab M.N., Deep temporal conv-LSTM for activity recognition, Neural Process. Lett., pp. 1-23, (2022); Lin Z., Li M., Zheng Z., Cheng Y., Yuan C., Self-attention convlstm for spatiotemporal prediction, 34, pp. 11531-11538; Qian H., Pan S.J., Da B., Miao C., A novel distribution-embedded neural network for sensor-based activity recognition, IJCAI Int. Jt. Conf. Artif. Intell., Vol. 2019-Augus, pp. 5614-5620, (2019); Sani S., Wiratunga N., Massie S., Cooper K., kNN sampling for personalised human recognition, Proceedings of the 25th International Case-Based Reasoning Conference, pp. 330-344, (2017); Uddin M.T., Uddiny M.A., A guided random forest based feature selection approach for activity recognition, 2nd International Conference on Electrical Engineering and Information and Communication Technology, ICEEiCT 2015, pp. 1-6, (2015); Manosha Chathuramali K.G., Rodrigo R., Faster human activity recognition with SVM, Int. Conf. Adv. ICT Emerg. Reg. ICTer 2012 - Conf. Proc, pp. 197-203, (2012); Fan L., Wang Z., Wang H., Human activity recognition model based on decision tree, 2013 International Conference on Advanced Cloud and Big Data, pp. 64-68, (2013); LeCun Y., Bengio Y., Hinton G., Deep learning, Nature, 521, pp. 436-444, (2015); Zeng M., Yu T., Wang X., Nguyen L.T., Mengshoel O.J., Lane I., Semi-supervised convolutional neural networks for human activity recognition, Proc. - 2017 IEEE Int. Conf. Big Data Big Data 2017, 2018-Janua, pp. 522-529, (2017); Plotz T., Guan Y., Deep learning for human activity recognition in mobile computing, Computer, 51, 5, pp. 50-59, (2018); Nusrat T., Mahbubul I., Joong-Hwan B., Deep learning-based action recognition using 3D skeleton joints information, Inventions, 5, 49, pp. 1-15, (2020); Ascioglu G., Senol Y., Design of a wearable wireless multi-sensor monitoring system and application for activity recognition using deep learning, IEEE Access, 8, pp. 169183-169195, (2020); Demrozi F., Pravadelli G., Bihorac A., Rashidi P., Human activity recognition using inertial, physiological and environmental sensors: A comprehensive survey, IEEE Access, 8, 550, pp. 210816-210836, (2020); Perez-Pozuelo I., Spathis D., Clifton E.A.D., Mascolo C., Wearables, smartphones, and artificial intelligence for digital phenotyping and health, Digit. Health, 54, pp. 33-54, (2021); Hammerla N.Y., Halloran S., Plotz T., Deep, convolutional, and recurrent models for human activity recognition using wearables, IJCAI Int. Jt. Conf. Artif. Intell., Vol. 2016-Janua, pp. 1533-1540, (2016); Wu D., Wang Z., Chen Y., Zhao H., Mixed-kernel based weighted extreme learning machine for inertial sensor based human activity recognition with imbalanced dataset, Neurocomputing, 190, pp. 35-49, (2016); Ranasinghe S., Al MacHot F., Mayr H.C., A review on applications of activity recognition systems with regard to performance and evaluation, Int. J. Distrib. Sens. Netw., 12, (2016); Li X., Zhao P., Wu M., Chen Z., Zhang L., Deep learning for human activity recognition, Neurocomputing, 444, pp. 214-216, (2021); Ramamurthy S.R., Roy N., Recent trends in machine learning for human activity recognition—A survey, Wiley Interdiscip. Rev. Data Min. Knowl. Discov., 8, 4, (2018); Gupta P., Caleb-Solly P., A Framework for Semi-Supervised Adaptive Learning for Activity Recognition in Healthcare Applications, Vol. 893, (2018); Wen J., Zhong M., Indulska J., Creating general model for activity recognition with minimum labelled data, ISWC 2015 - Proc. 2015 ACM Int. Symp. Wearable Comput, pp. 87-90, (2015)","M.H. Mohd Noor; School of Computer Sciences, Universiti Sains Malaysia, USM, Pulau Pinang, 11800, Malaysia; email: halimnoor@usm.my","","Elsevier Ltd","","","","","","15684946","","","","English","Appl. Soft Comput.","Review","Final","","Scopus","2-s2.0-85135340081"
"Mohd Noor M.H.; Ahmadon M.A.; Osman M.K.","Mohd Noor, Mohd Halim (36656106400); Ahmadon, Mohd Anuaruddin (57211430198); Osman, Muhammad Khusairi (7201930443)","36656106400; 57211430198; 7201930443","Activity Recognition using Deep Denoising Autoencoder","2019","Proceedings - 9th IEEE International Conference on Control System, Computing and Engineering, ICCSCE 2019","","","9068571","188","192","4","4","10.1109/ICCSCE47578.2019.9068571","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084324687&doi=10.1109%2fICCSCE47578.2019.9068571&partnerID=40&md5=0b4405c1a53c1e1bc65bc97af088ece0","School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, Malaysia; Technology for Innovation, Yamaguchi University, Graduate School of Sciences, Japan; Fakulti Kejuruteraan Elektrik Universiti Teknologi MARA, Pulau Pinang, Malaysia","Mohd Noor M.H., School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, Malaysia; Ahmadon M.A., Technology for Innovation, Yamaguchi University, Graduate School of Sciences, Japan; Osman M.K., Fakulti Kejuruteraan Elektrik Universiti Teknologi MARA, Pulau Pinang, Malaysia","Existing feature extraction method for activity recognition is time consuming and laborious and prone to error. This paper proposes an unsupervised deep learning method for feature learning in activity recognition using tri-axial accelerometer. The proposed method extracts the relevant features automatically, eliminating the needs of feature extraction and selection stages. We evaluate and compared the proposed method with the conventional method in terms of recognition accuracy on a public dataset with wide range of activities. Results have shown that the proposed method achieved a better performance, improving the recognition accuracy by 0.03. © 2019 IEEE.","accelerometer; Activity recognition; autoencoder; deep learning","Control systems; Deep learning; Extraction; Feature extraction; Activity recognition; Conventional methods; Feature extraction and selection; Feature extraction methods; Feature learning; Recognition accuracy; Relevant features; Triaxial accelerometer; Learning systems","","","","","Universiti Sains Malaysia, (304/PKOMP/6315206)","ACKNOWLEDGMENT This work was supported in part by the Universiti Sains Malaysia under Short Term Research Grant 304/PKOMP/6315206.","Eakin E.G., Brown W.J., Marshall A.L., Mummery K., Larsen E., Physical activity promotion in primary care, Am. J. Prev. Med, 27, 4, pp. 297-303, (2004); Grandes G., Et al., Effectiveness of physical activity advice and prescription by physicians in routine primary care: A cluster randomized trial, Arch. Intern. Med, 169, 7, pp. 694-701, (2009); Gonzalez S., Sedano J., Villar J.R., Corchado E., Herrero A., Baruque B., Features and models for human activity recognition, Neurocomputing, 167, pp. 52-60, (2015); Rosati S., Balestra G., Knaflitz M., Comparison of different sets of features for human activity recognition by wearable sensors, Sensors, 18, 12, (2018); Vanrell S.R., Milone D.H., Rufiner H.L., Assessment of homomorphic analysis for human activity recognition from acceleration signals, IEEE J. Biomed. Health Inform, 22, 4, pp. 1001-1010, (2018); Wang Z., Wu D., Chen J., Ghoneim A., Hossain M.A., A triaxial accelerometer-based human activity recognition via eemd-based features and game-theory-based feature selection, IEEE Sens. J, 16, 9, pp. 3198-3207, (2016); Ignatov A., Real-time human activity recognition from accelerometer data using convolutional neural networks, Appl. Soft Comput, 62, pp. 915-922, (2018); Ronao C.A., Cho S.-B., Human activity recognition with smartphone sensors using deep learning neural networks, Expert Syst. Appl, 59, pp. 235-244, (2016); Noor M.H.M., Salcic Z., Wang K.I.-K., Adaptive sliding window segmentation for physical activity recognition using a single tri-axial accelerometer, Pervasive Mob. Comput, 38, pp. 41-59, (2017); Reyes-Ortiz J.-L., Oneto L., Sama A., Parra X., Anguita D., Transition-aware human activity recognition using smartphones, Neurocomputing, 171, pp. 754-767, (2016); Gao L., Bourke A.K., Nelson J., Evaluation of accelerometer based multi-sensor versus single-sensor activity recognition systems, Med. Eng. Phys, 36, 6, pp. 779-785, (2014)","","","Institute of Electrical and Electronics Engineers Inc.","","9th IEEE International Conference on Control System, Computing and Engineering, ICCSCE 2019","29 November 2019 through 1 December 2019","Penang","159323","","978-172813500-7","","","English","Proc. - IEEE Int. Conf. Control Syst., Comput. Eng., ICCSCE","Conference paper","Final","","Scopus","2-s2.0-85084324687"
"Ahmad A.R.; Hussain Z.; Ahmad F.; Noor M.H.M.; Yahaya S.Z.","Ahmad, Abdul Rahim (55843287500); Hussain, Zakaria (24724464800); Ahmad, Fadzil (36350716900); Noor, Mohd Halim Mohd (36656106400); Yahaya, Saiful Zaimy (38362540900)","55843287500; 24724464800; 36350716900; 36656106400; 38362540900","Gel electrophoresis image segmentation with kapur method based on particle swarm optimization","2013","Proceedings - 5th International Conference on Computational Intelligence, Communication Systems, and Networks, CICSyN 2013","","","6571397","393","396","3","3","10.1109/CICSYN.2013.60","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84883397165&doi=10.1109%2fCICSYN.2013.60&partnerID=40&md5=617c15bfdee2eedae1967a1f63b912a4","Faculty of Electrical Engineering, Universiti Teknologi MARA, Pulau Pinang, Malaysia","Ahmad A.R., Faculty of Electrical Engineering, Universiti Teknologi MARA, Pulau Pinang, Malaysia; Hussain Z., Faculty of Electrical Engineering, Universiti Teknologi MARA, Pulau Pinang, Malaysia; Ahmad F., Faculty of Electrical Engineering, Universiti Teknologi MARA, Pulau Pinang, Malaysia; Noor M.H.M., Faculty of Electrical Engineering, Universiti Teknologi MARA, Pulau Pinang, Malaysia; Yahaya S.Z., Faculty of Electrical Engineering, Universiti Teknologi MARA, Pulau Pinang, Malaysia","One of the important tool in genomic analysis is Gel Eletrophoresis. It is a tool that is routinely used in genetics, microbiology, forensics, molecular biology and biochemistry. GE is also used in separating DNA, RNA and protein molecules by using electric field applied to a gel matrix. This paper describes the application of Particle Swarm Optimization (PSO) that is a population-based optimization technique based on the sociological interaction associated with bird flocking using the Kapur thresholding method to segment the DNA bands from the background. PSO is employed to achieve the optimum threshold levels selection. In addition, PSO greatly reduces the computational time. Median filter is used prior image segmentation to remove noise and ambiguous pixels. The experimental results show that the application the optimization technique on Kapur method successfully produces good separation of DNA bands from the background. © 2013 IEEE.","Gel electrophoresis (GE); Kapur method; Multilevel Thresholding; Particle Swarm Optimization (PSO)","Artificial intelligence; Communication systems; DNA; Electric fields; Electrophoresis; Image segmentation; Molecular biology; Tools; Computational time; Gel electrophoresis; Gel electrophoresis images; Kapur method; Multilevel thresholding; Optimization techniques; Population-based optimization; Thresholding methods; Particle swarm optimization (PSO)","","","","","","","Maramis C., Delopoulos A., Efficient quantitative information extraction from pcr-rflp gel electrophoresis images, Pattern Recognition (ICPR), 2010 20th International Conference on, pp. 2560-2563, (2010); Akbari A., Albregtsen F., Automatic segmentation of dna bands in one dimensional gel images produced by hybridizing techniques, Engineering in Medicine and Biology Society 2004. IEMBS '04. 26th Annual International Conference of the IEEE, 2, pp. 2852-2855, (2004); Labyed Y., Kaabouch N., Schultz R.R., Singh B.B., Automatic segmentation and band detection of protein images based on the standard deviation profile and its derivative, Electro/Information Technology, 2007 IEEE International Conference on, pp. 577-582, (2007); Lin C., Ching Y., Yang Y., Automatic method to compare the lanes in gel electrophoresis images, Information Technology in Biomedicine, IEEE Transactions on, 11, 2, pp. 179-189, (2007); Kaabouch N., Schultz R.R., A 2-d gel electrophoresis dna image analysis algorithm with automatic thresholding, Visual Communications and Image Processing 2007, 6508, pp. 1-12, (2007); Caridade R.C.M., Marcal S.A.R., Mendonca T., Pessoa A.M., Pereira S.S., Lecture notes in computer science (including subseries lecture notes in artificial intelligence and lecture notes in bioinformatics), Image Analysis and Recognition-7th International Conference, ICIAR 2010, Proceedings, 6112, pp. 185-194, (2010); Kapur J.N., Sahoo P.K., Wong A.K.C., A new method for gray-level picture thresholding using the entropy of the histogram, Comput. Vis. Graph. Image Process., 29, 3, pp. 273-285, (1985); Van Den Bergh, An analysis of particle swarm optimizers, University of Pretoria, (2001); Kaabouch N., Schultz R.R., A 2-d gel electrophoresis dna image analysis algorithm with automatic thresholding, Proceedings of SPIE, (2007)","","","","","5th International Conference on Computational Intelligence, Communication Systems, and Networks, CICSyN 2013","5 June 2013 through 7 June 2013","Madrid","99042","","978-076955042-8","","","English","Proc. - Int. Conf. Comput. Intell., Commun. Syst., Networks, CICSyN","Conference paper","Final","","Scopus","2-s2.0-84883397165"
"Yusof N.A.M.; Osman M.K.; Hussain Z.; Noor M.H.M.; Ibrahim A.; Tahir N.M.; Abidin N.Z.","Yusof, N.A.M. (57207308210); Osman, M.K. (7201930443); Hussain, Z. (24724464800); Noor, M.H.M. (36656106400); Ibrahim, A. (57198461652); Tahir, N.M. (56168849900); Abidin, N.Z. (55602740300)","57207308210; 7201930443; 24724464800; 36656106400; 57198461652; 56168849900; 55602740300","Automated Asphalt Pavement Crack Detection and Classification using Deep Convolution Neural Network","2019","Proceedings - 9th IEEE International Conference on Control System, Computing and Engineering, ICCSCE 2019","","","9068551","215","220","5","17","10.1109/ICCSCE47578.2019.9068551","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084320243&doi=10.1109%2fICCSCE47578.2019.9068551&partnerID=40&md5=9b1c67368f5dccd49a013d8d90f7135a","Politeknik Tuanku Sultanah Bahiyah, Department of Electrical Engineering, Kedah, Malaysia; Universiti Teknologi MARA, Faculty of Electrical Engineering, Pulau Pinang, Malaysia; School of Computer Science, Universiti Sains Malaysia, Pulau Pinang, Malaysia; Faculty of Civil Engineering, Universiti Teknologi MARA, Pulau Pinang, Malaysia; Keysight Technologies Malaysia Sdn Bhd, Pulau Pinang, Malaysia","Yusof N.A.M., Politeknik Tuanku Sultanah Bahiyah, Department of Electrical Engineering, Kedah, Malaysia; Osman M.K., Universiti Teknologi MARA, Faculty of Electrical Engineering, Pulau Pinang, Malaysia; Hussain Z., Universiti Teknologi MARA, Faculty of Electrical Engineering, Pulau Pinang, Malaysia; Noor M.H.M., School of Computer Science, Universiti Sains Malaysia, Pulau Pinang, Malaysia; Ibrahim A., Faculty of Civil Engineering, Universiti Teknologi MARA, Pulau Pinang, Malaysia; Tahir N.M., Faculty of Civil Engineering, Universiti Teknologi MARA, Pulau Pinang, Malaysia; Abidin N.Z., Keysight Technologies Malaysia Sdn Bhd, Pulau Pinang, Malaysia","Asphalt pavement defects on road surface contribute one of the most important factors for traffic accident. Research on asphalt pavement using image processing techniques have been carried but there are still have challenges to the presence of shadows, oil stains and water spot. Therefore, considering the abovementioned issues, this study proposed a fully automated pavement crack detection and classification using deep convolution neural network (DCNN). First, the image of pavement cracks with dimension of 1024x768 pixels, will segmented into patches (32x32 pixels) to prepare training dataset. Next, the trained DCNN with different numbers of layers and different size of filters are employed in network. Upon the evaluation of proposed method, with respect to accuracy and processing time, the result found that the size of filters and convolution layers has an influence on the network performance. The experimental results achieved a high performance with overall accuracies above 94.25%. © 2019 IEEE.","Asphalt pavement; crack detection and classification; deep convolution neural network","Asphalt pavements; Control systems; Convolution; Crack detection; Deep neural networks; Pixels; Convolution neural network; Fully automated; Image processing technique; Overall accuracies; Pavement crack detection; Pavement cracks; Processing time; Training dataset; Asphalt mixtures","","","","","Kementerian Pendidikan Malaysia, KPM","ACKNOWLEDGEMENT The authors would like to thank to all parties that support and involve directly or indirectly into this research especially UiTM, Pulau Pinang. This research is supported by the Fundamental Research Grant Scheme (FRGS), Grant No: FRGS/1/2019/TK04/UITM/02/30, and also, appreciation to the Ministry of Education (MOE) for giving great privilege in providing scholarship as inspiring encouragement for the success of this research.","Sun Y., Automated pavement distressdetection using advanced image processingtechniques, Theses Diss, pp. 29-47, (2009); Pan Y., Zhang X., Cervone G., Yang L., Detection of asphalt pavement potholes andcracks based on the unmanned aerialvehicle multispectral imagery, IEEE J. Sel.Top. Appl. Earth Obs. Remote Sens., pp. 1-12, (2018); Zhang L., Yang F., Daniel Zhang Y., Zhu Y.J., Road crack detection using deepconvolutional neural network, 2016IEEE International Conference on ImageProcessing (ICIP, pp. 3708-3712, (2016); Sun L., Qian Z., Multi-scale wavelettransform filtering of non-uniform pavementsurface image background for automatedpavement distress identification, Meas. J.Int. Meas. Confed, 86, pp. 26-40, (2016); Mathavan S., Kamal K., Rahman M., Areview of three-dimensional imagingtechnologies for pavement distressdetection and measurements, IEEE Trans.Intell. Transp. Syst, 16, 5, pp. 2353-2362, (2015); Oliveira H., Correia P.L., Automaticroad crack segmentation using entropy andimage dynamic thresholding, Eur. SignalProcess. Conf., No. Eusipco, pp. 622-626, (2009); Li B., Wang K.C.P., Zhang A., Yang E., Wang G., Automatic classification ofpavement crack using deep convolutionalneural network, Int. J. Pavement Eng., pp. 1-7, (2018); Salman M., Mathavan S., Kamal K., Rahman M., Pavement crack detection usingthe Gabor filter, 16th International IEEEConference on Intelligent TransportationSystems (ITSC 2013, pp. 2039-2044, (2013); Coenen T.B.J., Golroo A., A review onautomated pavement distress detectionmethods, Cogent Eng, 4, 1, pp. 1-23, (2017); Choudhary G.K., Dey S., Crack detection in concrete surfaces using imageprocessing, fuzzy logic, neural networks, IEEE Fifth Int. Conf. Adv.Comput. Intell., pp. 404-411, (2012); Fan Z., Wu Y., Lu J., Li W., AutomaticPavement Crack Detection Based OnStructured Prediction with the ConvolutionalNeural Network, pp. 1-9, (2018); Karakose M., Akarsu B., Parlak K., Sarimaden A., Akin E., A Fast AndAdaptive Road Defect Detection ApproachUsing Computer Vision with Real TimeImplementation, 4, pp. 290-295, (2016); Yu X., Yang J., Lin Z., Wang J., Wang T., Huang T., Subcategory-aware objectdetection, IEEE Signal Process. Lett., 22, 9, pp. 1472-1476, (2015); Takarli F., Aghagolzadeh A., Seyedarabi H., Combination of high-levelfeatures with low-level features for detectionof pedestrian, Signal, Image Video Process, 10, 1, pp. 93-101, (2016); Huang W., Zhang N., A novel roadcrack detection and identification methodusing digital image processing techniques, Comput. Converg. Technol. (ICCCT), 7th Int.Conf., pp. 397-400, (2012); Zou Q., Cao Y., Li Q., Mao Q., Wang S., CrackTree: Automatic crack detection frompavement images, Pattern Recognit. Lett, 33, 3, pp. 227-238, (2012); Gopalakrishnan K., Khaitan S.K., Choudhary A., Agrawal A., Deep convolutional neural networks with transferlearning for computer vision-based data-driven pavement distress detection, Constr.Build. Mater, 157, pp. 322-330, (2017); Chang T.K., Chang R.J., Liu K.J., Detection of pavement distresses using 3dlaser scanning technology, Comput. Civ.Eng, 2005, pp. 1-11, (2005); Roth H.R., Et al., Improving Computer-aided Detection Using Convolutional NeuralNetworks and, pp. 1-12; Gopalakrishnan K., Khaitan S.K., Choudhary A., Agrawal A., Deep Convolutional Neural Networks with transferlearning for computer vision-based data-driven pavement distress detection, Constr.Build. Mater, 157, pp. 322-330, (2017); Krizhevsky A., Sutskever I., Hinton G.E., Image net classification with deepconvolutional neural networks, Adv.Neural Inf. Process. Syst., pp. 1-9, (2012); Cha Y.-J., Choi W., Buyukozturk O., Deep learning-based crack damagedetection using convolutional neural networks, Comput. Civ. Infrastruct. Eng, 32, 5, pp. 361-378, (2017); Maeda H., Sekimoto Y., Seto T., Kashiyama T., Omata H., Road damagedetection and classification using deep neural networks with smartphone images, Comput. Civ. Infrastruct. Eng, 33, 12, pp. 1127-1141, (2018); Zhang A., Et al., Automated pixel-levelpavement crack detection on 3d asphaltsurfaces using a deep-learning network, Comput. Civ. Infrastruct. Eng, 32, 10, pp. 805-819, (2017); Zhang A., Et al., Deep learning-based fullyautomated pavement crack detection on 3dasphalt surfaces with an improvedcracknet, J. Comput. Civ. Eng, 32, 5, (2018); Wang K.C.P., Zhang A., Li J.Q., Fei Y., Chen C., Li B., Deep Learning for AsphaltPavement Cracking Recognition UsingConvolutional Neural Network, pp. 166-177, (2017); Krizhevsky A., Sutskever I., Geoffrey H., Image net classification with deepconvolutional neural networks, Adv.Neural Inf. Process. Syst, 25, pp. 1-9, (2012); Tong Z., Gao J., Han Z., Wang Z., Recognition of asphalt pavement cracklength using deep convolutional neuralnetworks, Road Materials and PavementDesign, pp. 1-16, (2017); Wang X., Hu Z., Grid-based pavementcrack analysis using deep learning, 2017 4th International Conference OnTransportation Information and Safety, ICTIS 2017-Proceedings, pp. 917-924, (2017); Hochreiter S., The vanishing gradientproblem during learning recurrent neuralnets and problem solutions, Int. J.Uncertainty, Fuzziness Knowledge-BasedSyst, 6, 2, pp. 107-116, (1998); He K., Zhang X., Ren S., Sun J., Spatialpyramid pooling in deep convolutionalnetworks for visual recognition, IEEETrans. Pattern Anal. Mach. Intell, 37, 9, pp. 1904-1916, (2015); Wang J., Lin J., Wang Z., Efficientconvolution architectures for convolutionalneural network, 2016 8th InternationalConference on Wireless Communicationsand Signal Processing, WCSP, (2016); Pauly L., Peel H., Luo S., Hogg D., Fuentes R., Deeper Networks for PavementCrack Detection, Proc. 34th ISARC. 34thInt. Symp. Autom. Robot. Constr., No. Isarc, pp. 479-485, (2017)","","","Institute of Electrical and Electronics Engineers Inc.","","9th IEEE International Conference on Control System, Computing and Engineering, ICCSCE 2019","29 November 2019 through 1 December 2019","Penang","159323","","978-172813500-7","","","English","Proc. - IEEE Int. Conf. Control Syst., Comput. Eng., ICCSCE","Conference paper","Final","","Scopus","2-s2.0-85084320243"
"Nordin N.; Zainol Z.; Mohd Noor M.H.; Fong C.L.; Buji R.I.","Nordin, Noratikah (57222566751); Zainol, Zurinahni (12144032400); Mohd Noor, Mohd Halim (36656106400); Fong, Chan Lai (57930802000); Buji, Ryna Imma (57201436472)","57222566751; 12144032400; 36656106400; 57930802000; 57201436472","An Ontology-based Approach for Depression Diagnosis","2023","AIP Conference Proceedings","2579","1","020002","","","","0","10.1063/5.0136298","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177581320&doi=10.1063%2f5.0136298&partnerID=40&md5=0a0517fa5965f3b571e4fe72f2f14478","School of Computer Sciences, Universiti Sains Malaysia, Penang, Minden, 11800, Malaysia; Department of Psychiatry, Universiti Kebangsaan Malaysia Medical Centre, Bandar Tun Razak,Cheras, Kuala Lumpur, 56000, Malaysia; Hospital Mesra Bukit Padang, Sabah, Kota Kinabalu, 88815, Malaysia","Nordin N., School of Computer Sciences, Universiti Sains Malaysia, Penang, Minden, 11800, Malaysia; Zainol Z., School of Computer Sciences, Universiti Sains Malaysia, Penang, Minden, 11800, Malaysia; Mohd Noor M.H., School of Computer Sciences, Universiti Sains Malaysia, Penang, Minden, 11800, Malaysia; Fong C.L., Department of Psychiatry, Universiti Kebangsaan Malaysia Medical Centre, Bandar Tun Razak,Cheras, Kuala Lumpur, 56000, Malaysia; Buji R.I., Hospital Mesra Bukit Padang, Sabah, Kota Kinabalu, 88815, Malaysia","A high-risk population for suicide attempts was found from a depressed patient. However, most people with depression are not aware, untreated, and misdiagnosed. The presence of semantic inconsistencies in the knowledge-based system and limited symptoms in representing the depression domain knowledge due to varying from one person to one person lead to a major challenge in diagnosing depression. This paper proposes an ontology-based approach for depression diagnosis by collecting and studying depression knowledge of subjects for further diagnosis. All concepts and relationships detailed are applied using Web Ontology Language (OWL). The findings show that the proposed model can identify an individual with depression with 80% accuracy, 70% specificity, and 90% sensitivity. The proposed model can be used as a reference diagnosis model and the classification of an individual with depression will be improved by adding the information on risk factors that affect depression for further analysis. © 2023 American Institute of Physics Inc.. All rights reserved.","","","","","","","Universiti Sains Malaysia, USM","The authors would like to thank all parties that support and involve directly or indirectly into this research, especially Universiti Sains Malaysia, Pulau Pinang and Universiti Kebangsaan Malaysia Medical Centre, Kuala Lumpur. This research is supported by the Universiti Sains Malaysia under Bridging Grant Scheme, Grant No: 304.PKOMP.6316284.","James S.L., Et al., Global, regional, and national incidence, prevalence, and years lived with disability for 354 diseases and injuries for 195 countries and territories, 1990–2017: a systematic analysis for the Global Burden of Disease Study 2017, The Lancet, 392, pp. 1789-1858, (2018); Fazel Zarandi M.H., Soltanzadeh S., Mohammadi A., Castillo O., Designing a general type-2 fuzzy expert system for diagnosis of depression, Appl. Soft Comput., 80, pp. 329-341, (2019); Yang Z., Chen C., Li H., Yao L., Zhao X., Unsupervised classifications of depression levels based on machine learning algorithms perform well as compared to traditional norm-based classifications, Front. Psychiatry, 11, (2020); Chattopadhyay S., A neuro-fuzzy approach for the diagnosis of depression, Appl. Comput. Inform., 13, pp. 10-18, (2017); Movaghari H., Maghsoudi R., Mohammadi A., Designing a fuzzy expert decision support system based on decreased rules to specify depression, Fundamental Research in Electrical Engineering, 480, pp. 197-213, (2019); Thieme A., Belgrave D., Doherty G., Machine learning in mental health: A systematic review of the hci literature to support the development of effective and implementable ML systems, ACM Trans. Comput.-Hum. Interact., 27, pp. 1-53, (2020); Ashish K., Chattopadhyay S., Gao X.-Z., Hui N.B., Neural network-based diagnostic tool for identifying the factors responsible for depression, Int. J. Comput. Intell. Appl., 18, (2019); Thakur A., Alam Md.S., Rashidul Hasan Abir Md., Kushal M.A.A., Rahman R.M., A fuzzy approach for the diagnosis of depression, Modern Approaches for Intelligent Information and Database Systems, 769, pp. 199-211, (2018); Tavana M., Hajipour V., A practical review and taxonomy of fuzzy expert systems: methods and applications, Grubational J, 27, pp. 81-136, (2019); Fung K.W., Bodenreider O., Knowledge representation and ontologies, Clinical Research Informatics, pp. 313-339, (2019); Larsen R.R., Hastings J., From affective science to psychiatric disorder: ontology as a semantic bridge, Front. Psychiatry, 9, (2018); Silva C., Marreiros G., Silva N., Development of an ontology for supporting diagnosis in psychiatry, Distributed Computing and Artificial Intelligence, 11th International Conference, 290, pp. 343-350, (2014); Ekong V.E., Onibere E.A., A soft computing model for depression prediction, Egypt. Comput. Sci. J., 39, pp. 1-21, (2015); Noy N.F., McGuinness D.L., Ontology development 101: A guide to creating your first ontology, Stanf. Knowl. Syst. Lab. Tech. Rep. KSL-01-05 Stanf. Med. Inform. Tech. Rep. SMI-2001-0880, (2001); Chan L.F., Maniam T., Shamsul A.S., Suicide attempts among depressed inpatients with depressive disorder in a malaysian sample: psychosocial and clinical risk factors, Crisis, 32, pp. 283-287, (2011); McDaniel M., Storey V.C., Evaluating domain ontologies: Clarification, classification, and challenges, ACM Comput. Surv., 52, pp. 1-44, (2019); Buji R.I., Et al., Suicidal ideation in systemic lupus erythematosus: NR2A gene polymorphism, clinical and psychosocial factors, Lupus, 27, pp. 744-752, (2018)","Z. Zainol; School of Computer Sciences, Universiti Sains Malaysia, Minden, Penang, 11800, Malaysia; email: zuri@usm.my","Ngadiran R.; Cheng E.M.; Isa M.M.; Rani K.N.A.; Ali N.; Mustafa W.A.W.; Yasin M.N.M.","American Institute of Physics Inc.","","2nd International Symposium on Engineering and Technology, ISETech 2021","5 October 2021","Virtual, Online","193320","0094243X","","","","English","AIP Conf. Proc.","Conference paper","Final","","Scopus","2-s2.0-85177581320"
"Chan M.H.; Noor M.H.M.","Chan, Mang Hong (57219053473); Noor, Mohd Halim Mohd (36656106400)","57219053473; 36656106400","A unified generative model using generative adversarial network for activity recognition","2021","Journal of Ambient Intelligence and Humanized Computing","12","7","","8119","8128","9","7","10.1007/s12652-020-02548-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091149132&doi=10.1007%2fs12652-020-02548-0&partnerID=40&md5=ee93fa49bfcd7d06525513dec3c4ade9","School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, Malaysia","Chan M.H., School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, Malaysia; Noor M.H.M., School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, Malaysia","The recent advancement of deep learning methods has seen a significant increase in recognition accuracy in many important applications such as human activity recognition. However, deep learning methods require a vast amount of sensor data to automatically extract the most salient features for activity classification. Therefore, in this paper, a unified generative model is proposed to generate verisimilar data of different activities for activity recognition. The proposed generative model not only able to generate data that have a similar pattern, but also data with diverse characteristics. This allows for data augmentation in activity classification to improve the overall recognition accuracy. Three similarity measures are proposed to assess the quality of the synthetic data in addition to two visual evaluation methods. The proposed generative model was evaluated on a public dataset. The training data was prepared by systematically varying the combination of original and synthetic data. Results have shown that classification using the hybrid training data achieved a comparable recognition accuracy with the classification using the original training data. The performance of the classifiers maintained at the recognition accuracy of 85%. © 2020, Springer-Verlag GmbH Germany, part of Springer Nature.","Activity recognition; Data augmentation; Data generation; Generative adversarial network","Classification (of information); Deep learning; Learning systems; Pattern recognition; Quality control; Activity classifications; Activity recognition; Data augmentation; Data generation; Generative model; Human activity recognition; Learning methods; Recognition accuracy; Synthetic data; Training data; Generative adversarial networks","","","","","Universiti Sains Malaysia, (304/PKOMP/6315206)","This work has been was supported in part by the Universiti Sains Malaysia under Short Term Grant 304/PKOMP/6315206. ","Tensorflow: Large-scale machine learning on heterogeneous distributed systems, Software Available From, (2016); Alzantot M., Chakraborty S., Srivastava M., SenseGen: A deep learning architecture for synthetic sensor data generation, IEEE Int Conf Pervasive Comput Commun Workshops PerCom Workshops, (2017); Banos O., Garcia R., Holgado-Terriza J.A., Damas M., Pomares H., Rojas I., Saez A., Villalonga C., (2014); Bolelli F., Pollastri F., Paredes R., Grana C., Improving skin lesion segmentation with generative adversarial networks, Proc IEEE Symp Comput Based Med Syst, (2018); Frid-Adar M., Klang E., Amitai M., Goldberger J., Greenspan H., Synthetic data augmentation using GAN for improved liver lesion classification, Proc Int Symp Biomed Imaging, (2018); Gan W., Wasserstein generative adversarial network, Int Conf Mach Learn, (2017); Courville A, (2014); Lima J.L.P., Macedo D., Zanchettin C., Heartbeat Anomaly Detection Using Adversarial Oversampling, (2019); Liu D., Fu J., Qu Q., Lv J., BFGAN: backward and forward generative adversarial networks for lexically constrained sentence generation, IEEE/ACM Trans Audio Speech Lang Process, 27, pp. 2350-2361, (2019); Mirza M., Osindero S., Conditional Generative Adversarial Nets, (2014); Norgaard S., Saeedi R., Sasani K., Gebremedhin A.H., Synthetic sensor data generation for health applications: a supervised deep learning approach, Proc Ann Int Conf IEEE Eng Med Biol Soc, (2018); Pan Z., Yu W., Yi X., Khan A., Yuan F., Zheng Y., Recent progress on generative adversarial networks (GANs): a survey, IEEE Access, 7, pp. 36322-36333, (2019); Panwar M., Ram Dyuthi S., Chandra Prakash K., Biswas D., Acharyya A., Maharatna K., Gautam A., Naik G.R., CNN based approach for activity recognition using a wrist-worn accelerometer, Proc Ann Int Conf IEEE Eng Med Biol Soc, (2017); Prati A., Shan C., Wang K.I.-K., Sensors, vision and networks: From video surveillance to activity recognition and&nbsp;health&nbsp;monitoring, J Ambient Intell Smart Environ, 11, pp. 5-22, (2019); Qi J., Yang P., Waraich A., Deng Z., Zhao Y., Yang Y., Examining sensor-based physical activity recognition and monitoring for healthcare using Internet of Things: a systematic review, J Biomed Inform, 87, pp. 138-153, (2018); Ramasamy S.R., Roy N., Recent trends in machine learning for human activity recognition—A survey, Wiley Interdiscip Rev, 8, pp. 1-16, (2018); Rueda F.M., Grzeszick R., Fink G.A., Feldhorst S., Ten Hompel M., Convolutional neural networks for human activity recognition using body-worn sensors, Informatics, 5, pp. 1-17, (2018); Shi D., Wang R., Wu Y., Mo X., Wei J., A novel orientation- and location-independent activity recognition method, Pers Ubiquit Comput, 21, pp. 427-441, (2017); Sun X., He J., A novel approach to generate a large scale of supervised data for short text sentiment analysis, Multimed Tools Appl, 79, pp. 5439-5459, (2020); Thakur D., Biswas S., Smartphone based human activity monitoring and recognition using ML and DL: a comprehensive survey, J Ambient Intell Human Comput, (2020); Tsanousa A., Meditskos G., Vrochidis S., Angelis L., A novel feature selection method based on comparison of correlations for human activity recognition problems, J Ambient Intell Human Comput, (2020); Wang J., Chen Y., Gu Y., Xiao Y., Pan H., SensoryGANs: an effective generative adversarial framework for sensor-based human activity recognition, Proc Int Joint Conf Neural Netw, (2018); Yi X., Walia E., Babyn P., Generative adversarial network in medical imaging: a review, Med Image Anal, 58, (2019); Zhang H., Xu T., Li H., Zhang S., Wang X., Huang X., Metaxas D.N., StackGAN++: realistic image synthesis with stacked generative adversarial networks, IEEE Trans Pattern Anal Mach Intell, 41, pp. 1947-1962, (2019)","M.H.M. Noor; School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, Malaysia; email: halimnoor@usm.my","","Springer Science and Business Media Deutschland GmbH","","","","","","18685137","","","","English","J. Ambient Intell. Humanized Comput.","Article","Final","","Scopus","2-s2.0-85091149132"
"Baraka A.R.; Mohd Noor M.H.","Baraka, AbdulRahman (57474769800); Mohd Noor, Mohd Halim (36656106400)","57474769800; 36656106400","Weakly-supervised temporal action localization: a survey","2022","Neural Computing and Applications","34","11","","8479","8499","20","1","10.1007/s00521-022-07102-x","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125638759&doi=10.1007%2fs00521-022-07102-x&partnerID=40&md5=2b1cf25b50da7d4b46ab0f752c311926","School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, 11800, Malaysia; Al-Quds Open University, Ramallah, Palestine","Baraka A.R., School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, 11800, Malaysia, Al-Quds Open University, Ramallah, Palestine; Mohd Noor M.H., School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, 11800, Malaysia","Temporal Action Localization (TAL) is an important task of various computer vision topics such as video understanding, summarization, and analysis. In the real world, the videos are long untrimmed and contain multiple actions, where the temporal boundaries annotations are required in the fully-supervised learning setting for classification and localization tasks. Since the annotation task is costly and time-consuming, the trend is moving toward the weakly-supervised setting, which depends on the video-level labels only without any additional information, and this approach is called weakly-supervised Temporal Action Localization (WTAL). In this survey, we review the concepts, strategies, and techniques related to the WTAL in order to clarify all aspects of the problem and review the state-of-the-art frameworks of WTAL according to their challenges. Furthermore, a comparison of models’ performance and results based on benchmark datasets is presented. Finally, we summarize the future works to allow the researchers to improve the model's performance. © 2022, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.","Action classification; Features extraction; Temporal action localization; Weakly-supervised","Benchmarking; Action classifications; Features extraction; Localisation; Modeling performance; Real-world; Temporal action localization; Video analysis; Video summarization; Video understanding; Weakly-supervised; Surveys","","","","","Ministry of Higher Education, Malaysia, MOHE, (FRGS/1/2019/ICT02/USM/02/1)","This work has been supported in part by the Ministry of Higher Education Malaysia for Fundamental Research Grant Scheme with Project Code: FRGS/1/2019/ICT02/USM/02/1. ","Towards train-test consistency for semi-supervised temporal action localization, [Online], Available, (2019); Ma F., SF-Net: Single-frame supervision for temporal action localization, [Online], (2020); Ding X., Wang N., Gao X., Li J., Wang X., Liu T., Weakly supervised temporal action localization with segment-level labels, 1(C), [Online], Available, (2020); Sun C., Shetty S., Sukthankar R., Nevatia R., Temporal localization of fine-grained actions in videos by domain transfer from web images, MM 2015 - Proc. 2015 ACM Multimed. Conf, pp. 371-380, (2015); Graph regularization network with semantic affinity for weakly-supervised temporal action localization, Proceedings - International Conference on Image Processing, ICIP, 2019, pp. 3701-3705, (2019); Nguyen P., Han B., Liu T., Prasad G., Weakly supervised action localization by sparse temporal pooling network, Proc IEEE Comput Soc Conf Comput Vis Pattern Recognit, pp. 6752-6761, (2018); Narayan S., Cholakkal H., Khan F.S., Shao L., 3C-Net: Category count and center loss for weakly-supervised action localization, Proc IEEE Int Conf Comput Vis, 2019, pp. 8678-8686, (2019); RGB stream is enough for temporal action detection, [Online], Available, (2021); Alwassel H., Giancola S., Ghanem B., TSP: Temporally-sensitive pretraining of video encoders for localization tasks, [Online], Available, (2020); Nawhal M., Mori G., Activity graph transformer for temporal action localization, [Online], Available, (2021); Alwassel H., Pardo A., Heilbron F.C., Thabet A., Ghanem B., RefineLoc: Iterative refinement for weakly-supervised action localization, [Online], Available, (2019); Bojanowski P., Et al., Weakly supervised action labeling in videos under ordering constraints, Lect. Notes Comput. Sci. (Including Subser. Lect. Notes Artif. Intell. Lect. Notes Bioinformatics), 8693, pp. 628-643, (2014); Huang D.A., Fei-Fei L., Niebles J.C., Connectionist temporal modeling for weakly supervised action labelling. Lect. Notes Comput. Sci. (including Subser. Lect. Notes Artif. Intell. Lect. Notes Bioinformatics), vol. 9908, LNCS, pp. 137-153, (2016); Yang H., He X., Porikli F., One-shot action localization by learning sequence matching network, Proc IEEE Comput Soc Conf Comput Vis Pattern Recognit, (2018); Cheron G., Alayrac J.B., Laptev I., Schmid C., A flexible model for training action localization with varying levels of supervision, Adv Neural Inf Process Syst, 2018, pp. 942-953, (2018); Xia H., Zhan Y., A survey on temporal action localization, IEEE Access, 8, pp. 70477-70487, (2020); Zhou Z.H., A brief introduction to weakly supervised learning, Natl Sci Rev, 5, 1, pp. 44-53, (2018); Kolesnikov A., Lampert C.H., Seed, expand and constrain: Three principles for weakly-supervised image segmentation. In: Lecture notes in computer science (including subseries Lecture notes in artificial intelligence and lecture notes in bioinformatics), 9908, LNCS, pp. 695-711, (2016); Carbonneau M.A., Cheplygina V., Granger E., Gagnon G., Multiple instance learning: a survey of problem characteristics and applications, Pattern Recognit, 77, pp. 329-353, (2018); Vanwinckelen G., Tragante do V.O., Fierens D., Blockeel H., Instance-level accuracy versus bag-level accuracy in multi-instance learning, Data Min Knowl Discov, 30, 2, pp. 313-341, (2016); Wang L., Xiong Y., Lin D., van Gool L., UntrimmedNets for weakly supervised action recognition and detection, Proc - 30Th IEEE Conf Comput Vis Pattern Recognition, CVPR, 2017, 2017, pp. 6402-6411, (2017); Xu Y., Et al., Segregated temporal assembly recurrent networks for weakly supervised multiple action detection, Proc AAAI Conf Artif Intell, 33, pp. 9070-9078, (2019); Lee P., Uh Y., Byun H., Background Suppression Network for Weakly-Supervised Temporal Action Localization, (2019); Paul S., Roy S., Roy-Chowdhury A.K., W-TALC: Weakly-supervised temporal activity localization and classification. Lect Notes Comput Sci (including Subser Lect Notes Artif Intell Lect Notes Bioinformatics), 11208, LNCS, pp. 588-607, (2018); Lee P., Wang J., Lu Y., Byun H., Background modeling via uncertainty estimation for weakly-supervised action localization. pp, Available, pp. 1-12, (2020); Rashid M., Kjellstrom H., Lee Y.J., Action graphs: Weakly-supervised action localization with graph convolution networks, Proceedings - 2020 IEEE Winter Conference on Applications of Computer Vision, WACV, 2020, pp. 604-613, (2020); Shi B., Dai Q., Mu Y., Wang J., Weakly-supervised action localization by generative attention modelling, pp. 1006-1016, (2020); Schindler K., van Gool L., Action snippets: How many frames does human action recognition require?. In: 26th IEEE Conf Comput Vis Pattern Recognition, CVPR, (2008); Liu D., Jiang T., Wang Y., Completeness modeling and context separation for weakly supervised temporal action localization, Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2019, pp. 1298-1307, (2019); Singh K.K., Lee Y.J., Hide-and-seek: Forcing a network to be meticulous for weakly-supervised object and action localization, Proc IEEE Int Conf Comput Vis, 2017, pp. 3544-3553, (2017); Shou Z., Gao H., Zhang L., Miyazawa K., Chang S.F., AutoLoc: Weakly-supervised temporal action localization in untrimmed videos. Lect Notes Comput Sci (including Subser Lect Notes Artif Intell Lect Notes Bioinformatics), vol. 11220, LNCS, pp. 162-179, (2018); Liu Z., Et al., Weakly supervised temporal action localization through contrast based evaluation networks, Proc IEEE Int Conf Comput Vis, (2019); Zeng R., Gan C., Chen P., Huang W., Wu Q., Tan M., Breaking winner-takes-all: iterative-winners-out networks for weakly supervised temporal action localization, IEEE Trans Image Process, 28, 12, pp. 5797-5808, (2019); Su H., Zhao X., Lin T., Cascaded pyramid mining network for weakly supervised temporal action localization. Lect Notes Comput Sci (including Subser Lect Notes Artif Intell Lect Notes Bioinformatics), vol. 11362, LNCS, pp. 558-574, (2019); Su H., Zhao X., Lin T., Fei H., Weakly supervised temporal action detection with shot-based temporal pooling network. Lect Notes Comput Sci (including Subser Lect Notes Artif Intell Lect Notes Bioinformatics), 11304, LNCS, pp. 426-436, (2018); Russakovsky O., Et al., ImageNet large scale visual recognition challenge, Int J Comput Vis, 115, 3, pp. 211-252, (2015); Kay W., Et al., The kinetics human action video dataset, [Online], Available, (2017); Zach C., Pock T., Bischof H., A duality based approach for realtime TV-L1 optical flow, Lect Notes Comput Sci (Including Subser Lect Notes Artif Intell Lect Notes Bioinformatics), 4713, pp. 214-223, (2007); Soomro K., Zamir A.R., Shah M., UCF101: A dataset of 101 human actions classes from videos in the wild, [Online], Available, (2012); Kuehne H., Jhuang H., Garrote E., Poggio T., Serre T., HMDB: a large video database for human motion recognition, Proc IEEE Int Conf Comput Vis, (2011); Simonyan K., Zisserman A., Two-stream convolutional networks for action recognition in videos, Adv Neural Inf Process Syst, 1, January, pp. 568-576, (2014); Wang L., Et al., Temporal segment networks: Towards good practices for deep action recognition. Lect Notes Comput Sci (including Subser. Lect Notes Artif Intell Lect Notes Bioinformatics), vol. 9912, LNCS, pp. 20-36, (2016); Karpathy A., Toderici G., Shetty S., Leung T., Sukthankar R., Li F.F., Large-scale video classification with convolutional neural networks, Proc IEEE Comput Soc Conf Comput Vis Pattern Recognit, (2014); Feichtenhofer C., Pinz A., Zisserman A., Convolutional two-stream network fusion for video action recognition, Proc IEEE Comput Soc Conf Comput Vis Pattern Recognit, (2016); Dai X., Singh B., Zhang G., Davis L.S., Chen Y.Q., Temporal context network for activity localization in videos, Proc IEEE Int Conf Comput Vis, (2017); Zhong J.X., Li N., Kong W., Zhang T., Li T.H., Li G., Step-by-step erasion, one-by-one collection: A weakly supervised temporal action detector, MM 2018 - Proceedings of the 2018 ACM Multimedia Conference, 2014, pp. 35-44, (2018); Huang L., Huang Y., Ouyang W., Wang L., Relational Prototypical Network for Weakly Supervised Temporal Action Localization, (2020); Carreira J., Zisserman A., Quo Vadis, action recognition? A new model and the kinetics dataset, Proc. - 30Th IEEE Conf Comput Vis Pattern Recognition, CVPR, 2017, 2017, pp. 4724-4733, (2017); Ioffe S., Szegedy C., Batch normalization: Accelerating deep network training by reducing internal covariate shift, 32Nd Int Conf Mach Learn. ICML 2015, 1, pp. 448-456, (2015); Nguyen P., Ramanan D., Fowlkes C., Weakly-supervised action localization with background modeling, Proc IEEE Int Conf Comput Vis, (2019); Kang Z., Wang L., Liu Z., Zhang Q., Zheng N., Extracting action sensitive features to facilitate weakly-supervised action localization, IFIP Adv Inform Commun Technol, (2019); Zhai Y., Wang L., Liu Z., Zhang Q., Hua G., Zheng N., Action coherence network for weakly supervised temporal action localization, Proc - Int Conf Image Process, (2019); Zhang C., Et al., Adversarial seeded sequence growing for weakly-supervised temporal action localization, MM 2019 - Proc 27Th ACM Int Conf Multimed, pp. 738-746, (2019); Yuan Y., Lyu Y., Shen X., Tsang I.W., Yeung D.Y., Marginalized average attentional network for weakly-supervised learning, 7Th Int Conf Learn. Represent. ICLR 2019, pp. 1-19, (2019); Min K., Corso J.J., Adversarial background-aware loss for weakly-supervised temporal activity localization. ECCV 2020, [Online], Available, (2020); Nair V., Hinton G.E., Rectified linear units improve restricted Boltzmann machines. In: ICML 2010 - Proceedings, 27th Int Conf, Mach Learn, pp. 807-814, (2010); Zhou B., Khosla A., Lapedriza A., Oliva A., Torralba A., Learning deep features for discriminative localization, Proc IEEE Comput Soc Conf Comput Vis Pattern Recognit, (2016); Narayan S., Cholakkal H., Hayat M., Khan F.S., Yang M.H., Shao L., D2-Net: Weakly-Supervised Action Localization via Discriminative Embeddings and Denoised Activations, (2020); Islam A., Radke R.J., Weakly supervised temporal action localization using deep metric learning, Proceedings - 2020 IEEE Winter Conference on Applications of Computer Vision, WACV, 2020, pp. 536-545, (2020); Idrees H., Et al., The THUMOS challenge on action recognition for videos ‘in the wild’, Comput Vis Image Underst, 155, pp. 1-23, (2017); Heilbron F.C., Escorcia V., Ghanem B., Niebles J.C., ActivityNet: a large-scale video benchmark for human activity understanding, Proc IEEE Comput Soc Conf Comput Vis Pattern Recognit, (2015); Sigurdsson G.A., Varol G., Wang X., Farhadi A., Laptev I., Gupta A., Hollywood in homes: Crowdsourcing data collection for activity understanding. Lect Notes Comput Sci (including Subser. Lect Notes Artif Intell Lect Notes Bioinformatics), vol. 9905, LNCS, pp. 510-526, (2016); Zhao H., Torralba A., Torresani L., Yan Z., HACS: Human action clips and segments dataset for recognition and temporal localization, Proc IEEE Int Conf Comput Vis, (2019); Huang Z., Wang X., Wang J.J., Liu W., Wang J.J., Weakly-supervised semantic segmentation network with deep seeded region growing, Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, pp. 7014-7023, (2018); Islam A., Long C., Radke R.J., A hybrid attention mechanism for weakly-supervised temporal action localization, no. Mil, [Online], Available, (2021); Ge Y., Qin X., Yang D., Jagersand M., Deep snippet selective network for weakly supervised temporal action localization, Pattern Recognit, 110, (2021); Yu T., Ren Z., Li Y., Yan E., Xu N., Yuan J., Temporal structure mining for weakly supervised action detection, Proc IEEE Int Conf Comput Vis, (2019); Hendrycks D., Gimpel K., A baseline for detecting misclassified and out-of-distribution examples in neural networks. 5th Int Conf Learn Represent ICLR 2017 – Conf Track Proc, pp. 1–12. [Online], Available, (2016); Hou R., Sukthankar R., Shah M., Real-time temporal action localization in untrimmed videos by sub-action discovery. Br Mach Vis Conf, BMVC, (2017); Heidarivincheh F., Mirmehdi M., Damen D., Weakly-supervised completion moment detection using temporal attention, Proc. - 2019 Int Conf Comput Vis Work. ICCVW 2019, pp. 1188-1196, (2019); Luo Z., Et al., Weakly-supervised action localization with expectation-maximization multi-instance learning. Lect. Notes Comput Sci (including Subser Lect Notes Artif Intell Lect Notes Bioinformatics), 12374 LNCS, no, Mil, pp. 729-745, (2020); Zhang X.Y., Li C., Shi H., Zhu X., Li P., Dong J., AdapNet: adaptability decomposing encoder-decoder network for weakly supervised action recognition and localization, IEEE Trans Neural Netw Learn Syst, (2020); Snell J., Swersky K., Zemel R., Prototypical networks for few-shot learning, Adv Neural Inform Process Syst, 2017, pp. 4078-4088, (2017); Kingmaba D.P.J.L., Adam: A method for stochastic optimization, 3Rd Int Conf Learn Represent. ICLR 2015 - Conf Track Proc, pp. 1-15, (2015); Zhao Y., Xiong Y., Wang L., Wu Z., Tang X., Lin D., Temporal action detection with structured segment networks, Int J Comput Vis, 128, 1, pp. 74-95, (2020); Defferrard M., Bresson X., Vandergheynst P., Convolutional neural networks on graphs with fast localized spectral filtering, Adv Neural Inform Process Syst, Nips, pp. 3844-3852, (2016); Pang J., Cheung G., Graph laplacian regularization for image denoising: analysis in the continuous domain, IEEE Trans Image Process, 26, 4, pp. 1770-1785, (2017); Zhai Y., Wang L., Tang W., Zhang Q., Yuan J., Two-Stream Consensus Network for Weakly-Supervised Temporal Action Localization, pp. 1-17, (2020); Gong G., Wang X., Mu Y., Tian Q., Learning temporal co-attention models for unsupervised video action localization, Proc IEEE Comput Soc Conf Comput Vis Pattern Recognit, (2020)","M.H. Mohd Noor; School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, 11800, Malaysia; email: halimnoor@usm.my","","Springer Science and Business Media Deutschland GmbH","","","","","","09410643","","","","English","Neural Comput. Appl.","Review","Final","","Scopus","2-s2.0-85125638759"
"Aminu M.; Ahmad N.A.; Mohd Noor M.H.","Aminu, Muhammad (57517921000); Ahmad, Noor Atinah (15724195500); Mohd Noor, Mohd Halim (36656106400)","57517921000; 15724195500; 36656106400","Covid-19 detection via deep neural network and occlusion sensitivity maps","2021","Alexandria Engineering Journal","60","5","","4829","4855","26","34","10.1016/j.aej.2021.03.052","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103792668&doi=10.1016%2fj.aej.2021.03.052&partnerID=40&md5=ed8035cd929f130d9d337519d65c860e","School of Mathematical Sciences, Universiti Sains Malaysia, Penang, 11800, Malaysia; School of Computer Sciences, Universiti Sains Malaysia, Penang, 11800, Malaysia","Aminu M., School of Mathematical Sciences, Universiti Sains Malaysia, Penang, 11800, Malaysia; Ahmad N.A., School of Mathematical Sciences, Universiti Sains Malaysia, Penang, 11800, Malaysia; Mohd Noor M.H., School of Computer Sciences, Universiti Sains Malaysia, Penang, 11800, Malaysia","Deep learning approaches have attracted a lot of attention in the automatic detection of Covid-19 and transfer learning is the most common approach. However, majority of the pre-trained models are trained on color images, which can cause inefficiencies when fine-tuning the models on Covid-19 images which are often grayscale. To address this issue, we propose a deep learning architecture called CovidNet which requires a relatively smaller number of parameters. CovidNet accepts grayscale images as inputs and is suitable for training with limited training dataset. Experimental results show that CovidNet outperforms other state-of-the-art deep learning models for Covid-19 detection. © 2021 THE AUTHORS","Covid-19; Deep neural networks; Occlusion sensitivity maps; Pneumonia","Transfer learning; Automatic Detection; Colour image; Covid-19; Fine tuning; Learning approach; Neural-networks; Occlusion sensitivity map; Pneumonia; Sensitivity map; Transfer learning; Deep neural networks","","","","","Ministry of Higher Education, Malaysia, MOHE","This work is supported by the the Ministry of Higher Education Malaysia under the FRGS grant (acc no: 203.PMATHS.6711942).","Sun Q., Qiu H., Huang M., Yang Y., Lower mortality of covid-19 by early recognition and intervention: experience from Jiangsu province, Ann. Intensive Care, 10, pp. 1-4, (2020); Tahamtan A., Ardebili A., (2020); Xie X., Zhong Z., Zhao W., Zheng C., Wang F., Liu J., Chest ct for typical 2019-ncov pneumonia: relationship to negative rt-pcr testing, Radiology, (2020); Li Y., Yao L., Li J., Chen L., Song Y., Cai Z., Yang C., Stability issues of rt-pcr testing of sars-cov-2 for hospitalized patients clinically diagnosed with covid-19, J. Med. Virol., (2020); Herpe G., Lederlin M., Naudin M., Ohana M., Chaumoitre K., Gregory J., Vilgrain V., Freitag C.A., De Margerie-Mellon C., Flory V., Et al., Efficacy of chest ct for covid-19 pneumonia in France, Radiology, (2020); Ozturk T., Talo M., Yildirim E.A., Baloglu U.B., Yildirim O., Acharya U.R., Automated detection of covid-19 cases using deep neural networks with x-ray images, Comput. Biol. Med., (2020); Khan A.I., Shah J.L., Bhat M.M., Coronet: A deep neural network for detection and diagnosis of covid-19 from chest x-ray images, Comput. Methods Programs Biomed., (2020); Shi F., Wang J., Shi J., Wu Z., Wang Q., Tang Z., He K., Shi Y., Shen D., (2020); Obeid J.S., Davis M., Turner M., Meystre S.M., Heider P.M., Lenert L.A., An ai approach to covid-19 infection risk assessment in virtual visits: a case report, J. Am. Med. Inform. Assoc., (2020); Li L., Qin L., Xu Z., Yin Y., Wang X., Kong B., Bai J., Lu Y., Fang Z., Song Q., Et al., Artificial intelligence distinguishes covid-19 from community acquired pneumonia on chest ct, Radiology, (2020); Hu S., Gao Y., Niu Z., Jiang Y., Li L., Xiao X., Wang M., Fang E.F., Menpes-Smith W., Xia J., Et al., Weakly supervised deep learning for covid-19 infection detection and classification from ct images, IEEE Access, 8, pp. 118869-118883, (2020); Huang L., Han R., Ai T., Yu P., Kang H., Tao Q., Xia L., Serial quantitative chest ct assessment of covid-19: Deep-learning approach, Radiology: Cardiothoracic, Imaging, 2, (2020); Oh Y., Park S., Ye J.C., Deep learning covid-19 features on cxr using limited training data sets, IEEE Trans. Med. Imaging, (2020); Ismael A.M., Sengur A., Deep learning approaches for covid-19 detection based on chest x-ray images, Expert Syst. Appl., 164, (2021); Nayak S.R., Nayak D.R., Sinha U., Arora V., Pachori R.B., Application of deep learning techniques for detection of covid-19 cases using chest x-ray images: A comprehensive study, Biomed. Signal Process. Control, 64, (2021); Zebin T., Rezvy S., Covid-19 detection and disease progression visualization: Deep learning on chest x-rays for classification and coarse localization, Appl. Intell., 51, pp. 1010-1021, (2021); Sheykhivand S., Mousavi Z., Mojtahedi S., Rezaii T.Y., Farzamnia A., Meshgini S., Saad I., Developing an efficient deep neural network for automatic detection of covid-19 using chest x-ray images, Alexandr. Eng. J., 60, pp. 2885-2903, (2021); Russakovsky O., Deng J., Su H., Krause J., Satheesh S., Ma S., Huang Z., Karpathy A., Khosla A., Bernstein M., Et al., Imagenet large scale visual recognition challenge, Int. J. Comput. Vision, 115, pp. 211-252, (2015); Mahmud T., Rahman M.A., Fattah S.A., Covxnet: A multi-dilation convolutional neural network for automatic covid-19 and other pneumonia detection from chest x-ray images with transferable multi-receptive feature optimization, Comput. Biol. Med., (2020); Brunese L., Mercaldo F., Reginelli A., Santone A., Explainable deep learning for pulmonary disease and coronavirus covid-19 detection from x-rays, Comput. Methods Programs Biomed., (2020); Imran A., Posokhova I., Qureshi H.N., Masood U., Riaz S., Ali K., John C.N., Hussain I., Nabeel M., (2020); Maghdid H.S., Ghafoor K.Z., Sadiq A.S., Curran K., Rabie K., (2020); Rustam F., Reshi A.A., Mehmood A., Ullah S., On B., Aslam W., Choi G.S., Covid-19 future forecasting using supervised machine learning models, IEEE Access, (2020); Peng Y., Nagata M.H., An empirical overview of nonlinearity and overfitting in machine learning using covid-19 data, Chaos, Solitons Fract., (2020); Pinter G., Felde I., Mosavi A., Ghamisi P., Gloaguen R., Covid-19 pandemic prediction for hungary; a hybrid machine learning approach, Mathematics, 8, (2020); Burdick H., Lam C., Mataraso S., Lynn-Palevsky A., Braden G., Dellinger R.P., McCoy A., Vincent J.-L., Green-Saxena A., Barnes G., Et al., Prediction of respiratory decompensation in covid-19 patients using machine learning: The ready trial, Comput. Biol. Med., (2020); Elaziz M.A., Hosny K.M., Salah A., Darwish M.M., Lu S., Sahlol A.T., New machine learning method for image-based diagnosis of covid-19, Plos One, 15, (2020); Kassani S.H., Kassasni P.H., Wesolowski M.J., Schneider K.A., Deters R., (2020); Redmon J., Farhadi A., Yolo9000: better, faster, stronger, in, Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 7263-7271, (2017); Chollet F., Xception: Deep learning with depthwise separable convolutions, in, Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 1251-1258, (2017); Apostolopoulos I.D., Mpesiana T.A., Covid-19: automatic detection from x-ray images utilizing transfer learning with convolutional neural networks, Phys. Eng. Sci. Med., (2020); Simonyan K., Zisserman A., (2014); Howard A.G., Zhu M., Chen B., Kalenichenko D., Wang W., Weyand T., Andreetto M., Adam H., (2017); Szegedy C., Ioffe S., Vanhoucke V., Alemi A., (2016); rekha Hanumanthu S., Role of intelligent computing in covid-19 prognosis: A state-of-the-art review, Chaos, Solitons Fract., (2020); Ardakani A.A., Kanafi A.R., Acharya U.R., Khadem N., Mohammadi A., Application of deep learning technique to manage covid-19 in routine clinical practice using ct images: Results of 10 convolutional neural networks, Comput. Biol. Med., (2020); Kingma D.P., Ba J., (2014); Soares E., Angelov P., Biaso S., Froes M.H., Abe D.K., (2020); Hemdan E.E.-D., Shouman M.A., Karar M.E., (2020); Sethy P.K., Behera S.K., (2020); Narin A., Kaya C., Pamuk Z., (2020); Butt C., Gill J., Chun D., Babu B.A., (2020); Wong H.Y.F., Lam H.Y.S., Fong A.H.-T., Leung S.T., Chin T.W.-Y., Lo C.S.Y., Lui M.M.-S., Lee J.C.Y., Chiu K.W.-H., Chung T., Et al., Frequency and distribution of chest radiographic findings in covid-19 positive patients, Radiology, (2020); Fang Y., Zhang H., Xie J., Lin M., Ying L., Pang P., Ji W., Sensitivity of chest ct for covid-19: comparison to rt-pcr, Radiology, (2020); Zeiler M.D., Fergus R., Visualizing and understanding convolutional networks, European conference on computer vision, pp. 818-833, (2014); Jacobi A., Chung M., Bernheim A., Eber C., Portable chest x-ray in coronavirus disease-19 (covid-19): A pictorial review, Clin. Imaging, (2020); Ng M.-Y., Lee E.Y., Yang J., Yang F., Li X., Wang H., Et al., (2020); Shi H., Han X., Jiang N., Cao Y., Alwalid O., Gu J., Fan Y., Zheng C., Radiological findings from 81 patients with covid-19 pneumonia in wuhan, china: a descriptive study, Lancet. Infect. Dis, (2020); Cleverley J., Piper J., Jones M.M., (2020); Donahue J., Jia Y., Vinyals O., Hoffman J., Zhang N., Tzeng E., Darrell T., Decaf: A deep convolutional activation feature for generic visual recognition, International conference on machine learning, pp. 647-655, (2014); Snoek J., Larochelle H., Adams R.P., Practical bayesian optimization of machine learning algorithms, pp. 2951-2959, (2012); Chen Y., Jiang H., Li C., Jia X., Ghamisi P., Deep feature extraction and classification of hyperspectral images based on convolutional neural networks, IEEE Trans. Geosci. Remote Sens., 54, pp. 6232-6251, (2016)","N.A. Ahmad; School of Mathematical Sciences, Universiti Sains Malaysia, Penang, 11800, Malaysia; email: nooratinah@usm.my","","Elsevier B.V.","","","","","","11100168","","","","English","Alexandria Engineering Journal","Article","Final","All Open Access; Gold Open Access; Green Open Access","Scopus","2-s2.0-85103792668"
"Noor M.H.M.; Salcic Z.; Wang K.I.-K.","Noor, Mohd Halim Mohd (36656106400); Salcic, Zoran (7003306034); Wang, Kevin I-Kai (7501398184)","36656106400; 7003306034; 7501398184","Ontology-based sensor fusion activity recognition","2020","Journal of Ambient Intelligence and Humanized Computing","11","8","","3073","3087","14","15","10.1007/s12652-017-0668-0","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049571920&doi=10.1007%2fs12652-017-0668-0&partnerID=40&md5=cc757b4c71731222f9d8e0852a715002","Faculty of Electrical Engineering, Universiti Teknologi MARA, Permatang Pauh, Penang, Malaysia; Department of Electrical and Computer Engineering, The University of Auckland, Auckland, New Zealand","Noor M.H.M., Faculty of Electrical Engineering, Universiti Teknologi MARA, Permatang Pauh, Penang, Malaysia; Salcic Z., Department of Electrical and Computer Engineering, The University of Auckland, Auckland, New Zealand; Wang K.I.-K., Department of Electrical and Computer Engineering, The University of Auckland, Auckland, New Zealand","This paper investigates the fusion of wearable and ambient sensors for recognizing activities of daily living in a smart home setting using ontology. The proposed approach exploits the advantages of both types of sensing to resolve uncertainties due to missing sensor data. The resulting system is able to infer activities which cannot be inferred with the single type of sensing only. The methodology of ontological modeling the wearable and ambient sensors and the fusion of contexts captured from the sensors, as well as corresponding activity is investigated and described. The proposed system is compared with a system that uses ambient sensors without wearable sensor on the internally collected and publicly available datasets. The results of the experiments show that the proposed system is more robust in handling uncertainties. It is also more capable of inferring additional information about activities, which is not possible with environment sensing only, with overall recognition accuracy of 91.5 and 90% on internal and public datasets, respectively. © 2018, Springer-Verlag GmbH Germany, part of Springer Nature.","","Automation; Ontology; Activities of Daily Living; Ambient sensors; Environment sensing; Ontological modeling; Ontology-based; Recognition accuracy; Sensor fusion; Smart homes; Wearable sensors","","","","","Nazrin Muhammad; University of Aizu, UoA","The authors would like to thank Embedded System Research Group for providing sensors and devices utilized in this study. The authors would also like to thank Nazrin Muhammad (UoA) and Akshat Bisht for assisting with this work.","Alirezaie M., Renoux J., Kockemann U., Kristoffersson A., Karlsson L., Blomqvist E., Tsiftes N., Voigt T., Loutfi A., An ontology-based context-aware system for smart homes: e-care@home, Sensors, 17, (2017); Atallah L., Lo B., Ali R., King R., Yang G.-Z., Real-time activity classification using ambient and wearable sensors, IEEE Trans Inf Technol Biomed, 13, pp. 1031-1039, (2009); Baader F., Calvanese D., McGuinness D.L., Nardi D., Patel-Schneider P.F., The description logic handbook: theory, implementation, and applications, (2003); Bakhshandehabkenar A., Loke S.W., MyActivity: Cloud-hosted continuous activity recognition using ontology-based stream reasoning, 2014 2Nd IEEE International Conference on Mobile Cloud Computing, Services, and Engineering (Mobilecloud), pp. 117-126, (2014); Chen L., Hoey J., Nugent C.D., Cook D.J., Yu Z., Sensor-based activity recognition, IEEE Trans Syst Man Cybern Part C Appl Rev, 42, pp. 790-808, (2012); De D., Bharti P., Das S.K., Chellappan S., Multimodal wearable sensing for fine-grained activity recognition in healthcare, IEEE Internet Comput, 19, pp. 26-35, (2015); Do T.M., Loke S.W., Liu F., HealthyLife: an activity recognition system with smartphone using logic-based stream reasoning, Mobile and ubiquitous systems: computing, networking, and services, pp. 188-199, (2012); Forster K., Biasiucci A., Chavarriaga R., del Millan J.R., Roggen D., Troster G., On the use of brain decoded signals for online user adaptive gesture recognition systems, Pervasive computing, pp. 427-444, (2010); Gavrila D.M., The visual analysis of human movement: a survey, Comput Vis Image Underst, 73, pp. 82-98, (1999); Ge Y., Xu B., Elderly personal intention recognition by activity and context recognition in smart home, 2014 9Th International Conference on Computer Science Education (ICCSE), pp. 347-350, (2014); Gravina R., Alinia P., Ghasemzadeh H., Fortino G., Multi-sensor fusion in body sensor networks: state-of-the-art and research challenges, Inf Fusion, 35, pp. 68-80, (2017); Gu T., Wang L., Wu Z., Tao X., Lu J., A pattern mining approach to sensor-based human activity recognition, IEEE Trans Knowl Data Eng, 23, pp. 1359-1372, (2011); Hodges M.R., Pollack M.E., An ‘object-use fingerprint’: the use of electronic sensors for human identification, UbiComp 2007: ubiquitous computing, pp. 289-303, (2007); Jia R., Liu B., Human daily activity recognition by fusing accelerometer and multi-lead ECG data, 2013 IEEE International Conference on Signal Processing, Communication and Computing (ICSPCC), pp. 1-4, (2013); Khattak A.M., Truc P.T.H., Hung L.X., Vinh L.T., Dang V.-H., Guan D., Pervez Z., Han M., Lee S., Lee Y.-K., Towards smart homes using low level sensory data, Sensors, 11, pp. 11581-11604, (2011); Laukkanen P., Leskinen E., Kauppinen M., Sakari-Rantala R., Heikkinen E., Health and functional capacity as predictors of community dwelling among elderly people, J Clin Epidemiol, 53, pp. 257-265, (2000); Lee M.L., Dey A.K., Sensor-based observations of daily living for aging in place, Pers Ubiquitous Comput, 19, pp. 27-43, (2014); McIlwraith D., Pansiot J., Yang G.-Z., Wearable and ambient sensor fusion for the characterisation of human motion, 2010 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS), pp. 5505-5510, (2010); Ni Q., Garcia Hernando A.B., de la Cruz I.P., The elderly’s independent living in smart homes: a characterization of activities and sensing infrastructure survey to facilitate services development, Sensors, 15, pp. 11312-11362, (2015); Noor M.H.M., Salcic Z., Wang K.I.-K., Adaptive sliding window segmentation for physical activity recognition using a single tri-axial accelerometer, Pervasive Mob Comput, 38, pp. 41-59, (2017); Pansiot J., Stoyanov D., McIlwraith D., Lo B.P.L., Yang G.Z., Ambient and wearable sensor fusion for activity recognition in healthcare monitoring systems, 4Th International Workshop on Wearable and Implantable Body Sensor Networks (BSN 2007), pp. 208-212, (2007); Peeters P.H.F., Design criteria for an automatic safety-alarm system for elderly, Technol Health Care, 8, pp. 81-91, (2000); Philipose M., Fishkin K.P., Perkowitz M., Patterson D.J., Fox D., Kautz H., Hahnel D., Inferring activities from interactions with objects, IEEE Pervasive Comput, 3, pp. 50-57, (2004); Riboni D., Bettini C., COSAR: hybrid reasoning for context-aware activity recognition, Pers Ubiquitous Comput, 15, pp. 271-289, (2011); Rodriguez N.D., Cuellar M.P., Lilius J., Calvo-Flores M.D., A survey on ontologies for human behavior recognition, ACM Comput Surv, 46, pp. 1-43:33, (2014); Roggen D., Calatroni A., Rossi M., Holleczek T., Forster K., Troster G., Lukowicz P., Bannach D., Pirkl G., Ferscha A., Doppler J., Holzmann C., Kurz M., Holl G., Chavarriaga R., Sagha H., Bayati H., Creaturamillan M.J.R., Collecting complex activity datasets in highly rich networked sensor environments, 2010 Seventh International Conference on Networked Sensing Systems (INSS), pp. 233-240, (2010); Roy N., Misra A., Cook D., Ambient and smartphone sensor assisted ADL recognition in multi-inhabitant smart environments, J Ambient Intell Humaniz Comput, 7, pp. 1-19, (2015); Sagha H., Digumarti S.T., Millan J., Del R., Chavarriaga Calatroni R., Roggen A., Troster D.G., Benchmarking classification techniques using the opportunity human activity dataset, 2011 IEEE International Conference on Systems, Man, and Cybernetics (SMC), pp. 36-40, (2011); Scalmato A., Sgorbissa A., Zaccaria R., Describing and recognizing patterns of events in smart environments with description logic, IEEE Trans Cybern, 43, pp. 1882-1897, (2013); Shoaib M., Bosch S., Incel O.D., Scholten H., Havinga P.J.M., Fusion of smartphone motion sensors for physical activity recognition, Sensors, 14, pp. 10146-10176, (2014); Steigmiller A., Glimm B., Liebig T., Coupling tableau algorithms for expressive description logics with completion-based saturation procedures, Automated reasoning, pp. 449-463, (2014); Sun H., Fan W., Shen W., Xiao T., Ontology fusion in high-level-architecture-based collaborative engineering environments, IEEE Trans Syst Man Cybern Syst, 43, pp. 2-13, (2013); Sung M., Devaul R., Jimenez S., Gips J., Pentland A., Shiver motion and core body temperature classification for wearable soldier health monitoring systems, Eighth International Symposium on Wearable Computers, 2004. ISWC 2004, pp. 192-193, (2004); Turaga P., Chellappa R., Subrahmanian V.S., Udrea O., Machine recognition of human activities: a survey, IEEE Trans Circuits Syst Video Technol, 18, pp. 1473-1488, (2008); Valle E.D., Ceri S., Harmelen F.V., Fensel D., It’s a streaming world! Reasoning upon rapidly changing information, IEEE Intell Syst, 24, pp. 83-89, (2009); Villalonga C., Pomares H., Rojas I., Banos O., MIMU-wear: ontology-based sensor selection for real-world wearable activity recognition, Neurocomputing, 250, pp. 76-100, (2017); Wang C., Cao L., Chi C.H., Formalization and verification of group behavior interactions, IEEE Trans Syst Man Cybern Syst, 45, pp. 1109-1124, (2015); Wannenburg J., Malekian R., Physical activity recognition from smartphone accelerometer data for user context awareness sensing, IEEE Trans Syst Man Cybern Syst, pp. 1-8, (2016); WHO, Facts about Ageing, (2014); Wongpatikaseree K., Ikeda M., Buranarach M., Supnithi T., Lim A.O., Tan Y., Activity recognition using context-aware infrastructure ontology in smart home domain, 2012 Seventh International Conference on Knowledge, Information and Creativity Support Systems (KICSS), pp. 50-57, (2012); Wu K., Haarslev V., Parallel OWL reasoning: merge classification, Semantic technology, pp. 211-227, (2013); Wu J., Osuntogun A., Choudhury T., Philipose M., Rehg J.M., A scalable approach to activity recognition based on object use, 2007 IEEE 11Th International Conference on Computer Vision, pp. 1-8, (2007); Yilmaz A., Javed O., Shah M., Object tracking: a survey, ACM Comput Surv, (2006); Yoshihiro T., Masako K.-P., Noriaki K., Jukai M., Miwa H., Yasuko K., Recognition of nursing activity with accelerometers and RFID, Kybernetes, 42, pp. 1059-1071, (2013); Zgheib R., Nicola A.D., Villani M.L., Conchon E., Bastide R., A flexible architecture for cognitive sensing of activities in ambient assisted living, 2017 IEEE 26Th International Conference on Enabling Technologies: Infrastructure for Collaborative Enterprises (WETICE), pp. 284-289, (2017); Zhou F., Jiao J.R., Chen S., Zhang D., A case-driven ambient intelligence system for elderly in-home assistance applications, IEEE Trans Syst Man Cybern Part C Appl Rev, 41, pp. 179-189, (2011)","M.H.M. Noor; Faculty of Electrical Engineering, Universiti Teknologi MARA, Permatang Pauh, Malaysia; email: mohalimnoor@gmail.com","","Springer","","","","","","18685137","","","","English","J. Ambient Intell. Humanized Comput.","Article","Final","","Scopus","2-s2.0-85049571920"
"Yusof N.A.M.; Osman M.K.; Noor M.H.M.; Ibrahim A.; Tahir N.M.; Yusof N.M.","Yusof, N.A.M. (57207308210); Osman, M.K. (7201930443); Noor, M.H.M. (36656106400); Ibrahim, A. (57198461652); Tahir, N.M. (56168849900); Yusof, N.M. (58422899800)","57207308210; 7201930443; 36656106400; 57198461652; 56168849900; 58422899800","Crack detection and classification in asphalt pavement images using deep convolution neural network","2019","Proceedings - 8th IEEE International Conference on Control System, Computing and Engineering, ICCSCE 2018","","","8685007","227","232","5","24","10.1109/ICCSCE.2018.8685007","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065018963&doi=10.1109%2fICCSCE.2018.8685007&partnerID=40&md5=3ee52440bf031a9ff0b5611a296ff2ba","Department of Electrical Engineering, Politeknik Tuanku Sultanah Bahiyah, Kedah, Malaysia; Faculty of Electrical Engineering, Universiti Teknologi MARA, Malaysia Dept., Pulau Pinang, Malaysia; School of Computer Science, Universiti Sains Malaysia, Pulau Pinang, Malaysia; Faculty of Civil Engineering, Universiti Teknologi MARA, Pulau Pinang, Malaysia; Faculty of Electrical Engineering, Universiti Teknologi MARA, Selangor, Malaysia; PLUS Berhad, Persada PLUS, Selangor, Malaysia","Yusof N.A.M., Department of Electrical Engineering, Politeknik Tuanku Sultanah Bahiyah, Kedah, Malaysia; Osman M.K., Faculty of Electrical Engineering, Universiti Teknologi MARA, Malaysia Dept., Pulau Pinang, Malaysia; Noor M.H.M., School of Computer Science, Universiti Sains Malaysia, Pulau Pinang, Malaysia; Ibrahim A., Faculty of Civil Engineering, Universiti Teknologi MARA, Pulau Pinang, Malaysia; Tahir N.M., Faculty of Electrical Engineering, Universiti Teknologi MARA, Selangor, Malaysia; Yusof N.M., PLUS Berhad, Persada PLUS, Selangor, Malaysia","Pavement distress particularly cracks, are the most significant type of pavement distress that has been studied for many years due to the complicated pavement crack condition. The continuous severity of crack can cause a dangerous environment that may affect the road users. Therefore, an efficient computer algorithm plays an important role in developing analysis tools for automated crack detection. In Malaysia, many of road surveyors are still employing manual inspection, which is a labour-intensive, error-prone and hazardous task. Various attempts have been made to automate this task by using image processing techniques. However the method turns out to suffer from the problem of lighting variation and complexity of the background such as low contrast on the surrounding pavement that similar to the intensity of crack. This study proposed a deep convolution neural network (CNN) as a detection system of ashpalt pavement crack that capable to detect and classify the pavement crack robustly when dealing with complexity background image. A digital camera is used to capture the image of pavement crack. Then, the captured images are divided into two (2) different grid scales, 32× 32 and 64× 64, and further fed as input to the first deep CNN. For each grid size, the network is trained independently to detect the presence of crack in the image. In the classification stage, the captured images are binarized with the similar grid scales to extract the crack pattern. The binary images containing two types of crack, transverse and longitudinal are then fed as input to the second deep CNN and trained to identify the type of crack. Experimental results show that deep CNN using 32x32 grid scale images provides higher performance for crack detection and classification compared to 64x64. The network achieved the recall, precision and accuracy of 98.0%, 99.4% and 99.2% respectively for crack and non-crack detection, while the performance for transverse and longitudinal achieved the accuracy of 98% and 97% © 2018 IEEE.","asphalt pavement crack; crack classification; crack detection; deep convolution neural network","Asphalt; Asphalt pavements; Binary images; Complex networks; Control systems; Convolution; Deep neural networks; Image classification; Background image; Convolution neural network; Crack classification; Image processing technique; Labour-intensive; Lighting variations; Manual inspection; Pavement distress; Crack detection","","","","","","","Lee B., Erdenee E., Jin S., Kyu P., Efficient object detection using convolutional neural network-based hierarchical feature modeling, Signal, Image Video Process, (2016); Wang X., Hu Z., Grid-based pavement crack analysis using deep learning, 2017 4th International Conference on Transportation Information and Safety, ICTIS 2017-Proceedings, pp. 917-924, (2017); Jing L., Aiqin Z., Pavement crack distress detection based on image analysis, 2010 Int. Conf. Mach. Vis. Human-Machine Interface, MVHI 2010, No. C, pp. 576-579, (2010); Yu X., Yang J., Lin Z., Wang J., Wang T., Huang T., Subcategory-aware object detection, IEEE Signal Process. Lett, 22, 9, pp. 1472-1476, (2015); Takarli F., Aghagolzadeh A., Seyedarabi H., Combination of high-level features with low-level features for detection of pedestrian, Signal, Image Video Process, 10, 1, pp. 93-101, (2016); Radopoulou S.C., Brilakis I., Patch detection for pavement assessment, Autom. Constr, 53, pp. 95-104, (2015); Kapela R., Et al., Asphalt surfaced pavement cracks detection based on histograms of oriented gradients, In Proceedings of the 22nd International Conference Mixed Design of Integrated Circuits and Systems, MIXDES, 2015; Ouyang A., Luo C., Zhou C., Surface distresses detection of pavement based on digital image processing, IFIP Adv. Inf. Commun. Technol, 347, pp. 368-375, (2011); Kapela R., Et al., Asphalt surfaced pavement cracks detection based on histograms of oriented gradients, Proc. 22nd Int. Conf. Mix. Des. Integr. Circuits Syst. Mix, 2015, pp. 579-584, (2015); Bray J., Verma B., Li X., He W., A neural network based technique for automatic classification of road cracks, 2006 IEEE Int. Jt. Conf. Neural Netw. Proc, pp. 907-912, (2006); Goodfellow I., Bengio Y., Courville A., Regularization for Deep Learning, Deep Learn, pp. 216-261, (2016); Murphy K.P., Machine Learning: A Probabilistic Perspective, (2012); Mao X., Hijazi S., Casas R., Kaul P., Kumar R., Rowen C., Hierarchical CNN for traffic sign recognition, IEEE Intelligent Vehicles Symposium, Proceedings, 2016, pp. 130-135, (2016); Avril S., Vautrin A., Surrel Y., Grid method: Application to the characterization of cracks, Exp. Mech., (2004); Fan Z., Wu Y., Lu J., Li W., Automatic Pavement Crack Detection Based on Structured Prediction with the Convolutional Neural Network, pp. 1-9, (2018); Wang X., Grid-based pavement crack analysis using deep learning, 2017 4th International Conference on Transportation Information and Safety, ICTIS 2017-Proceedings, pp. 917-924, (2017); Krizhevsky A., Sutskever I., Hinton G.E., Imagenet classification with deep convolutional neural networks, Adv. Neural Inf. Process. Syst., pp. 1-9, (2012); He K., Zhang X., Ren S., Sun J., Spatial pyramid pooling in deep convolutional networks for visual recognition, IEEE Trans. Pattern Anal. Mach. Intell, 37, 9, pp. 1904-1916, (2015); Wang J., Lin J., Wang Z., Efficient convolution architectures for convolutional neural network, 2016 8th International Conference on Wireless Communications and Signal Processing, WCSP 2016, (2016)","","","Institute of Electrical and Electronics Engineers Inc.","","8th IEEE International Conference on Control System, Computing and Engineering, ICCSCE 2018","23 November 2018 through 25 November 2018","Penang","147373","","978-153866324-0","","","English","Proc. - IEEE Int. Conf. Control Syst., Comput. Eng., ICCSCE","Conference paper","Final","","Scopus","2-s2.0-85065018963"
"Shaninah F.S.E.; Mohd Noor M.H.","Shaninah, Fathi Said Emhemed (58482379900); Mohd Noor, Mohd Halim (36656106400)","58482379900; 36656106400","The impact of big five personality trait in predicting student academic performance","2023","Journal of Applied Research in Higher Education","","","","","","","0","10.1108/JARHE-08-2022-0274","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164492472&doi=10.1108%2fJARHE-08-2022-0274&partnerID=40&md5=93b3c744acbf7b5220219bd53893b535","School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, Malaysia","Shaninah F.S.E., School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, Malaysia; Mohd Noor M.H., School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, Malaysia","Purpose: The study aims to propose a predictive model that combines personality and demographic factors to predict student academic performance (SAP). This research study works on understanding, enhancing and applying techniques to enhance the prediction of SAP. Design/methodology/approach: The authors gathered information from 305 university students from Al-Zintan University Libya. The study uses a survey questionnaire to collect data on essential variables. The purpose of the questionnaire is to discover variables that affect students' academic performance. The survey questionnaire has 44 closed questions with Likert scale designs that were distributed to a variety of college students at the start of the first semester of 2022. It includes questions about demographics, personality, employment and institutional aspects. The authors proposed a predictive model to identify the main fundamental components, consisting of one dependent variable (SAP) and five independent constructs. The suggested model is tested using partial least squares (PLS) and structural equation modeling (SEM), which perform better than covariance-based structural equation modeling (CB-SEM). PLS-SEM performs well with smaller sample sizes, even for complicated models. Findings: The study results show that the proposed model accurately predicted the student's academic performance. The personality trait variables are a key factor that determines the actual student's academic performance. The student's academic performance is significantly impacted by each variable in the personality trait variables as well. Originality/value: The process of validating research was done empirically through the accuracy and efficiency of model performance. The study differs from previous studies in that it accumulated a wide range of factors from different dimensions, including student demographics and personality trait factors. The authors developed a structural equation model to predict students' academic performance. © 2023, Emerald Publishing Limited.","Al-Zintan University Libya; Big five personality trait; Prediction; Structural equation modelling; Student academic performance","","","","","","Ministry of Higher Education, Malaysia, MOHE; Universiti Sains Malaysia, USM, (LRGS MRUN/F2/01/2019)","This work was supported in part by the Ministry of Higher Education Malaysia and in part by the Universiti Sains Malaysia (USM) for Long-Term Research Grant Scheme (LRGS) Malaysian Research University Network (MRUN) under Project LRGS MRUN/F2/01/2019.","Acharya A., Sinha D., Application of feature selection methods in educational data mining, International Journal of Computer Applications, 103, 2, pp. 34-38, (2014); Acheboune A., Driouchi A., Unemployment persistence, risks of skill obsolescence, and impacts on the knowledge economy in Arab countries, Knowledge-Based Economic Policy Development in the Arab World, pp. 273-291, (2014); Adeyemi, Adeyemi, Institutional factors as predictors of students' academic achievement in colleges of education in South western Nigeria, International Journal of Educational Administration and Policy Studies, 6, 8, pp. 141-153, (2014); Ali Elabbar A., National Libyan public education reform: entire transformative strategies, 2020-2026, American Journal of Educational Research, 5, 10, pp. 1044-1057, (2017); Ahmad H., Asghar M.Z., Khan A.S., Habib A., A systematic literature review of personality trait classification from textual content, Open Computer Science, 10, 1, pp. 175-193, (2020); Ahmouda Shafter M.E., Ruth C., State of higher education in Libya: a game change administrative approach, Shanlax International Journal of Education, 8, 3, pp. 19-23, (2020); Al-Zoubi S.M., Younes M.A.B., Low academic achievement: causes and results, Theory and Practice in Language Studies, 5, 11, (2015); Alami M., Manizheh Alami, International Journal of Social Science Research, 4, 1, pp. 126-136, (2016); Alansari B., The Big Five Inventory (BFI): reliability and validity of its Arabic translation in non clinical sample, European Psychiatry, 33, S1, pp. S209-S210, (2016); Ali F., Omar R., An examination of the relationships between physical environment, perceived value, image and behavioural Intentions : a SEM approach towards Malaysian resort hotels keywords: physical environment, Image, Perceived Value, Behavioural Intentions, Journal of Hotel and Tourism Management, 27, October 2015, pp. 9-26, (2013); Allensworth E.M., Clark K., High school GPAs and ACT scores as predictors of college completion: examining assumptions about consistency across high schools, Educational Researcher, 49, 3, pp. 198-211, (2020); Allik J., Realo A., Oxford handbooks online universal and specific in the five-factor model of personality, pp. 1-22, (2017); Amrieh E.A., Hamtini T., Aljarah I., Mining educational data to predict student's academic performance using ensemble methods, International Journal of Database Theory and Application, 9, 8, pp. 119-136, (2016); Awheda A.A.M., Radwan F.S., An extensive study on factors affecting the quality of higher education and, Al-Mukhtar Journal of Social Science, 40, 2, pp. 337-350, (2022); Banerjee P.A., A systematic review of factors linked to poor academic performance of disadvantaged students in science and maths in schools, Cogent Education, 3, 1, pp. 1-17, (2016); Benet-Martinez V., John O.P., Los cinco grandes across cultures and ethnic groups: multitrait-multimethod analyses of the big five in Spanish and English, Journal of Personality and Social Psychology, 75, 3, (1998); Boerst T., Shaughnessy M., Tenney-Muirhead M., Double the learning potential, Learning Professional, 41, 4, pp. 50-54, (2020); Borkar S., Rajeswari K., Predicting students academic performance using education data mining, International Journal of Computer Science and Mobile Computing, 2, 7, pp. 273-279, (2013); Bornstein M.H., Big five personality traits, The Sage Encyclopedia of Lifespan Human Development [Preprint], (2018); Brew-Graves C., Farewell V., Monson K., Milosevic M., Williams N.R., Morris E., Macbeth F., Treasure T., Fallowfield L., Pulmonary metastasectomy in colorectal cancer: health utility scores by EQ‐5D‐3L in a randomized controlled trial show no benefit from lung metastasectomy, Colorectal Disease, 23, 1, pp. 200-205, (2021); Dalvi-Esfahani M., Niknafs A., Alaedini Z., Ahmadabadi H.B., Kuss D.J., Ramayah T., Social Media Addiction and Empathy: moderating impact of personality traits among high school students, Telematics and Informatics, 57, (2021); Digman J.M., Personality structure: emergence of the five-factor model, Annual Review of Psychology, 41, 1, pp. 417-440, (1990); Elzalitni S., The Higher Education system in Libya: trends and issues, Libyan Studies, 39, May, pp. 131-144, (2008); Fariba T.B., Academic performance of virtual students based on their personality traits, learning styles and psychological well being: a prediction, Procedia - Social and Behavioral Sciences, 84, pp. 112-116, (2013); Fornell C., Larcker D.F., Evaluating structural equation models with unobservable variables and measurement error, Journal of Marketing Research, 18, 1, pp. 39-50, (2016); Francisco A.R.S., Teachers' personal and professional demographic characteristics as predictors of students' academic performance in English, International Journal of Management, Technology, and Social Sciences (IJMTS), 5, 2, pp. 80-91, (2020); Fraser W.J., Factors influencing academic success or failure of first-year and senior university students: do education students and lecturers perceive things differently?, 23, 4, pp. 254-260, (2003); Furnham A., Cheng H., Socio-demographic indicators, intelligence, and locus of control as predictors of adult financial well-being, Journal of Intelligence, 5, 2, pp. 1-11, (2019); Galla B.M., Shulman E.P., Plummer B.D., Gardner M., Hutt S.J., Goyer J.P., D'Mello S.K., Finn A.S., Duckworth A.L., Why high school grades are better predictors of on-time college graduation than are admissions test scores: the roles of self-regulation and cognitive ability, American Educational Research Journal, 56, 6, pp. 2077-2115, (2019); Garcia E.P.I., Mora P.M., Model prediction of academic performance for first year students, Proceedings - 2011 10th Mexican International Conference on Artificial Intelligence: Advances in Artificial Intelligence and Applications, MICAI 2011 - Proceedings of Special Session, pp. 169-174, (2011); Gray H., 18. Precarious diversity: representation and demography, Precarious Creativity, pp. 241-253, (2016); Hair J.F., Multivariate data analysis, (2009); Hair J.F., Matthews L.M., Matthews R.L., Sarstedt M., PLS-SEM or CB-SEM: updated guidelines on which method to use, International Journal of Multivariate Data Analysis, 1, 2, (2017); Hair J.F., Sarstedt M., Hopkins L., Kuppelwieser V.G., Partial least squares structural equation modeling (PLS-SEM): an emerging tool in business research, European Business Review, 26, 2, pp. 106-121, (2014); Hair J., Sarstedt M., Matthews L., Ringle C., Identifying and treating unobserved heterogeneity with FIMIX-PLS: part I – method, European Business Review, 28, 1, pp. 63-76, (2016); Halama P., Kohut M., Soto C.J., John O.P., Slovak adaptation of the big five inventory (BFI-2): psychometric properties and initial validation, Studia Psychologica, 62, 1, pp. 74-87, (2020); Hasan R., Palaniappan S., Mahmood S., Abbas A., Sarker K.U., Sattar M.U., Predicting student performance in higher educational institutions using video learning analytics and data mining techniques, Applied Sciences (Switzerland), 10, 11, (2020); Henseler J., Ringle C.M., Sarstedt M., Common beliefs and reality about PLS: comments on rönkkö and evermann (2013), Organizational Research Methods, 17, 2, pp. 182-209, (2014); Hsiao K.-L., Shu Y., Huang T.-C., Exploring the effect of compulsive social app usage on technostress and academic performance: perspectives from personality traits, Telematics and Informatics, 34, 2, pp. 679-690, (2017); John O.P., Srivastava S., The Big Five trait taxonomy: history, measurement, and theoretical perspectives, Handbook of Personality: Theory and Research, 2, 1999, pp. 102-138, (1999); Jayanthi S.V., Balakrishnan S., Ching A.L.S., Latiff N.A.A., Nasirudeen A.M.A., Factors contributing to academic performance of students in a tertiary institution in Singapore, American Journal of Educational Research, 2, 9, pp. 752-758, (2014); John O.P., Naumann L.P., Soto C.J., Paradigm shift to the integrative Big Five trait taxonomy: history, measurement, and conceptual issues, (2008); Kumar B., Pal S., Mining educational data to analyze students performance, International Journal of Advanced Computer Science and Applications, 2, 6, pp. 63-69, (2011); Martinez D.L., Gomez C.E., Contributions from data mining to study academic performance of students of a tertiary institute, American Journal of Educational Research, 2, 9, pp. 713-726, (2014); McCredie M.N., Morey L.C., Who are the turkers? A characterization of MTurk workers using the personality assessment inventory, Assessment, 26, 5, pp. 759-766, (2019); Mehta Y., Majumder N., Gelbukh A., Cambria E., Recent trends in deep learning based personality detection, Artificial Intelligence Review, 53, 4, pp. 2313-2339, (2020); Michael I.O., Wumi O.A., Causes and remedies to low academic performance of students in public secondary schools, A Study of Ijero Local Government Area of Ekiti State, 6, 15, pp. 2225-0484, (2016); Mirashrafi S.B., Bol G., Nakhaiezadeh G., The effect of individual factors, family background and socioeconomic status on university, Literacy Information and Computer Education Journal, 4, 2, pp. 1133-1139, (2013); Mushtaq I., Khan S.N., Factors affecting students' academic performance, Global Journal of Management and Business Research, 12, 9, pp. 17-22, (2012); Nik Ahmad Shukra'Am N.N.S.A., Hasuni P.D.H., Shafie N.A., Factors affecting academic performance among bachelor computer and mathematical sciences students, International Journal of Academic Research in Business and Social Sciences, 12, 4, pp. 316-325, (2022); Ogor E.N., Student academic performance monitoring and evaluation using data mining techniques, Electronics, Robotics and Automotive Mechanics Conference, CERMA 2007 - Proceedings, pp. 354-359, (2007); Papurt M.J., A study of the Woodworth Psychoneurotic Inventory with suggested revision, The Journal of Abnormal and Social Psychology, 25, 3, (1930); Pojon M., Using Machine Learning to Predict Student Performance, pp. 1-28, (2017); Qazi A., Naseer K., Qazi J., AlSalman H., Naseem U., Yang S., Hardaker G., Gumaei A., Conventional to online education during COVID-19 pandemic: do develop and underdeveloped nations cope alike, Children and Youth Services Review, 119, (2020); Raosoft I., Sample size calculator, (2004); Ringle C.M., Da Silva D., Bido D.D.S., Modelagem de Equações estruturais com utilização do smartpls, Revista Brasileira de Marketing, 13, 2, pp. 56-73, (2015); Sabani H., A personality and big five factor models of personality, International Scientific Journal, 3, 1, pp. 105-118, (2018); Sembiring R.W., Zain J.M., Embong A., A comparative agglomerative hierarchical clustering method to cluster implemented course, 2, 12, pp. 1-6, (2011); Shakil Ahamed A.T.M., Mahmood N.T., Rahman R.M., An intelligent system to predict academic performance based on different factors during adolescence, Journal of Information and Telecommunication, 1, 2, pp. 155-175, (2017); Shakil Ahamed A.T.M., Mahmood N.T., Rahman R.M., Prediction of academic performance during adolescence based on socioeconomic, psychological and academic factors, Studies in Computational Intelligence, 710, pp. 71-80, (2017); Solomon D., Patil S., Agrawal P., Predicting performance and potential difficulties of university student using classification: survey paper, International Journal of Pure and Applied Mathematics, 118, 18, pp. 2703-2707, (2018); Soric I., Penezic Z., Buric I., The Big Five personality traits, goal orientations, and academic achievement, Learning and Individual Differences, 54, pp. 126-134, (2017); Sosu E.M., Pheunpha P., Trajectory of university dropout: investigating the cumulative effect of academic vulnerability and proximity to family support, Frontiers in Education, (2019); Stajkovic A.D., Bandura A., Locke E.A., Lee D., Sergent K., Test of three conceptual models of influence of the big five personality traits and self-efficacy on academic performance: a meta-analytic path-analysis, Personality and Individual Differences, 120, pp. 238-245, (2018); Stinebrickner R., Stinebrickner T., Academic performance and college dropout : using longitudinal expectations data to estimate a learning, Model’, 32, 3, (2014); Strecht P., Soares C., A Comparative Study of Classification and Regression Algorithms for Modelling Students, pp. 392-395, (2015); Suhan, Samartha V., Kodikal R., Measuring the effect size of coefficient of determination and predictive relevance of exogenous latent variables on endogenous latent variables throught PLS-SEM, International Journal of Pure and Applied Mathematics, 119, 18, pp. 39-48, (2018); Tamtam A., Gallagher F., Olabi A.G., Et al., Higher education in Libya, system under stress, 2010, pp. 742-751, (2011); Ter Ji-Xi J., Salamzadeh Y., Teoh A.P., Behavioral intention to use cryptocurrency in Malaysia: an empirical study, The Bottom Line [Preprint], 34, 2, pp. 170-197, (2021); Voda A.I., Florea N., Impact of personality traits and entrepreneurship education on entrepreneurial intentions of business and engineering students, Sustainability, 11, 4, (2019)","M.H. Mohd Noor; School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, Malaysia; email: halimnoor@usm.my","","Emerald Publishing","","","","","","20507003","","","","English","J. Appl. Res. High. Edu.","Article","Article in press","","Scopus","2-s2.0-85164492472"
"Noor M.H.M.; Salcic Z.; Wang K.I.-K.","Noor, Mohd Halim Mohd (36656106400); Salcic, Zoran (7003306034); Wang, Kevin I-Kai (7501398184)","36656106400; 7003306034; 7501398184","Adaptive sliding window segmentation for physical activity recognition using a single tri-axial accelerometer","2017","Pervasive and Mobile Computing","38","","","41","59","18","102","10.1016/j.pmcj.2016.09.009","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84994410114&doi=10.1016%2fj.pmcj.2016.09.009&partnerID=40&md5=6eee448a841424c3ef65e0fb9bb8e27f","The University of Auckland, Auckland, New Zealand; Faculty of Electrical Engineering, Universiti Teknologi MARA, Penang, Malaysia","Noor M.H.M., The University of Auckland, Auckland, New Zealand, Faculty of Electrical Engineering, Universiti Teknologi MARA, Penang, Malaysia; Salcic Z., The University of Auckland, Auckland, New Zealand; Wang K.I.-K., The University of Auckland, Auckland, New Zealand","Previous studies on physical activity recognition have utilized various fixed window sizes for signal segmentation targeting specific activities. Naturally, an optimum window size varies depending on the characteristics of activity signals and fixed window size will not produce good segmentation for all activities. This paper presents a novel approach to activity signal segmentation for physical activity recognition. Central to the approach is that the window size is adaptively adjusted according to the probability of the signal belongs to a particular activity to achieve the most effective segmentation. In addition, an activity transition diagram for activity recognition is developed to validate the activity transition and improve recognition accuracy. The adaptive sliding window segmentation algorithm and the role of activity transition diagram are described in the context of physical activity recognition. The approach recognizes not only well defined static and dynamic activities, but also transitional activities. The presented approach has been implemented, evaluated and compared with an existing state-of-the-art approach by using internal and public datasets which contains activity signals of dynamic, static and transitional activities. Results have shown that the proposed adaptive sliding window segmentation achieves overall accuracy of 95.4% in all activities considered in the experiments compared to the existing approach which achieved an overall accuracy of 89.9%. The proposed approach achieved an overall accuracy of 96.5% compared to 91.9% overall accuracy with the existing approach when tested on the public dataset. © 2016 Elsevier B.V.","Activity recognition; Activity transition diagram; Adaptive sliding window; Signal segmentation","Dynamics; Activity recognition; Adaptive sliding windows; Recognition accuracy; Segmentation algorithms; Signal segmentation; State-of-the-art approach; Transition diagram; Triaxial accelerometer; Pattern recognition","","","","","","","(2014); (2016); Ni Q., Garcia Hernando A.B., de la Cruz I.P., The elderly's independent living in smart homes: a characterization of activities and sensing infrastructure survey to facilitate services development, Sensors, 15, 5, pp. 11312-11362, (2015); Kleinberger T., Becker M., Ras E., Holzinger A., Muller P., Ambient intelligence in assisted living: enable elderly people to handle future interfaces, Universal Access in Human-Computer Interaction. Ambient Interaction, pp. 103-112, (2007); Perera C., Zaslavsky A., Christen P., Georgakopoulos D., Context aware computing for the internet of things: A survey, IEEE Commun. Surv. Tutor., 16, 1, pp. 414-454, (2014); Viswanathan H., Chen B., Pompili D., Research challenges in computation, communication, and context awareness for ubiquitous healthcare, IEEE Commun. Mag., 50, 5, pp. 92-99, (2012); Gross M.M., Stevenson P.J., Charette S.L., Pyka G., Marcus R., Effect of muscle strength and movement speed on the biomechanics of rising from a chair in healthy elderly and young women, Gait Posture, 8, 3, pp. 175-185, (1998); Unver B., Karatosun V., Bakirhan S., Ability to rise independently from a chair during 6-month follow-up after unilateral and bilateral total knee replacement, J. Rehabil. Med., 37, 6, pp. 385-387, (2005); Eriksrud O., Bohannon R.W., Relationship of knee extension force to independence in sit-to-stand performance in patients receiving acute rehabilitation, Phys. Ther., 83, 6, pp. 544-551, (2003); Deandrea S., Bravi F., Turati F., Lucenteforte E., La Vecchia C., Negri E., Risk factors for falls in older people in nursing homes and hospitals. A systematic review and meta-analysis, Arch. Gerontol. Geriatr., 56, 3, pp. 407-415, (2013); Najafi B., Aminian K., Loew F., Blanc Y., Robert P.A., Measurement of stand-sit and sit-stand transitions using a miniature gyroscope and its application in fall risk evaluation in the elderly, IEEE Trans. Biomed. Eng., 49, 8, pp. 843-851, (2002); Nyberg L., Gustafson Y., Patient falls in stroke rehabilitation. A challenge to rehabilitation strategies, Stroke J. Cereb. Circ., 26, 5, pp. 838-842, (1995); Rapp K., Becker C., Cameron I.D., Knig H.-H., Buchele G., Epidemiology of falls in residential aged care: analysis of more than 70,000 falls from residents of bavarian nursing homes, J. Am. Med. Dir. Assoc., 13, 2, pp. 187.e1-187.e6, (2012); Zijlstra A., Mancini M., Lindemann U., Chiari L., Zijlstra W., Sit-stand and stand-sit transitions in older adults and patients with Parkinson's disease: event detection based on motion sensors versus force plates, J. Neuroeng. Rehabil., 9, (2012); Preece S.J., Goulermas J.Y., Kenney L.P.J., Howard D., Meijer K., Crompton R., Activity identification using body-mounted sensors—a review of classification techniques, Physiol. Meas., 30, 4, (2009); Bersch S., Azzi D., Khusainov R., Achumba I., Ries J., Sensor data acquisition and processing parameters for human activity classification, Sensors, 14, 3, pp. 4239-4270, (2014); Banos O., Galvez J.-M., Damas M., Pomares H., Rojas I., Window size impact in human activity recognition, Sensors, 14, 4, pp. 6474-6499, (2014); Fida B., Bernabucci I., Bibbo D., Conforto S., Schmid M., Varying behavior of different window sizes on the classification of static and dynamic physical activities from a single accelerometer, Med. Eng. Phys., 37, 7, pp. 705-711, (2015); Weinland D., Ronfard R., Boyer E., A survey of vision-based methods for action representation, segmentation and recognition, Comput. Vis. Image Underst., 115, 2, pp. 224-241, (2011); Banos O., Galvez J.-M., Damas M., Guillen A., Herrera L.-J., Pomares H., Rojas I., Evaluating the effects of signal segmentation on activity recognition, Presented at the 2nd International Work-Conference on Bioinformatics and Biomedical Engineering, (2014); Santos L., Khoshhal K., Dias J., Trajectory-based human action segmentation, Pattern Recognit., 48, 2, pp. 568-579, (2015); Kozina S., Lustrek M., Gams M., Dynamic signal segmentation for activity recognition, 1622, (2011); Bifet A., Gavalda R., Learning from time-changing data with adaptive windowing., 7, (2007); Nunez M., Fidalgo R., Morales R., Learning in environments with unknown dynamics: Towards more robust concept learners, J. Mach. Learn. Res., 8, pp. 2595-2628, (2007); Sheng Z., Hailong C., Chuan J., Shaojun Z., An adaptive time window method for human activity recognition, pp. 1188-1192, (2015); Sekine M., Tamura T., Togawa T., Fukui Y., Classification of waist-acceleration signals in a continuous walking record, Med. Eng. Phys., 22, 4, pp. 285-291, (2000); Nyan M.N., Tay F.E.H., Seah K.H.W., Sitoh Y.Y., Classification of gait patterns in the time–frequency domain, J. Biomech., 39, 14, pp. 2647-2656, (2006); Yoshizawa M., Takasaki W., Ohmura R., Parameter exploration for response time reduction in accelerometer-based activity recognition, Proceedings of the 2013 ACM Conference on Pervasive and Ubiquitous Computing Adjunct Publication, New York, NY, USA, pp. 653-664, (2013); Aminian D.K., Rezakhanlou K., Andres E.D., Fritsch C., Leyvraz P.-F., Robert P., Temporal feature estimation during walking using miniature accelerometers: an analysis of gait improvement after hip arthroplasty, Med. Biol. Eng. Comput., 37, 6, pp. 686-691, (1999); Selles R.W., Formanoy M.A.G., Bussmann J., Janssens P.J., Stam H.J., Automated estimation of initial and terminal contact timing using accelerometers; development and validation in transtibial amputees and controls, IEEE Trans. Neural Syst. Rehabil. Eng., 13, 1, pp. 81-88, (2005); Aminian K., Najafi B., Bula C., Leyvraz P.-F., Robert P., Spatio-temporal parameters of gait measured by an ambulatory system using miniature gyroscopes, J. Biomech., 35, 5, pp. 689-699, (2002); Jasiewicz J.M., Allum J.H.J., Middleton J.W., Barriskill A., Condie P., Purcell B., Li R.C.T., Gait event detection using linear accelerometers or angular velocity transducers in able-bodied and spinal-cord injured individuals, Gait Posture, 24, 4, pp. 502-509, (2006); Benocci M., Bachlin M., Farella E., Roggen D., Benini L., Troster G., Wearable assistant for load monitoring: recognition of on-body load placement from gait alterations, Pervasive Computing Technologies for Healthcare (PervasiveHealth), 2010 4th International Conference on-NO PERMISSIONS, pp. 1-8, (2010); Sant'Anna A., Wickstrom N., A symbol-based approach to gait analysis from acceleration signals: Identification and detection of gait events and a new measure of gait symmetry, IEEE Trans. Inf. Technol. Biomed., 14, 5, pp. 1180-1187, (2010); Chen L., Hoey J., Nugent C.D., Cook D.J., Yu Z., Sensor-based activity recognition, IEEE Trans. Syst. Man Cybern. Part C Appl. Rev., 42, 6, pp. 790-808, (2012); Ermes M., Parkka J., Mantyjarvi J., Korhonen I., Detection of daily activities and sports with wearable sensors in controlled and uncontrolled conditions, IEEE Trans. Inf. Technol. Biomed., 12, 1, pp. 20-26, (2008); Ozdemir A.T., Barshan B., Detecting falls with wearable sensors using machine learning techniques, Sensors, 14, 6, pp. 10691-10708, (2014); De D., Bharti P., Das S.K., Chellappan S., Multimodal wearable sensing for fine-grained activity recognition in healthcare, IEEE Internet Comput., 19, 5, pp. 26-35, (2015); Bao L., Intille S.S., Activity recognition from user-annotated acceleration data, Pervasive Computing, pp. 1-17, (2004); Jia R., Liu B., Human daily activity recognition by fusing accelerometer and multi-lead ECG data, 2013 IEEE International Conference on Signal Processing, Communication and Computing, ICSPCC, pp. 1-4, (2013); Chiang J.-H., Yang P.-C., Tu H., Pattern analysis in daily physical activity data for personal health management, Pervasive Mob. Comput., 13, pp. 13-25, (2014); Peeters P.H.F., Design criteria for an automatic safety-alarm system for elderly, Technol. Health Care, 8, 2, pp. 81-91, (2000); Adaskevicius R., Method for recognition of the physical activity of human being using a wearable accelerometer, Elektron. Elektrotechn., 20, 5, pp. 127-131, (2014); Hu L., Chen Y., Wang S., Chen Z., b-COELM: A fast, lightweight and accurate activity recognition model for mini-wearable devices, Pervasive Mob. Comput., 15, pp. 200-214, (2014); Catal C., Tufekci S., Pirmit E., Kocabag G., On the use of ensemble of classifiers for accelerometer-based activity recognition, Appl. Soft Comput., 37, pp. 1018-1022, (2015); Xiao W., Lu Y., Xiao W., Lu Y., Daily human physical activity recognition based on kernel discriminant analysis and extreme learning machine, daily human physical activity recognition based on kernel discriminant analysis and extreme learning machine, Math. Probl. Eng., (2015); He Z., Activity recognition from accelerometer signals based on Wavelet-AR model, 2010 IEEE International Conference on Progress in Informatics and Computing PIC, 1, pp. 499-502, (2010); Preece S.J., Goulermas J.Y., Kenney L.P.J., Howard D., A comparison of feature extraction methods for the classification of dynamic activities from accelerometer data, IEEE Trans. Biomed. Eng., 56, 3, pp. 871-879, (2009); Lara O.D., Labrador M.A., A survey on human activity recognition using wearable sensors, IEEE Commun. Surv. Tutor., 15, 3, pp. 1192-1209, (2013); Kozina S., Gjoreski H., Gams M., Lustrek M., Three-layer activity recognition combining domain knowledge and meta-classification, J. Med. Biol. Eng., 33, 4, pp. 406-414, (2013); Zhang Y., Markovic S., Sapir I., Wagenaar R.C., Little T.D.C., Continuous functional activity monitoring based on wearable tri-axial accelerometer and gyroscope, 2011 5th International Conference on Pervasive Computing Technologies for Healthcare (PervasiveHealth), pp. 370-373, (2011); Ahanathapillai V., Amor J.D., Tadeusiak M., James C.J., Wrist-Worn Accelerometer to Detect Postural Transitions and Walking Patterns, XIII Mediterranean Conference on Medical and Biological Engineering and Computing 2013, pp. 1515-1518, (2014); Khan A., Lee Y.-K., Lee S.Y., Kim T.-S., A triaxial accelerometer-based physical-activity recognition via augmented-signal features and a hierarchical recognizer, IEEE Trans. Inf. Technol. Biomed., 14, 5, pp. 1166-1172, (2010); Reyes-Ortiz J.-L., Oneto L., Sama A., Parra X., Anguita D., Transition-aware human activity recognition using smartphones, Neurocomputing, 171, pp. 754-767, (2016); Gupta P., Dallas T., Feature selection and activity recognition system using a single triaxial accelerometer, IEEE Trans. Biomed. Eng., 61, 6, pp. 1780-1786, (2014); Rencher A.C., Christensen W.F., Methods of Multivariate Analysis, (2012); Gao L., Bourke A.K., Nelson J., Evaluation of accelerometer based multi-sensor versus single-sensor activity recognition systems, Med. Eng. Phys., 36, 6, pp. 779-785, (2014); Trost S.G., Zheng Y., Wong W.-K., Machine learning for activity recognition: hip versus wrist data, Physiol. Meas., 35, 11, (2014); Weka 3 - Data Mining with Open Source Machine Learning Software in Java, (2015); Quinlan J.R., Induction of decision trees, Mach. Learn., 1, 1, pp. 81-106, (1986); Atallah L., Lo B., King R., Yang G.-Z., Sensor positioning for activity recognition using wearable accelerometers, IEEE Trans. Biomed. Circuits Syst., 5, 4, pp. 320-329, (2011); Noor M.H.M., Salcic Z., Wang K.I.-K., Dynamic sliding window method for physical activity recognition using a single tri-axial accelerometer, 2015 IEEE 10th Conference on Industrial Electronics and Applications, ICIEA, pp. 102-107, (2015)","M.H.M. Noor; The University of Auckland, Auckland, New Zealand; email: mmoh626@aucklanduni.ac.nz","","Elsevier B.V.","","","","","","15741192","","","","English","Pervasive Mob. Comput.","Article","Final","","Scopus","2-s2.0-84994410114"
"Abdullah M.F.; Madzhi N.K.; Khuan L.Y.; Mohd Noor M.H.; Ahmad K.A.; Ahmad A.; Zulkeply N.","Abdullah, M.F. (36975141500); Madzhi, N.K. (35092792600); Khuan, L.Y. (14042088400); Mohd Noor, M.H. (36656106400); Ahmad, K.A. (35760857000); Ahmad, A. (56288566800); Zulkeply, N. (57499511500)","36975141500; 35092792600; 14042088400; 36656106400; 35760857000; 56288566800; 57499511500","A miniaturization using Surface Mount Technology of potentiometric indicator system for measuring human stress","2012","ISIEA 2012 - 2012 IEEE Symposium on Industrial Electronics and Applications","","","6496673","67","71","4","1","10.1109/ISIEA.2012.6496673","https://www.scopus.com/inward/record.uri?eid=2-s2.0-84876754339&doi=10.1109%2fISIEA.2012.6496673&partnerID=40&md5=62a20df6f8c3a244511d88c4b82ebfb3","Faculty of Electrical Engineering, Universiti Teknologi Mara, Malaysia; Faculty of Engineering, Universiti Selangor, Malaysia","Abdullah M.F., Faculty of Electrical Engineering, Universiti Teknologi Mara, Malaysia; Madzhi N.K., Faculty of Electrical Engineering, Universiti Teknologi Mara, Malaysia; Khuan L.Y., Faculty of Electrical Engineering, Universiti Teknologi Mara, Malaysia; Mohd Noor M.H., Faculty of Electrical Engineering, Universiti Teknologi Mara, Malaysia; Ahmad K.A., Faculty of Electrical Engineering, Universiti Teknologi Mara, Malaysia; Ahmad A., Faculty of Engineering, Universiti Selangor, Malaysia; Zulkeply N., Faculty of Engineering, Universiti Selangor, Malaysia","This paper concerns miniaturization using Surface Mount Technology (SMT) of potentiometric indicator system for measuring human stress. The piezoresistive MEMS sensor is integrated with potentiometric indicator system that converts a biochemical signal into a measurable signal. The overall project involved transduction stage, filtering, voltage follower, and linearization stage. The design of this new approach is implemented using Cadence OrCAD Capture CIS 15.7 software and the miniaturization part uses SMT and troubleshooting. The advantages of SMT over the older through-hole technique are surface mount allows for much smaller components to be used which, in turn, allows for smaller, more portable and lightweight electronic device application. Details descriptions of the hardware for the circuit miniaturization will be presented. From the previous research, it has been found that for a sensor input range of 1.1 to 1.3kilo ohms, an output range of-100 to +100 millivolts is obtained. The result from the SMT testing indicates discrepancy within 10.75% was found for the last output stage on the average, which could be attributed to tolerance of electronic components and wiring. This development allowed stress measurement with relatively high precision and accuracy. © 2012 IEEE.","Human Stress; Miniaturization; Potentiometric Indicator System; Surface Mount Technology","Industrial electronics; Miniature instruments; Potentiometers (electric measuring instruments); Sensors; Biochemical signal; Circuit miniaturization; Electronic component; Electronic device; Human stress; Indicator system; Miniaturization; Voltage follower; Surface mount technology","","","","","","","Yamaguchi M., Kanemori T., Kanemaru M., Takai N., Mizuno Y., Yoshida H., Performance evaluation of salivary amylase activity monitor, Biosensors and Bioelectronics, 20, pp. 491-497, (2004); Lee M.H., Lee H.K., Bang S., Development stress monitoring system based on personal digital assistant (pda), Proceeding of the 26th Annual International Conference of the IEEE EMBS, (2004); Bond G.C.H.D., Lifestyle-specific outcome measures, The International Electronic Journal of Health Education, pp. 159-168, (2000); Takai N., Aragaki T., Eto K., Uchihashi K., Nishikawa Y., Effect of psychological stress on the salivary cortisol and amylase levels in healthy young adults, Achieves of Oral Biology, pp. 963-968, (2004); Chun-Chieh H., Shao-Hang H., Jen-Feng C., Van L.D., Chin-Teng L., Front-end amplifier of low-noise and tunable BW/gain for portable biomedical signal acquisition, Circuits and Systems, 2008. ISCAS 2008. IEEE International Symposium on, pp. 2717-2720, (2008); Hwang-Cherng C., Jia-Yu W., High CMRR instrumentation amplifier for biomedical applications, Signal Processing and Its Applications, 2007. ISSPA 2007. 9th International Symposium on, pp. 1-4, (2007); Bhatti M.A., Zhong L.Y., Abdalla A.N., Design and Finite Element Analysis of Piezoresistive Cantilever with Stress Concentration Holes, (2007); Wongkittisukka B., Limsakul C., Thavarungkul P., Kanatharana P., Asawatreratanakul P., A conductimetric transducer for biosensor system, NECTEC, 4, pp. 369-374; Prasad R.P., Introduction to surface mount technology, Surface Mount Technology, pp. 3-50, (2002); Boden P.J., Surface mount technology-A study of safety considerations: Silver migration and adhesive flammability, IEEE Transactions on Component, Packaging, and MAnufacturing Technology, 17, pp. 83-91, (1994); Blackwell G.R., Surface mount technology and power applications, Electrical Electronics Insulation Conference and Electrical Manufacturing & Coil Winding Conference West Lafayette, pp. 647-650, (1995); Schiek M., Online cardiac arrhythmia classification by means of circle maps analysis implemented on an intelligent miniaturized sensor, 30th Annual International IEEE EMBS Conference Canada, (2008); Kudo H., Sawada T., Kazawa E., Yoshida H., Iwasaki Y., Mitsubayashi K., A flexible and wearable glucose sensor based on functional polymers with Soft-MEMS techniques, Biosensors and Bioelectronics, 22, pp. 558-562, (2006); Gibbs P., Asada H.H., Reducing motion artifact in wearable bio-sensors using mems accelerometers for active noise cancellation, American Control Conference, (2005); Nagl L., Wearable sensor system for wireless state-of-health determination in cattle, 25th Annual International Conference of the IEEE EMBS Mexico, (2003); Bonato P., Wearable Sensors/Systems and Their Impact on Biomedical Engineering, (2003); Abdullah M.F., Khuan L.Y., Madzhi N.K., Masrie M., Ahmad A., Development of A Potentiometric Circuit for A PZR Microcantilever Biosensor for Measurement of Human Stress 2010 IEEE EMBS Conference on Biomedical Engineering & Sciences, (2010); Madzhi N.K., Ahmad A., Modelling of Piezoresistive Microcantilever As APressure Sensor for Human Stress Measurement, (2007); Madzhi N.K., Ahmad A., Khuan L.Y., Rani R.A., Abdullah F., Design and fabrication of polysilicon-based piezoresistive microcantilever for biological sensing, International Conference on NanoScience and NanoTechnology, (2008)","M.F. Abdullah; Faculty of Electrical Engineering, Universiti Teknologi Mara, Malaysia; email: badli_84@yahoo.co.uk","","","IEEE Malaysia Section; IEEE Indonesia Section; IEEE Malaysia Power Electron.,/Ind.; Electron./Ind. Appl. Jt. Chapter","2012 IEEE Symposium on Industrial Electronics and Applications, ISIEA 2012","23 September 2012 through 26 September 2012","Bandung","96680","","978-146733004-6","","","English","ISIEA - IEEE Symp. Ind. Electron. Appl.","Conference paper","Final","","Scopus","2-s2.0-84876754339"
"Mohd Noor M.H.; Hussain Z.; Ahmad K.A.; Ainihayati A.R.","Mohd Noor, M.H. (36656106400); Hussain, Z. (24724464800); Ahmad, K.A. (7202244730); Ainihayati, A.R. (38360991000)","36656106400; 24724464800; 7202244730; 38360991000","Gel electrophoresis image segmentation with Otsu method based on particle swarm optimization","2011","Proceedings - 2011 IEEE 7th International Colloquium on Signal Processing and Its Applications, CSPA 2011","","","5759915","426","429","3","4","10.1109/CSPA.2011.5759915","https://www.scopus.com/inward/record.uri?eid=2-s2.0-79957450407&doi=10.1109%2fCSPA.2011.5759915&partnerID=40&md5=fb4b803e234d7d45b5c8a591c1d2627f","Faculty of Electrical Engineering, Universiti Teknologi MARA, Pulau Pinang, Malaysia; School of Biological Sciences, Universiti Sains Malaysia, Malaysia","Mohd Noor M.H., Faculty of Electrical Engineering, Universiti Teknologi MARA, Pulau Pinang, Malaysia; Hussain Z., Faculty of Electrical Engineering, Universiti Teknologi MARA, Pulau Pinang, Malaysia; Ahmad K.A., Faculty of Electrical Engineering, Universiti Teknologi MARA, Pulau Pinang, Malaysia; Ainihayati A.R., School of Biological Sciences, Universiti Sains Malaysia, Malaysia","Gel electrophoresis (GE) is an important tool in genomic analysis. It is a process of DNA, RNA and protein molecules separation using electric field applied to a gel matrix. This paper describes the image processing techniques applied on GE image to segment the bands from their background. Numerous pre-processing steps are applied on the image prior to the segmentation technique for the purpose of removing noise in the image. Then multilevel thresholding using Otsu method based on Particle Swarm Optimization is applied. The experimental results show that the PSO-Otsu successfully segmented all the bands. © 2011 IEEE.","Gel electrophoresis (GE); multilevel thresholding; Otsu method; Particle Swarm Optimization (PSO)","Electric fields; Electrophoresis; Gels; Image segmentation; RNA; Signal processing; Gel electrophoresis; Gel electrophoresis images; Gel matrix; Genomic analysis; Image processing technique; Multilevel thresholding; Otsu method; Pre-processing step; Protein molecules; Segmentation techniques; Particle swarm optimization (PSO)","","","","","","","Maramis C., Delopoulos A., Efficient Quantitative Information Extraction from PCR-RFLP Gel Electrophoresis Images, Pattern Recognition (ICPR), 2010 20th International Conference on, pp. 2560-2563, (2010); Akbari A., Albregtsen F., Automatic segmentation of DNA bands in one dimensional gel images produced by hybridizing techniques, Engineering in Medicine and Biology Society, 2004. IEMBS '04. 26th Annual International Conference of the IEEE, 2, pp. 2852-2855, (2004); Labyed Y., Kaabouch N., Schultz R.R., Singh B.B., Automatic segmentation and band detection of protein images based on the standard deviation profile and its derivative, Electro/Information Technology, 2007 IEEE International Conference on, pp. 577-582, (2007); Lin C.-Y., Ching Y.-T., Yang Y.-L., Automatic Method to Compare the Lanes in Gel Electrophoresis Images, Information Technology in Biomedicine, IEEE Transactions on, 11, 2, pp. 179-189, (2007); Kaabouch N., Schultz R.R., A 2-D gel electrophoresis DNA image analysis algorithm with automatic thresholding, Visual Communications and Image Processing 2007, 6508, pp. 1-12, (2007); Caridade C.M.R., Marcal A.R.S., Mendonca T., Pessoa A.M., Pereira S., Image Analysis and Recognition - 7th International Conference, ICIAR 2010, Proceedings, Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), 6112, PART 2, pp. 185-194, (2010); Otsu N., A Threshold Selection Method from Gray-Level Histograms, Systems, Man and Cybernetics, IEEE Transactions on, 9, 1, pp. 62-66, (1979); Van Den Bergh, An Analysis of Particle Swarm Optimizers, (2001); Kaabouch N., Schultz R.R., A 2-D gel electrophoresis DNA image analysis algorithm with automatic thresholding, Proceedings of SPIE, San Jose, CA, USA: 2007","M. H. Mohd Noor; Faculty of Electrical Engineering, Universiti Teknologi MARA, Pulau Pinang, Malaysia; email: halim5381@ppinang.uitm.edu.my","","","","2011 IEEE 7th International Colloquium on Signal Processing and Its Applications, CSPA 2011","4 March 2011 through 6 March 2011","Penang","84971","","978-161284414-5","","","English","Proc. - IEEE Int. Colloq. Signal Process. Its Appl., CSPA","Conference paper","Final","","Scopus","2-s2.0-79957450407"
"Ige A.O.; Tomar N.K.; Aranuwa F.O.; Oriola O.; Akingbesote A.O.; Noor M.H.M.; Mazzara M.; Aribisala B.S.","Ige, Ayokunle Olalekan (57828337400); Tomar, Nikhil Kumar (57222073120); Aranuwa, Felix Ola (57192949971); Oriola, Oluwafemi (57194425742); Akingbesote, Alaba O. (56073901600); Noor, Mohd Halim Mohd (36656106400); Mazzara, Manuel (8557895400); Aribisala, Benjamin Segun (26660607700)","57828337400; 57222073120; 57192949971; 57194425742; 56073901600; 36656106400; 8557895400; 26660607700","ConvSegNet: Automated Polyp Segmentation From Colonoscopy Using Context Feature Refinement With Multiple Convolutional Kernel Sizes","2023","IEEE Access","11","","","16142","16155","13","0","10.1109/ACCESS.2023.3244789","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149174323&doi=10.1109%2fACCESS.2023.3244789&partnerID=40&md5=389e7005db704e8160949f5d6636f1cb","Universiti Sains Malaysia, School of Computer Sciences, Pulau Pinang, 11800, Malaysia; Indira Gandhi National Open University, School of Computer and Information Sciences (SOCIS), New Delhi, 110068, India; Adekunle Ajasin University, Department of Computer Science, Akungba-Akoko, Ondo, Nigeria; Institute of Software Development and Engineering, Innopolis University, Innopolis, 420500, Russian Federation; Lagos State University, Department of Computer Science, Lagos, 102101, Nigeria; The University of Chicago, Department of Medicine, Chicago, 60637, IL, United States","Ige A.O., Universiti Sains Malaysia, School of Computer Sciences, Pulau Pinang, 11800, Malaysia, Adekunle Ajasin University, Department of Computer Science, Akungba-Akoko, Ondo, Nigeria; Tomar N.K., Indira Gandhi National Open University, School of Computer and Information Sciences (SOCIS), New Delhi, 110068, India; Aranuwa F.O., Adekunle Ajasin University, Department of Computer Science, Akungba-Akoko, Ondo, Nigeria; Oriola O., Adekunle Ajasin University, Department of Computer Science, Akungba-Akoko, Ondo, Nigeria; Akingbesote A.O., Adekunle Ajasin University, Department of Computer Science, Akungba-Akoko, Ondo, Nigeria; Noor M.H.M., Universiti Sains Malaysia, School of Computer Sciences, Pulau Pinang, 11800, Malaysia; Mazzara M., Institute of Software Development and Engineering, Innopolis University, Innopolis, 420500, Russian Federation; Aribisala B.S., Lagos State University, Department of Computer Science, Lagos, 102101, Nigeria, The University of Chicago, Department of Medicine, Chicago, 60637, IL, United States","Colorectal cancer occurs in the rectal of humans, and early detection has been proved to reduce its mortality rate. Colonoscopy is the standard used in detecting the presence of polyps in the rectal, and accurate segmentation of the polyps from colonoscopy images often provides helpful information for early diagnosis and treatment. Although existing deep learning models often achieve high segmentation performance when tested on the same dataset used in model training; still, their performance often degrades when applied to out-of-distribution datasets, leading to low model generalization or overfitting. This challenge is often associated with the quality of the features learnt from the input images. In this work, a novel Context Feature Refinement (CFR) module is proposed to address the challenge of low model generalization and segmentation performance. The CFR module is built to extract contextual information from the incoming feature map by using multiple parallel convolutional layers with progressively increasing kernel sizes. Using multiple parallel convolutions with different kernel sizes helped to extract more efficient multi-scale contextual information and thus enabled the network to effectively identify and segment small and fine details, as well as larger and more complex structures in the input images. Extensive experiments on three public benchmark datasets in CVC-ClinicDB, Kvasir-SEG, and BKAI-NeoPolyp showed that the proposed ConvSegNet model achieved jaccard, dice and F2 scores of 0.8650, 0.9177, and 0.9328 on CVC-ClinicDB, 0.7936, 0.8618, and 0.8855 on Kvasir-SEG, and 0.8045, 0.8747 and 0.8909 on BKAI-NeoPolyp datasets respectively. Also, an improved generalization performance was achieved by the ConvSegNet model, compared to the benchmark polyp segmentation models. Code is available at https://github.com/AOige/ConvSegNet.  © 2013 IEEE.","Biomedical; colonoscopy; image; kernel; polyp; segmentation","Benchmarking; Deep learning; Diseases; Endoscopy; Image segmentation; Biomedical; Colonoscopy; Context features; Feature refinement; Image; Kernel; Kernel size; Polyp; Polyp segmentation; Segmentation; Convolution","","","","","","","Cirean D.C., Giusti A., Gambardella L.M., Schmidhuber J., Deep neural networks segment neuronal membranes in electron microscopy images, Proc. Adv. Neural Inf. Process. Syst., 4, pp. 2843-2851, (2012); Brandao P., Mazomenos E., Ciuti G., Calio R., Bianchi F., Menciassi A., Dario P., Koulaouzidis A., Arezzo A., Stoyanov D., Fully convolutional neural networks for polyp segmentation in colonoscopy, Proc. SPIE, 10134, (2017); Havaei M., Davy A., Warde-Farley D., Biard A., Courville A., Bengio Y., Pal C., Jodoin P.-M., Larochelle H., Brain tumor segmentation with deep neural networks, Med. Image Anal., 35, pp. 18-31, (2017); Thomas S.M., Lefevre J.G., Baxter G., Hamilton N.A., Interpretable deep learning systems for multi-class segmentation and classification of non-melanoma skin cancer, Med. Image Anal., 68, (2021); Zhou L., Li Z., Zhou J., Li H., Chen Y., Huang Y., Xie D., Zhao L., Fan M., Hashmi S., Abdelkareem F., A rapid, accurate and machine-agnostic segmentation and quantification method for CT-based COVID-19 diagnosis, IEEE Trans. Med. Imag., 39, 8, pp. 2638-2652, (2020); Bouget D., Jorgensen A., Kiss G., Leira H.O., Lango T., Semantic segmentation and detection of mediastinal lymph nodes and anatomical structures in CT data for lung cancer staging, Int. J. Comput. Assist. Radiol. Surg., 14, 6, pp. 977-986, (2019); Akbari M., Mohrekesh M., Nasr-Esfahani E., Soroushmehr S.M.R., Karimi N., Samavi S., Najarian K., Polyp segmentation in colonoscopy images using fully convolutional network, Proc. 40th Annu. Int. Conf. IEEE Eng. Med. Biol. Soc. (EMBC), pp. 69-72, (2018); Nguyen N.-Q., Vo D.M., Lee S.-W., Contour-aware polyp segmentation in colonoscopy images using detailed upsampling encoder-decoder networks, IEEE Access, 8, pp. 99495-99508, (2020); Torre L.A., Bray F., Siegel R.L., Ferlay J., Lortet-Tieulent J., Jemal A., Global cancer statistics, 2012, CA, Cancer J. Clin., 65, 2, pp. 87-108, (2015); Rundle A.G., Lebwohl B., Vogel R., Levine S., Neugut A.I., Colonoscopic screening in average-risk individuals ages 40 to 49 vs 50 to 59 years, Gastroenterology, 134, 5, pp. 1311-1315, (2008); Van Rijn J.C., Reitsma J.B., Stoker J., Bossuyt P.M., Van Deventer S.J., Dekker E., Polyp miss rate determined by tandem colonoscopy: Asystematic review, Amer. J. Gastroenterol., 101, 2, pp. 343-350, (2006); Yeung M., Sala E., Schonlieb C.-B., Rundo L., Focus U-Net: A novel dual attention-gated CNN for polyp segmentation during colonoscopy, Comput. Biol. Med., 137, (2021); Thakkar S., Carleton N.M., Rao B., Syed A., Use of artificial intelligence-based analytics from live colonoscopies to optimize the quality of the colonoscopy examination in real time: Proof of concept, Gastroenterology, 158, 5, pp. 1219-1221, (2020); Kassani S.H., Kassani P.H., Wesolowski M.J., Schneider K.A., Deters R., Automatic polyp segmentation using convolutional neural networks, Advances in Artificial Intelligence (Lecture Notes in Computer Science), 12109, (2020); Zhong J., Wang W., Wu H., Wen Z., Qin J., PolypSeg: An efficient context-aware network for polyp segmentation from colonoscopy videos, Proc. Int. Conf. Med. Image Comput. Comput.-Assist. Intervent., in Lecture Notes in Computer Science: Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics, 12266, pp. 285-294, (2020); Bernal J., Nunez J.M., Sanchez F.J., Vilarino F., Polyp segmentation method in colonoscopy videos by means of MSA-DOVA energy maps calculation, Proc.Workshop Clin. Image-Based Procedures, in Lecture Notes in Computer Science: Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics, 8680, pp. 41-49, (2014); Puyal J.G.B., Bhatia K.K., Brandao P., Ahmad O.F., Toth D., Kader R., Lovat L., Mountney P., Stoyanov D., Endoscopic polyp segmentation using a hybrid 2D/3D CNN, Proc. Int. Conf. Med. Image Comput. Comput.-Assist. Intervent., in Lecture Notes in Computer Science: Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics, 12266, pp. 295-305, (2020); Zhang L., Dolwani S., Ye X., Automated polyp segmentation in colonoscopy frames using fully convolutional neural network and textons, Proc. Annu. Conf. Med. Image Understand. Anal., in Communications in Computer and Information Science, 723, pp. 707-717, (2017); Feng S., Zhao H., Shi F., Cheng X., Wang M., Ma Y., Xiang D., Zhu W., Chen X., CPFNet: Context pyramid fusion network for medical image segmentation, IEEE Trans. Med. Imag., 39, 10, pp. 3008-3018, (2020); Hwang S., Oh J., Tavanapong W., Wong J., De Groen P.C., Polyp detection in colonoscopy video using elliptical shape feature, Proc. IEEE Int. Conf. Image Process., 2, pp. 465-468, (2007); Ameling S., Wirth S., Paulus D., Lacey G., Vilarino F., Texturebased polyp detection in colonoscopy, Bildverarbeitung für die Medizin (Informatik aktuell), (2009); Tajbakhsh N., Gurudu S.R., Liang J., Automated polyp detection in colonoscopy videos using shape and context information, IEEE Trans. Med. Imag., 35, 2, pp. 630-644, (2015); You D., Antani S., Demner-Fushman D., Thoma G.R., An MRF model for biomedical image segmentation, Proc. IEEE 27th Int. Symp. Comput.-Based Med. Syst., pp. 539-540, (2014); Van Opbroek A., Ikram M.A., Vernooij M.W., De Bruijne M., Transfer learning improves supervised image segmentation across imaging protocols, IEEE Trans. Med. Imag., 34, 5, pp. 1018-1030, (2015); Norouzi A., Rahim M.S.M., Altameem A., Saba T., Rad A.E., Rehman A., Uddin M., Medical image segmentation methods, algorithms, and applications, IETE Tech. Rev., 31, 3, pp. 199-213, (2014); Zhou X., Thompson G.B., Influence of solute partitioning on the microstructure and growth stresses in nanocrystalline Fe(Cr) thin films, Thin Solid Films, 648, pp. 83-93, (2018); Zhou X., Yamada K., Kojima T., Takayama R., Wang S., Zhou X., Hara T., Fujita H., Performance evaluation of 2D and 3D deep learning approaches for automatic segmentation of multiple organs on CT images, Proc. SPIE, 10575, (2018); Ronneberger O., Fischer P., Brox T., U-Net: Convolutional networks for biomedical image segmentation, Proc. 18th Int. Conf. Med. Image Comput. Comput.-Assist. Intervent., 9351, pp. 234-241, (2015); Zhou Z., Siddiquee M.M.R., Tajbakhsh N., Liang J., UNet++: A nested U-Net architecture for medical image segmentation, Proc. Int. Workshop Multimodal Learn. Clin. Decis. Support, in Lecture Notes in Computer Science: Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics, 11045, pp. 3-11, (2018); Zhang Z., Liu Q., Wang Y., Road extraction by deep residual U-Net, IEEE Geosci. Remote Sens. Lett., 15, 5, pp. 749-753, (2018); Condessa F., Bioucas-Dias J., Segmentation and detection of colorectal polyps using local polynomial approximation, Proc. ICIAR, in Lecture Notes in Computer Science: Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics, 7325, pp. 188-197, (2012); Zunair H., Hamza A.B., Sharp U-Net: Depthwise convolutional network for biomedical image segmentation, Comput. Biol. Med., 136, (2021); Srivastava A., Jha D., Chanda S., Pal U., Johansen H.D., Johansen D., Riegler M.A., Ali S., Halvorsen P., MSRF-Net: A multi-scale residual fusion network for biomedical image segmentation, IEEE J. Biomed. Health Informat., 26, 5, pp. 2252-2263, (2021); Weng W., Zhu X., INet: Convolutional networks for biomedical image segmentation, IEEE Access, 9, pp. 16591-16603, (2021); Jha D., Smedsrud P.H., Riegler M.A., Johansen D., Lange T.D., Halvorsen P., Johansen H.D., ResUNet++: An advanced architecture for medical image segmentation, Proc. IEEE Int. Symp. Multimedia (ISM), pp. 225-230, (2019); Schlemper J., Oktay O., Schaap M., Heinrich M., Kainz B., Glocker B., Ruecker D., Attention gated networks: Learning to leverage salient regions in medical images, Med. Image Anal., 53, pp. 197-207, (2019); Kim T., Lee H., Kim D., UACANet: Uncertainty augmented context attention for polyp segmentation, Proc. 29th ACM Int. Conf. Multimedia, pp. 2167-2175, (2021); Mahmud T., Paul B., Fattah S.A., PolypSegNet: A modified encoder-decoder architecture for automated polyp segmentation from colonoscopy images, Comput. Biol. Med., 128, (2021); Zhao X., Zhang L., Lu H., Automatic polyp segmentation via multiscale subtraction network, Proc. Int. Conf. Med. Image Comput. Comput.-Assist. Intervent., in Lecture Notes in Computer Science: Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics, 12901, pp. 120-130, (2021); Gu Z., Cheng J., Fu H., Zhou K., Hao H., Zhao Y., Zhang T., Gao S., Liu J., CE-Net: Context encoder network for 2D medical image segmentation, IEEE Trans. Med. Imag., 38, 10, pp. 2281-2292, (2019); Qadir H.A., Shin Y., Solhusvik J., Bergsland J., Aabakken L., Balasingham I., Polyp detection and segmentation using mask R-CNN: Does a deeper feature extractorCNNalways perform better?, Proc. 13th Int. Symp. Med. Inf. Commun. Technol. (ISMICT), pp. 1-6, (2019); Tomar N.K., Jha D., Riegler M.A., Johansen H.D., Johansen D., Rittscher J., Halvorsen P., Ali S., FANet: A feedback attention network for improved biomedical image segmentation, IEEE Trans. Neural Netw. Learn. Syst.; Valanarasu J.M.J., Patel V.M., UNeXt: MLP-based rapid medical image segmentation network, Medical Image Computing and Computer Assisted Intervention-MICCAI (Lecture Notes in Computer Science), 13435, (2020); Sharma P., Gautam A., Maji P., Pachori R.B., Balabantaray B.K., Li-SegPNet: Encoder-decoder mode lightweight segmentation network for colorectal polyps analysis, IEEE Trans. Biomed. Eng.; Jha D., Smedsrud P.H., Riegler M.A., Halvorsen P., De Lange T., Johansen D., Johansen H.D., Kvasir-SEG: A segmented polyp dataset, Proc. Int. Conf. Multimedia Modeling, in Lecture Notes in Computer Science: Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics, 11962, pp. 451-462, (2020); Bernal J., Sanchez F.J., Fernandez-Esparrach G., Gil D., Rodriguez C., Vilarino F., WM-DOVA maps for accurate polyp highlighting in colonoscopy: Validation vs. saliency maps from physicians, Computerized Med. Imag. Graph., 43, pp. 99-111, (2015); Lan P.N., An N.S., Hang D.V., Long D.V., Trung T.Q., Thuy N.T., Sang D.V., NeoUNet: Towards accurate colon polyp segmentation and neoplasm detection, Proc. 16th Int. Symp. Adv. Vis. Comput. (ISVC), in Lecture Notes in Computer Science: Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics, 13018, pp. 15-28, (2021); Vazquez D., Bernal J., Sanchez F.J., Fernandez-Esparrach G., Lopez A.M., Romero A., Drozdzal M., Courville A., A benchmark for endoluminal scene segmentation of colonoscopy images, J. Healthcare Eng., 2017, pp. 1-9, (2017); Pogorelov K., Randel K.R., Griwodz C., Eskeland S.L., De Lange T., Johansen D., Spampinato C., Dang-Nguyen D.-T., Lux M., Schmidt P.T., Riegler M., Halvorsen P., KVASIR: A multi-class image dataset for computer aided gastrointestinal disease detection, Proc. 8th ACM Multimedia Syst. Conf., pp. 164-169, (2017); Huang C.-H., Wu H.-Y., Lin Y.-L., HarDNet-MSEG: A simple encoder-decoder polyp segmentation neural network that achieves over 0.9 mean dice and 86 FPS, (2021)","A.O. Ige; Universiti Sains Malaysia, School of Computer Sciences, Pulau Pinang, 11800, Malaysia; email: ayo.ige@aaua.edu.ng","","Institute of Electrical and Electronics Engineers Inc.","","","","","","21693536","","","","English","IEEE Access","Article","Final","All Open Access; Gold Open Access","Scopus","2-s2.0-85149174323"
"Abdu H.; Noor M.H.M.","Abdu, Haruna (57201667366); Noor, Mohd Halim Mohd (36656106400)","57201667366; 36656106400","Domestic Trash Classification with Transfer Learning Using VGG16","2022","ICCSCE 2022 - Proceedings: 2022 12th IEEE International Conference on Control System, Computing and Engineering","","","","137","141","4","5","10.1109/ICCSCE54767.2022.9935653","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142425267&doi=10.1109%2fICCSCE54767.2022.9935653&partnerID=40&md5=669732a00c21b7ec72d8678f9e310b40","School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, Malaysia","Abdu H., School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, Malaysia; Noor M.H.M., School of Computer Sciences, Universiti Sains Malaysia, Pulau Pinang, Malaysia","Environmental contamination is a major issue affecting all inhabitants living in any environment. The domestic environment is engulfed with many trash items such as solid and toxic trashes, leading to severe environmental contamination and causing life-threatening diseases if not appropriately managed. Trash classification is at the heart of these issues because the inability to classify the trash leads to difficulty in recycling. Humans categorize trash based on what they understand about the trash object rather than on the recyclability status of an object, which frequently leads to incorrect classification in manual classification. Additionally, coming into contact with toxic waste directly could be physically dangerous for those involved. Few machine learning and Deep Learning (DL) techniques were proposed using benchmarked trash classification datasets. However, most benchmarked datasets used to train DL models have a transparent or white background, which leads to a lack of model generalization, particularly in the real world. In this paper, we propose a Deep Learning model based on the VGG16 Architecture that can accurately classify various types of trash objects. On the TrashNet dataset plus the images collected in the wild, we achieved an accuracy of more than 96%.  © 2022 IEEE.","classification; Deep Learning; Domestic Trash; Transfer Learning; Trash","Deep learning; Learning systems; Toxic materials; Deep learning; Domestic environments; Domestic trash; Environmental contamination; Learning models; Machine-learning; Manual classification; Recyclability; Transfer learning; Trash; Classification (of information)","","","","","Ministry of Higher Education, Malaysia, MOHE; Universiti Sains Malaysia, USM, (LRGS MRUN/F2/01/2019)","ACKNOWLEDGMENT This research was funded by Ministry of Higher Education and USM under LRGS MRUN grant with project code: LRGS MRUN/F2/01/2019.","Sami K.N., Amin Z.M.A., Hassan R., Waste Management Using Machine Learning and Deep Learning Algorithms, Int. J. Perceptive Cogn. Comput., 6, 2, pp. 97-106, (2020); Shahab S., Anjum M., Umar M.S., Deep Learning Applications in Solid Waste Management: A Deep Literature Review, Int. J. Adv. Comput. Sci. Appl., 13, 3, (2022); Triassi M., Alfano R., Illario M., Nardone A., Caporale O., Montuori P., Environmental Pollution from Illegal Waste Disposal and Health Effects: A Review on the 'Triangle of Death,, Int. J. Environ. Res. Public. Health, 12, 2, pp. 1216-1236, (2015); Namen A.A., Da Costa Brasil F., Abrunhosa J.J.G., Abrunhosa G.G.S., Tarre R.M., Marques F.J.G., RFID technology for hazardous waste management and tracking, Waste Manag. Res. J. Sustain. Circ. Econ., 32, 9, pp. 59-66, (2014); Bhandari S., Automatic Waste Sorting In Industrial Environments Via Machine Learning Approaches, (2020); Mythili T., Anbarasi A., A concatenation of deep and texture features for medicinal trash image classification using EnSegNet-DNN-based transfer learning, Mater. Today Proc., 62, pp. 4691-4698, (2022); Kumsetty N.V., Bhat A., Nekkare S.K.S., Kumar M.A., TrashBox: Trash Detection and Classification using Quantum Transfer Learning, 2022 31st Conference of Open Innovations Association (FRUCT), pp. 125-130, (2022); Geetha S., Saha J., Dasgupta I., Bera R., Lawal I.A., Kadry S., Design of Waste Management System Using Ensemble Neural Networks, Designs, 6, 2, (2022); Liu H., Guo Z., Bao J., Xie L., Research on Trash Classification based on Artificial Intelligence and Sensor, 2021 2nd International Conference on Intelligent Computing and Human-Computer Interaction (ICHCI), pp. 274-279, (2021); Yu Y., A Computer Vision Based Detection System for Trash Bins Identification during Trash Classification, J. Phys. Conf. Ser., 1617, 1, (2020); Domestic Trash Dataset, (2022); Thung G., Yang M., Classification of Trash for Recyclability Status, (2016); Bircanoglu C., Atay M., Beser F., Genc O., Kizrak M.A., RecycleNet: Intelligent Waste Sorting Using Deep Neural Networks, 2018 Innovations in Intelligent Systems and Applications (INISTA), pp. 1-7, (2018); Chu Y., Huang C., Xie X., Tan B., Kamal S., Xiong X., Multilayer Hybrid Deep-Learning Method for Waste Classification and Recycling, Comput. Intell. Neurosci., 2018, pp. 1-9, (2018); Zhou S.K., Et al., A Review of Deep Learning in Medical Imaging: Imaging Traits, Technology Trends, Case Studies With Progress Highlights, and Future Promises, Proc. IEEE, 109, 5, pp. 820-838, (2021); Song F., Zhang Y., Zhang J., Optimization of CNN-based Garbage Classification Model, Proceedings of the 4th International Conference on Computer Science and Application Engineering, pp. 1-5, (2020); Meng S., Chu W.-T., A Study of Garbage Classification with Convolutional Neural Networks, 2020 Indo - Taiwan 2nd International Conference on Computing, Analytics and Networks (Indo-Taiwan ICAN), pp. 152-157, (2020); Bobulski J., Kubanek M., Deep Learning for Plastic Waste Classification System, Appl. Comput. Intell. Soft Comput., 2021, pp. 1-7, (2021); Azis F.A., Suhaimi H., Abas E., Waste Classification using Convolutional Neural Network, Proceedings of the 2020 2nd International Conference on Information Technology and Computer Communications, pp. 9-13, (2020); Vo A.H., Hoang Son L., Vo M.T., Le T., A Novel Framework for Trash Classification Using Deep Transfer Learning, IEEE Access, 7, pp. 178631-178639, (2019); Ma W., Wang X., Yu J., A Lightweight Feature Fusion Single Shot Multibox Detector for Garbage Detection, IEEE Access, 8, pp. 188577-188586, (2020); Tiyajamorn P., Lorprasertkul P., Assabumrungrat R., Poomarin W., Chancharoen R., Automatic Trash Classification using Convolutional Neural Network Machine Learning, 2019 IEEE International Conference on Cybernetics and Intelligent Systems (CIS) and IEEE Conference on Robotics, Automation and Mechatronics (RAM), pp. 71-76, (2019); Hong J., Fulton M., Sattar J., A Generative Approach Towards Improved Robotic Detection of Marine Litter, 2020 IEEE International Conference on Robotics and Automation (ICRA), pp. 10525-10531, (2020); Dong X., Research and Design of Marine Trash Classification Robot Based on Color Recognition, IOP Conf. Ser. Earth Environ. Sci., 514, 3, (2020); Sun A., Xiao H., ThanosNet: A Novel Trash Classification Method Using Metadata, 2020 IEEE International Conference on Big Data (Big Data), pp. 1394-1401, (2020); Alzyoud F., Maqableh W., Al Shrouf F., A Semi Smart Adaptive Approach for Trash Classification, Int. J. Comput. Commun. CONTROL, 16, 4, (2021); Tatke A., Patil M., Khot A., Jadhav P., Karad D.V., HYBRID APPROACH OF GARBAGE CLASSIFICATION USING COMPUTER VISION AND DEEP LEARNING, Int. J. Eng. Appl. Sci. Technol., 5, 10, (2021); Simonyan K., Zisserman A., Very Deep Convolutional Networks for Large-Scale Image Recognition, (2015); Garythung/trashnet: Dataset of images of trash; Torch-based CNN for garbage image classification, (2022)","","","Institute of Electrical and Electronics Engineers Inc.","","12th IEEE International Conference on Control System, Computing and Engineering, ICCSCE 2022","21 October 2022 through 22 October 2022","Penang","184194","","978-166548339-1","","","English","ICCSCE - Proc.: IEEE Int. Conf. Control Syst., Comput. Eng.","Conference paper","Final","","Scopus","2-s2.0-85142425267"
"Abdu H.; Noor M.H.M.; Abdullah R.","Abdu, Haruna (57201667366); Noor, Mohd Halim Mohd (36656106400); Abdullah, Rosni (7004462407)","57201667366; 36656106400; 7004462407","An Efficient Multi-sensor Positions Human Activity Recognition: Elderly Peoples in Rural Areas in Focus","2021","Lecture Notes in Networks and Systems","254","","","205","219","14","1","10.1007/978-3-030-80216-5_15","https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112719292&doi=10.1007%2f978-3-030-80216-5_15&partnerID=40&md5=45cbdd82509783bd32a2112f8764a4a5","National Advanced IPv6 Center of Excellence, Universiti Sains Malaysia, George Town, Malaysia; School of Computer Sciences, Universiti Sains Malaysia, George Town, Malaysia; Department of Computer Science, Federal University Lokoja, Lokoja, Kogi State, Nigeria","Abdu H., National Advanced IPv6 Center of Excellence, Universiti Sains Malaysia, George Town, Malaysia, Department of Computer Science, Federal University Lokoja, Lokoja, Kogi State, Nigeria; Noor M.H.M., School of Computer Sciences, Universiti Sains Malaysia, George Town, Malaysia; Abdullah R., School of Computer Sciences, Universiti Sains Malaysia, George Town, Malaysia","The increase in the availability of wearable devices offers a prospective solution to the increasing demand for elderly human activity monitoring, in the essence of improving the independent living standard of the growing population of elderly humans. With all the availability of the wearable devices fully embedded with sensors that are being used for human health monitoring, a lot of techniques are been proposed and used in the process. However, most of the publicly available datasets in use today, are collected in a fully controlled or semi-natural settings. Also, elderly peoples from rural areas and transitional activities are mostly not considered, which will cause a lack of generalization of the dreamed HAR models. The purpose of this research is to collect a new dataset from elderly peoples in a rural area and find the best sensor position among ankle and waist by subjecting the newly collected datasets to different machine learning classifiers. Sliding window technique with 50% overlapping was used to segment the sensor data collected from the elderly subjects. Relevant features were extracted, and selected using the wrapper method. From the results obtained, it has shown that the sensor attached at the waist position yield a better result compared to the ankle position on the newly collected elderly data. KNN algorithm has the highest accuracy level in both cases compared to the remaining tested classifiers. © 2021, The Author(s), under exclusive license to Springer Nature Switzerland AG.","Elderly; Human-activity-recognition; Sensor and position; Waist","","","","","","Universiti Sains Malaysia, (304/PKOMP/6315206)","Acknowledgment. This work has been was supported in part by the Universiti Sains Malaysia under Short Term Grant 304/PKOMP/6315206.","Woznowski P.R., King R., Harwin W., Craddock I., A human activity Recognition framework for healthcare applications: Ontology, labelling strategies, and best practice, Iotbd 2016 – Proceedings of International Conference Internet Things Big Data, No. Iotbd, pp. 369-377, (2016); Wang Z., Meng F., Yuan G., Yan Q., Xia S., An overview of human activity recognition based on smartphone, Sensor Rev, (2018); Noor M.H.M., Salcic Z., Wang K.I.K., Adaptive sliding window segmentation for physical activity recognition using a single tri-axial accelerometer, Pervasive Mob. Comput., 38, pp. 41-59, (2017); Wang X., Kim H., Detecting user activities with the accelerometer on android smartphones, J. Multimed. Inf. Syst., 2, 2, pp. 233-240, (2015); Kwapisz J.R., Weiss G.M., Moore S.A., Activity recognition using cell phone accelerometers, ACM SIGKDD Explor. Newsl., 12, 2, (2011); Incel O.D., Analysis of movement, orientation and rotation-based sensing for phone placement recognition, Sensors, 15, 10, pp. 25474-25506, (2015); Lo B., Atallah L., Aziz O., El Elhew M., Darzi A., Yang G.Z., Real-time pervasive monitoring for postoperative care, IFMBE Proc, 13, pp. 122-127, (2007); Atallah L., Lo B., King R., Yang G.Z., Sensor positioning for activity recognition using wearable accelerometers, IEEE Trans. Biomed. Circuits Syst., 5, 4, pp. 320-329, (2011); Lee S.H., Park H.D., Hong S.Y., Lee K.J., Kim Y.H., A study on the activity classification using a triaxial accelerometer, Annual International Conference of the IEEE Engineering in Medicine and Biology Society-Proceedings, August, Vol. 3, Pp. 2941–2943, (2003); Bouten C.V.C., Koekkoek K.T.M., Verduin M., Kodde R., Janssen J.D., A triaxial accelerometer and portable data processing unit for the assessment of daily physical activity, IEEE Trans. Biomed. Eng., 44, 3, pp. 136-147, (1997); Bonomi A.G., Goris A.H.C., Yin B., Westerterp K.R., Detection of type, duration, and intensity of physical activity using an accelerometer, Med. Sci. Sports Exerc., 41, 9, pp. 1770-1777, (2009); Li J.H., Tian L., Wang H., An Y., Wang K., Yu L., Segmentation and recognition of basic and transitional activities for continuous physical human activity, IEEE Access, 7, (2019); Lara O.D., Labrador M.A., A survey on human activity recognition using wearable sensors, IEEE Commun. Surv. Tutorials, 15, 3, pp. 1192-1209, (2013); Wang Y., Et al., Smartphone-based human activity recognition, Device-To-Device Based Proximity Service, pp. 199-239, (2017); Ronao C.A., Cho S.B., Human activity recognition with smartphone sensors using deep learning neural networks, Expert Syst. Appl., 59, pp. 235-244, (2016); Subetha T., Chitrakala S., A survey on human activity recognition from videos, 2016 International Conference on Information Communication Embeded System, 2016, (2016); Gani M.O., A Novel Approach to Complex Human Activity Recognition, (2017); Nweke H.F., Teh Y.W., Al-Garadi M.A., Alo U.R., Deep learning algorithms for human activity recognition using mobile and wearable sensor networks: State of the art and research challenges, Expert Syst. Appl., 105, pp. 233-261, (2018); Weiss G.M., WISDM Smartphone and Smartwatch Activity and Biometrics Dataset; Anguita D., Ghio A., Oneto L., Parra X., Reyes-Ortiz J.L., A public domain dataset for human activity recognition using smartphones, ESANN 2013 Proceedings, 21St European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning, April, pp. 437-442, (2013); Mannini A., Intille S.S., Rosenberger M., Sabatini A.M., Haskell W., Activity recognition using a single accelerometer placed at the wrist or ankle, Med. Sci. Sports Exerc., 45, 11, pp. 2193-2203, (2013); Ranasinghe D.C., Torres R.L.S., Wickramasinghe A., Automated activity recognition and monitoring of elderly using wireless sensors: Research challenges, Proceedings of the 2013 5Th IEEE International Working Advances Sensors Interfaces, IWASI 2013, Pp. 224–227, (2013); Cleland I., Et al., Optimal placement of accelerometers for the detection of everyday activities, Sensors (Basel), 13, 7, pp. 9183-9200, (2013); Voicu R.A., Dobre C., Bajenaru L., Ciobanu R.I., Human physical activity recognition using smartphone sensorsH, Sensors (Switzerland), 19, 3, pp. 1-18, (2019); Voicu R.A., Dobre C., Bajenaru L., Ciobanu R.I., Human physical activity recognition using smartphone sensors, Sensors (Switzerland), 19, 3, (2019); Chernbumroong S., Cang S., Atkins A., Yu H., Elderly activities recognition and classification for applications in assisted living, Expert Syst. Appl., 40, 5, pp. 1662-1674, (2013); Reyes-Ortiz J.L., Oneto L., Sama A., Parra X., Anguita D., Transition-aware human activity recognition using smartphones, Neurocomputing, 171, pp. 754-767, (2016)","H. Abdu; National Advanced IPv6 Center of Excellence, Universiti Sains Malaysia, George Town, Malaysia; email: haruna.abdu@fulokoja.edu.ng","Abawajy J.H.; Choo K.R.; Chiroma H.","Springer Science and Business Media Deutschland GmbH","","International Conference on Emerging Applications and Technologies for Industry 4.0, EATI 2020","21 July 2020 through 23 July 2020","Virtual, Online","262749","23673370","978-303080215-8","","","English","Lect. Notes Networks Syst.","Conference paper","Final","","Scopus","2-s2.0-85112719292"
